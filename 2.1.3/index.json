[
{
	"uri": "https://redhawksdr.github.io/2.1.3/",
	"title": "REDHAWK Documentation - 2.1.3",
	"tags": [],
	"description": "",
	"content": "  Getting Started With REDHAWK    REDHAWK’s Approach to Process Management and Interaction     Getting Started     IDE Quickstart     Further Reading      REDHAWK Manual - 2.1.3    Installation     Components    REDHAWK Core Assets     Creating a Component Project     Creating Octave Components     Running a Component     Sandbox     Creating and Running a Hello World Component      Component Structure    Auto-Generated Component Files     Auto-Generated Component Methods     Base Component Members     Component Implementations     Java Version     Managing and Defining Properties     Working with Events      Shared Libraries    Creating a REDHAWK Shared Library Project     Using a REDHAWK Shared Library Project     Packaging Shared Libraries     Manually Including External Libraries      Connections    The Connection Process     Why Ports?     Port Access     Dynamic Connections     Standardized Data Interfaces     BulkIO    Data Transfers     Signal Related Information (SRI)     Stream API     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples      BurstIO    Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics      Messaging    Message Producer     Message Consumer     Viewing Messages     Connecting Producers and Consumers      Connection Callbacks     Custom IDL Interfaces      Waveforms    Waveform Editor     Create and Deploy a Sample Waveform     Waveform Deployment and Computing Resources      Working with Devices    Using Devices to Interact with Hardware    Creating an FEI Device in the IDE     Interacting with an FEI Device with the Python Package     Using an FEI Device in the IDE      Associating a Waveform with an FEI Device     Using Devices to Run Components     Using Devices to Interface with FPGAs     Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators     Miscellaneous FrontEnd Tuner Library Implementation Details      Services     Nodes    Running a Node     Creating a New Node     Distributed Computing and RF Devices      Sandbox    Python Sandbox    Working with Components, Devices, and Services     Helpers     Devices     Example Sandbox Interaction     Built-in Sources and Sinks     Working with SDDS Data     Plotting Data     Miscellaneous      IDE Sandbox      The Runtime Environment    Launching a Domain     Domain Manager     File System     Applications     The Application Factory     The Device Manager     The Allocation Manager     The Connection Manager     Events      Runtime Environment Inspection     Logging    Configuring Logging Capabilities     LOGGING_CONFIG_URI Resolution     Logging Within A Resource     Adjusting Logging at Runtime     Viewing Logging Events      Using the REDHAWK IDE    Launching the REDHAWK IDE for the First Time     PyDev Overview     The Workbench     Editors and Views    SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View      Creating REDHAWK Projects     Adding/Changing/Removing REDHAWK Project Namespaces     Debugging REDHAWK Components and Devices with Eclipse     Deploying Projects to the SDRROOT     Snapshot Tool     Connect Wizard     Using the Octave Wizard     Plot Port Wizard      Sharing REDHAWK Projects With Others     Exploring SDRROOT Using the REDHAWK IDE     Exploring a Running Domain Using the REDHAWK IDE    Connecting to a Domain     Viewing the Contents of the Domain in the REDHAWK Explorer View     Working with Waveforms on a Running Domain     Plotting BulkIO Ports     Increasing the Bandwidth of BulkIO Connections     Displaying Port Statistics     Getting Details About Error Conditions      Appendices    REDHAWK Yum Repository and Packages     External Dependencies     Installing a Stand-alone IDE     Building and Installing REDHAWK from Source     Optimization     FrontEnd Interfaces     REDHAWK Persona Device Pattern     Troubleshooting     Logging Configuration Plugin     List of Acronyms      Glossary      "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/getting-started/",
	"title": "Getting Started With REDHAWK",
	"tags": [],
	"description": "",
	"content": " What is REDHAWK? REDHAWK is a software package that supports the design, development, deployment, management, and upgrading of real-time, network-enabled Software-Defined Radios (SDR). This chapter provides a high-level overview of REDHAWK and its capabilities.\nOverview The REDHAWK software package is comprised of four major pieces:\n A set of programs to manage distributed deployment of software applications. A set of tools that allow developers to easily create software that is deployable within the REDHAWK environment. A set of tools for introspecting a running REDHAWK system. A set of signal processing building blocks that developers can compose into larger, customized applications.  A signal processing application developed in REDHAWK can be deployed on anything from a single Linux computer to network-enabled system of Linux computers. Typically, the integration of hardware and software required for such a form of multi-asset computing is a non-trivial undertaking, requiring a significant expenditure of resources. REDHAWK takes care of the complicated “under the hood” hardware/software integration challenges so that developers can focus on application development: an in-depth understanding of hardware and software systems is not required for basic REDHAWK use.\nREDHAWK also standardizes data interfaces, hardware management, and configuration management, which benefits non-distributed application developers. This standardization, coupled with the provided toolkit, reduces integration cost for both legacy capabilities and future development.\nApplications of REDHAWK REDHAWK was designed for the development of SDRs. SDRs have the advantage of being highly reconfigurable relative to their hardware-defined counterparts. This flexibility comes at the cost of increased size, weight, and power consumption, which leads to the use of larger, sometimes distributed, computing systems to perform the computationally-intensive signal processing tasks associated with radios. Through the use of REDHAWK, an SDR developer can focus on signal processing algorithms without worrying about the onus of deploying such algorithms in a network environment.\nThe process of software and hardware integration among disparate project teams and vendors can be a major undertaking that is often resolved with one-off, custom solutions. While designed to support the data-streaming needs of SDRs, REDHAWK also facilitates integrating additional software and hardware assets into computing systems through features such as well-defined common interfaces. REDHAWK provides a streamlined and consistent methodology to the otherwise tedious and difficult process of assimilating new technologies.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/auto-generated-files/",
	"title": "Auto-Generated Component Files",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a tool for auto-generating component code for C++, Python, or Java languages. This process takes care of REDHAWK compliance and allows the developer to insert their own custom processing algorithm for working with the data sent/received by the component. The following section provides a brief description of the generated files. Note that some files may be freely modified, while other files should not be modified.\nModifying particular files is discouraged for two reasons:\n If a user regenerates the component using the IDE (for example, to add a port), particular files are overwritten by the code generators.\n Files whose modification is not discouraged (e.g., componentName.cpp) are not affected by such an action.\n The REDHAWK IDE provides the option of not rewriting particular files.\n    Modification of files implementing REDHAWK interfaces may impact compatibility with other REDHAWK modules.\n  The word componentName is replaced with the component name provided during component creation.\nFiles Generated for All Components Build-Related Files The code generators create the following files for building and installing the component using Autotools:\n build.sh - Two of these files are generated: one of them resides in the top-level component directory and the other resides in the source directory. The first of the two calls the build.sh script in the source directory.\nThe build.sh script in the source directory runs ./reconf; ./configure; make. The Autotools documentation can provide more information on these commands: in short, this process creates the component entry point.\nIf you use this script, you must install the dependency rpm-build by entering the following command: sudo yum install rpm-build.\n  configure.ac - A standard Autoconf configuration file. Refer to the Autoconf documentation for more information.\n Makefile.am - A standard Automake configuration file. Refer to the Automake documentation for more information.\n Makefile.am.ide - Provides build information for the REDHAWK IDE.\n reconf - Script that is used to generate the configure script in the Autotools chain.\n componentName.spec - Provides rpmbuild configuration information for facilitating building RPMs for the component. Refer to the RPM documentation for more information.\n  Component XML Descriptors  componentName.prf.xml - Describes the component’s properties. More information on the component’s prf.xml file can be found in the REDHAWK specification.\n componentName.scd.xml - Describes the component’s ports and interfaces. More information on the component’s scd.xml file can be found in the REDHAWK specification.\n componentName.spd.xml - Provides a top-level description of the component, including the names and locations of the component entry point and XML files. More information on the component’s spd.xml file can be found in the REDHAWK specification.\n  Unit Tests File  test_componentName.py - Contains a unit test built on the standard Python unittest Framework. The provided test exercises the generated code. Additional tests may be added for testing algorithms produced by the developer. For more information on how to add unit tests, consult the Python unittest Framework documentation.\nTo run the unit test(s), simply execute the file from the command-line ./test_componentName.py.\n  Files Generated for C++ Components Files where your implementation-specific code should be  componentName.h - The appropriate place to put header-related code in support of componentName.cpp.\n componentName.cpp - The appropriate place for developers to add their own processing behavior.\n port_impl.h (Optional) - This file is only generated for ports that utilize interfaces other than BulkIO, BurstIO, FEI and Messaging. Contains the port-related code for the component. If the type of ports changes, then this file needs to be re-generated, overwriting your application-specific code.\n port_impl.cpp (Optional) - This file is only generated for ports that utilize interfaces other than BulkIO, BurstIO, FEI and Messaging. Contains the port-related code for the component. If the type of ports changes, then this file needs to be re-generated, overwriting your application-specific code.\n  Files that you should not modify If these files are modified, then your ability to regenerate the component is affected.\n main.cpp - Contains the function that is used to create an instance of the component. For shared library components, this is a dynamically-loadable function called make_component(). For executable components, this is the main() function for the process. Modification of this file is not recommended.\n struct_props.h - Contains support classes for struct properties that are defined in the code-generation interface. Modification of this file is discouraged.\n componentName_base.h - Provides interface implementations for the component based on the component’s ports and properties. Modification of componentName_base.h is discouraged.\n componentName_base.cpp - Provides interface implementations for the component based on the component’s ports and properties. Modification of componentName_base.cpp is discouraged.\n  Files Generated for Python Components Files where your implementation-specific code should be  componentName.py - The appropriate place for developers to add their own processing behavior.  Files that you should not modify If these files are modified, then your ability to regenerate the component is affected.\n componentName_base.py - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is discouraged.  Files Generated for Java Components Files where your implementation-specific code should be  componentName.java - The appropriate place for developers to add their own processing behavior.  Files that you should not modify If these files are modified, then your ability to regenerate the component is affected.\n startJava.sh - Script containing the process that is started when the component is instantiated.\n componentName_base.java - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is discouraged.\n  Transitioning Java Components from REDHAWK version 1.8 to later versions If componentName.java is not regenerated when migrating from REDHAWK 1.8 to later versions, the component does not inherit from the base class, so it does not take advantage of the new code pattern. In addition, in order for the component to build, the method configureOrb must be added to componentName.java because the base class makes a call on that method.\nIf you want to inherit from the base class and take advantage of the new pattern, save off the custom main class Java file, regenerate the main Java class to get the new code pattern, and for example, move source from the run() method to the serviceFunction() method to integrate the custom code in the 1.8 main class into the new main class.\nIf componentName.java is regenerated, any custom code added to it is removed.\n Add this class to the componentName.java right before the last line which is \u0026ldquo;}\u0026rdquo;\n/** * Set additional options for ORB startup. For example: * * orbProps.put(\u0026#34;com.sun.CORBA.giop.ORBFragmentSize\u0026#34;, * Integer.toString(fragSize)); * * @param orbProps */ public static void configureOrb(final Properties orbProps) { }"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/configuring-logging-capabilities/",
	"title": "Configuring Logging Capabilities",
	"tags": [],
	"description": "",
	"content": " A resource has the ability to provide a severity level (logging level) with each logging message. The following severity levels are listed in order of increasing verbosity. FATAL messages describe events that are unrecoverable to the resource, whereas DEBUG messages enable developers to understand the processing behavior.\n FATAL ERROR WARN INFO DEBUG TRACE  Each different logging implementation library uses a log4j configuration file format to define the configuration context for that library. This file defines how and where the logging messages are recorded. For example, if the configuration logging level is set to INFO, then messages published at the INFO, WARN, ERROR, and FATAL severity levels are displayed in the log. All other message levels are suppressed. The following two log-level configuration options are also available.\n OFF: Suppress all logging messages from the log ALL: Allow all logging messages  The following code displays the default log4j configuration settings used by all REDHAWK resources.\nlog4j.rootLogger=INFO,STDOUT log4j.appender.STDOUT=org.apache.log4j.ConsoleAppender log4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout log4j.appender.STDOUT.layout.ConversionPattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n \\n\u0026#34; This configuration suppresses logging levels above INFO and writes those messages to the standard out console.\nConfiguration Context Tokens For REDHAWK release 1.10 and above, the log4j configuration file can contain special tokens that expand to provide the runtime execution context of the resource. These tokens can be located anywhere in the configuration file and are resolved during resource startup. The following table describes the tokens.\nlog4j Configuration File Special Tokens    Token Definition     @@@HOST.NAME@@@ Host name returned from gethostname call (multi-homed systems may have issues).   @@@HOST.IP@@@ Dot notation IP Address of the machine on which the processing is running.   @@@NAME@@@ Name of the resource given on the command line.   @@@INSTANCE@@@ Instance name given to the resource on the command line.   @@@PID@@@ pid of the running resource.   @@@DOMAIN.NAME@@@ Name of the domain under which your resource is running.   @@@DOMAIN.PATH@@@ The contents of the DOM_PATH parameter on the command line.   @@@DEVICE_MANAGER.NAME@@@ Name of the Device Manager that started the device or service.   @@@DEVICE_MANAGER.INSTANCE@@@ Instance name of the Device Manager from the command line.   @@@SERVICE.NAME@@@ Name of the service as specified on the command line.   @@@SERVICE.INSTANCE@@@ Instance name of the service as specified on the command line.   @@@SERVICE.PID@@@ pid of the running service.   @@@DEVICE.NAME@@@ Name of the device as specified on the command line.   @@@DEVICE.INSTANCE@@@ Instance name of the device as specified on the command line.   @@@DEVICE.PID@@@ pid of the device.   @@@WAVEFORM.NAME@@@ Name of the waveform from the DOM_PATH command line variable.   @@@WAVEFORM.INSTANCE@@@ Instance name of the waveform from the DOM_PATH command line variable.   @@@COMPONENT.NAME@@@ Name of the component binding parameter as specified on the command line.   @@@COMPONENT.INSTANCE@@@ Instance name of the component identifier parameter as specified on the command line.   @@@COMPONENT.PID@@@ pid of the component.    This table lists the availability of token definitions for each REDHAWK resource type.\nAvailability of Tokens    Token Domain Manager Device Manager Device Service Component     @@@HOST.IP@@@ Y Y Y Y Y   @@@HOST.NAME@@@ Y Y Y Y Y   @@@NAME@@@ Domain Manager Y Y Y Y   @@@INSTANCE@@@ DOMAIN_MANAGER_1 Y Y Y Y   @@@PID@@@ Y Y Y Y Y   @@@DOMAIN.NAME@@@ Y Y Y Y Y   @@@DOMAIN.PATH@@@ Y Y Y Y Y   @@@DEVICE_MANAGER.NAME@@@ N DEVICE_MANAGER Y Y N   @@@DEVICE_MANAGER.INSTANCE@@@ N Y Y Y N   @@@SERVICE.NAME@@@ N Y N Y N   @@@SERVICE.INSTANCE@@@ N Y N Y N   @@@SERVICE.PID@@@ N Y N Y N   @@@DEVICE.NAME@@@ N Y Y N N   @@@DEVICE.INSTANCE@@@ N Y Y N N   @@@DEVICE.PID@@@ N Y Y N N   @@@WAVEFORM.NAME@@@ N N N N Y   @@@WAVEFORM.INSTANCE@@@ N N N N Y   @@@COMPONENT.NAME@@@ N N N N Y   @@@COMPONENT.INSTANCE@@@ N N N N Y   @@@COMPONENT.PID@@@ N N N N Y    Log Configuration Example - Simple Appender with a Named Logger In the following example, the root most logger passes logging messages with a severity level INFO or less. Those messages are sent to the appenders called: CONSOLE and FILE. The CONSOLE appender messages are displayed in the console of the running application. The FILE appender writes log messages to a file called allmsgs.out.\nIf the resource uses a named logger, EDET_cpp_impl1_i, then log messages with a severity of DEBUG or less are diverted to a file called edet_log.out.\n# Set root logger default levels and appender log4j.rootLogger=INFO, CONSOLE, FILE # Console Appender log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.STDERR=org.apache.log4j.ConsoleAppender log4j.appender.STDERR.Threshold=ERROR log4j.appender.STDERR.Target=System.err # Default Log Appender log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.Append=true log4j.appender.FILE.File=allmsgs.out # Edet Appender log4j.appender.edetLog=org.apache.log4j.FileAppender log4j.appender.edetLog.Append=true log4j.appender.edetLog.File=edet_log.out # Appender layout log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.STDERR.layout=org.apache.log4j.PatternLayout log4j.appender.STDERR.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.edetLog.layout=org.apache.log4j.PatternLayout log4j.appender.edetLog.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.NULL.layout=org.apache.log4j.PatternLayout log4j.appender.NULL.layout.ConversionPattern=%n log4j.category.EDET_cpp_impl1_i=DEBUG, edetLog log4j.additivity.EDET_cpp_impl1_i=false Log Configuration Example - Configuring a Component with Token Macros The logging configuration information for component MEGA_WORKER is configured from $SDRROOT/dom/logcfg/component.log4j.cfg. Prior to configuring the underlying logging library, the configuration information is processed for the context macros (in this example, @@@WAVEFORM.NAME@@@, @@@COMPONENT.NAME@@@ and @@@COMPONENT.PID@@@). The root most logger passes logging messages with a severity level INFO or less, to the appenders called: CONSOLE and FILE. The CONSOLE appender messages are displayed in the console of the running application. For the FILE appender, the destination file is: /data/logdir/MY_EXAMPLE_1/MEGA_WORKER_1.212.log.\nWaveform: MY_EXAMPLE Component: MEGA_WORKER property: LOGGING_CONFIG_URI = \u0026#34;sca://logcfg/component.log4j.cfg\u0026#34; \\$SDRROOT/ dev/ ... deps/ .. dom/ ... logcfg/ component.log4j.cfg /data/logdir/# Set root logger default levels and appender log4j.rootLogger=INFO, CONSOLE, FILE # Console Appender log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender # File Appender log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.File=/data/logdir/@@@WAVEFORM.NAME@@@/@@@COMPONENT.NAME@@@.@@@COMPONENT.PID@@@.log log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n When the waveform MY_EXAMPLE is deployed on the domain, the component is launched with the following logging configuration:\nMEGA_WORKER \u0026quot;.....\u0026quot; LOGGING_CONFIG_URI sca://logcfg/component.log4j.cfg?fs= \u0026lt;br\u0026gt;IOR:010…\nLogging with Event Channels for Components, Devices and Services For REDHAWK resources, the underlying logging functionality has been extended to include support for publishing log messages to a specified Event Channel. To include this capability, add the org.ossie.logging.RH_LogEventAppender in your log4j configuration file. This appender responds to the following configuration options (all options are string values unless otherwise noted):\nRH_LogEventAppender Configuration Options    Appender Option Description     EVENT_CHANNEL Event Channel name where logging messages are published.   NAME_CONTEXT Directory in omniNames to lookup Event Channel (domain name - REDHAWK_DEV).   PRODUCER_ID Identifier of the resource producing the log message (resource name).   PRODUCER_NAME Name of the resource producing the log message.   PRODUCER_FQN Fully qualified name of the resource (domain-name/waveform-name/resource-name).   RETRIES Number of times to retry connecting to the Event Channel. (Integer)   THRESHOLD log4cxx log level; FATAL, WARN, ERROR, INFO, DEBUG, TRACE.    The NAME_CONTEXT option, is required for C++ resources to maintain backwards compatibility. For REDHAWK 2.0 and greater resources developed in Python or Java, the EVENT_CHANNEL is acquired using the EventChannelManager interface that is available to resources with domain awareness and ignores the NAME_CONTEXT option.\n Eventable logging is currently not supported for the Domain Manager and Device Manager. The following messages may occur during start up of these services with configurations that use eventable logging.\nlog4cxx: Could not instantiate class [org.ossie.logging.RH_LogEventAppender]. log4cxx: Class not found: org.ossie.logging.RH_LogEventAppender log4cxx: Could not instantiate appender named \u0026#34;pse\u0026#34;. In the following example, a component configured with this log4j properties file publishes log messages with a severity of ERROR or less to the Event Channel ERROR_LOG_CHANNEL in the domain, REDHAWK_DEV. The threshold level for the appender supersedes the rootLogger’s logging level.\nlog4j.rootLogger=INFO,stdout,pse # Direct log messages to stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target=System.out log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n # Direct error messages to an event channel log4j.appender.pse=org.ossie.logging.RH_LogEventAppender log4j.appender.pse.Threshold=ERROR log4j.appender.pse.event_channel=ERROR_LOG_CHANNEL log4j.appender.pse.name_context=@@@DOMAIN.NAME@@@ log4j.appender.pse.producer_id=@@@COMPONENT.INSTANCE@@@ log4j.appender.pse.producer_name=@@@COMPONENT.NAME@@ log4j.appender.pse.producer_FQN=@@@DOMAIN.NAME@@@.@@@WAVEFORM.NAME@@@.@@@COMPONENT.NAME@@@ log4j.appender.pse.layout=org.apache.log4j.PatternLayout log4j.appender.pse.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c:%L - %m%n Synchronous Logging for C++ Devices and Components For C++ Devices and Components, the REDHAWK Core Framework libraries provide a Synchronous Rolling File Appender that will allow atomic write operations to a common file. To include this capability, add the org.ossie.logging.RH_SyncRollingAppender in your log4j configuration file. This appender responds to the following configuration options (all options are string values unless otherwise noted):\nRH_SyncRollingAppender Configuration Options    Appender Option Description     Retries Number of retries when waiting for the lock fails. (Integer)   WaitOnLock Time in milliseconds to wait when attempting to take ownership of the lock. (Integer)   MaxFileSize Maximum file size before rolling to the next file.   MaxBackupIndex Maximum number of files to keep. (Integer)   File Full local file system path.   Cleanup Clean up synchronization resources when the process ends. (Value is True or False.)    In the following example, a component configured with this log4j properties file publishes a log message to the file MP_RedhawkTest.\nlog4j.rootLogger=INFO,stdout,mp # Direct log messages to stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target=System.out log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n log4j.appender.mp=org.ossie.logging.RH_SyncRollingAppender log4j.appender.mp.Retries=2 log4j.appender.mp.WaitOnLock=30 log4j.appender.mp.MaxFileSize=5MB log4j.appender.mp.MaxBackupIndex=10 log4j.appender.mp.File=MP_RedhawkTest log4j.appender.mp.Cleanup=False log4j.appender.mp.layout=org.apache.log4j.PatternLayout log4j.appender.mp.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c:%L - %m%n The synchronous appender only works for single GPP systems. The synchronization resources used require all the processes to reside on the same host.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/connecting-to-a-domain/",
	"title": "Connecting to a Domain",
	"tags": [],
	"description": "",
	"content": " In the IDE, you can launch and connect to a domain through the IDE interface or connect to a running domain.\nYou can also launch a domain and Device Manager from the command line.\nLaunching and Connecting Using the IDE The following procedure explains how to launch and connect to a domain through the IDE.\n In the REDHAWK Explorer View, right-click Target SDR and select Launch Domain…\nLaunching a Domain The Launch Domain Manager window is displayed:\nLaunch Domain Manager  In the Domain Name field, enter a name.\n Optionally, select a Device Manager to start.\nA running Device Manager is required to launch applications.\n  Optionally, in either the Domain Manager or Device Manager section, select a Debug Level. By default, the Debug Level is set to Info, which displays any messages at the Info level or higher: (Info, Warn, Error, and Fatal message levels). If this is the first time using REDHAWK, changing the Debug Level from Info to Debug for both the domain and Device Manager may be helpful in the learning process.\n Optionally, in either the Domain Manager or Device Manager section, select Arguments for the nodeBooter process. This option is provided to advanced users who are comfortable with command line options.\n Finally, click OK to launch and connect to the new domain.\n Notice that the IDE reacts to the newly launched domain:\n The new domain has been added to the REDHAWK Explorer View\n The new domain, within a short amount of time, is connected and this connection is indicated to the right of the domain name within the REDHAWK Explorer View.\n At least one new Console view (within the\u0026rdquo; IDE) has been created. One contains a nodeBooter instance for the Domain Manager that launched and one nodeBooter instance for each Device Manager.\n   Console Showing the Domain Manager Start Up Connecting to a Running Domain To connect to a running domain through the IDE use the following procedure:\n Click the New Domain Connection button (i.e. the plus symbol) in the upper right of the REDHAWK Explorer View.\nNew Domain Connection The New Domain Manager dialog is displayed:\nNew Domain Manager  Enter the Name Service. This is the CORBA URI of the Naming Service where the domain is registered. By default, this is populated with the value from the IDE’s preferences (set by selecting Window \u0026gt; Preferences, REDHAWK \u0026gt; Domain Connections, Default Naming Service).\n To specify the domain to which you want to connect, chose one of the following options:\n Enter a Display Name and a Domain Name. The Display Name is a used only in the IDE and does not need to match the Domain Name. The Domain Name is the actual name of the domain in the Naming Service.\n Wait for the IDE to scan the name service for running domains. When the button next to Display Name shows a + icon, click it and select a running domain from the list.\n  Click one of the following options under Connection Settings:\n Don’t connect: This adds the domain to the REDHAWK Explorer View but leaves the domain in the disconnected state. When the IDE is restarted, the domain remains in the REDHAWK Explorer and is in the disconnected state. After adding a disconnected domain to the REDHAWK Explorer View, the domain may be connected by right-clicking the domain and selecting Connect.\n Connect Once: This adds the domain to the REDHAWK Explorer View and connects the IDE with the domain. When the REDHAWK IDE is restarted, the domain remains in the REDHAWK Explorer but is in the disconnected state.\n Always Connect: This adds the domain to the REDHAWK Explorer View and connects the IDE with the domain. When the REDHAWK IDE is restarted, the domain remains in the REDHAWK Explorer and attempts to connect with this domain.\n  Select Finish to close the wizard.\n The domain now appears in the REDHAWK Explorer View. If Connect Once or Always Connect was chosen, the domain is connected. If Don’t Connect was selected, right-click the domain and select Connect.\nMany of these options may be changed later through the Properties View.\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/shared-libraries/creating-a-shared-library-project/",
	"title": "Creating a REDHAWK Shared Library Project",
	"tags": [],
	"description": "",
	"content": " The REDHAWK Shared Library Project Wizard enables users to quickly create a C++ shared library for use in REDHAWK. In the wizard, the user specifies the project name and can then generate a simple set of code files to begin adding in library functions. The following procedure explains how to use the Shared Library Project Wizard.\n To open the Shared Library Project Wizard, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard dialog is displayed:\nSelect a Wizard  Select REDHAWK Shared Library Project and click Next.\nThe Create a REDHAWK Shared Library Project dialog is displayed:\nCreate a REDHAWK Shared Library Project  In the Project Name field, enter a project name.\n Click Finish.\nThe Shared Libary Project is created and the Overview tab is displayed.:\nShared Library Project Overview  Click the Generate All Implementations icon to generate the source code.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/interacting-with-hardware/creating-fei-device-ide/",
	"title": "Creating an FEI Device in the IDE",
	"tags": [],
	"description": "",
	"content": " Using the FEI Wizard to Create an FEI Device The REDHAWK Front End Device Project wizard enables users to quickly create an FEI compliant receiver or transmitter device. In the wizard, the user specifies the physical properties of the device, including whether the device ingests or outputs GPS and if the device has digital or analog input and output ports. Additionally, the user can choose to augment the required tuner status properties with additional optional properties.\n To open the wizard and create a new device, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard page is displayed:\nSelect a Wizard  Select REDHAWK Front End Device Project and click Next.\nThe Create a REDHAWK Device Project page is displayed:\nCreate a REDHAWK Device Project  In the Project name field, enter a project name and click Next.\nThe New Implementation page is displayed:\nNew Implementation  Select the programming language; enter a description for this implementation; and click Next.\nThe Setup Code Generation page is displayed:\nSetup Code Generation  Click Next.\nThe FrontEnd Interfaces Device Type Selection page is displayed:\nFrontEnd Interfaces Device Type Selection  Select the appropriate aspects of the device (needs GPS data or produces GPS data) and its general usage (receive/transmit, scanning capability). Click Next.\nThe FrontEnd Interface Tuner Options page is displayed:\nFrontEnd Interface Tuner Options  Specify the types of inputs and outputs that the device supports (analog, digital float) and click Next.\nThe FrontEnd Interfaces Tuner Status Customization page is displayed:\nFrontEnd Interfaces Tuner Status Customization  To add an optional tuner status properties, click +, select the checkboxes for the properties, and click OK. To remove optional tuner status properties, under Tuner Status Property Selection, select the properties to remove, and click X. If a required property is selected, the X button is disabled. Click Finish to exit this wizard.   Upon exiting this wizard,the FEI device project to is created, and the Overview tab of the project is displayed:\nFEI Device Overview tab Editing a FrontEnd Interfaces Device Project After completing the wizard, you can add ports, properties, and descriptions to an FEI device using the same processes used for all other components and devices. For more information about adding ports, refer to SoftPkg Editor Overview Tab. For more information about adding properties, refer to SoftPkg Editor Properties Tab\nFor example, it may be useful to add a property used to uniquely identify the target device, such as an IP address.\nWhen editing a FrontEnd Device Project:\n Do not rename properties that were generated using the wizard. Do not modify the pre-populated values generated in the wizard (for example, the property, device_kind). You may, however, add default values to the properties without pre-populated values, such as device_model. Do not change pre-defined FEI Tuner Status properties that were generated in the wizard. You may, however, add user-defined FEI Tuner Status properties. Before adding user-defined FEI Tuner Status properties, check to see if relevant pre-defined FEI Tuner Status properties are already available. Use pre-defined FEI Tuner Status properties whenever possible.   To add or remove optional FEI Tuner Status properties using the FrontEnd Interfaces Tuner Status Customization dialog, on the Overview tab of the project, click the Edit FrontEnd properties icon. The same dialog used to define the FEI device’s tuner status property on the creation wizard () is displayed. Add or remove the properties and click Finish.\nGenerating and Customizing the Source Code  On the Overview tab for the project, click the Generate All Implementations icon to generate the source code.\nThe Regenerate Files dialog is displayed:\nRegenerate Files  Select the files to be generated and click OK.\nFiles are generated that define the classes for the FEI device. In C++, the FEI base class inherits from the frontend::FrontendTunerDevice class (or frontend::FrontendScanningTunerDevice for a scanner) to provide much of the FEI capability. The generated FEI device class must be modified to interact with the target device. During generation, intentional compiler warnings are inserted in the main class to indicate where code should be modified to reflect the behavior of the device. The output of the make command for a C++ device, including the compiler warnings, is displayed in the Console view:\nFEI Device Compiler Warnings There are five functions that contain a default implementation that should be modified to match the desired behavior. These functions are constructor, deviceEnable, deviceDisable, deviceSetTuning, and deviceDeleteTuning. The constructor function is called when the device is instantiated. During allocation of an FEI device, deviceSetTuning is called and, if successful, deviceEnable is called. During deallocation, deviceDisable is called followed by a call to deviceDeleteTuning.\nFor scanners, the additional methods deviceSetTuningScan, setScanStrategy, setScanStartTime, getScanStatus must be modified to provide the scanner capability.\n Add source code to allocate and setup a tuner channel.\nThe following table explains what is expected in each function/method.\nEach of the following functions have fts and tuner_id passed in as parameters. The tuner_id parameter specifies which tuner channel to operate on, and fts is a reference to the FEI tuner status associated with the specified tuner channel. Additionally, deviceSetTuning has a parameter called request, which defines the parameters of the tuning request.\n Functions/methods in the generated code    Function/Method Description     constructor This is the REDHAWK constructor. All properties are initialized prior to this function being invoked. The default behavior when implementing a tuner is to create 1 RX_DIGITIZER channel.   deviceEnable Command the hardware to enable the output and begin generating data. The FEI tuner status element fts.enabled is updated to reflect the current state of the tuner output. This is a good place to call start to start the service function.   deviceDisable Command the hardware to disable the output and stop generating data. The FEI tuner status element fts.enabled is updated to reflect the current state of the tuner output. This is a good place to call stop to start the service function.   deviceSetTuning Validate that the request parameters can be satisfied by the tuner indicated by tuner_id. There are several helper functions (validateRequest, validateRequestVsSRI, validateRequestVsRFInfo, and validateRequestVsDevice) provided in the inherited FrontendTunerDevice class of the device to assist in validation. Then, either configure the hardware with the tuner request, throw a BadParameterException if the request is outside of the capabilities of the tuner, or return false. Update the appropriate FEI tuner status elements (i.e. fts.center_frequency, fts.bandwidth, fts.sample_rate) with the actual values queried from the hardware rather than with the requested values. Push new SRI within this function. Finally, when using the multi-out capability for BulkIO ports, it is recommended that the matchAllocationIdToStreamId function be called at this point with the stream ID and Allocation id. Return True upon successful configuration of the tuner according to the request, or False otherwise.   deviceDeleteTuning Prior to deallocateCapacity return, a pushPacket call with eos set to True must be called, and deviceDeleteTuning is where this should occur. Also, update the appropriate FEI tuner status elements (i.e fts.center_frequency, fts.bandwidth, fts.sample_rate) if desired. Return True upon success, or False otherwise.    Additional functions/methods in the generated scanner code    Function/Method Description     deviceSetTuningScan Called instead of deviceSetTuning when a scanner allocation is made.   setScanStrategy Called by the user to provide a plan for how the frequencies the scanner will cover. Validate the request and store the plan.   setScanStartTime Called by the user to specify when a scan should start. At the specified time, the scanner should begin outputting data according to the scan plan.   getScanStatus Provide the status of all current and scheduled scans    In addition to the code required for allocation and deallocation, information used to identify the target device at run-time must be added to the main class. The recommended method for dynamically identifying a target device is through configuration of a property. For example, configuring a property with an IP address or some other unique identifier allows the FEI device to identify the specific target device.\n Add source code to interact with the target hardware.\nThere are two key aspects to an FEI device: 1) how many channels does it support? and 2) how does it interact with the hardware?\nIn an FEI device, the number of channels is set through the setNumChannels function. By default, this function is included in the generated code with 1 channel. Interaction with the hardware is, obviously, specific to the hardware. The nature of the hardware (i.e.: receiver, transmitter), is specified for the supported channels as the second argument in the setNumChannels function. The valid strings for this argument are: RX_DIGITIZER, TX, RX, CHANNELIZER, DDC, RX_DIGITIZER_CHANNELIZER. See Types of Tuners for more information. By default, setNumChannels is populated with RX_DIGITIZER, irrespective of the selections made on the FEI wizard.\nThe other aspect of the interaction with hardware is the interaction with the actual driver code. While this interaction is hardware-specific, there are some structures that may be useful. The loop function (serviceFunction in C++ and Java, process in Python), is iteratively called after the device is started. As part of the deviceEnable callback, calling start on the device starts processing loop. Conversely, as part of the deviceDisable callback, calling the stop on the device stops the processing loop.\nThe tuner interface provides the ability to set parameters like center frequency and bandwith for the receiver. Any FEI compliant device may not output any data until the transients from any receiver setting change have settled to steady state. In short, all data output from an FEI compliant device must correspond to unambiguous receiver settings.\n In the service loop function, the implementation of, in the case of a receiver, reading data from the hardware and pushing it out a port would exist. Conversely, in the case of the transmitter, the service loop function would be used to retrieve data from a port and push it through the driver to the hardware.\n Add source code to implement FEI-related port functions.\nIf using an RFInfo port, it may be useful to store the RFInfo packet as part of the device because it is not stored within the port.\n   Installing the FEI Device To install the FEI device, build the project and export it to the Target SDR. After the FEI device is installed, you can use it in a REDHAWK system.\nTest-running a Sample FEI Device Create a new FEI project following the steps shown in Using the FEI Wizard to Create an FEI Device. For the purposes of this example, select Python as the language for the device and dataShort as the type for the digital output, otherwise select the defaults on the Wizard for all other settings. Follow steps 1 and 2 in Generating and Customizing the Source Code.\nIn the deviceEnable function, add the following line:\nself.start() In the deviceDisable function, add the following line:\nself.stop() In the process function, add the following lines:\ndata = range(10000) self.port_dataShort_out.pushPacket(data, bulkio.timestamp.now(), False, \u0026#34;my stream id\u0026#34;) Install and launch the device.\nTo test-run the device, follow these steps:\n In the REDHAWK Explorer tab, expand the Sandbox item.\n In the Sandbox item, expand the Device Manager item. The devices running in the Sandbox are displayed.\n Right-click the device’s output Port (probably called dataShort_out) and select Plot Port Data.\n Right-click the running device and and select Allocate. The Allocate Tuner wizard is displayed.\nAllocate Tuner Wizard  Enter any arbitrary number in the Center Frequency, Bandwidth, and Sample Rate fields.\n To have the wizard perform the allocation as a background job, check the Run in background checkbox. If this checkbox is not checked, the wizard does not close until the allocation is complete.\n Click Finish. Data is plotted on the plot.\n To stop the flow, right-click the device under the Device Manager item and select Deallocate All. A deallocation warning message is displayed.\n Click Yes to confirm that you want to deallocate all.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/data-transfers/",
	"title": "Data Transfers",
	"tags": [],
	"description": "",
	"content": " Data transfers happen through the pushPacket() method call of a REDHAWK component’s port object. This method transfers the data from the uses-side port to the corresponding connected provides-side port. The data is marshaled by the middleware (omniORB) and placed on a queue for processing by the receiving component. The implementations of the pushPacket() methods are maximized for the efficiency of data throughput while providing network-accessible ingest/egress of data and minimizing the complexity of the implementation.\nBulkIO Data Flow via pushPacket() Each implementation maintains the required behavior of providing an SRI object before receiving any data transfers. This is accomplished by calling the pushSRI() method of the port with an SRI object. In most cases, a component takes the ingest SRI object received from an input port, makes any required modifications as necessary, and passes this object down stream over its output port. If a component does not provide an SRI object before its first pushPacket(), the port creates a default SRI object with nominal values to pass out the port.\nThe following sections explain the different methods for transferring supported data types by a component.\nFor the current implementation of omniORB, the /etc/omniORB.cfg maintains the configurable maximum transfer size defined by the value for giopMaxMsgSize. The default maximum transfer size is set to 2097152 (2 MB). For every pushPacket(), the data+headers must be less than this value; otherwise, a MARSHAL exception is raised by the middleware. This maximum value can be found during run time by using the omniORB::giopMaxMsgSize() function call or the bulkio::Const::MAX_TRANSFER_BYTES value.\n Vector Data A component usually ingests and egresses data from its ports in the service function. A component with a provides-port (input), grabs data from the port using the getPacket() method. This method returns a dataTransfer object (described in DataTransfer Member Descriptions) from the input port’s data queue or a null/None value if the queue is empty.\nThe following code snippet is an example of the getPacket() method.\n/** Grab data from the port\u0026#39;s getPacket method */ bulkio::InFloatPort::dataTransfer *pkt; pkt = inFloatPort-\u0026gt;getPacket( bulkio::Const::NON_BLOCKING ); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check if any SRI changes occurred if ( pkt-\u0026gt;sriChanged ) { outFloatPort-\u0026gt;pushSRI( pkt-\u0026gt;SRI ); } ... perform some algorithm on the data: pkt-\u0026gt;dataBuffer ... DataTransfer Member Descriptions    Name Type Description     dataBuffer std::vector\u0026lt;TYPE\u0026gt; The data transferred, where TYPE is some native CORBA type (e.g., float, short). The sequence may be zero-length.   T PrecisionUTCTime The epoch birth date of the first sample of the sequence.   EOS boolean Flag describing whether this particular stream ends with this buffer of data.   streamID string Stream ID for this particular payload. This value is used to reconcile this sequence of data with a particular Stream SRI data structure.   SRI BULKIO::StreamSRI The Signal Related Information (metadata) associated with the buffer of data.   sriChanged boolean Flag that describes if a new SRI object was received for this stream.   inputQueueFlushed boolean Flag that signifies if the port’s incoming data queue was flushed (purged) because the limit was reached. This happens when the consuming component does not keep up with the incoming rate at which the data is being received.    The following code snippet is an example of the pushPacket() method call for vector data with sample parameters. The pushPacket() parameters for vector data are described in the table below.\nstd::vector\u0026lt;short\u0026gt; data; ... perform algorithm and save results to data vector ... BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); outShortPort-\u0026gt;pushPacket( data, tstamp, false, \u0026#34;sample\u0026#34; ); pushPacket() Parameter Descriptions for Vector Data    Name Type Description     data sequence\u0026lt;TYPE\u0026gt; A sequence of a particular type, where TYPE is some native CORBA type (e.g., float, short). The sequence may be zero-length.   T PrecisionUTCTime The epoch birth date of the first sample of the sequence passed in this call.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    String Data/XML Document The following code snippet is an example of the pushPacket() method call for string data with sample parameters. The pushPacket() parameters for string data are described in the table below.\nstd::string data; ... generate some text data to transfer ... outStringPort-\u0026gt;pushPacket( data.c_str(), false, \u0026#34;sample\u0026#34; ); pushPacket() Parameter Descriptions for String Data    Name Type Description     data char A string of characters to pass between components. Also used for passing XML documents in-line between components.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    URL/File Data The following code snippet is an example of the pushPacket() method call for file transfers with sample parameters. The pushPacket() parameters for file transfers are described in the table below.\nstd::string uri; uri = \u0026#34;file:///data/samples.8t\u0026#34;; ... open the file, fill with samples of data, close the file ... BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); outURLPort-\u0026gt;pushPacket( uri.c_str(), tstamp, false, \u0026#34;sample\u0026#34; ); pushPacket() Parameter Descriptions for File Transfers    Name Type Description     url string The URL describing the file. Appropriate schemes for the URLs are file:// and sca://. The file scheme applies to the local file system, while the SCA scheme applies to the SCA File Manager.   T PrecisionUTCTime An appropriate time stamp for the data being passed.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    Data files may be sent via the BulkIO dataFile type. When using the BulkIO dataFile type, a filename is passed to the pushPacket() method. The location of the file is specified by a URI that either points to the local file system or the SDR file system. To support portability, use of the SDR file system is recommended. The table below describes the URI options in greater detail.\nURI Options    Protocol Format Description     file file://[localhost]/\u0026lt;path\u0026gt; A host specific absolute path of the deployed component/device/service.   sdr sdr://[ior]/\u0026lt;path\u0026gt; A path on the Domain Manager’s file system. If the optional IOR is provided, this path provides the reference to the Domain Manager. If not provided, the Domain Manager is the default used by the component/device/service    SDDS Stream Definition The SDDS Stream Definition object defines a multicast connection source for data from a network interface. The methods for the SDDS Stream Definition Interface do not follow the normal BulkIO pushPacket() convention. Instead this interface defines attach() and detach() methods as described in the code snippet and tables below.\n/** * SDDS Stream Definition Interface */ /** * attach : request to an attachment to a specified network data source */ char *attach( BULKIO::SDDSStreamDefinition stream, const char * userid ); /** * detach: unlatch from a network data source */ void detach( const char* attachId ); char* attach()    Name Type Description     return value char* Attachment identifier assigned to this request.   stream SDDSStreamDefinition Stream definition object describing a multicast address (SDDS Stream Definition Member Descriptions).   userid const char* Identification for the request of the attach call.    void detach()    Name Type Description     attachId char* Attachment identifier returned from attach request.    SDDS Stream Definition Member Descriptions    Name Type Description     ID string Unique identifier for the source stream.   dataFormat SDDSDataDigraph Data format of the data stream samples.   multicastAddress string IPv4 network address in dot notation form.   vlan unsigned long Virtual lan identifier as defined by 802.11q.   port unsigned long IP port number associated with the network connection.   sampleRate unsigned long Expected sample rate for the data.   timeTagValid boolean Denotes if data stream can provide valid time stamp values.   privateInfo string Allows for user-defined values to be passed as a string.    "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/data-transfers/",
	"title": "Data Transfers",
	"tags": [],
	"description": "",
	"content": " BurstIO data transfers happen through the pushBurst() and pushBursts() method calls of a REDHAWK resource’s (component or device) BurstIO port object. A resource can use these push methods to transfer bursts and their associated meta data from one resource to another within the resource’s service function. Similar to BulkIO, BurstIO interfaces provide the same BULKIO::PrecisionUTCTime time stamp for each data vector of the burst. BurstIO defines a new BurstSRI SRI object that enables developers to further describe the signaling environment and the data transformations. These fields are further described in Burst Signal Related Information (SRI).\nInput A resource with a provides-port (input), grabs data from the port using the getBurst() method. This method returns a PacketType object (described in Burst Packet Accessors) from the input port’s data queue or a null/None value if the queue is empty.\nThe following code snippet is an example of the getBurst() method.\n/** Grab data from the port\u0026#39;s getBurst method */ burstio::BurstShortIn::PacketType *pkt; pkt = inShortPort-\u0026gt;getBurst( bulkio::Const::NON_BLOCKING ); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check for EOS if ( pkt-\u0026gt;getEOS() ) { outShortPort-\u0026gt;pushBurst(pkt-\u0026gt;getSequence(), pkt-\u0026gt;getSRI(), pkt-\u0026gt;getEOS()); } ... perform algorithm on the data: pkt-\u0026gt;getData() ... or pkt-\u0026gt;getSequence() Burst Packet Accessors    Name Type Description     getSize size The number of samples in the burst. For complex data, the number of samples is half this value.   getData pointer to \u0026lt;TYPE\u0026gt; Pointer to the data samples.   getSequence container to \u0026lt;TYPE\u0026gt; Returns an iterable sequence to the data samples.   getEOS boolean Returns TRUE if this is the last burst in a stream.   getSRI BULKIO::StreamSRI The SRI (metadata) associated with the sample data.   getTime PrecisionUTCTime The epoch birth date of the first sample of the sequence.   blockOccurred boolean Returns TRUE if an incoming burst was blocked.   isComplex boolean Returns TRUE if data is complex.   getComplexData pointer to \u0026lt;TYPE\u0026gt; Pointer to a vector of complex pairs.    Output Due to the asynchronous nature of BurstIO data, the interface enables the developer to control the output (egress) of bursts from a resource. The 2 main method calls to push burst data downstream from one resource to another are: pushBursts() and pushBurst(). pushBursts() enables multiple bursts to be sent directly downstream as a sequence of BurstType objects, whereas, pushBurst() provides an interface to queue a single burst to be pushed but follows policy directives based on the number of bursts, total queue size, and send intervals. Both methods route burst data using the specified routing constraints and connection filter which are controlled using the following interface:\n// this route streams with stream ID == \u0026#34;data-stream-one\u0026#34; to a connection // identified as \u0026#34;connection-one\u0026#34; shortBurstPort-\u0026gt;addConnectionFilter(\u0026#34;data-stream-one\u0026#34;, \u0026#34;connection-one\u0026#34;); or\n// update connection filter using the Component\u0026#39;s connection property // \u0026#34;myConnectionTable\u0026#34; shortBurstPort-\u0026gt;updateConnectionFilter(myConnectionTable); // this sets the stream filter to only route streams to specific connections shortBurstPort-\u0026gt;setRoutingMode(burstio::ROUTE_CONNECTION_STREAMS); Routing Control Directives    Routine Directive Description     ROUTE_ALL_INTERLEAVED All connections receive all streams; streams are interleaved in one buffer.   ROUTE_ALL_STREAMS All connections receive all streams; streams are buffered independently.   ROUTE_CONNECTION_STREAMS Each connection may subscribe to a set of streams; streams are buffered independently.    The major difference between the pushBurst() and pushBursts() methods is the ability to manage how and when the data is transferred. Only burst traffic that is queued using pushBurst() is controlled by the policy constraints, whereas, calls to pushBursts() are directly sent downstream to the connected resource.\n// this method will limit the maximum number of bursts that // can be queued before they are sent shortBurstPort-\u0026gt;setMaxBursts(size_t count); // this method will enable threshold monitoring for the amount of sample // data that exceeds this limit before sending data downstream shortBurstPort-\u0026gt;setByteThreshold(size_t bytes); // this method will enable the latency time between the sending of // available data downstream shortBurstPort-\u0026gt;setLatencyThreshold( long usec ); The following code snippet is an example of the pushBurst() method call for a vector data sample that is queued to the port.\nstd::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); BURSTIO::BurstSRI sri; burstio::BurstShortOut::BurstType burst; burst.SRI = sri; burst.EOS = false; burst.T = burstio::utils::now(); burst.data.length(data.size()); for(int i=0; i\u0026lt; data.size(); i++ ) burst.data[i] = data[i]; // this queues a single burst shortBurstPort-\u0026gt;pushBurst( burst ); // or  std::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); // this queues a single burst shortBurstPort-\u0026gt;pushBurst( data, sri, burstio::utils::now() ); The following code snippet is an example of the pushBursts() method call for a vector data sample. The bursts from this call are directly passed downstream to the connected resource.\nstd::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); BurstShortOut::BurstSequenceType bursts; bursts.length(1); burstio::BurstShortOut::BurstType burst; burst.SRI = sri; burst.EOS = false; burst.T = burstio::utils::now(); burst.data.length(data.size()); for(int i=0; i\u0026lt; data.size(); i++ ) burst.data[i] = data[i]; bursts[0] = burst; // this pushes the burst directly downstream because // it is a sequence of bursts shortBurstPort-\u0026gt;pushBursts(bursts);"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " This chapter explains how to install the Core Framework, the IDE, and the basic assets. The Core Framework is the software back-end of REDHAWK. The IDE is a GUI for development and interaction with REDHAWK systems. The basic assets are a collection of components, devices, and waveforms that developers can use to create simple software-defined radio applications.\nTo configure and install REDHAWK and associated dependencies, you must have root permissions. The REDHAWK installation is compatible with RHEL or CentOS 6 (32-and 64-bit) and RHEL or CentOS 7 (64-bit). The current REDHAWK release was tested against CentOS 6.9 (32-and 64-bit) and CentOS 7.4 (64-bit).\nInstalling REDHAWK from RPMs This section provides step-by-step instructions for installing a REDHAWK release using the YUM command-line package management tool. The installation process includes:\n Configuring the host system to install REDHAWK dependencies from Fedora EPEL Downloading and configuring the REDHAWK YUM repository on the host system Installing the REDHAWK software Setting up the user environment for immediate REDHAWK runtime or development use  Before beginning the installation process, if you are upgrading from a 1.8.x version of REDHAWK or for more information about external dependencies, refer to External Dependencies.\n Configuring the Host System to Install REDHAWK EPEL Dependencies REDHAWK has several open-source software dependencies from the EPEL repository. If your system is not configured to receive software packages from EPEL, you can configure it as follows:\nFor RHEL/CentOS 7:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm For RHEL/CentOS 6:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm Downloading and Configuring the REDHAWK Yum Repository on the Host System The following conventions are used in the instructions that follow.\n   Variable Description Example     \u0026lt;version\u0026gt; REDHAWK version 2.0.3   \u0026lt;dist\u0026gt; Linux distribution as represented by rpm macros el6 (for CentOS 6)   \u0026lt;arch\u0026gt; host architecture x86_64    Adjust the variables to match the desired REDHAWK version, host Linux distribution, and host machine architecture. For example, for REDHAWK version 2.0.3, 64-bit CentOS 6, redhawk-yum-2.0.3-el6-x86_64.tar.gz.\nDownloading the YUM Archive of REDHAWK Download the archive of the desired version of REDHAWK for your host OS and architecture.\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz Setting Up the REDHAWK Repository  In the directory that you want to use for the REDHAWK yum repository, extract the contents of the tar file.\ntar xzvf redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz cd redhawk-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt; Install the redhawk-release package (containing the REDHAWK GPG signing key):\nsudo yum install -y redhawk-release*.rpm Enter the following commands to add the following file, /etc/yum.repos.d/redhawk.repo:\ncat\u0026lt;\u0026lt;EOF|sed \u0026#39;s@LDIR@\u0026#39;`pwd`\u0026#39;@g\u0026#39;|sudo tee /etc/yum.repos.d/redhawk.repo [redhawk] name=REDHAWK Repository baseurl=file://LDIR/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhawk EOF  Installing REDHAWK Use one of the following options to install the IDE, Core Framework, and accompanying dependencies from RPMs.\n To install only the runtime REDHAWK software, enter the following command:\nsudo yum groupinstall \u0026#34;REDHAWK Runtime\u0026#34; To install the REDHAWK development software, enter the following command:\nsudo yum groupinstall \u0026#34;REDHAWK Development\u0026#34;  If you want to be more selective about the packages you install, refer to REDHAWK Yum Repository and Packages  for a list of packages that can be installed. You can also install a stand-alone IDE.\n Setting Up the User Environment  Enter the following commands to set up the environment variables:\n. /etc/profile.d/redhawk.sh . /etc/profile.d/redhawk-sdrroot.sh Use the following command to add each REDHAWK user to the redhawk group:\nsudo /usr/sbin/usermod -a -G redhawk \u0026lt;username\u0026gt; Where \u0026lt;username\u0026gt; is the name of a user to add to the group. If you are logged into an account that you modify with usermod, you must log out and back in for the changes to take effect.\n  Configuring omniORB The omniORB configuration file (/etc/omniORB.cfg) must be edited to provide information about how to reach the CORBA name service. By default, the config file contains the following entries:\nInitRef = NameService=corbaname::127.0.0.1:2809 supportBootstrapAgent = 1 The NameService line provides information about how to reach the CORBA naming service. The number is an IP address followed by a colon and a port number. The port number is used as a default if no other number is specified. SupportBootstrapAgent is a server side option. This enables omniORB servers and Sun’s JavaIDL clients to work together. When set to 1, an omniORB server responds to a bootstrap agent request.\n  Add the following line to the config file to configure the CORBA event service (this requires root permissions):\nInitRef = EventService=corbaloc::127.0.0.1:11169/omniEvents The first number is the IP address followed by a colon and a port number. omniEvents is the object key.\n Enter the following command to start the omniNames and omniEvents services:\nsudo $OSSIEHOME/bin/cleanomni For CentOS 6 systems, to have omniNames and omniEvents start automatically at system boot (recommended), enter the following commands:\nsudo /sbin/chkconfig --level 345 omniNames on sudo /sbin/chkconfig --level 345 omniEvents on For CentOS 7 systems, to have omniNames and omniEvents start automatically at system boot (recommended), enter the following commands:\nsudo systemctl enable omniNames.service sudo systemctl enable omniEvents.service  For more information about omniORB configuration file settings (/etc/omniORB.cfg), refer to Chapter 4 of the omniORB User’s Guide (http://omniorb.sourceforge.net/omni41/omniORB/omniORB004.html.\nConfiguring omniORB for Distributed Systems If you want to run a Domain Manager and Device Manager from two different computers, the following procedure explains how to configure omniORB for distributed systems.\n On the computer from which you want to run the Domain Manager, start omniNames and omniEvents and then launch a Domain Manager.\nThe firewall may need to be disabled to allow the Device Manager to connect.\n  On the computer from which you want to run the Device Manager, modify the omniORB.cfg file so that the IP address for the NameService and EventService is the address of the computer running the Domain Manager.\nThe following example is a modified Domain Manager omniORB.cfg file:\nInitRef = NameService=corbaname::127.0.0.1: InitRef = EventService=corbaloc::127.0.0.1:11169/omniEvents The following example is a modified Device Manager omniORB.cfg file:\nInitRef = NameService=corbaname::\u0026lt;IP address of Domain Manager\u0026gt;: InitRef = EventService=corbaloc::\u0026lt;IP address of Domain Manager\u0026gt;:11169/omniEvents Neither omniEvents nor omniNames needs to be running on this computer.\n  On the computer running the Device Manager, test that you can see the Domain Manager by running nameclt list.\nThe name of the Domain Manager is displayed.\n Start the Device Manager.\nAny devices in the node are registered with the Domain Manager.\n To verify that you can view both the Device Manager and Domain Manager, from either computer, run nameclt list \u0026lt;Domain Manager Name\u0026gt;.\nThe Device Manager and Domain Manager are displayed.\n  omniORB may have trouble automatically resolving its location. In this case, it may be necessary to set the endpoints in the omniORB.cfg files by adding the following to each omniORB.cfg file: endpoint = giop:tcp:\u0026lt;IP address of achine\u0026gt;. You must restart omniEvents and omniNames for these changes to take effect.\n Run rh_net_diag to help diagnose any problems. Refer to for more information on how to use rh_net_diag.\n Configuring JacORB to Support the IDE The IDE uses JacORB version 3.3 for CORBA communication. The IDE includes a configuration file for JacORB in the IDE’s directory (in configuration/jacorb.properties). The file includes explanations and examples for many of JacORB’s configuration options. For more information, refer to chapter 3 of the JacORB 3.3 Programming Guide. Typically, there is no need to adjust any JacORB settings.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/launching-a-domain/",
	"title": "Launching a Domain",
	"tags": [],
	"description": "",
	"content": " If REDHAWK was installed from RPMs, a Domain Manager and Device Manager are ready for immediate use on the localhost. To launch a default domain in the IDE, follow these steps:\n In the REDHAWK Explorer View (by default, on the right-side of the window) right-click the Target SDR element and select Launch Domain…:\nLaunching a Domain  In the Device Manager section of the Launch Domain Manager window, select DevMgr_*hostname*:\nDevice Manager Selection  Click OK.\n  This launches both a Domain Manager and a Device Manager that manages a single GPP device. The output from both the Domain Manager and Device Manager is displayed in the Console view. If this view is not visible, select Window \u0026gt; Show View \u0026gt; Console. To stop these processes, click the Terminate icon (red square). To toggle between consoles, click the Display Selected Console icon (computer monitor):\nTerminate Icon Display Selected Console Icon The REDHAWK_DEV domain connection is displayed in the REDHAWK Explorer View. Its state is CONNECTED and there are no errors. A Domain Manager process and a Device Manager process now exist on the host.\nDomain Connections Show in IDE Shutting Down the Domain Normally, the Domain Manager and Device Manager remain running indefinitely; these programs are designed to remain running for extended periods of time as different parts of the overall domain (e.g., Device Managers, applications, and files on $SDRROOT) come and go. However, for the purpose of the following procedure, the process for shutting down a running domain is explained. To cleanly shutdown, it is best to disconnect the domain and stop the processes that have been started.\n In the REDHAWK Explorer View, right-click the REDHAWK_DEV domain and select Disconnect\nDisconnect From Domain  In the Console view, select the Device Manager Console from the Display Selected Console icon.\n To stop the Device Manager, click the Terminate icon.\n In the Console view, select the Domain Manager Console from the Display Selected Console icon.\n To stop the Domain Manager, click the Terminate icon.\n Select File \u0026gt; Exit.\n  The Domain Manager and Device Manager processes no longer exist on the host. The domain entry remains in the REDHAWK Explorer View with a DISCONNECTED state indicating that the domain is no longer visible. This decoupling of the running domain from the environment enables the REDHAWK Explorer to interact with an arbitrary number of domains on a network where each domain’s life cycle is outside the control of the IDE.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/launching-the-ide/",
	"title": "Launching the REDHAWK IDE for the First Time",
	"tags": [],
	"description": "",
	"content": "This section describes the basic process for starting the REDHAWK IDE for the first time.\nBefore starting the REDHAWK IDE for the first time, the REDHAWK Core Framework and the IDE must be installed (Installation).\n  Start the REDHAWK IDE by entering the following command:  rhide At startup, the IDE may prompt for a workspace location. The workspace stores many of the IDE’s settings and also acts as a logical collection of projects under development. The IDE creates new projects in the workspace by default.\nIf you upgraded from 1.8.x, 1.9.x, or 1.10.x, it is recommended that you use a different workspace location rather than reusing a previous version’s workspace. If you set the workspace to the same workspace that you used in 1.8.x, 1.9.x, or 1.10.x, you must delete the domain from REDHAWK Explorer before launching the domain from Target SDR.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/messaging/message-producer/",
	"title": "Message Producer",
	"tags": [],
	"description": "",
	"content": " To create a message producer, create a new component or edit an existing component.\n Add a Struct property  Choose an ID that uniquely identifies the message produced. Select the kind for the property as only message Add any arbitrary number of members to the struct  Add uses port of IDL Interface ExtendedEvent\u0026gt; MessageEvent Regenerate the component  For the purposes of the following examples, assume that the structure is as follows:\n id: foo Contains two members:  name: some_string, type: string name: some_float, type: float  The component’s uses port is called message_out The component’s name is message_producer If a connection exists between this component and either a message consumer or an EventChannel, the following code examples send a message.  C++ Whenever a message needs to be generated (e.g., in the serviceFunction() method of the implementation file):\nfoo_struct my_msg; my_msg.some_string = \u0026#34;hello\u0026#34;; my_msg.some_float = 1.0; this-\u0026gt;message_out-\u0026gt;sendMessage(my_msg); A specific connection may be targeted by providing a connectionId argument:\nthis-\u0026gt;message_out-\u0026gt;sendMessage(my_msg, \u0026#34;connection_1\u0026#34;); If connectionId does not match any connection, an std::illegal_argument exception is thrown.\nJava Whenever a message needs to be generated (e.g., in the serviceFunction() method):\nfoo_struct my_msg = new foo_struct(); my_msg.some_string.setValue(\u0026#34;hello\u0026#34;); my_msg.some_float.setValue((float)1.0); this.port_message_out.sendMessage(my_msg); A specific connection may be targeted by providing a connectionId argument:\nthis.port_message_out.sendMessage(my_msg, \u0026#34;connection_1\u0026#34;); If connectionId does not match any connection, an IllegalArgumentException is thrown.\nPython Whenever a message needs to be generated (e.g., in the process() method of the implementation file):\nmy_msg = message_producer_base.Foo() my_msg.some_string = \u0026#34;hello\u0026#34; my_msg.some_float = 1.0 self.port_message_out.sendMessage(my_msg) A specific connection may be targeted by providing a connectionId argument:\nself.port_message_out.sendMessage(my_msg, \u0026#34;connection_1\u0026#34;) If connectionId does not match any connection, a ValueError is raised.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/",
	"title": "Python Sandbox",
	"tags": [],
	"description": "",
	"content": " The Python-based Sandbox is a Python package that is imported as any other Python package. Included in the Python package are tools that provide a means for passing BulkIO data to and from components or devices. Plotting is also supported from the Python package. This section discusses how to instantiate and test a component using the provided Sandbox tools.\nThe Sandbox is Python-centric, so its use requires some basic Python knowledge.\nSetup In order to run the Sandbox, REDHAWK must be installed and the OSSIEHOME and SDRROOT environment variables must be set correctly.\nTo use the Sandbox none of the following programs need to be running: omniNames, omniEvents, Domain Manager, Device Manager, nodeBooter\nThe Python-based Sandbox includes basic analytical plotting tools based on the matplotlib Python plotting library. To use these plots, the following Python packages must be installed:\n matplotlib PyQt4  Starting the Sandbox The Python-based Sandbox, like any other Python module, may be used in another Python program or run directly within the Python interpreter. The following examples assume that the Sandbox is being used within the Python interpreter.\nTo begin, start a Python interpreter session and import the Sandbox:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb As with any other Python module, the built-in functions help() and dir() are useful when searching for available commands.\n\u0026gt;\u0026gt;\u0026gt; help(sb) \u0026gt;\u0026gt;\u0026gt; dir(sb) To exit the Sandbox, press Ctrl+D at the Python prompt. On exit, the Sandbox terminates and cleans up all of the components and helpers it creates.\nRunning the Sandbox Within the Sandbox, components and helpers are launched in an idle state. In order to begin processing (e.g., serviceFunction() in C++ components), each object must be started.\nAfter the desired components and helpers are created, the start() method starts all registered objects:\n\u0026gt;\u0026gt;\u0026gt; sb.start() It is not necessary to stop the Sandbox prior to exiting, as this is handled as part of normal exit cleanup. However, if you wish to stop processing, the stop() method stops all registered objects:\n\u0026gt;\u0026gt;\u0026gt; sb.stop() In non-interactive scripts, the Python interpreter exits after the last statement. This may be undesirable, such as in the case where a set of components should run for an arbitrary amount of time, with their output monitored via plots. The built-in Python method raw_input() can be used to prevent the interpreter from exiting:\n\u0026gt;\u0026gt;\u0026gt; raw_input() When using plots, calling raw_input() instead of time.sleep() allows the UI thread to continue updating.\n Items launched in the Sandbox are registered in the Sandbox’s internal state. To view the items that are deployed in the Sandbox, use the show command:\n\u0026gt;\u0026gt;\u0026gt; sb.show() The items shown by the show command are referenced by a unique name. To recover an item by its Sandbox internal name, use the getComponent function:\n\u0026gt;\u0026gt;\u0026gt; comp = sb.getComponent(\u0026#34;name\u0026#34;) Connecting to a Running Domain The Python Sandbox allows a developer to not only launch components, but it also allows one to interact with a live Domain. This is accomplished through the redhawk package.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/redhawk-core-assets/",
	"title": "REDHAWK Core Assets",
	"tags": [],
	"description": "",
	"content": " REDHAWK packages Core Assets that consist of starter/example Components, Devices, Waveforms, and Shared Libraries.\nREDHAWK Basic Components REDHAWK Basic components are a collection of starter/example REDHAWK components. These components provide basic DSP capabilities while demonstrating many of the features and use cases of REDHAWK.\nThe following Basic components have been removed:\n DataWriter and DataReader have been deprecated by FileWriter and FileReader, respectively. whitenoise has been deprecated by SigGen, which includes a whitenoise generation mode. BurstDeserializer, freqfilter, medianfilter, and unwrap have been removed.  The following Basic components have been updated to use the new shared library dependencies: agc, AmFmPmBasebandDemod, ArbitraryRateResampler, autocorrelate, fastfilter, psd, and TuneFilterDecimate.\n    component Version Description     rh.agc 2.0 Provides automatic gain control to normalize power levels for real or complex signals.   rh.AmFmPmBasebandDemod 2.0 Performs analog demodulation on complex baseband input signals.   rh.ArbitraryRateResampler 2.0 Resamples a data stream at output rates that are not limited to integer multiples of the input sampling rate. This component can increase or decrease the sample rate. No anti-aliasing filtering is included, therefore, you must use this component with caution when decreasing the sampling rate to avoid aliasing or, if required, pre-filter in an upstream component.   rh.autocorrelate 2.0 Performs a frequency domain implemenation of a windowed autocorrelation algorithm. This algorithm works by windowing the input data to break it up into separate frames. Each frame is independently autocorrelated with each other frame using a \u0026ldquo;full\u0026rdquo; autocorrelation, which includes the full transient response. This is efficiently computed in the frequency domain.   rh.DataConverter 4.0 Converts between BulkIO data types in REDHAWK. With proper configuration, converts between any of the following data types; Char, Octet, Unsigned Short, Short, Float, and Double. Also capable of converting real data into complex data, and similarly, complex data into real data. By default, nothing needs to be configured. When using float or double output BulkIO ports, set the normalize_floating_point with the floatingPointRange of -1 and 1.   rh.fastfilter 2.0 Provides a FIR filter implementation using the FFT-based overlap-add technique. This component includes a filter designer, which aids in impulse response creation for lowpass, highpass, bandpass, and bandstop filters. The component accepts custom impulse responses via property configuration.   rh.fcalc 2.0 Enables users to perform calculations on one or two input streams simultaneously on an element by element basis. The calculation is specified in Python syntax using a and b to denote input on the a and b ports. Valid examples: 3*a+b and a*math.cos(b).   rh.FileReader 4.0 Reads in a file and converts it to BulkIO data to be streamed out. Capable of sending data, regardless of file format, out of most of its ten data ports. This ability excludes the XML port. To use this component, the file_format must match that of the file and you are required to specify a source_uri (location of the file); a sample_rate; the center_frequency when applicable; and the playback state to play.   rh.FileWriter 4.0 Writes out a data file from a BulkIO stream. It is not capable of changing the file format to be different from the BulkIO input stream. To use this component, you are required to specify a destinations_uri (location to write to) and a file format and set recording_enable to true.   rh.HardLimit 2.0 Thresholds data so that all data is between the upper and lower limit as specified by the properties.   rh.psd 2.0 Transforms data from the time domain to the frequency domain using an FFT-based PSD. Output data is framed data where each frame contains the frequency domain representation of a subsection of the input. This component provides both the real-valued PSD and the complex FFT outputs.   rh.psk_soft 2.0 Takes complex baseband pre-d data and does a PSK demodulation of either BPSK, QPSK, or 8-PSK and outputs symbols and bits. Input must be an integer number of samples per symbol (recommended 8-10).   rh.RBDSDecoder 2.0 Decodes RBDS data from broadcast FM using the RBDS Standard Specification.   rh.SigGen 2.0 Generates different output signals based on its configuration. Contains an implementation in each of the supported languages (Python, C++, Java) and is an example of a component with multiple implementations.   rh.SinkSDDS 1.0 Accepts BulkIO data and produces a single SDDS stream over the provided multicast or unicast address.   rh.sinksocket 2.0 Reads data from a BulkIO port and writes it to a TCP socket.   rh.SinkVITA49 3.0 Creates a UDP/multicast or TCP VITA49 packet stream and converts the data and SRI Keywords to IF data packets and Context packets for use within/between/outside of a REDHAWK domain application.   rh.SourceSDDS 1.0 Consumes a single SDDS formatted multicast or unicast UDP stream and outputs the data via the appropriate BulkIO native type.   rh.sourcesocket 2.0 Reads data from a TCP socket and writes it to a BulkIO port.   rh.SourceVITA49 3.0 Connects to a UDP/multicast or TCP VITA49 packet stream and converts the headers to SRI Keywords and data to the BULKIO interface of the user’s choice for use within REDHAWK domain applications.   rh.TuneFilterDecimate 2.0 Selects a narrowband cut from an input signal. Tuning, filtering, and decimation are used to remove noise and interference in other frequency bands and reduce the sampling rate for more efficient downstream processing.    REDHAWK Basic Devices    Device Version Description     rh.FmRdsSimulator 2.0 Designed to be used in conjunction with the libRfSimulators library. Using the simulator library, this FrontEnd Interfaces compliant REDHAWK device will generate FM modulated mono or stereo audio with RDS encoded PI (Call Sign), PS (Short Text), and RT (Full Text) data.   rh.MSDD 3.0 FrontEnd Interfaces compliant device for the MSDD-X000 series receivers. Supports multiple FPGA loads for the target hardware. The device provides an RX_DIGITIZER and an RX_DIGITIZER_CHANNELIZER capability.   rh.RTL2832U 2.0 Interfaces with the Realtek RTL2832U usb dongle device using the librtlsdr Device dependency. Supports various tuners, including Elonics E4000, Rafael Micro R820T and R828D, Fitipower FC0012 and FC0013, and FCI FC2580.   rh.USRP_UHD 4.0 FrontEnd Interfaces compliant device for the USRP that requires the UHD host code and supporting libraries to be installed.    REDHAWK Basic Waveforms    Waveform Version Description     rh.basic_components_demo 1.0 Uses a few core assets. Data from SigGen is created and manipulated to demonstrate REDHAWK.   rh.FM_RBDS_demo 1.0 Processes the RBDS digitial message present in broadcast FM radio signals. Tunes and filters out this signal, performs a BPSK demodulation, and then decodes the RBDS data.   rh.FM_mono_demo 1.0 Processes the mono audio channel of broadcast FM Radio.   rh.short_file_to_float_file 1.0 Reads in a file containing shorts, converts them to floats in REDHAWK, and then writes out the file. Uses three components: FileReader, DataConverter, and FileWriter.   rh.socket_loopback_demo 1.0 Puts REDHAWK data out onto a network socket using sinksocket and then reads it back from the socket into REDHAWK via sourcesocket.   rh.VITA49_loopback_demo 1.0 Uses the sourceVITA49 and sinkVITA49 components to demonstrate how VITA49 network data can move into and out of REDHAWK.    REDHAWK Shared Libraries All shared library (formerly soft package) dependencies have been repackaged using the new code generators, and the following basic components have been updated to use the new shared library dependencies: agc, AmFmPmBasebandDemod, ArbitraryRateResampler, autocorrelate, fastfilter, psd, and TuneFilterDecimate.\nThe following shared libraries have been renamed:\n redhawk-VITA49Libraries_V1 has been renamed VITA49. RedhawkDevUtils_v1 has been renamed RedhawkDevUtils.      Shared Library Version Description     rh.blueFileLib 2.0 Provides a library for interacting with Midas BLUE files, the standard binary file format used by modern Midas frameworks.   rh.dsp 2.0 Provides a DSP library for basic components. Much of the actual signal processing code is contained in this library, which is independent of REDHAWK.   rh.fftlib 2.0 Provides a DSP library wrapping FFTW for basic components. Provides a higher level of functionality than what is contained in FFTW by providing classes for taking FFTs and their inverses and signal processing classes, which leverage these FFT capabilities.   rh.RedhawkDevUtils 4.0 Provides a library that contains utility functions useful for REDHAWK development. Utility functions are included for working with vectors, byte swapping, file I/O, universal data types, and transforms between data types, as well as assisting with compatability across multiple boost versions. Additionally, various REDHAWK helper functions are provided for UUID generation and CORBA serialization, and working with Properties, BulkIO, base-64 characters, strings, and Domain Managers.   rh.VITA49 3.0 Provides VITA Radio Transport (VRT) libraries that represent a (nearly-complete) software-based implementation of the following ANSI specifications: VRT/VITA 49.0 VITA Radio Link Layer (VRL) / VITA 49.1    REDHAWK Device Dependencies    Device Dependency Version Description     libRfSimulators 1.1 Used to simulate an RF Digitizer. At present, the RF Simulators library contains a single implementation: the FM RDS Simulator. While the RF Simulators library was designed to be used within the REDHAWK SDR environment, the library itself has no dependency on the REDHAWK framework and may be used as a stand alone C++ library.   librtlsdr 0.5.2 Provides the rtl-sdr hardware driver that enables Realtek RTL2832-based DVB dongles to be used as SDR receivers. Managed by osmocom.org.   uhd 3.7.3 Provides the USRP hardware driver (UHD) for use with the USRP product family. Managed by ettus.com. This is the version shipped with REDHAWK; however, some USRP hardware may require a more current version.    "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/",
	"title": "REDHAWK Manual - 2.1.3",
	"tags": [],
	"description": "",
	"content": " REDHAWK is a software framework designed to support the design, development, deployment, management, upgrade, and recycling of real-time distributed applications as well as the systems that run them.\nTo support the design and development of software applications, REDHAWK provides tools that allow development and testing of software modules, or “components”. In addition, REDHAWK provides tools to facilitate composure of components into “waveforms” that can be seamlessly deployed as “applications” on a single host computer or a network-enabled system of computers.\nDeployment, management, and upgrade of real-time distributed applications is supported by providing a runtime environment.\nThe runtime environment can:\n Deploy components to different computers on a network. Support processing hardware hot-swapping. Manage colliding software dependencies. Manage constrained/specialized hardware resources. Reduce the configuration burden on remote computing hardware. Coordinate the sharing of limited hardware resources between different applications.  Finally, REDHAWK supports the recycling of applications by establishing strong boundaries between processing stages and providing an integration path for existing libraries into the REDHAWK infrastructure.\nBenefits of Using REDHAWK REDHAWK provides the following benefits when used in a computing system:\n Defines patterns for integrating existing libraries into a common framework. Enables seamless deployment of software applications to one or more computing resources. Decouples specialized hardware from processing algorithms; this allows processing algorithms to be easily ported to new platforms. Supports language agnosticism, allowing appropriate languages to be used for various aspects of the system. Decouples processing software from the UI, allowing for any number of custom uis to operate with the same underlying Core Framework. Supports metadata-tagging of data streams. Supports precision-time-stamping of data API. Provides a powerful and flexible IDE based on the extensible Eclipse Framework. Supports dynamic inter-connection of modules, allowing redirection of data flow during runtime. Provides a data transport mechanism optimized for signal processing applications.  What Systems May Benefit from Using REDHAWK? A hardware/software system may benefit from the use of REDHAWK if it:\n Deals with multiple specialized hardware platforms but with a single software application. Integrates multiple disparate libraries into a single solution space. Emphasizes signal processing development rather than system software development. Distributes its software algorithms to more than one piece of hardware. Partitions development between geographically-separated teams. Supports shifting support work from the development team to a support team. Supports shifting deployment work from the development team to a deployment team.  Relationship to the SCA REDHAWK adopts a significant number of concepts from the SCA (specifically, version 2.2.2). As a result, the SCA specification is a very useful piece of supplemental reading to the REDHAWK documentation.\nOverview of this Document REDHAWK is infrastructure that enables for the distribution of processing elements over an arbitrary number of computers connected to a network. These processing elements can be associated with different types of hardware (i.e.: data acquisition) to ingest/egress data, or to leverage some specialized coprocessors. The REDHAWK framework provides tooling for the creation, deployment, and management of these processing elements and hardware interaction elements.\nThe basic processing element in REDHAWK is a component, which is described in detail in Components and Component Structure. A component is a single linux process. Components interact with each other through connections, which are described in Connections. An application, described in Waveforms, is a logical association of interconnected components.\nHardware interaction elements are called devices. Devices are described in Working with Devices. Devices can be logically associated together in nodes, which are described in Nodes. A specialized device called GPP is used to model the processing availability of a single computer. Each node contains no more than one GPP, and is generally mapped to a single computer. By deploying components through different GPP devices, an application can be automatically distributed over multiple computers. The distributed processing aspects of REDHAWK are discussed in Distributed Computing and RF Devices.\nComponents can either be deployed through a distributed environment called a domain, as seen in The Runtime Environment, or standalone through a Sandbox.\nREDHAWK contains code generators and visualization tools. Descriptions of this tooling are available throughout this document.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/redhawk-yum/",
	"title": "REDHAWK Yum Repository and Packages",
	"tags": [],
	"description": "",
	"content": " The following sections describe the REDHAWK packages and provided dependencies.\nExternal dependencies are also necessary for development with REDHAWK and for building REDHAWK from source.\n REDHAWK Yum Repository All of the REDHAWK packages are included in a yum repository, which can be configured as described in Setting Up the REDHAWK Repository. The repository contains two yum groups (REDHAWK Runtime, and REDHAWK Development) and additional OS dependencies. The yum groups and additional OS dependencies are described in the following sections:\nREDHAWK Yum Groups REDHAWK Runtime  bulkioInterfaces burstioInterfaces frontendInterfaces GPP GPP-profile redhawk-sdrroot-dev-mgr redhawk-sdrroot-dom-mgr redhawk-sdrroot-dom-profile redhawk  REDHAWK Development  redhawk-basic-components redhawk-basic-devices redhawk-basic-waveforms redhawk-codegen redhawk-devel redhawk-ide redhawk-qt-tools  The Development group will install the Runtime group packages as dependencies.\n Dependencies Packaged with REDHAWK Dependencies for RHEL/CentOS 6  libomniEvents2 libomniEvents2-devel log4cxx log4cxx-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB uhd uhd-debuginfo uhd-devel uhd-doc uhd-firmware  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install libomniEvents2 libomniEvents2-devel log4cxx \\  log4cxx-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc \\  omniEvents-server omniEvents-utils omniORBpy-debuginfo omniORBpy-devel \\  omniORBpy-libs python-omniORB uhd uhd-debuginfo uhd-devel uhd-doc uhd-firmware Dependencies for RHEL/CentOS 7  libomniEvents2 libomniEvents2-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install libomniEvents2 libomniEvents2-devel omniEvents-bootscripts \\  omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils \\  omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB \\  uhd uhd-debuginfo uhd-devel uhd-doc uhd-firmware Selective Installation After you set up the REDHAWK yum repository as described in Setting Up the REDHAWK Repository, you can also install individual packages via yum for selective installations.\nFor example, to perform a selective installation that includes the GPP, enter the following command:\nsudo yum install GPP To perform a selective development installation that includes the REDHAWK IDE, enter the following command:\nsudo yum install redhawk-ide"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/getting-started/process-management/",
	"title": "REDHAWK’s Approach to Process Management and Interaction",
	"tags": [],
	"description": "",
	"content": " This chapter addresses the basic level of decomposition and deployment for REDHAWK and the middleware used to support communications between basic functional units.\nProcess Management The basic functional unit in REDHAWK is a component, which represents a single process on a host computer. The component supports the interfaces necessary to initialize, configure, query, test, connect to other components, and terminate the component. It also manages a processing thread which contains the component’s functionality and the buffering of input/output data. components can be written in C++, Python, or Java.\nA waveform is a logical collection of components that are to be deployed as an application onto a REDHAWK system and is defined in an XML file. A waveform allows a developer to create algorithms composed of components. The composition of algorithms as separate processes allows REDHAWK to appropriately deploy these components into a network environment. REDHAWK supports distributed computing by finding an appropriate host for a component, deploying the component to that host, and managing that component once it is running.\nData Transfer Data exchange across a network is integral to REDHAWK’s core functionality. Managing the exchange of data is handled through “middleware”, which is a sophisticated software infrastructure that provides a common language for the efficient transfer of data between arbitrary languages over arbitrary media. The middleware selected for REDHAWK is omniORB, an implementation of the CORBA (Common Object Request Broker Architecture) specification. REDHAWK uses omniORB because it provides substantial technical benefits over other middleware implementations.\nThe primary benefits of using omniORB include:\n omniORB is a small package that is easy to build and install. It supports Python and C++ by default and was easily expandable to support Java. omniORB data transfers are very efficient. The pluggable nature of omniORB’s communication mechanism allows the use of multiple underlying transport protocols that can be tailored based on the deployment environment. For example, components that are located on the same host use Linux domain sockets for the transfer of data as an alternative to IP-based communications. CORBA handles the data translation between different host types (e.g., 32-bit versus 64-bit systems and big endian versus little endian). CORBA supports the Any type, allowing generic compatibility between interfaces. omniORB implements the open standard CORBA, allowing system developers to use whatever other implementation of CORBA they may want to use for their infrastructure to interact with the underlying REDHAWK system.  The technical benefits of omniORB come at the cost of CORBA’s awkward language mapping. This disadvantage is addressed in REDHAWK by mapping CORBA constructs to native language types through code generators and base classes, thus alleviating the burden of CORBA’s complexity from the REDHAWK user.\nIn conclusion, omniORB is a simple and efficient middleware package that allows programs in C++, Python, or Java to interact with each other. The disadvantages from CORBA are mitigated by the REDHAWK framework, while CORBA’s inherent benefits, such as platform independence, generic type support, strongly-typed interfaces, and open standard, bring powerful features to REDHAWK.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/nodes/running-a-node/",
	"title": "Running a Node",
	"tags": [],
	"description": "",
	"content": " As part of the REDHAWK install, a domain and node are setup by default. To launch the domain and node refer to Launching a Domain.\nExploring the Running Node  In the REDHAWK Explorer View, expand REDHAWK_DEV. Expand Device Managers. Expand DevMgr_\u0026lt;localhost\u0026gt;.localdomain. Select GPP_\u0026lt;localhost\u0026gt;_localdomain. Select the Properties view tab. The Properties view displays all the properties for this device, such as the operation system name, amount of available memory, and other important information, as seen below:  Properties View of a Running GPP Creating a Component that Consumes Resources  Create a Python component called sample. On the Project View, select the Implementations tab. On the bottom-right of this view, the Dependencies section is visible. Click Add\u0026hellip; on the Dependency subsection of the Dependencies section. In the Dependency Wizard, select Kind=Property Reference and Type=allocation. The Refid field is more complicated; the component needs to be given some property that the component consumes when it is running on a device. An example of such a property is memory. For this example, memory is an attribute (property) of the device that the component consumes. To describe this, click the Browse button on the Refid field and select GPP:memCapacity (do not worry if there are multiple instances of the same property on the list, just pick one). After selecting this property, the globally unique ID of the property populates the Refid field, which in this case is: DCE:8dcef419-b440-4bcf-b893-cab79b6024fb (this is the id of the corresponding property of the gpp). To complete the dependency definition, provide a value for the consumption of this property: in this case, set Value=1000. Click Finish. Save the project, generate the code and drag the component project to REDHAWK Explorer \u0026gt; Target SDR.  Create a Waveform for the New Component  Create a new waveform called sample_deploy. Drag the component sample from the Palette onto the Diagram. Save the project and drag the project sample_deploy from the Project Explorer to REDHAWK Explorer \u0026gt; Target SDR.  Observe the Effect of Launching the Component  On the running domain, select GPP_\u0026lt;localhost\u0026gt;_localdomain and note the value for memCapacity on the Properties tab for the GPP device. Launch the application sample_deploy on the running domain (right-click domain, select Launch Waveform\u0026hellip; \u0026gt; sample_deploy \u0026gt; Finish). Note memCapacity for GPP_\u0026lt;localhost\u0026gt;_localdomain again; it is 1000 less than before the launch of the application. Release the application (REDHAWK_DEV \u0026gt; Waveforms \u0026gt; sample_deploy_\u0026lt;#\u0026gt; right-click Release). Note memCapacity for GPP_\u0026lt;localhost\u0026gt;_localdomain again; it is restored to the original value.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/softpkg-editor/",
	"title": "SoftPkg Editor",
	"tags": [],
	"description": "",
	"content": " To open the SoftPkg Editor, double-click an SPD file from the Project Explorer View. It presents all the content that can be found within the spd.xml file in an editing environment designed for ease of use. If the SPD file references a PRF or SCD file, additional tabs are made available that represent these files in similar fashion.\nEach of the editor tabs, with the exception of the raw XML tabs, have the following buttons located in the top right corner:\n Generate All Implementations Button: This button is used to generate the code implementation of the SPD file. The generated code is based on the code generator template that was chosen during the New Project Wizard and the content found within the SPD, PRF, and SCD files. Code generation is not exhaustive, and custom port types may not compile.\n  New Control Panel Button: This button is used to generate a new control panel.  The SoftPkg Editor is organized into four main tabs:\n Basic information about the SoftPkg can be edited from the Overview tab Properties and messages can be edited from the Properties tab Ports can be edited from the Ports tab Implementations and code generation settings can be edited from the Implementations tab.  The following sections describe each of these tabs.\nOverview Tab The Overview tab is a representation of the content found within the SPD file and contains five sections:\n The General Information section provides the ability to view and set (if write permissions are granted) the resource’s ID and Name as well as the location of the PRF and SCD files. The initial content of these fields is auto-generated when the project is created and is generally left unaltered. The optional fields, Version, Title, and Description, may be set to aid in the project’s documentation. The Project Documentation section displays a Header hyperlink, which if clicked, provides the option to create and edit the file \u0026ldquo;HEADER\u0026rdquo; in the project. When code generation is performed, the header is applied to your project files. The Interfaces section lists the IDLs that this resource inherits. This includes IDLs used by the resource’s ports, lifecycle, and properties. This table is read only, and additional IDL interfaces cannot be added here. The Testing section displays two hyperlinks. Launch a local component launches a local instantiation of this resource within the Sandbox. Launch a local component in debug mode provides additional runtime control, including the ability to place breakpoints, pause execution, and inspect and modify variables. See Debugging REDHAWK Components and Devices with Eclipse for more information. The Exporting section provides a hyperlink for deploying a project to the SDR Root. Use the following procedure to export a project using the Export Wizard:\n Click Export Wizard. Select the projects to export. Type or browse to the export location. Click Finish.   Properties Tab SoftPkg Editor Properties Tab Within the Properties tab, the All Properties section displays all of the properties defined for the component or device.\nTo add a property, click on one of Add Simple, Add Sequence, Add Struct or Add StructSeq to create a new property of the corresponding type. To remove a property, select it in the All Properties section and click the Remove button on the right. To clone existing properties, click Browse\u0026hellip; and select from items in the SDRROOT, projects in the workspace, or well-known properties. In addition to creating a new property from scratch, a user may also copy an existing property from a deployed resource:\n In the All Properties Section, click Browse…. Expand Target SDR. Drill down to and select the desired property. Click Finish.  When a property is selected in the All Properties section, a type-specific details section appears on the right-hand side of the tab. All property types include a few common fields:\n Name is optional, but if given, is favored over the ID for generated code. ID is an identifier that is unique from all other properties within the component or device. It must be used when accessing the property via APIs. Kind describes the intended use of the property. The default is property. Mode determines whether the property can be read and/or written. The default is readwrite. Description is optional; it documents the intended use of the property. User interfaces may present the description as help text.  Nested properties—fields in a struct, or the struct definition for a struct sequence—do not include Kind or Mode. The parent property determines these fields.\nThe Simple Property details section includes additional fields:\n Type describes the basic data type of the property (e.g., float). For complex numeric types, select complex in the the combo box next to the type. Value is the initial value for the property. If not given, the initial value is undefined. Units is strictly informative, but may be displayed in user interfaces. Enumerations is a mapping of human-readable string labels to values. User interfaces may use the enumerations to present the labels in place of values. Action is only applicable to properties with a kind of allocation. Range, if enabled, sets optional lower and upper limits on the value. The range is not enforced by generated code; however, user interfaces may choose to enforce it.  Ordinarily, properties are set to their initial value via a call to the component or device’s initializeProperties() method. However, for certain use cases, simple properties may receive their initial value on the executable command line by enabling the Pass on command line checkbox, located next to Kind.\nIn the Simple Sequence details section, the fields Type, Units, Action and Range are identical to those for simple properties. The default value of a simple sequence property can be viewed or edited via the Values list.\nThe fields that make up a struct property are displayed as children of the struct in the All Properties section.\n To add a field, right-click the struct in the All Properties section, select New and then select one of Simple or Simple Sequence. To remove a field, select the field in the All Properties section and click Remove.  The default value of a struct property is the determined by the default values of its fields.\nIf any field has a default value, all fields must have a default value.\n The default value of a struct sequence may be viewed or edited via the StructValue section in the Struct Sequence Property details section.\nThe struct definition appears as a child of the struct sequence in the All Properties section. It may be modified in the same manner as a struct property.\nPorts Tab SoftPkg Editor Ports Tab The Ports tab provides the ability to add, edit, and view port information.\nClick Add to create a new port with default values. The Port Details section shows the new port, which can be modified as needed:\n Give the port a Name unique to this component or device. Select a Direction: either input, output, or bidirectional.  Only Message Consumer ports should be bidirectional.\n  The Type is optional and strictly informative. A port may have one or more type, defaulting to control if none is selected. Select the IDL Interface that this port implements. Click Browse… to open the selection dialog. By default, the interface selection dialog only shows the most common interfaces used in REDHAWK. Select the Show all interfaces checkbox to show the complete list for IDL interfaces within the Core Framework’s install location.\n  Optionally, enter a Description of the port, such as its intended use.  An existing port may be edited by selecting it from the All Ports section and changing its options via the Port Details section.\nTo remove a port, select it from the All Ports section and click the Remove button.\nImplementations Tab The Implementations Tab is a representation of the content found within the SCD file. It describes the programming language implementations that are generated and the hardware dependencies required for this resource.\nDuring the New Project Wizard, the initial programming language and code generation template were selected. In the All Implementations section there is the option to add additional programming language implementations.\nThe right portion of the editor is context sensitive, and displays the information pertaining to the selected implementation.\n The Implementation section defines the compiler for the selected language and provides a custom description for this implementation. The Dependencies section provides the opportunity to place limitations on a resource so that it may only execute on a suitable device. This is done through the use of property dependencies. A resource’s execution may be limited to a particular device by placing a dependency on a device’s property. To provide compatibility among different sets of users, well known properties have been created, including different OS and processor types. The OS and processor dependencies sections contain a preset list of properties to select from. The Code section indicates the local file name, priority, and executable for the implementation. The Code Generation Details section contains configuration values for the implementation’s code generation. This includes the code template used, output folder location and code generator properties.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/the-connection-process/",
	"title": "The Connection Process",
	"tags": [],
	"description": "",
	"content": "All connections take a client-server pattern. All calls are made from the client to the server. It is the role of the server to provide a set of functions that can be called by the client. It is the role of the client to understand what interfaces the server provides and to invoke (use) them. This is the basis for the uses/provides nomenclature for ports.\nAll uses ports implement the CF::Port interface. CF::Port is an interface that is part of the REDHAWK Core Framework; it contains only two methods: connectPort() and disconnectPort(). To connect a uses port to a provides port, an external entity needs to invoke the connectPort() function on the uses port, where the arguments are a CORBA pointer to the provides port and a string that identifies that connection. To sever a connection, an external entity needs to invoke the disconnectPort() function on the uses port, where its only argument is the string ID used to establish the connection. In the case of an application, the connections are established/destroyed by an object in the Domain Manager process space based on the waveform’s XML file. In the case of the Sandbox, the Sandbox makes the correct calls to establish and destroy a connection based on user input.\nAll provides ports must implement an interface described in IDL. This interface implements the methods that the uses port invokes after a connection has been made. When a uses port is given a pointer to a provides port, it essentially casts this generic pointer to the interface that it believes the provides port to implement. If this casting process fails, an exception is raised during the connectPort() call.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/interacting-with-hardware/",
	"title": "Using Devices to Interact with Hardware",
	"tags": [],
	"description": "",
	"content": "REDHAWK devices can be used to interact with hardware receivers and digitizers, for example, a data acquisition board or a USRP. To have a REDHAWK component use a REDHAWK device, you can establish a usesdevice relationship between a component and a device. The usesdevice relationship requires the component to only use that particular type of device . The REDHAWK distribution includes three devices that can be used out-of-the-box: Realtek RTL2832-based DVB dongles with Osmocom’s rtl-sdr library, Ettus’s USRP, and an FM RDS simulator with the libRfSimulators library.\nThe following example explains how to use the FmRdsSimulator REDHAWK device to receive and process a generated FM signal, and provide the audio and a plot of the signal.\nThe RTL2832U REDHAWK device can be substituted for the FmRdsSimulator REDHAWK device to receive a live FM signal.\n  Open the Python Sandbox and import the frontend module.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; import frontend Launch the FmRdsSimulator device, the AmFmPmBasebandDemod component, the fastfilter component, the ArbitraryRateResampler component, the SoundSink Sandbox component, and set up the REDHAWK IDE plotter.\nTo plot data, the REDHAWK IDE must be installed and the path to the Eclipse directory of the installed IDE must be specified in the Sandbox. This can be done through the IDELocation() function.\n \u0026gt;\u0026gt;\u0026gt; sim = sb.launch(\u0026#34;rh.FmRdsSimulator\u0026#34;) \u0026gt;\u0026gt;\u0026gt; demod=sb.launch(\u0026#34;rh.AmFmPmBasebandDemod\u0026#34;) \u0026gt;\u0026gt;\u0026gt; filter=sb.launch(\u0026#34;rh.fastfilter\u0026#34;) \u0026gt;\u0026gt;\u0026gt; resample=sb.launch(\u0026#34;rh.ArbitraryRateResampler\u0026#34;) \u0026gt;\u0026gt;\u0026gt; agc=sb.launch(\u0026#34;rh.agc\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sink=sb.SoundSink() \u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse/directory\u0026#34;) \u0026gt;\u0026gt;\u0026gt; plot=sb.Plot() Connect devices and components.\n\u0026gt;\u0026gt;\u0026gt; sim.connect(demod) \u0026gt;\u0026gt;\u0026gt; demod.connect(filter, usesPortName=\u0026#34;fm_dataFloat_out\u0026#34;) \u0026gt;\u0026gt;\u0026gt; filter.connect(resample) \u0026gt;\u0026gt;\u0026gt; resample.connect(agc) \u0026gt;\u0026gt;\u0026gt; agc.connect(sink) \u0026gt;\u0026gt;\u0026gt; agc.connect(plot) Configure and start all components and devices in the Sandbox.\n\u0026gt;\u0026gt;\u0026gt; sim.addAWGN=False \u0026gt;\u0026gt;\u0026gt; demod.freqDeviation=15000.0 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.freq1=16000.0 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.Ripple=0.5 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.Type=\u0026#34;lowpass\u0026#34; \u0026gt;\u0026gt;\u0026gt; resample.outputRate=32000.0 \u0026gt;\u0026gt;\u0026gt; sb.start() Create a tuner allocation structure and allocate the device.\n\u0026gt;\u0026gt;\u0026gt; alloc = frontend.createTunerAllocation(\u0026#34;RX_DIGITIZER\u0026#34;, allocation_id=\u0026#34;testing\u0026#34;, center_frequency=100.1e6, sample_rate=256e3,sample_rate_tolerance=20.0) \u0026gt;\u0026gt;\u0026gt; sim.allocateCapacity(alloc) Set the center_frequency property in the allocation structure to the radio station desired. Specifying a bandwidth of 0.0 indicates that any bandwidth is acceptable given that the other parameters are met.\n   Devices may be used within the Sandbox or within a domain, in which case devices are deployed by a Device Manager at startup. The lifecycles of the devices used within the Sandbox follow the same lifecycle as the scripting environment; when the scripting environment is shutdown, the devices are shutdown. The lifecycles of devices deployed by a Device Manager follow the lifecycle of the Device Manager; when a Device Manager is started, the devices associated with that Device Manager are launched, and when the Device Manager is shutdown, the associated devices are released.\nThe configuration of a Device Manager’s Devices is controlled through an XML file called a Device Configuration Descriptor (DCD) file. Any one DCD file associated with a Device Manager instance is often referred to as a node.\nWhen a node is deployed, the devices associated with the node become available to the domain. Applications can contain usesdevice relationships. In other words, elements in the SAD XML file can declare that the application requires the use of a particular type of device. When the application is deployed by the domain, the domain searches through the deployed devices for any one device that can satisfy the declared dependency. Any device that satisfies an application dependency may become busy and unavailable for use by other applications. When the application is released, the device is brought back into the pool of available devices.\nGiven the radio nature of REDHAWK, the interaction between the REDHAWK environment and RF devices has been standardized through a common API, known as FrontEnd Interfaces (FEI).\nIf you have RF FrontEnd hardware that you want to model in REDHAWK, you can use the FEI module to facilitate this process. The FEI module contains interfaces designed to standardize the interaction (allocation, operation, and development) of tuner devices within the REDHAWK Core Framework (between applications and radio hardware). This standard breaks the tie between the application and the hardware and provides more flexibility.\nThe FEI module defines a number of interfaces to enable users to interact with several different generic types of tuners, including:\n Receiver (RX) tuner Receiver Digitizer (RX_DIGITIZER) tuner Channelizer (CHANNELIZER) tuner Digital Down Converter (DDC) tuner Receiver Digitizer Channelizer (RX_DIGITIZER_CHANNELIZER) tuner Transmitter (TX) tuner Receiver With Scanning Capability (RX_SCANNER_DIGITIZER) tuner  Before you can interact with the tuners, you must create a REDHAWK device that is FEI compliant. The following procedure explains how to make a REDHAWK device that is compliant with FEI version 2.4.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/waveforms/waveform-editor/",
	"title": "Waveform Editor",
	"tags": [],
	"description": "",
	"content": " The following sections further describe the definition of the waveform as well as its creation and manipulation within the IDE. Like the PRF, SCD, and SPD XML files of a component, a waveform is completely represented by its SAD file (*.sad.xml). The REDHAWK IDE provides a means of modifying the XML files without the need to directly edit this file by hand.\nOverview Tab Within the Overview tab, the name, Assembly Controller, and external ports of a waveform are defined.\nThe Assembly Controller is a component instance in the waveform that is designated as the component where the waveform-level start(), stop(), configure(), and query() calls are delegated. In complex waveforms, the Assembly Controller can be used to orchestrate the life cycle of components. In trivial waveforms, the identity of the Assembly Controller is of less importance.\nExternal ports are used to make component ports available to other applications, facilitating inter-application connectivity.\nDevelopers use the Overview tab to set the Assembly Controller for the waveform and describe the waveform.\nThe following steps explain how to set the Assembly Controller and describe the waveform.\n On the Overview tab of the Waveform, from the Controller drop-down menu, ensure SigGen_1 is selected. In the Description field, enter a description for the waveform.\nWaveform Overview Tab   Components Tab The components tab displays a master/details form with individual component instantiation elements and their associated details, which can be modified.\nThe master section (on the left) displays all components currently in the waveform. The Add\u0026hellip; and Remove buttons can be used to add and remove components from the waveform.\nThe details section displays the following fields, which can be selected to modify the current values:\n Component ID - Edit the selected component instantiations ID element. Usage Name - Edit the selected component instantiations Usage Name element and Naming Service name, which is based on the component’s usage name. Logging Configuration checkbox - Add or remove a Logging Configuration element to the selected component instantiation. Log Level combo box - Select predefined Logging Levels, including: OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE, and ALL. For more information, refer to . Logging URI - Populate the selected component instantiations logging URI element and provide some context-specific validation.  Diagram Tab Most of the work done on waveforms takes place within the Diagram tab. The Diagram tab is very similar to the Sandbox/Chalkboard. Unlike the Sandbox, only components that exist within the $SDRROOT can be added to the waveform. The Palette contains a list of components residing within the $SDRROOT. From the Diagram tab, external ports of the waveform can be indicated and the role of Assembly Controller can be assigned to a component.\nEditing Component Properties in a Waveform From the Diagram tab, properties of components can be set. When these properties are set, they become specific to the waveform and are written to the *.sad.xml file, which describes this waveform.\nThe following steps explain how to edit the properties of a component in a waveform.\n On the Diagram tab of the waveform, select the component. In the Properties View, verify the Properties tab is selected.\nProperties View  Select the Property you want to set, and edit the value.\n  Editing the devicerequires Set in a Waveform The devicerequires set for a Component is managed through the Requirements tab of the Properties view. When these Requirements are set, they become specific to the waveform and are written to the *.sad.xml file. For more information about the devicrequires set, Refer to .\nThe following steps explain how to edit the devicerequires set.\n On the Diagram tab of the Waveform, select the Component. In the Properties View, verify the Requirements tab is selected.\nProperties View Requirements Tab  To add an ID and value, click + and add the ID and value. The ID and value can be any alphanumeric string value. This assigns a devicerequires key/value pair to the Component.\n To remove an ID and value, select the ID and click X.\n  Start Order Each of the components within the waveform contain a number with a circle around it which represents that component’s start order. The start order represents the order in which its start() method is called by the Assembly Controller. The only component that does not have a start order is the Assembly Controller, which always has an assumed start order of 0. The Assembly Controller has a yellow circle containing 0. The start order may be changed by right-clicking a component and selecting Move Start Order Earlier or Move Start Order Later from the context menu. The Assembly Controller may be changed by right-clicking a component and selecting Set As Assembly Controller from the context menu.\nSAD File Tab The information displayed in the Overview, Components, and Diagram tabs is represented within the XML of the SAD file. The XML can be edited manually, but it is not recommended. Each of the components used within the waveform are referenced within the SAD file by pointing to the file location of the component’s SPD file.\nInstructions for inspecting the SAD file are below:\n Open the myWaveform.sad.xml tab of the waveform Editor. Look through the SAD file and identify:  The location of the two SPD files used in this waveform (remember that this file location is in reference to the $SDRROOT) The Assembly Controller The connection between the two components The external port is set in the Diagram Tab The start order of each component The property is changed on the SigGen component  Before continuing, return to the Diagram tab and change the dataDouble_out port so that it is no longer marked as an external port.  Application Options Two options can be set for applications in the SAD file:\n STOP_TIMEOUT - controls the time allowed before a timeout occurs. The application’s stop function is delegated to each component in the application. In some cases, the component may require an unusually long amount of time to reach a stopped state. To prevent this timeout, configure the application’s option for STOP_TIMEOUT to the desired value. The default timeout value is 3 seconds. To remove the timeout altogether, set the value to 0 or -1. AWARE_APPLICATION - controls the Component’s ability for domain awareness. The default domain awareness value is true. To remove a component’s pointer to the domain, set the option AWARE_APPLICATION to false.  To set the application options from the SAD File Overview Tab in the IDE:\nSAD File Overview Tab  To add an option, expand the waveform Options section, click Add, and enter the value. To edit an option, expand the waveform Options section, select the option and edit the value. To remove an option, expand the waveform Options section, select the option and click Remove.  To set the application options using a text editor, the options section must follow the connections section in the SAD file.\nThe following example XML sets the timeout to 5 seconds and the domain awareness to false:\n\u0026lt;softwareassembly id=\u0026#34;DCE:d67ebd01-d580-47ff-9fe6-5560a9d8f5f8\u0026#34; name=\u0026#34;sample_waveform\u0026#34;\u0026gt; \u0026lt;componentfiles\u0026gt; \u0026lt;componentfile id=\u0026#34;SigGen_062a14e1-d152-4eb0-b580-821567b323c6\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/components/rh/SigGen/SigGen.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;/componentfiles\u0026gt; \u0026lt;partitioning\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;SigGen_062a14e1-d152-4eb0-b580-821567b323c6\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;SigGen_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;SigGen_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;/partitioning\u0026gt; \u0026lt;assemblycontroller\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/assemblycontroller\u0026gt; \u0026lt;connections/\u0026gt; \u0026lt;options\u0026gt; \u0026lt;option name=\u0026#34;STOP_TIMEOUT\u0026#34; value=\u0026#34;5\u0026#34;/\u0026gt; \u0026lt;option name=\u0026#34;AWARE_APPLICATION\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/options\u0026gt; \u0026lt;/softwareassembly\u0026gt; The following example Python session sets the timeout to 5 seconds and the domain awareness to false:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; d=redhawk.attach(\u0026#34;REDHAWK_DEV\u0026#34;) \u0026gt;\u0026gt;\u0026gt; app=d.createApplication(\u0026#34;sample_waveform\u0026#34;, initConfiguration={ \u0026#34;STOP_TIMEOUT\u0026#34; : \u0026#34;5\u0026#34; , \u0026#34;AWARE_APPLICATION\u0026#34; : \u0026#34;false\u0026#34; } )"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/associating-a-waveform/",
	"title": "Associating a Waveform with an FEI Device",
	"tags": [],
	"description": "",
	"content": " Two processes can be used to associate a waveform with an FEI device:\n Write code that creates an allocation and creates the connection between the allocated device and the waveform or component that is to receive or produce the data. Create a usesdevice relationship artifact in the waveform.  The benefit of creating a usesdevice relationship artifact is that the deployment of the waveform can be tied to the availability of hardware resources. If the usesdevice relationship cannot be established at deployment time, then the waveform deployment will fail. Also, when the waveform is torn down, the allocation created for this deployment is undone automatically.\nTo create a usesdevice relationship artifact on the waveform:\n Create a waveform\n Find and place the usesdevice relationship artifact, which is located under the Advanced tab:\nFrontEnd Tuner Device Artifact When the artifact is dragged onto the canvas, a menu of target devices is shown. The devices shown are the result of a scan of $SDRROOT.\n Either select the desired device or select the Generic FrontEnd device, which does not have any ports (so a connection cannot be defined), but it allows an allocation to be associated with the deployment.\nSelect Target Device After selecting a device, a series of wizards are displayed. In the wizards, define the usesdevice relationship ID to use and the parameters for the allocation itself.\nThe usesdevice relationship ID is the identifier used in the waveform description to reference the usesdevice relationship artifact. It is an architectural detail that is not relevant to the developer, so use the default value given.\n  If the device has ports, connect them to the appropriate component:\nCreate a Connection Between the FEI Device and a Component   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/auto-generated-methods/",
	"title": "Auto-Generated Component Methods",
	"tags": [],
	"description": "",
	"content": " This section provides an overview of noteworthy methods provided in the auto-generated component files. In some cases, the names of the methods vary by language.\nserviceFunction() The core functionality of a component resides in the serviceFunction() method in C++, the process() method in Python, and the serviceFunction() method in Java. The serviceFunction() is invoked on a recurring basis after start() is called on the component’s base class.\nconstructor() This is the component/device constructor. When this function is invoked, properties of kind property are initialized to their default or overloaded state.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/sri/",
	"title": "Burst Signal Related Information (SRI)",
	"tags": [],
	"description": "",
	"content": " BurstSRI objects are delivered with each data burst and describe the data payload and processing state from the data producer. The table below describes only the required fields of the data structure when passing burst data between resources.\nBurstSRI fields    Name Type Description     hversion long Version of the StreamSRI header. This field is typically ignored, so a default value of 1 is adequate.   streamID string Stream id. Unique streams can be delivered over the same port, where each stream is identified by a unique string (generated or passed along by the provides side). The generation of this stream ID is application-specific and not controlled by the REDHAWK Core Framework.   xdelta double Delta between two values in the payload vector. In the case of time data, this is the sampling period. In the case of spectral data, this is the frequency difference between two adjacent fft bins.   mode short 0-Scalar, 1-Complex. Complex data is passed as interleaved I/Q values in the sequence. The type for the sequence remains the same for both real and complex data.   expectedStartOfBurstTime BULKIO::PrecisionUTCTime The epoch birth date of the first sample of the sequence.   keywords sequence \u0026lt;CF::DataType\u0026gt; User-defined keywords. This is a sequence of structures that contain an ID of type string and a value of type CORBA Any. The content of the CORBA Any can be any type.    "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/waveforms/sample-waveform/",
	"title": "Create and Deploy a Sample Waveform",
	"tags": [],
	"description": "",
	"content": " This section describes the process of creating a waveform, deploying this waveform to the staging area, starting a Domain Manager and a Device Manager, creating an instance of an application representing this waveform, releasing the application, and shutting down the Domain Manager and Device Manager.\nThe Domain Manager and Device Manager normally remain running during the creation/destruction of different applications.\nCreate a Sample Waveform Below is a description of how to create a waveform:\n Select File \u0026gt; New \u0026gt; REDHAWK Waveform Project\n Set the Project name to demo\n Select Finish\n  This opens an editor on the demo.sad.xml file.\nTo add components to this waveform:\n Select the Diagram tab.\n In the Palette, drag the SigGen component onto the diagram.\n In the Palette, drag the HardLimit component onto the diagram.\n Drag a connection between the SigGen_1 dataFloat_out port and the HardLimit_1 dataFloat_in port.\n The waveform looks like :\nDemo Waveform  If SigGen_1 does not have a yellow 0, right-click the component and select Set As Assembly Controller/\n Press Ctrl+S to save or select File \u0026gt; Save.\n Close the waveform editor by selecting the X or by selecting File \u0026gt; Close All.\n  Export the Waveform Below is a description of how to export the waveform in the IDE:\n In the Project Explorer View (typically on the left-side) select demo.\n Drag the demo project onto the Target SDR in the REDHAWK Explorer View.\n  This installs the waveform into $SDRROOT/dom/waveforms. If a permissions denied error is encountered, ensure that the $SDRROOT is set up per the installation instructions in Installing the Framework from Source.\nVerify that the waveform is installed:\n In the REDHAWK Explorer View expand Target SDR.\n Expand Waveforms.\n Verify that the demo waveform is shown.\n  Run the Waveform on the Runtime Environment This section provides an overview of how to launch a waveform as an application and release an application.\nLaunching a Domain Begin by starting a Domain Manager and Device Manager\nLaunch the Waveform  In the REDHAWK Explorer View right-click the REDHAWK_DEV domain connection.\n Select Launch Waveform\u0026hellip;\n Select the demo waveform, then select Finish.\n To start the waveform, select the Start Waveform (green triangle) button in the toolbar.\n  This opens the waveform explorer. A waveform is displayed in the REDHAWK Explorer by expanding the REDHAWK_DEV domain connection and the waveforms folder.\nOpen a Plot  Left-click the dataFloat_out port to select it.\n Right-click the port to open the port context menu.\n Select Plot Port Data. This opens a plot showing the plot data.\n To clearly view the sinusoid wave in the plot, reduce the frequency produced by SigGen.\n Open the Properties View and change the frequency property to a value of 50.\n  Stop and Release the Application  Select the Stop Waveform (red square) button in the toolbar. The plot stops updating.\n Select the Release Waveform (red X) button in the toolbar. The waveform explorer closes.\n  Shutdown the Domain Finally, shutdown the Domain Manager and Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/creating-a-component/",
	"title": "Creating a Component Project",
	"tags": [],
	"description": "",
	"content": " In this section, an overview of the structure of a component is presented.\nComponent Wizard In the REDHAWK IDE, development of new components, devices, or other artifacts in a REDHAWK environment is contained within an Eclipse project. Each REDHAWK-specific artifact is associated with a wizard that leads the developer through the steps necessary to create a project, which supports the minimum required pieces for proper functioning. For components, the default project settings allow the developer to choose between Python, C++, and Java as the development language. To start the IDE and begin creating a component, run the eclipse binary in the IDE installation directory. Then, select File \u0026gt; New \u0026gt; REDHAWK Component Project.\nComponent Descriptors A REDHAWK component is described through three XML files, a SPD file (\u0026lt;component\u0026gt;.spd.xml), a PRF file (\u0026lt;component\u0026gt;.prf.xml), and a SCD file (\u0026lt;component\u0026gt;.scd.xml). The role of the SPD is to describe all the files that are associated with the component: the PRF and SCD files, all binaries, and associated data files. The PRF file contains a description of all the properties that this component supports. The SCD file contains a description of the component inputs/outputs.\nThe REDHAWK IDE uses an internal model to maintain the state of the component design. This model is a Java representation of the three XML files described above as well as project-specific information (like the development language). The main screen on the component development perspective contains several tabs. Some of these tabs are for panels and some are for XML files. The different panels available for component design are used to change this model; the model is automatically and continuously mapped to the three XML files. This awareness is symmetrical; much like changes in the panels result in changes in the XML files, changes in the XML files result in automatic updates to the panels.\nPorts Data flow into and out of components is accomplished through the use of ports. Ports are described as being either a provides (input) or uses (output) port. This naming convention is often viewed as counter-intuitive, so an explanation is in order. Ports are RPC interfaces to a component. An input port, therefore, provides functionality that can be used by an output port.\nREDHAWK contains a variety of standardized interfaces that facilitate interoperability. These interfaces are implemented by ports. When a port is selected in the component generation wizard in the REDHAWK IDE, code to implement these interfaces is automatically generated.\nProperties Properties provide a way to adjust a component’s configuration or settings while also allowing external entities (e.g., programs, UIs, or status scripts) to inspect the state of the component. Properties are the primary means for component configuration.\nThere are four types of properties: simple, simple sequence, struct, and struct sequence. A simple property has a single value of a particular primitive type (e.g., short or float). A simple sequence is an array of values of a the same primitive type. A struct property is a structure that contains a set of named simple and/or simple sequence properties. A struct sequence is an array of instances of the same struct type.\nProperties also have a kind that expresses the role in which the property is used. The kind can be property, allocation, or message. The property kind is used for configuration and status. The allocation kind is used to express requirements on capabilities provided by devices. The message kind is used only with struct properties to send event messages within REDHAWK.\nLogging Components, irrespective of which language is used for their implementation, contain access to loggers. Logging in C++, Python, and Java utilizes log4j, a powerful logging framework maintained by the Apache Software Foundation.\nGenerating Code for Components After a component project is created and appropriate details for the component are entered in the SPD editor, the IDE can generate skeleton code for the project. To begin the code generation process, click the Generate All Implementations button located in the top-right of the Overview panel of the SPD editor.\nGenerate All Implementations When you click the Generate All Implementations button, the IDE:\n Determines if your project contains any deprecated features from older versions of REDHAWK and prompts you to upgrade them. Displays the files that will be generated and enables you to select/deselect files. Generates code files and applies any headers specified in the project documentation. Updates the SPD file with the version of REDHAWK used to generate code.  Code generation is not exhaustive, and custom port types may not compile.\n Installing Components After a component is compiled, it must be installed in the staging area ($SDRROOT/dom/components). To install a component from the Project Explorer View, drag the top-level component project onto the Target SDR section of the REDHAWK Explorer View. See Deploying Projects to the SDRROOT for additional information.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/nodes/creating-a-new-node/",
	"title": "Creating a New Node",
	"tags": [],
	"description": "",
	"content": " As shown in Exploring the Running Node a node is a Device Manager instance with an associated set of devices and services. A node is completely defined by a DMD XML file. A Device Manager uses the information in this XML file to deploy, configure, and inter-connect devices and services.\nThe REDHAWK Node Project in the REDHAWK IDE provides a mechanism for generating these DMD files. By invoking the REDHAWK Node Project, a wizard is started where the developer selects different characteristics for the node like the project name. In the wizard, the developer must provide both a project name and a Domain Manager name. The Domain Manager name is the name of the domain that the Device Manager automatically associates with upon startup. At runtime, the Domain Manager name that the Device Manager associates with can be overridden.\nThe node project has multiple tabs: Overview, Devices, Diagram, and the DCD file tab (see Node Editor for additional information). The most intuitive tab is the Diagram tab, which allows a developer to drag devices available in $SDRROOT into the node, as shown below. Once the set of members for a particular node is determined, save the project and drag it to Target SDR to install it.\nNode Design Diagram To launch this new node:\n Right-click the node descriptor, Target SDR \u0026gt; nodes \u0026gt; sample_node. Select Launch Device Manager. The running node is now visible under the running domain’s Device Managers section.  Device and Service Affinity The REDHAWK RPMs do not include a Device Manager with the affinity option enabled. To enable affinity processing by the Device Manager, build the REDHAWK software with the affinity option enabled (run the configure command with the –enable-affinity=yes). For more information about the affinity directives and how to include them in a DCD file, consult Resource Affinity. The following example sets the processing affinity for the ChannelizerSW device to use the CPUs from the second processor socket.\n\u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;ChannelizerSW_12345\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Channelizer_1\u0026#34; startorder=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Channelizer_1\u0026lt;/usagename\u0026gt; \u0026lt;affinity\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_class\u0026#34; value=\u0026#34;socket\u0026#34; /\u0026gt; \u0026lt;!-- uses numa_parse_nodestring, socket id\u0026#39;s start at 0 --\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_value\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;/affinity\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Channelizer_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/domain-manager/",
	"title": "Domain Manager",
	"tags": [],
	"description": "",
	"content": " The Domain Manager interface is in charge of the control and configuration of the entire systems domain.\nIts primary responsibilities can be grouped into three main categories:\n Registration Core Framework administration Human Computer Interfacing  Each domain has a single Domain Manager that keeps track of a File Maanger, a set of Device Managers, and a set of Application Factories. The Domain Manager maintains information on all aspects of the waveform’s implementations contained within its system.\nThe Domain Manager is configured from the DMD XML file that is located at $SDRROOT/dom/Domain. This file contains the domain’s name, an ID and a description of the domain.\nLaunching a Domain Manager from the command line Enter the following commands to launch a Domain Manager from the command line:\nnodeBooter -D INFO:DomainManager - Starting Domain Manager INFO:DomainManager - Starting ORB! Registration The Domain Manager is able to maintain information about all working parts and interactions in the environment through registration. It can be thought of as the Domain Manager’s responsibility of bookkeeping for the system.\nAny time a Device Manager, device, service or application is created within the system, it is registered through the Domain Manager. Likewise, when they are destroyed, they are unregistered from the Domain Manager. These tasks are handled through a serious of register() and unregister() functions for each of the different modules that the Domain Manager is responsible for supporting.\nCore Framework Administration The Domain Manager has Core Framework administrative duties that are required to provide interface access to its registered items. The API of the Device Managers, ApplicationFactories, Applications, and the FileManager that are registered in the domain are made available to be accessed from an external piece of software.\nThis is made available so that changes can be made from outside of the running domain. A Python module is distributed with REDHAWK that allows for simple interfacing with a running domain. This allows for runtime inspection and tweaking of the environment.\nHuman Computer Interfacing The Domain Manager is also responsible for providing functionality that allows for simple interaction between the user and the system, granting the user control over the running domain. Functionality exists that provide the ability to configure the domain, get its current device, service and application capabilities and launch maintenance functions.\nCapabilities are managed through a series of data structure sequences. Lists are maintained for all services, Device Managers and devices that have been registered with the domain. Each entry in the list contains name and identification information as well as a reference to the object that has been registered. For any application that has been installed, a reference to its Application Factory is stored in a list along with its name and identification information. Once the application has started, its reference, along with all relevant identification, component, connection and ordering information is stored for later retrieval.\nLogging By default the Domain Manager will output messages to the console. You can provide a custom logging configuration file and logging level using the following options:\nnodeBooter -D -endlogcfgfile \u0026lt;config file\u0026gt; -enddebug \u0026lt;5=TRACE,4=DEBUG,3=INFO,2=WARN,1=ERROR,0=FATAL\u0026gt; This file location will be used as the default value when resolving the LOGGING_CONFIG_URI as well as the DEBUG_LEVEL during deployments. For further details about logging configuration files and LOGGING_CONFIG_URI resolution, consult Logging.\nTo override the default resolution of the LOGGING_CONFIG_URI during deployments, the Domain Manager can be launched with an option to use a plugin library (libossielogcfg.so) for this resolution. To activate this feature launch the Domain Manager as follows:\nnodeBooter -D --useloglib Persistence Store A unique feature of the Domain Manager is the ability to recover from catastrophic failures through domain Persistence. In order to make use of Persistence, a compile-time option must be specified. Ensure that the Core Framework has been compiled from source and that ./configure was run with --enable-persistence=persist_type; see: Installing the Framework from Source.\nWith this feature enabled, all bookkeeping data structures that are used to maintain information about services, devices, Device Managers, Applications and Application Factories are written to a database whenever any change is made to them. This database file needs to be specified upon launch of the Domain Manager with the --dburl \u0026lt;file path\u0026gt; argument:\nnodeBooter -D --dburl $SDRROOT/dom/persistence.sqlite Then, upon failure of the Domain Manager, all ids and references to objects within it domain are stored. Since these objects themselves are actually separate processes, the Domain Manager can be relaunched with the same arguments, and it is restored to the previous state. When the Domain Manager gets launched, it calls the restoreState() function with a file path string as an argument. It then opens the given database file and attempts to parse out any stored information in order to reconnect those processes with the domain. Once this is finished, the domain is rebuilt to the state it was in before it died.\nSystem-Wide Reset When persistence is enabled and the Domain Manager suffers a catastrophic failure, the data storage functions may lose synchronization. (For example, the Naming Service may be out of sync with the object database.) If this occurs, it is necessary to erase the database, clean out the Event Service, and clean out the Naming Service. In such instances, the Device Managers that are operating in the system, which may span multiple computers, also need to be reset to an idle state.\nTo deal with such instances, each Device Manager contains a separate thread that checks to see if the Domain Manager contains a reference to this Device Manager. If the reference is missing, the Device Manager assumes that the Domain Manager has been restarted to a blank state, and the Device Manager resets itself (as well as all devices and services that it controls). After resetting itself, the Device Manager re-associates with the Domain Manager. The frequency with which the Device Manager checks with the Domain Manager is controlled by the Device Manager property, DOMAIN_REFRESH. This property’s default value is 10 seconds but can be set to any system-appropriate setting.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/dependencies/",
	"title": "External Dependencies",
	"tags": [],
	"description": "",
	"content": " The following sections explain how to install the dependencies from the Fedora Extra Packages for Enterpise Linux (EPEL) and Red Hat/CentOS repositories. Dependencies not available from either of those sources are included with REDHAWK.\nIf you are upgrading from a previous 1.8.x version of REDHAWK, some software from the 1.8 series dependencies must be uninstalled before installing the REDHAWK 2.0 series. Enter the following command to uninstall the software:\n sudo yum erase \\  libomniORB4.1 omniORB-debuginfo omniORB-doc \\  libomniORBpy3 omniORBpy-debuginfo omniORBpy-doc \\  omniEvents-doc omniEvents-debuginfo \\  apache-log4cxx apache-log4cxx-debuginfo Installing the EPEL Repository For more information on the Fedora EPEL project, refer to http://fedoraproject.org/wiki/EPEL.\n From the Fedora Downloads Site Install the EPEL repository on your system from the Fedora downloads site.\nFor RHEL/CentOS 7:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm For RHEL/CentOS 6:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm Standalone EPEL from REDHAWK REDHAWK provides a condensed version of the EPEL yum repository that can be used to satisfy the required external dependencies from the EPEL repository. The repository is available from the REDHAWK release page on github (https://github.com/RedhawkSDR/redhawk/releases/\u0026lt;version\u0026gt;). (Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE. For example, for REDHAWK version 2.0.3, https://github.com/RedhawkSDR/redhawk/releases/2.0.3)).\nTo install the Standalone EPEL yum repository from REDHAWK, use the following commands:\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz tar xf redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz cd redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt; sudo yum install --nogpgcheck *.rpm Where \u0026lt;version\u0026gt;, \u0026lt;dist\u0026gt;, and \u0026lt;arch\u0026gt; correspond to the associated REDHAWK version, Linux distribution, and architecture respectively. For example, for REDHAWK version 2.0.3, 64-bit CentOS 6, redhawk-yum-2.0.3-el6-x86_64.tar.gz.\nRuntime-only Dependencies The following dependencies are required for the REDHAWK Framework for runtime, operational-only systems that do not need to support development. These dependencies will enable the installation of Domain Manager, Device Manager, GPP, Core Framework, omniNames, and omniEvents.\nDependencies for RHEL/CentOS 6  python-matplotlib omniORB omniORB-devel omniORB-doc omniORB-servers omniORB-utils python-jinja2-26  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install python-matplotlib \\  omniORB \\  omniORB-devel \\  omniORB-doc \\  omniORB-servers \\  omniORB-utils \\  python-jinja2-26 Dependencies for RHEL/CentOS 7  gstreamer-python python-matplotlib-qt4 log4cxx omniORB omniORB-devel omniORB-doc omniORB-servers omniORB-utils python-jinja2  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install gstreamer-python \\  python-matplotlib-qt4 \\  log4cxx \\  omniORB \\  omniORB-devel \\  omniORB-doc \\  omniORB-servers \\  omniORB-utils \\  python-jinja2 Dependencies for Development and Building from Source The following dependencies are required for development with the REDHAWK Framework and building REDHAWK from source.\nDependencies for RHEL/CentOS 6  libuuid-devel boost-devel autoconf automake libtool cppunit-devel expat-devel gcc-c++ java-1.8.0-openjdk-devel junit4 python-devel python-matplotlib numpy PyQt4 omniORB omniORB-devel omniORB-doc omniORB-servers omniORB-utils python-jinja2-26 xsd  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install libuuid-devel \\  boost-devel \\  autoconf automake libtool \\  cppunit-devel \\  expat-devel \\  gcc-c++ \\  java-1.8.0-openjdk-devel \\  junit4 \\  python-devel \\  python-matplotlib \\  numpy \\  PyQt4 \\  omniORB \\  omniORB-devel \\  omniORB-doc \\  omniORB-servers \\  omniORB-utils \\  python-jinja2-26 \\  xsd Dependencies for RHEL/CentOS 7  gstreamer-python libuuid-devel boost-devel cppunit-devel autoconf automake libtool expat-devel gcc-c++ java-1.8.0-openjdk-devel python-devel python-matplotlib-qt4 numpy PyQt4 log4cxx log4cxx-devel omniORB omniORB-devel omniORB-doc omniORB-servers omniORB-utils python-jinja2 xsd  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install gstreamer-python \\  libuuid-devel \\  boost-devel \\  cppunit-devel \\  autoconf automake libtool \\  expat-devel \\  gcc-c++ \\  java-1.8.0-openjdk-devel \\  python-devel \\  python-matplotlib-qt4 \\  numpy \\  PyQt4 \\  log4cxx \\  log4cxx-devel \\  omniORB \\  omniORB-devel \\  omniORB-doc \\  omniORB-servers \\  omniORB-utils \\  python-jinja2 \\  xsd Optional Dependencies for Development The following dependencies are required for Octave component development.\n octave-devel  To install the dependencies, enter the following command:\nsudo yum install octave-devel"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/file-system/",
	"title": "File System",
	"tags": [],
	"description": "",
	"content": " The File System interface defines CORBA operations that exists to provide a runtime abstraction of an Operating System\u0026rsquo;s (OS) real file system. It gives REDHAWK the ability to have a single interface for reading and writing individual files within a file system regardless of the underlying implementation in the OS.\nFiles that are stored on the File System may be either plain files or directories.\nCharacters and symbols that are valid in directories and file names consist of:\n Upper and lowercase letters Numbers “_” (underscore) “-” (hyphen) “.” (period)  The file names “.” and “..” are invalid in the context of a File System.   Path names are structured according to the POSIX specification where the “/” (forward slash) is a valid character that acts as the separator between directories.\nAdditionally, the File System interface provides implementation of many standard functions such as:\n remove() copy() exists() list() create() open() mkdir() rmdir() query()  File System attached to the Domain Manager mounts with $SDRROOT/dom as the root. Each Device Manager mounts a File System with $SDRROOT/dev as the root.\nFile Manager The File Manager exists to manage multiple distributed file systems. This interface allows these file systems to act as a single entity, though they may span multiple physical file systems on different pieces of hardware. This provides for a distributed file system that functions as a single file system across multiple Device Managers and the Domain Manager.\nThe File Manager inherits the IDL interface of a File System. It then delegates tasks from the Core Framework based off of the path names to the correct mounted File System, depending on where that File System is mounted. It is also responsible for copying the appropriate component files into the specific Device Manager’s File System as applications are installed and launched.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/getting-started/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Installation Installation of the REDHAWK Core Framework and IDE is handled through a set of RPMs. The use of RPMs allows for automated installation of dependencies required for REDHAWK to run as well as automated installation of the Core Framework and IDE. Greater detail on REDHAWK installation can be found in the REDHAWK manual.\nBasic Example The fastest and easiest way to get a REDHAWK application started is through the REDHAWK sandbox, a self contained Python module that is able to run REDHAWK components outside the runtime environment, which limits the components to a single host computer.\nIn order to do this, first bring up a command line terminal. Begin a Python session and import the sandbox module by typing:\nfrom ossie.utils import sb The Sandbox has commands to list components available for use and to create an instance of a component by passing its name as an argument:\nsb.catalog()  Output:\n[\u0026#39;rh.HardLimit\u0026#39;, \u0026#39;rh.SigGen\u0026#39;]  sigGen = sb.launch(\u0026#34;rh.SigGen\u0026#34;) hardLimit = sb.launch(\u0026#34;rh.HardLimit\u0026#34;) The REDHAWK IDE plotting tool can be used in the Sandbox to display data graphically. The path to the Eclipse directory of the installed IDE must be specified in the sandbox (this can also be done by setting the RH_IDE environment variable to the REDHAWK path prior to starting the python session):\nsb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) plot = sb.Plot() The two components need to be connected, and HardLimit must be connected to the plotter to display the results.\nsigGen.connect(hardLimit) hardLimit.connect(plot) Once the HardLimit component is connected to the plotter, a window appears that plots any data coming from the output port. Once the sandbox is started, the plot begins to display data:\nsb.start() Component properties can be modified as attributes of the component. The HardLimit property upper_limit can be changed to set an upper limit on the data that is displayed:\nhardLimit.upper_limit = .8 For further reading on application development, the component and sandbox chapters of the REDHAWK manual provide a more thorough description of the makeup of components and how to test them in the REDHAWK environment.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/ide/",
	"title": "IDE Sandbox",
	"tags": [],
	"description": "",
	"content": " The IDE-based Sandbox provides a graphical environment for launching, inspecting, and debugging components, devices, services, and waveforms. The IDE-based Sandbox can host an instance of a Python-based Sandbox, with both interlinked, allowing artifacts from the Python environment to interact with those on the graphical UI.\nLaunching Components in the IDE Sandbox The following procedures explain how to launch a component in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a component with default property values, from the REDHAWK Explorer View, right-click the component, select Launch in Sandbox, and select an implementation of the component to start within the Sandbox’s Chalkboard.\nThe component is launched in the Sandbox. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue.\n  Customized Property Values  To launch an implementation of a component with customized property values, from the REDHAWK Explorer View, right-click the component, select Launch in Sandbox, and select Advanced.\nIf the component has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\nThe Assign Initial Properties dialog of the Launch wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Specify the launch options and click Finish.\nThe component is launched in the IDE Sandbox. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue.\n  Launching Devices in the IDE Sandbox The following procedures explain how to launch a device in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a device with default property values, from the REDHAWK Explorer View, right-click the device, select Launch in Sandbox, and select an implementation of the device to start within the Sandbox’s Chalkboard.\nThe device is launched in the Sandbox.\n  Customized Property Values  To launch an implementation of a device with customized property values, from the REDHAWK Explorer View, right-click the device, select Launch in Sandbox, and select Advanced.\nIf the device has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\nThe Assign Initial Properties dialog of the Launch wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Specify the launch options and click Finish.\nThe device is launched in the IDE Sandbox.\n  Launching Services in the IDE Sandbox The following procedures explain how to launch a service in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a service with default property values, from the REDHAWK Explorer View, right-click the service, select Launch in Sandbox, and select an implementation of the service to start within the Sandbox’s Chalkboard.\nThe service is launched in the Sandbox.\n  Customized Property Values  To launch an implementation of a service with customized property values, right-click the service, select Launch in Sandbox, and select Advanced.\nIf the service has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\nThe Assign Initial Properties dialog of the Launch wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Specify the launch options and click Finish.\nThe service is launched in the IDE Sandbox.\n  Launching Waveforms in the IDE Sandbox The following procedures explain how to launch a waveform in the IDE Sandbox.\nDefault Property Values  To launch a waveform with default property values, right-click the waveform, select Launch in Sandbox, and select Default.\nThe waveform is launched in the Sandbox.\n  Customized Property Values  To launch a waveform with customized property values, right-click the waveform, select Launch in Sandbox, and select Advanced.\nThe Assign Initial Properties dialog of the Launch waveform wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog of the Launch waveform wizard is displayed.\n Specify the launch options and click Finish.\nThe waveform is launched in the IDE Sandbox.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/interacting-with-hardware/interacting-fei-device-python-package/",
	"title": "Interacting with an FEI Device with the Python Package",
	"tags": [],
	"description": "",
	"content": "The Python package contains helpers that simplify the allocation/deallocation of FEI tuners. For example, to allocate a tuner to receive, centered at 1 MHz with a bandwidth of 1kHz, a 10% tolerance in the requested values, and a sample rate of 2 kHz, the following functionality can be used:\n\u0026gt;\u0026gt;\u0026gt; import frontend \u0026gt;\u0026gt;\u0026gt; allocation = frontend.createTunerAllocation(tuner_type=\u0026#34;RX\u0026#34;, allocation_id=\u0026#34;someid\u0026#34;,center_frequency=1e6, bandwidth=1e3,bandwidth_tolerance=0.1, sample_rate=2e3,sample_rate_tolerance=0.1) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(allocation) where dev is a reference to the device object and retval is True if the allocation succeeded.\nTo connect to an allocated tuner, use the allocation ID as the connection id:\n\u0026gt;\u0026gt;\u0026gt; dev.connect(comp, connectionId=\u0026#34;someid\u0026#34;) where comp is a reference to the component being connected to an allocated tuner. If the connection id corresponding to an allocation is not provided and the possible sources of data are not ambiguous, the Python package will create a connection that delivers the allocated stream.\nWhen a device contains a single allocated tuner and there is a single output bulkio port, it is possible to unambiguously determine what tuner to connect to and over which Port to connect. In such instances, the Python package creates a listener allocation against the allocated tuner and establishes a connection between the FEI device and the destination using the listener allocation id as the connection id. The created listener enables the owner of the allocation to establish a connection to the data source with the given allocation id. When the connection is removed, the Python package automatically deallocates the listener allocation. In such instances, the following call can be used to connect:\n\u0026gt;\u0026gt;\u0026gt; dev.connect(comp) To deallocate the tuner, use the following call:\n\u0026gt;\u0026gt;\u0026gt; dev.deallocateCapacity(allocation) To allocate a listener to a specific allocated tuner, use the following call:\n\u0026gt;\u0026gt;\u0026gt; listen_alloc = frontend.createTunerListenerAllocation(allocation_id, \u0026#34;some ID listener\u0026#34;) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(listen_alloc) To allocate a listener to any tuner with a particular set of values, use the following call:\n\u0026gt;\u0026gt;\u0026gt; allocation=frontend.createTunerGenericListenerAllocation(tuner_type=\u0026#34;RX\u0026#34;, allocation_id=\u0026#34;someidanotherlistener\u0026#34;,center_frequency=1e6, bandwidth=1e3,bandwidth_tolerance=0.1,sample_rate=2e3, sample_rate_tolerance=0.1) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(allocation) Deallocation of listeners follows the same pattern as the deallocation of tuners.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/logging-config-uri-resolution/",
	"title": "LOGGING_CONFIG_URI Resolution",
	"tags": [],
	"description": "",
	"content": "For all REDHAWK resources, the command line argument LOGGING_CONFIG_URI provides the location of the logging configuration file to load for that resource. This section details how each resource type receives this parameter.\n Domain Manager: The Domain Manager is started via nodeBooter with the -D option. The additional nodeBooter command line argument -logcfgfile is passed to the Domain Manager as LOGGING_CONFIG_URI. The following lines describe acceptable parameter values and their resolution:\n sca://path/to/config/file: $SDRROOT/dom/path/to/config/file file:///absolute/path/to/config/file: /absolute/path/to/config/file  Device Manager: The Device Manager is started via nodeBooter with the -d option. The additional nodeBooter command line argument -logcfgfile is passed to the Device Manager as LOGGING_CONFIG_URI. The following lines describe acceptable parameter values and their resolution:\n sca://path/to/config/file: $SDRROOT/dev/path/to/config/file file:///absolute/path/to/config/file: /absolute/path/to/config/file  Device: A device is started by the Device Manager. If the device has a LOGGING_CONFIG_URI property with Pass on command line enabled, you can set the value via the node’s dcd.xml file. This value is passed to the device at startup; otherwise, the device receives the value from the Device Manager’s LOGGING_CONFIG_URI command line argument.\n Service: A service is started by the Device Manager. If the service has a LOGGING_CONFIG_URI property with Pass on command line enabled, you can set the value via the node’s dcd.xml file. This value is passed to the service at startup; otherwise, the service receives the value from the Device Manager’s LOGGING_CONFIG_URI command line argument.\n Component: When a component is deployed by the Domain Manager, the LOGGING_CONFIG_URI command line parameter is resolved by the following sequence: (each step in the sequence can override the value from the prior step)\n The component defines a LOGGING_CONFIG_URI property with Pass on command line enabled. The component’s componentplacement in a waveform contains a simpleref with ID = LOGGING_CONFIG_URI. Normally, only defined properties are passed to the component during deployment, the LOGGING_CONFIG_URI is passed regardless of being defined. The component’s componentplacement contains a \u0026lt;loggingconfig\u0026gt; element. The Domain Manager’s is configured with a plugin library and the -useloglib option was provided when the Domain Manager was started. Refer to Logging Configuration Plugin for details. If this process does not provide a value, then the Domain Manager’s LOGGING_CONFIG_URI command line is used.   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/messaging/message-consumer/",
	"title": "Message Consumer",
	"tags": [],
	"description": "",
	"content": " To create a message consumer, create a new component or edit an existing component.\n Add a Struct property\n Enter the ID of the message you want the component to consume Select the kind for the property as only message Add any arbitrary number of members to the struct  Add uses/provides (bidirectional) port of IDL Interface\nExtendedEvent\u0026gt; MessageEvent\n Regenerate the component\n  The bidirectional port is needed because in point-to-point connections, the port behaves like a Provides port, while in connections with an EventChannel, the consumer behaves like a Uses port. This is an artifact of mapping a uses/provides pattern over a producer/consumer pattern. A single object is created for the port, and a call to getPort() returns a pointer to the same object irrespective of whether or not the port is to be employed as a Uses or Provides; the object implements both sets of interfaces. The scd contains two entries for this port, both with the same name, but one is a uses and the other is a provides.\nFor the purposes of the following examples, assume that the structure is as follows:\n id: foo Contains two members:  name: some_string, type: string name: some_float, type: float  The component’s uses/provides port is called message_in The component’s callback function for this message is messageReceived() The component’s name is message_consumer  If a connection exists between this component and either a message producer or an EventChannel, the following code examples process an incoming message.\nAny message that comes in with the property ID foo will trigger the callback function messageReceived().\n C++ Given the asynchronous nature of events, a callback pattern was selected for the consumer.\nIn the component header file, declare the following callback function:\nvoid messageReceived(const std::string \u0026amp;id, const foo_struct \u0026amp;msg); In the component source file, implement the callback function:\nvoid message_consumer_i::messageReceived(const std::string \u0026amp;id, const foo_struct \u0026amp;msg) { LOG_INFO(message_consume_i, id\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;msg.some_float\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;msg.some_string); } In the constructor() method, register the callback function:\nmessage_in-\u0026gt;registerMessage(\u0026#34;foo\u0026#34;, this, \u0026amp;message_consumer_i::messageReceived); Java Java callbacks use the org.ossie.events.MessageListener interface, which has a single messageReceived() method. The recommended style for Java messaging is to define the callback as a private method on the component class, and use an anonymous subclass of MessageListener to dispatch the message to your callback.\nAdd to the list of imports:\nimport org.ossie.events.MessageListener; Implement the callback as a method on the component class:\nprivate void messageReceived(String id, foo_struct msg) { logger.info(id + \u0026#34; \u0026#34; + msg.some_float.getValue() + \u0026#34; \u0026#34; + msg.some_string.getValue()); } In the constructor() method, register a MessageListener for the message to dispatch the message to your callback:\nthis.port_message_in.registerMessage(\u0026#34;foo\u0026#34;, foo_struct.class, new MessageListener\u0026lt;foo_struct\u0026gt;() { public void messageReceived(String messageId, foo_struct messageData) { message_consumer.this.messageReceived(messageId, messageData); } }); Python In the constructor() method, register the expected message with a callback method:\nself.port_message_in.registerMessage(\u0026#34;foo\u0026#34;, message_consumer_base.Foo, self.messageReceived) In the class, define the callback method. In this example, the method is called messageReceived():\ndef messageReceived(self, msgId, msgData): self._log.info(\u0026#34;messageReceived *************************\u0026#34;) self._log.info(\u0026#34;messageReceived msgId \u0026#34; + str(msgId)) self._log.info(\u0026#34;messageReceived msgData \u0026#34; + str(msgData))"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/pydev-overview/",
	"title": "PyDev Overview",
	"tags": [],
	"description": "",
	"content": "PyDev is an external product that comes bundled with the REDHAWK IDE and provides a Python IDE for Eclipse, which may be used in Python, Jython, and IronPython development.\nPyDev’s many features include:\n Code completion Code completion with auto import Type hinting Code analysis Go to definition Refactoring Debugger Interactive console Unittest integration  PyDev has its own set of documentation and getting started details. First time users are strongly advised to read the Getting Started Guide, which explains how to properly configure PyDev. The PyDev documentation can be found in the following locations:\n PyDev Getting Started, http://pydev.org/manual_101_root.html PyDev Configuring Interpreter, http://pydev.org/manual_101_interpreter.html PyDev Manual, http://pydev.org/manual.html  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/sri/",
	"title": "Signal Related Information (SRI)",
	"tags": [],
	"description": "",
	"content": " SRI is delivered with the data (when in-band) that describes the data payload. SRI Keywords provides guidance on how to manipulate keywords in SRI. The SRI data structure fields are described in the table below.\nSRI Fields    Name Type Description     hversion long Version of the Stream SRI header. Set to 1.   xstart double Specifies the start of the primary axis. (Refer to SRI Fields for Contiguous Data or SRI Fields for Framed Data)   xdelta double Specifies the interval along the primary axis. (Refer to SRI Fields for Contiguous Data or SRI Fields for Framed Data   xunits short Specifies the units associated with the xstart and xdelta values. Refer to the REDHAWK Interface Control Document (ICD) for definitions.   subsize long For contiguous data, 0. For framed data, specifies the number of data elements in each frame (i.e., the row length).   ystart double Specifies the start of the secondary axis. (Refer to SRI Fields for Framed Data)   ydelta double Specifies the interval along the secondary axis. Refer to (SRI Fields for Framed Data)   yunits short Specifies the units associated with the ystart and ydelta values. Refer to the REDHAWK Interface Control Document (ICD) for definitions.   mode short 0-Scalar, 1-Complex. Complex data is passed as interleaved I/Q values in the sequence. The type for the sequence remains the same for both real and complex data.   streamID string Stream ID. Unique streams can be delivered over the same port, where each stream is identified by a unique string (generated or passed along by the provides side). The generation of this stream ID is Application-specific and not controlled by the REDHAWK Core Framework.   blocking boolean Flag to determine whether the receiving port exhibits back pressure. If this is false and the provides-side queue is full, the data is dumped. If this is true and the provides-side queue is full, the pushPacket() call blocks.   keywords sequence \u0026lt;CF::DataType\u0026gt; User defined keywords. This is a sequence of structures that contain an ID of type string and a value of type CORBA Any. The content of the CORBA Any can be any type.    There are two modes of operation for BulkIO, contiguous or framed data, with subsize equal to zero or frame size, respectively.\nContiguous Data The most common use of BulkIO is to transfer contiguous data, typically digitized samples. The SRI subsize field must be set to 0. The primary axis is typically in units of time. The secondary axis is unused.\nSRI Fields for Contiguous Data    Name Description     xstart Specifies, in units identifed by xunits, the start time of the first sample, relative to the Unix epoch (January 1, 1970).   xdelta Specifies the interval between consecutive samples.   xunits Specifies the units associated with the xstart and xdelta values.   subsize Set to 0.   ystart Not used.   ydelta Not used.   yunits Not used.    Framed Data BulkIO supports framed data, such as the output of an FFT, in which one dimension has a fixed size. The SRI subsize field is set to the the frame length.\nSRI Fields for Framed Data    Name Description     xstart Specifies an abscissa-style value (i.e., relative to xunits) associated with the first element in each frame. For example, in streams containing a series of one-dimensional FFT results, each frame represents a frequency interval with xstart specifying the frequency associated with the lower end of the interval. For real-valued samples, xstart is typically zero, while for complex-valued samples, xstart is typically bw/2.   xdelta Specifies the interval between consecutive samples in a frame.   xunits Specifies the units associated with the xstart and xdelta values.   subsize Specifies the number of data elements in each frame (i.e., the row length).   ystart Interpreted the same way as the xstart field in contiguous data (Refer to SRI Fields for Contiguous Data, except that it refers to the start time of the first frame.   ydelta Specifies the interval between consecutive frames.   yunits Specifies the units associated with the ystart and ydelta values.    SRI Transfer SRI is transferred over a connection by the uses-side invoking the provides-side function pushSRI(). The pushSRI() function contains a single argument, an instance of an SRI object.\nEach provides-side port that implements a BulkIO interface expects that SRI regarding data being received become available before any data is transferred. When using the code generators and base classes in the REDHAWK development tools, this behavior is hard-coded into the uses-side BulkIO ports. If the user code on the uses-side of a BulkIO connection does not explicitly invoke a pushSRI() call before any data is sent out, the auto-generated code creates a trivial SRI message with normalized values.\nPart of the hard-coded behavior on the uses-side BulkIO port is to issue a pushSRI() when a new connection is made to the newly-connected object. For example, a system is created in which data is flowing between components A and B. As data is flowing between these components, a new connection is established between components A and C. When this connection is established, a pushSRI() method call is automatically made from component A to component C.\nSRI Keywords SRI is metadata to describe the payload being pushed (for example, sampling period). While it is possible to describe some generic parameters, signal specific parameters are be stored in a generalized structure called SRI Keywords. SRI keywords are passed as a sequence of key/value pairs (CF::DataType) of type CF::Properties. In properties, the keys are strings, and the values are a CORBA type called CORBA::Any. CORBA::Any is a structure that can be used to marshal a wide variety of types. REDHAWK has developed helper APIs to interact with the keyword sequence.\nAdding SRI Keywords in C++, Python, and Java Given a component with simple propertys chan_rf and col_rf that are of type double and have an initial value of -1, and a BulkIO StreamSRI instance named sri, the following implementations in C++, Python and Java, push out those property values as the keywords COL_RF and CHAN_RF.\nC++ Implementation The redhawk::PropertyMap property map enables you to manipulate the sequence of keywords.\ninclude \u0026lt;ossie/PropertyMap.h\u0026gt; redhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(sri.keywords); tmp[\u0026#34;CHAN_RF\u0026#34;] = chan_rf; tmp[\u0026#34;COL_RF\u0026#34;] = col_rf; Python Implementation omniORB helpers any.to_any are used to convert a Python type to a CORBA::Any.\nfrom omniORB import any self.sri.keywords.append(CF.DataType(\u0026#34;CHAN_RF\u0026#34;, any.to_any(self.chan_rf))) self.sri.keywords.append(CF.DataType(\u0026#34;COL_RF\u0026#34;, any.to_any(self.col_rf))) Java Implementation The AnyUtils package is used to convert a Java type to a CORBA::Any.\nimport org.ossie.properties.AnyUtils; double chan_rf = this.chan_rf.getValue(); double col_rf = this.col_rf.getValue(); sri.keywords = new DataType[2]; sri.keywords[0] = new DataType(\u0026#34;CHAN_RF\u0026#34;, AnyUtils.toAny(chan_rf, TCKind.tk_double)); sri.keywords[1] = new DataType(\u0026#34;COL_RF\u0026#34;, AnyUtils.toAny(col_rf, TCKind.tk_double)); Verifying SRI Keywords It is possible to verify the keywords and values being pushed out by connecting a DataSink() component in the Python Sandbox. This assumes there is at least one BulkIO output port for the test component, and a pushSRI() call is made on that port. The following code demonstrates this verification:\nfrom ossie.utils import sb comp = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;) sink = sb.DataSink() comp.connect(sink) sb.start() print sink.sri().keywords Retrieving SRI Keywords in C++ Because redhawk::PropertyMap contains CORBA::Any values, retrieving the contents requires the use of getters to convert to a native type. Assuming that the content of a particular keyword is a double:\nredhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(sri.keywords); chan_rf = tmp[\u0026#34;CHAN_RF\u0026#34;].toDouble();"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/shared-libraries/using-a-shared-library-project/",
	"title": "Using a REDHAWK Shared Library Project",
	"tags": [],
	"description": "",
	"content": " To add a shared library dependency to a component or device:\nThe shared library must be installed to SDRROOT before you can add it to a component or device.\n  Open the SPD file for the component or device.\nComponent SPD File  Select the Implementations tab.\nComponent Implementations Tab  On the left side of the editor, select the appropriate implementation.\n On the right side of the editor, under Dependencies, next to the Dependency box, click Add\u0026hellip;\nThe Edit Dependency dialog is displayed.\nEdit Dependency Dialog  In the dialog, change the Kind to Shared Library (SoftPkg) Reference.\n In the Type box, select other.\n Select a shared library from the list of shared libraries installed in the SDRROOT.\nShared Library Dependency Dialog  Click Finish.\nThe shared library dependency is displayed under the All Implementations section of the Implementations tab.\nShared Library Project Dependency  To update your code to use the dependency, click the Generate All Implementations icon.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/viewing-domain-contents/",
	"title": "Viewing the Contents of the Domain in the REDHAWK Explorer View",
	"tags": [],
	"description": "",
	"content": " After the domain connection is established, the file system visible to the Domain Manager and its attached Device Managers is displayed in the REDHAWK Explorer View. Detailed information about each item is available in the Properties View.\nThe Domain Manager’s root contains the following folders:\n Device Managers: Displays the currently connected Device Managers. More than one Device Manager may be connected to the domain. Each Device Manager entry consists of a single node, and each node may contain multiple devices. Right-click devices to monitor port information, plot port output, and play audio.\nDevice Managers  Event Channels: Displays the Event Channels in the domain. Right-click a channel to display the Refresh and Listen to Event Channel options. Select Listen to Event Channel to open the Event Viewer View.\nEvent Channels  File Manager: Displays the file systems in the domain’s view. It contains references to all components, devices, waveforms, and the device and Domain Managers configuration and executable files.\nExample Domain File System  Waveforms: Displays the applications running on the domain. When applications launch, they are displayed and can be expanded to show each of the running components within the application. These components can be expanded to show the device on which they are executing and port information.\nWaveforms   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/waveform-editor/",
	"title": "Waveform Editor",
	"tags": [],
	"description": "",
	"content": " To open the Waveform Editor, double-click a SAD file from the Project Explorer View. It presents all the content that can be found within the sad.xml file in an editing environment designed for ease of use. The Waveform Editor contains an Overview, Properties, Components, Diagram, and a raw XML tab, which contains the SAD file content.\nOverview Tab Waveform Editor Overview Tab The Overview tab provides general information about the waveform, and hyperlinks to additional waveform-related sections within the IDE.\n The General Information section provides controls to set the ID, Name, Version, Controller and Description for the waveform.\n The External Ports section provides the ability to promote a component\u0026rsquo;s port so it is accessible from the waveform object. By default, an external port name is equal to the name of that port within the component, but the external port can be renamed.\nTo change the external port name:\n In the External Ports section, locate the port and click the cell in the External Name column in the port’s row.\n Enter a new value for the name.\nRenaming External Ports  Press Enter.\n  The Testing section allows for the launching of local waveforms. A local waveform does not require a running domain or Device Manager and executes within the Sandbox. A local waveform is similar to launching an individual component in the Chalkboard and constructs the waveform within a new Chalkboard instance. You may launch additional components into the waveform running in the Chalkboard using the palette. These newly launched components have standard runtime actions (Plot, Start, Stop, Terminate, and Connect) available. When the local running waveform is released these newly launched components are not saved in the waveform.\n The Exporting section provides a hyperlink to the Export Wizard, which steps through the process of deploying the waveform into the SDR Root.\n  Properties Tab Waveform Editor Properties Tab The Properties tab provides access to the component’s properties within the waveform. Within the Properties tab, you can:\n Assign an external property ID Set the overridden value within the SAD file Filter and search for properties Compare the overridden value to the original PRF value  The properties of the component designated as the Assembly Controller are always accessible externally and are grayed out in the Properties tab. Additional properties may be assigned an external ID, which allows for a particular component’s property to be designated as accessible to external waveform objects. See External Properties for additional information.\nTo make a property external:\n Select the properties tab of the application’s SAD file.\n Edit the External ID field by entering the desired ID.\n  The external IDs must be unique. They can not duplicate another external property\u0026rsquo;s ID, or the ID of a property belonging to the assembly controller.\n Waveform External Properties Diagram Tab Waveform Editor Diagram Tab You can use the Diagram tab to place components into a waveform, connect components together, set waveform-specific properties for components, make a port external, and add a FrontEnd Tuner device to a waveform.\nTo zoom in and out on the diagram, press and hold Ctrl then scroll up or down. Alternatively, press and hold Ctrl then press + or -.\n To add a component to the waveform and configure its properties:\n Drag the component from the Palette onto the diagram. Right-click the component. Select Show Properties From the Properties View, change the desired properties. Press Ctrl+S to save the changes.  If you want to quickly locate a component in the Palette, you can replace the text type filter text in the text field at the top of the Palette with a keyword to filter the component list.\n Any property modified here is specific to this waveform and does not impact the component’s execution in other environments.\n To make a port external:\n Left-click the port you want to make external, to gain focus on the port.\n Right-click the port to open the port context menu.\n Select Mark External Port.\nMark External Ports   From the Diagram tab, a user may also use the Find By feature. The Find By feature enables a user to find a resource by name, a service by name or type, or an Event Channel by name.\nConnections may be made from input to output ports by clicking and dragging from one port to the other. Multiple connections can be drawn to or from ports. Any unsupported or erroneous connection that the IDE can detect is marked with an appropriate indicator. Hovering over the indicator provides information concerning the error.\nTo add a dependency on a FrontEnd Tuner device that the waveform needs to use at runtime (a usesdevice in the XML):\n From the Palette, in the Advanced folder, select Use FrontEnd Tuner Device and drag it onto the diagram. The Allocate Tuner dialog is displayed.\nSelect Target Device  Select the FrontEnd Tuner device you want to use. This will complete some of the information in the subsequent wizard pages. Alternatively, select Generic FrontEnd Device for defaults. Click Next.\nAllocate Tuner  Enter the Uses Device ID and optionally, enter the Device Model, and then click Next.\n Enter the appropriate information and click Next. See Allocating a FrontEnd Tuner for more details.\nIdentify Ports  Enter the names of any uses and provides ports that you want to use from the target device and click Finish. The Use FrontEnd Tuner Device is displayed in the diagram. When you launch the waveform, the FrontEnd Tuner device must be available in order for the waveform to run.\nThe sad.xml tab displays the raw XML data, which describes this waveform fully. Although not recommended, manually editing the XML file is supported.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/why-ports/",
	"title": "Why Ports?",
	"tags": [],
	"description": "",
	"content": "It seems burdensome to connect components through port objects; this is an additional level of indirection that adds another layer of complexity. This approach is taken largely because it allows modularization of interfaces when components have more than one input or output port.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/working_with_components/",
	"title": "Working with Components, Devices, and Services",
	"tags": [],
	"description": "",
	"content": " The Sandbox contains the following commands for working with components, devices, and services:\n The show() Command The catalog() Command The api() Method The launch() Command  The show() command displays running components, connections between components, and the SDRROOT:\n\u0026gt;\u0026gt;\u0026gt; sb.show() The catalog() command displays which components, devices, and services are available in SDRROOT. To determine what types are displayed, use the objType argument (by default objType=\u0026quot;components\u0026quot;) as shown below:\n\u0026gt;\u0026gt;\u0026gt; sb.catalog() \u0026gt;\u0026gt;\u0026gt; sb.catalog(objType=\u0026#34;devices\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sb.catalog(objType=\u0026#34;services\u0026#34;) An alternative to catalog() is browse(). The function browse() provides formatted human-readable text that describes the items that are installed on the system rather than the computer-friendly list that catalog() provides.\nThe api() method displays the ports and properties for a running component:\n\u0026gt;\u0026gt;\u0026gt; comp.api() Component [FloatToShort]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- float_in IDL:BULKIO/dataFloat:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- short_out IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- max_value (float/SF/32f) 1.0 1.0 min_value (float/SF/32f) -1.0 -1.0 The launch() command launches components, devices, and services. The first argument identifies the object to launch. It may be either a path to an SPD file or, for objects installed to the current SDRROOT, the name of the object as given in the SPD. The path can be absolute or relative and does not need to reside in SDRROOT.\nThe following example demonstrates how to launch a device from the current working directory using the path:\n\u0026gt;\u0026gt;\u0026gt; my_dev = sb.launch(\u0026#34;./MyDevice.spd.xml\u0026#34;) The following example demonstrates how to launch a device named SigGen from the current working directory using the name:\n\u0026gt;\u0026gt;\u0026gt; my_dev = sb.launch(\u0026#34;rh.SigGen\u0026#34;) The execparams or property kind properties for a component may be overridden by command line at launch time by passing a Python dictionary of parameter names and values to the keyword argument execparams:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;MyComponent\u0026#34;, execparams={\u0026#34;EXECPARAM_1\u0026#34;: \u0026#34;value\u0026#34;}) In the case of components and devices, after the process is launched and the component is initialized, the component’s configure and property kind properties are set to their default values as listed in the PRF file. The default values for this initial calls to configure() and initializeProperties() may be overridden by passing a Python dictionary of property names and values to the keyword argument configure:\n\u0026gt;\u0026gt;\u0026gt; siggen = sb.launch(\u0026#34;rh.SigGen\u0026#34;, configure={\u0026#34;sample_rate\u0026#34;:100e3, ... \u0026#34;frequency\u0026#34;:22e3, ... \u0026#34;shape\u0026#34;:\u0026#34;square\u0026#34;}) By default, the Sandbox selects the first component implementation whose entry point exists on the file system. A particular implementation may be specified by passing the implementation ID to the impl argument:\n\u0026gt;\u0026gt;\u0026gt; siggen = sb.launch(\u0026#34;rh.SigGen\u0026#34;, impl=\u0026#34;cpp\u0026#34;) The Sandbox includes limited support for attaching a debugger to a component process. The debugger console opens in a new XTerm window to allow continued interaction on the Sandbox console.\nIn the case of C++, to launch a component and attach gdb to the process, enter the following command:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;./MyComponent.spd.xml\u0026#34;, debugger=\u0026#34;gdb\u0026#34;) The component and gdb are run in separate processes. Exiting gdb closes the window, but the component continues to function.\nThe debugger argument also supports jdb (Java), pdb (Python), and valgrind (Valgrind, a tool used for diagnostics such as memory leak detection).\nTo provide arguments to the supported debuggers, the debugger needs to be instantiated outside the scope of the launch function. For example, to perform a full leak check using Valgrind, use the following argument:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils.sandbox.debugger import GDB, JDB, PDB, Valgrind \u0026gt;\u0026gt;\u0026gt; vg_option = {\u0026#39;--leak-check\u0026#39;:\u0026#39;full\u0026#39;} \u0026gt;\u0026gt;\u0026gt; vg = Valgrind(**vg_option) \u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;./MyComponent.spd.xml\u0026#34;, debugger=vg) If incorrect arguments are passed, the component fails to deploy. Note that the Python debugger does not take arguments.\nProperties In addition to the standard REDHAWK query() and configure() functions, the Sandbox presents a simplified interface to properties for components and devices. Configure properties can be accessed as attributes on the component object:\n\u0026gt;\u0026gt;\u0026gt; my_comp.string_prop = \u0026#34;Hello World!\u0026#34; \u0026gt;\u0026gt;\u0026gt; my_comp.long_prop 1 Property names are taken from the component PRF file, with any characters that are invalid for Python identifiers replaced by an underscore.\nThe current value of properties with a mode of “readonly” or “readwrite” may be inspected. Properties with a mode of “readwrite” or “writeonly” can be assigned a new value.\nTo view the configure properties that are available for a given component, along with their types and current and default values, use the api() function.\nSimple properties with numeric types can be assigned from any Python numeric type:\n\u0026gt;\u0026gt;\u0026gt; my_comp.float_prop = 3 \u0026gt;\u0026gt;\u0026gt; my_comp.long_prop = 1.0e3 The value is range checked and coerced into the desired type before being configured on the component:\n\u0026gt;\u0026gt;\u0026gt; my_comp.ushort_prop = -1 ossie.utils.type_helpers.OutOfRangeException: ... Floating point values are truncated, not rounded, during conversion to integer types:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_value = 1.5 \u0026gt;\u0026gt;\u0026gt; my_comp.long_value 1 A simple property with a complex value type can be assigned from a Python complex or two-item sequence. The numeric conversion of the real and imaginary components is identical to that of single numeric values.\n\u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = 1.0+2.5j \u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = (1, 2) Complex properties support assignment from single numeric values; the imaginary component is assumed to be 0.\n\u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = 1 \u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop 1+0j properties that have enumerated values in the component’s PRF support assignment using the enumerated name as a Python string:\n\u0026gt;\u0026gt;\u0026gt; siggen.shape = \u0026#34;triangle\u0026#34; Struct properties can be set with a Python dictionary:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop = {\u0026#34;item_string\u0026#34;: \u0026#34;value\u0026#34;, ... \u0026#34;item_long\u0026#34;: 100} The dictionary keys are the IDs of the simple properties that make up the struct. Each value is converted to the appropriate type following the same rules as simple properties. Any struct members that are not in the dictionary retain their current values.\nIndividual struct members may be set directly, using the simple property name:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop.item_string = \u0026#34;new value\u0026#34; Properties have a mode (i.e.: readwrite, readonly, writeonly), and, for compatibility reasons, is a member of the Python Struct property container and cannot change. If the Struct property has a member called “mode”, requesting the member “mode” from the property will return its access mode rather than the content of the property member. Access the value of any element of a property with a reserved word as its name as follows\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop[\u0026#34;mode\u0026#34;] = \u0026#34;Hello World!\u0026#34; Setting a struct member as an attribute uses the simple property’s name, while setting the member via a dictionary uses the simple property’s id.\n Both simple and struct sequence properties may be manipulated as lists. Sequence properties support the common Python list operations, such as slicing and in-place modifiers:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_seq = [1, 2, 3, 4] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq[2:] [3, 4] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq.append(5) \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 3, 4, 5] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq[2:4] = [6] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 6, 5] The items of simple sequences follow the same conversion rules as the corresponding simple property:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_seq = [1.5, 2.5, 3.5] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 3] Each item in a struct sequence works identically to a single struct property:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq [{\u0026#39;a\u0026#39;:\u0026#39;first\u0026#39;, \u0026#39;b\u0026#39;:1}, {\u0026#39;a\u0026#39;:\u0026#39;second\u0026#39;, \u0026#39;b\u0026#39;:2}] \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq[0].a = \u0026#34;new value\u0026#34; \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq[1] = {\u0026#34;a\u0026#34;:\u0026#34;third\u0026#34;, \u0026#34;b\u0026#34;:3} \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq [{\u0026#39;a\u0026#39;:\u0026#39;new value\u0026#39;, \u0026#39;b\u0026#39;:1}, {\u0026#39;a\u0026#39;:\u0026#39;third\u0026#39;, \u0026#39;b\u0026#39;:3}] The Sandbox generates a low-level CORBA configure() call each time a property value is set. However, Sandbox components also support setting multiple property values at once using a Python dictionary:\n\u0026gt;\u0026gt;\u0026gt; my_comp.configure({\u0026#34;long_prop\u0026#34;:1, \u0026#34;string_prop\u0026#34;:\u0026#34;new value\u0026#34;}) The keys may be either the property names or ids. The values are converted in the same manner as setting the individual property directly.\nProperty Listener It is possible to asynchronously listen to changes in properties such that it is not necessary to poll the component to see the state of a particular property. This is done through property change listeners. To implement this listener, create a property change listener and register it with the component. Note that the listener can be a local object or an eventchannel\n\u0026gt;\u0026gt;\u0026gt; def property_change_callback(self, event_id, registration_id, resource_id, properties, timestamp): print event_id, registration_id, resource_id, properties, timestamp \u0026gt;\u0026gt;\u0026gt; listener = sb.PropertyChangeListener(changeCallbacks={\u0026#39;prop_1\u0026#39;:callback_fn}) \u0026gt;\u0026gt;\u0026gt; comp.registerPropertyListener(listener, [\u0026#39;prop_1\u0026#39;], 0.5) # check the property every 0.5 seconds"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/helpers/",
	"title": "Helpers",
	"tags": [],
	"description": "",
	"content": "The Python Sandbox provides a variety of helpers to both simplify the interaction with REDHAWK subsystems as well as increase the reliability of interactions with these subsystems.\nA common problem is type matching in properties. While Python is very flexible with types, other languages, like C++ and Java, are not. When properties are set on components, the type for the value has to match the type that is expected by the component. Python, given its dynamic type system, will pack the value in what it deems appropriate, which may or may not match the expected type. While the property mapping performs this matching automatically, it is sometimes desirable to create a set of properties for other systemic uses. For example, it may be desirable to use the Allocation Manager, making it impossible for the Python script to know which device will satisfy the allocateCapacity call. To support this need, the createProps function was created. createProps is given a dictionary of the required properties, and it also takes an optional prf file. Using the prf file, the property dictionary is converted to the appropriate format, where the filename is the location on the local filesystem.\nThe following example demonstrates how to use the createProps function with an existing PRF file to generate a set of properties.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import allocations \u0026gt;\u0026gt;\u0026gt; prop = allocations.createProps({\u0026#39;some_prop\u0026#39;:[1.0,2.0]}, prf=\u0026#39;/var/tmp/sdr/dev/devices/my_dev/my_dev.prf.xml\u0026#39;)"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/base-component-members/",
	"title": "Base Component Members",
	"tags": [],
	"description": "",
	"content": " This section provides an overview of members available to the component class. There are four kinds of members: ports, properties, domain awareness, and network interface.\nPorts Data flow into and out of components is accomplished through the use of ports. Ports are described as being either a provides (input) or uses (output) port. This naming convention is often viewed as counter-intuitive, so an explanation is in order. Ports are RPC interfaces to a component. An input port, therefore, provides functionality that can be used by an output port.\nREDHAWK contains a variety of standardized interfaces that facilitate interoperability. These interfaces are implemented by ports. When a port is selected in the component generation wizard in the REDHAWK IDE, code to implement these interfaces is automatically generated.\nIrrespective of direction, a port is accessed as a member of the component’s base class. Assuming that a port called myport of any interface exists in the component, it is accessed in the following ways in C++, Python, and Java, respectively:\nthis-\u0026gt;myportself.port_myportthis.port_myport See Standardized Data Interfaces for details on how to use ports for sending or receiving data.\nProperties Much like ports, properties are available to the component through generated members to for the component’s base class. The property is found through the property’s name (if it has one) or its ID. For example, if a property is defined with an ID of foo and a name of abc, it would be accessed in the following ways in C++, Python, and Java, respectively:\nthis-\u0026gt;abcself.abcthis.abc If the property does not have a name defined, then it would be accessed in the following way in C++, Python, and Java, respectively:\nthis-\u0026gt;fooself.foothis.foo Note that no automated check is performed on the code generation to avoid a name collision between properties or ports.\nEnumerations simple properties can have enumerated values, which associate symbolic names with values. Code generation creates constants for these values, allowing the component developer to use the symbolic name instead of the literal value. For simple properties in struct or struct sequence properties, the generated constants are nested under the name of the struct.\nC++ In C++, the generated constants for enumerations are static variables in nested namespaces, under the top-level namespace enums:\nenums::simple::LABEL enums::structprop::field::LABEL enums::structseq_struct::field::LABEL Enumerated values for simple properties are in the component base class header, while those in struct or struct sequence properties are in struct_props.h along with the struct definitions.\nJava In Java, the generated constants for enumerations are public static variables in nested static classes, under a top-level class named enums:\nenums.simple.LABEL enums.structprop.field.LABEL enums.structseq_struct.field.LABEL The enums class is a static nested class in the component base class.\nPython In Python, the generated constants for enumerations are class attributes in nested classes, under a top-level class named enums:\nenums.simple.LABEL enums.structprop.field.LABEL enums.structseq_struct.field.LABEL The enums class is imported from the component base class module.\nDomain Awareness Each component has two members that provide a reference to the domain and application in which the component is operating. To retrieve the Domain Manager and Application, access the member functions getDomainManager() and getApplication(), which return a DomainManagerContainer and ApplicationContainer, respectively. DomainManagerContainer has the member getRef(), which returns the CORBA pointer to the Domain Manager object. ApplicationContainer has the member getRef(), which returns the CORBA pointer to the Application object.\nIn the case of devices, instead of getApplication(), the base class contains getDeviceManager(), which returns a DeviceManagerContainer. The DeviceManagerContainer has the member getRef(), which returns the CORBA pointer to the DeviceManager object.\nNetwork Interface If a component contains a dependency against any member of GPP’s nic_allocation allocation property, then the framework will, upon deployment, make sure that those network resources are made available to the component. Whichever NIC statisfies the allocation requirement is fed to the component, and it is made available to the developer through the getNetwork() member, which returns a NetworkContainer. NetworkContainer has the member function getNic(), which is the string name of the NIC that satisfied the requirement (i.e.: eth0).\nNote that if the network dependency is declared for any one component, that component’s deployment is made to the core(s) that are closest to the NIC on the processor. This happens automatically with no need for additional input from the deployer.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/",
	"title": "Components",
	"tags": [],
	"description": "",
	"content": " A component is a modular building block that can be inserted into any number of signal processing applications to perform a specific and reusable function. A component is fully defined by its interfaces, properties, and functionality. Examples include a component that tunes, filters, and decimates a wideband signal and one that performs a FM demodulation. Some components inevitably need to be custom implementations, but a majority of signal processing functions can be reused and shared.\nREDHAWK allows for developers to create components in either C++, Python, or Java. C++ is recommended for most computationally-intensive tasks, whereas Python or Java work well for handling metadata manipulation or command and control tasks.\nComponents can be interconnected together within a waveform to create a complete signal processing application or can be run independently in the REDHAWK Sandbox to perform trivial tasks on a local host. The figure below depicts the composition of components into a waveform.\nREDHAWK Workflow By using the REDHAWK Framework, basic processing elements may be encapsulated as components and reused by other REDHAWK compliant systems. Using the REDHAWK IDE and the included code generators, much of the code for control and input/output can be auto-generated. The figure below depicts the encapsulation of an arbitrary processing algorithm into an auto-generated REDHAWK component wrapper.\nComponent Container  REDHAWK Core Assets     Creating a Component Project     Creating Octave Components     Running a Component     Sandbox     Creating and Running a Hello World Component     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/octave-components/",
	"title": "Creating Octave Components",
	"tags": [],
	"description": "",
	"content": " REDHAWK provides the ability to auto-generate a REDHAWK component given an Octave M function. Assuming M functions are set up to input/output data vectors rather than relying on file or terminal-based input/output, these components are seamlessly deployable on runtime systems.\nOctave version 3.4 or greater, with development support, must be installed on the development and deployment systems. This requirement can be met by either installing Octave from source or installing the octave-devel rpm.\nThe generated REDHAWK C++ code utilizes the Octave C++ programming interface to:\n Translate incoming REDHAWK data to the available Octave data formats. Call the M function using Octave’s feval() C++ function. Translate the resulting Octave data to REDHAWK data formats.  In many cases, the Octave component can be created without any C++ programming by the developer and without an in-depth understanding of REDHAWK. Developers with a more in-depth understanding of C++ programming and REDHAWK have the option of leveraging more advanced REDHAWK features by modifying the generated C++ code. Furthermore, Octave components can be composed into waveforms with components written in other languages (Java, C++, and Python).\nThe createOctaveComponent Script Octave components can be generated using a command line tool (createOctaveComponent) or using the REDHAWK IDE. The help string for the command line tool can be accessed by entering the following command:\ncreateOctaveComponent --help In the most simple case, the command line tool is passed a list of M files with no additional flags. Function arguments that have a default value are treated as properties and function arguments without default values are treated as ports.\nBelow is an example of a basic M function defined in a file named addConst.m:\nfunction myOutput = addConst(myInput, myConst=0) myOutput = myInput + myConst To generate the component code, use the following command:\ncreateOctaveComponent addConst.m Refer to the createOctaveComponent help string for flags to:\n Automatically compile and install the component. Automatically create an RPM for the component. Enable buffering, which causes the component to wait for an EOS before processing data. Enable the Octave diary, which writes Octave’s standard out and standard error to a file. Point to shared .m and .oct files. Specify an output directory.  Design Considerations There are a few design considerations to keep in mind when creating an M file to be used in REDHAWK:\n Data must be passed as row vectors or n-by-m matrices. All values must be doubles. Configuration (property) values may be doubles, double vectors, or strings. All numerical properties are treated as complex. The serviceFunction of the component is auto-generated and should not be hand-modified. To manipulate data before or after the feval() call to Octave, modify the inputPackets and outputPackets maps in the preProcess and postProcess methods.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/devices/",
	"title": "Devices",
	"tags": [],
	"description": "",
	"content": " Devices in the Sandbox support all of the features of components, plus additional features specific to devices. A Sandbox device instance always supports the base CF::Device allocation and deallocation interfaces. If the device supports the CF::LoadableDevice, CF::ExecutableDevice or CF::AggregateDevice interfaces, the methods for those interfaces are also available.\nCapacity Allocation The Sandbox provides a simplified interface for capacity allocation and deallocation. The allocateCapacity() and deallocateCapacity() methods can take a Python dictionary of allocation property names and values. The values are automatically converted to the correct data type in the same manner as configure properties.\nThe following code demonstrates allocation and deallocation of multiple properties, including a struct property:\n\u0026gt;\u0026gt;\u0026gt; caps = {\u0026#34;long_cap\u0026#34;: 1000, ... \u0026#34;float_cap\u0026#34;: 1.0, ... \u0026#34;struct_cap\u0026#34;: {\u0026#34;ushort_item\u0026#34;: 0, ... \u0026#34;bool_item\u0026#34;: False}} \u0026gt;\u0026gt;\u0026gt; my_dev.allocateCapacity(caps) True \u0026gt;\u0026gt;\u0026gt; my_dev.deallocateCapacity(caps) If an allocation is successful, allocateCapacity() returns True; if the device does not have sufficient capacity, it returns False.\nAllocation Properties The api() method for devices shows the allocation properties in addition to the ports and configure properties. The names, types and actions of the allocation properties are given:\n\u0026gt;\u0026gt;\u0026gt; my_dev.api() Component [MyDevice]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- None Uses (Output) Ports ============== Port Name Port Interface --------- -------------- None Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- config_prop (float/SF/32f) 1.0 1.0 DeviceKind (string) MyDevice MyDevice long_cap (long) None 1000 float_cap (float) None 100.0 Allocation Properties ====== Property Name (Data Type) Action ------------- ----------- ------ DeviceKind (string) eq long_cap (long) external float_cap (float) external struct_cap (struct) external ushort_item (ushort) bool_item (boolean) Only properties with an action of “external” may be used for the allocateCapacity() and deallocateCapacity() methods.\nFrontEnd Interfaces REDHAWK has defined a standard API for interacting with RF hardware called FEI. The Python Sandbox contains multiple helpers to make interaction between the Python environment and FEI devices easier.\nIn FEI, when BulkIO data is generated by the FEI device, a set of SRI keywords is mandated. The helper create in the frontend.sri module can translate between the FEI tuner_status structure and the required SRI.\n\u0026gt;\u0026gt;\u0026gt; from frontend import sri \u0026gt;\u0026gt;\u0026gt; my_SRI = sri.create(\u0026#34;my stream id\u0026#34;, self.frontend_tuner_status[tuner_idx])"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/nodes/distributed-computing-and-rf-devices/",
	"title": "Distributed Computing and RF Devices",
	"tags": [],
	"description": "",
	"content": " Dependencies A component can be described as consuming an arbitrary amount of capacity from a device; this relationship is called a dependency. Dependencies are generalized, so it is possible to create a dependency based on attributes (properties of kind allocation) of devices irrespective of the specific nature of a device.\nA dependency is defined by how much of a particular device resource is required. For example, a component dependency could be a requirement of 1.7 units of device property some_id. Testing this description requires the runtime environment to only determine whether a device contains an allocation property with the ID some_id; this concept can be generalized to any physical constraint that a device might have, requiring only a convention between the component developer and the device developer regarding a device’s property ID and units, both of which are publicized in a device’s PRF file (prf.xml).\nAllocation Properties Allocation properties are device properties that are associated with an action and are used by the runtime environment to determine whether or not a device can support a particular component dependency. This action can either be external or some logical operation (e.g., eq (equals) or lt (less than)).\nNon-External Properties Non-external properties are evaluated by the runtime environment without querying the device. For example, a component dependency on an allocation property with operation eq might be blue. The runtime environment then checks the device’s PRF file (prf.xml) and the Device Manager’s configuration file for the deployment of that device (dcd.xml) to determine whether that property’s value is equal to blue.\nExternal Properties External properties, on the other hand, are handled by the device. For example, a component dependency on an allocation property with operation external might be yellow. The runtime environment then makes a function call on that device with two arguments: the allocation property ID and the value yellow. The device then, at its own discretion, determines whether to provide a positive response or a negative one. The algorithm used by the device to determine whether or not it has sufficient capacity to allocate against a value of yellow is left up to the device developer.\nAllocation Usage Capacity allocation can be defined at either the component level or the application level. When defining the capacity allocation at a component level, that means that every time this component is deployed, that capacity must be available. When defining the capacity allocation at a application level, that means that every time that this application is deployed, that capacity must be available, irrespective of which components make up the application.\nEven though capacity allocation can be used to describe any dependency that a component may have, in reality there are two kinds of capacities that concern REDHAWK: RF and computing.\nRF Allocation The allocation of RF capacities is with properties that are defined as part of the FrontendInterfaces. It generally makes more sense to define the RF capacity allocation at the application level rather than the component level, since the application understands the context for the deployment. However, RF capacity dependencies can be declared at either the component level or the application level.\nComputing Allocation Determining capacity for computation is different from determining RF needs. RF needs are fairly straightforward (i.e.: I need to tune to 100 MHz with a 200 kHz bandwidth). Computing resources, on the other hand, can vary substantially. A program (i.e.: a component) consumes different amount of computing resources depending on the nature of the computing platform. Things like L2 cache size and the layout of the processor (from a NUMA perspective) can have a dramatic impact on the computational load a program has on the processor.\nDue to the variability intrinsic to computing resources, REDHAWK does not rely on hardcoded estimates for the selection of a computing platform. Instead, GPP implements a reservation mechanism. When a component is loaded onto the GPP, the GPP reserves an arbitrary, and tunable, amount of resources. GPP tracks the state of the component, and when the component changes state from stopped to started, the reservation is tabled, and GPP inspects the actual usage by the component. When the state of the component changes from started to stopped, the tabled reservation is applied again.\nUsing this reservation/observation behavior, components can be automatically distributed over an arbitrary number of computers with no planning needed on the part of the user.\nThe user can force components to deploy to specific GPPs. To force a specific placement, use the device assignment fields when creating the application.\nThe Deployment Process The runtime environment scans all non-busy executable devices registered in the domain to determine which GPP matches the processor/operating system dependency. A device is busy when its state is returned as BUSY, otherwise it is either IDLE or ACTIVE. When a device is found that satisfies all component dependencies, it marks that device as assigned to the deployment of that component and moves on to whatever other components make up the waveform. Once all components have been found an assigned GPP, the components are deployed to all those GPPs.\nBinding a Component’s Deployments to Executable Devices When deploying Components, you may want to bind a Component’s deployment to a specific Executable Device without going through the allocation process. For more information about binding a Component’s deployment to an Executable Device, refer to . The Node definition file (DCD) provides the necessary deployerrequires id/value pairs to be associated with an Executable Device. These id/value pairs are alphanumeric strings that are matched during a Component’s deployments. If a Component defines a set of devicerrequires, then the Domain is searched for ExecutableDevices that have a matching set. For Components that do not have an id/value set, but request to deploy on an ExecutableDevice with an id/value set, that request for deployment fails.\nThe following example describes the new xml elements deployerrequires that can be assigned to a GPP device (ExecutableDevice):\n\u0026lt;!-- example of ID/value pairs for a GPP in a DCD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;GPP1_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;RED_NODE:GPP_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;RED_NODE:GPP_1\u0026lt;/usagename\u0026gt; \u0026lt;deployerrequires\u0026gt; \u0026lt;requires id=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;requires id=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/deployerrequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; Distribution of Files All component binaries and descriptor files reside in $SDRROOT/dom on whatever host is running the Domain Manager. In every host that is running a Device Manager, a cache directory is created in $SDRROOT/dev/.\u0026lt;Device Manager name\u0026gt;, with a directory entry for each device that the Device Manager manages. When a component runs on any given device, the binary (or module or JAR file) is copied from $SDRROOT/dom to the device’s cache directory. Using this mechanism, the device can start the component process on a remote host.\nDependency Management A difficulty in deploying a component is that, as a program, it might have dependencies like C/C++ libraries, Python modules, or Java JARs. REDHAWK allows for the creation of soft package dependencies, where a library, module, or JAR can be associated with its own profile. Components that have a runtime dependency with this library, module, or JAR, can declare this library profile as a dependency. When the component is loaded over the network, this dependency is also loaded, and before the component is forked, the component’s local running environment is changed to include the library in $LD_LIBRARY_PATH, module in $PYTHONPATH, or JAR in $CLASSPATH. The allocation/dependency requirements associated with the component are also applied to the library; for example, if a component is designed to run on an x86_64 platform, the runtime environment checks that dependency runs on an x86_64 platform.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/getting-started/ide-quickstart/",
	"title": "IDE Quickstart",
	"tags": [],
	"description": "",
	"content": " This section provides a simple example of the REDHAWK signal processing development environment, though it is far from a comprehensive guide to all of the features available in the REDHAWK IDE. While this guide assumes the user has no prior knowledge of the REDHAWK Core Framework, certain concepts and skills are required to fully understand the material.\nThe minimum technical requirements include:\n Object-oriented programming experience Linux/Unix experience Engineering/Computer Science background Understanding of basic communication theory  In addition to the minimum set of technical requirements, the following prerequisites must be met before beginning the following procedure:\n REDHAWK Core Framework and IDE installed Example components installed:  SigGen HardLimit   Basic IDE Use The following sections discuss how to launch the REDHAWK IDE, how to open the Chalkboard, how to create a signal generator, and how to test the input/output response of a component.\nLaunching the REDHAWK IDE  Start the REDHAWK IDE with the following command:\nrhide If prompted to specify a workspace location, select an appropriate location and select OK.\n  Opening the Chalkboard From the REDHAWK Explorer view expand Sandbox, and double-click Chalkboard.\nCreating a signal generator  From the Chalkboard Palette, drag the SigGen (python) component into the Chalkboard canvas.\n In the Palette, if the SigGen component is not displayed, under Components, left-click the rh folder to display the list of available components. If the Python implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name. After the list is displayed, left-click the desired implementation. When the component is finished loading, its background color is blue.  Right-click the SigGen component, and click Start.\n Right-click the SigGen component, and click Show Properties View.\n From the Properties view, change the frequency to 20Hz.\n From the Properties view, change the magnitude to 1.\n Right-click SigGen’s dataFloat_out port, and click Plot Port Data.\n Right-click the SigGen component, and click Stop.\n  Testing the input/output response of a component  From the Chalkboard Palette, drag the HardLimit (python) component into the Chalkboard canvas.\n In the Palette, if the HardLimit component is not displayed, under Components, left-click the rh folder to display the list of available components. If the Python implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name. After the list is displayed, left-click the desired implementation. When the component is finished loading, its background color is blue.  Click-and-drag from SigGen’s dataFloat_out port to the HardLimit dataFloat_in port.\n Right-click the SigGen component, and click Start.\n Right-click the HardLimit component, and click Start.\n Right-click the HardLimit’s dataFloat_out port, and click Plot Port Data. Two Plot Port views are now open, one for each of the plotted ports.\n  Right-click the SigGen component, and click Show Properties View.\n From the Properties view, change the magnitude to 5.\nThe Plot Port view for the HardLimit dataFloat_out port is now limiting the output to 1.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/standalone-ide/",
	"title": "Installing a Stand-alone IDE",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE leverages Java technologies and requires Java 8. The IDE also includes native libraries that allow the IDE to have a look and feel appropriate for the OS. A minimum of 2 GB of RAM is required, but 4 GB+ is recommended.\nThe following procedure explains how to install a stand-alone IDE.\n Ensure your system has the appropriate dependencies installed.\nOn RHEL/CentOS 7:\nsudo yum install java-1.8.0-openjdk-devel PackageKit-gtk3-module libcanberra-gtk3 libwebkit2gtk On RHEL/CentOS 6:\nsudo yum install java-1.8.0-openjdk-devel PackageKit-gtk-module libcanberra-gtk2 webkitgtk Locate the appropriate archive from the REDHAWK release page on GitHub (https://github.com/RedhawkSDR/redhawk/releases/\u0026lt;version\u0026gt;). (Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE. For example, https://github.com/RedhawkSDR/redhawk/releases/2.0.3)).\n Run the following command:\ntar zxf redhawk-ide-\u0026lt;version\u0026gt;-linux.gtk.\u0026lt;arch\u0026gt;.tar.gz Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE and \u0026lt;arch\u0026gt; is either x86 for 32-bit systems or x86_64 for 64-bit systems.\n Start the IDE by running the eclipse executable in the eclipse directory.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/logging-within-a-resource/",
	"title": "Logging Within A Resource",
	"tags": [],
	"description": "",
	"content": " Resource code generated using the REDHAWK code generators provides all the necessary prerequisites for establishing and configuring the logging capability.\nC++ For C++ implementations, the generated REDHAWK code contains macro definitions that define a logger object with the class name for your resource. For example, for component SigGen, the logger is SigGen_i.\nSetup The following example describes how to define and declare the SigGen_i logger.\n//SigGen.h // this macro defines a logging object ENABLE_LOGGING; //SigGen.cpp // this macro declares the logging object PREPARE_LOGGING( SigGen_i ); Use To add logging messages within your resource’s code, the following macros are available. These macros use the predefined class logger as the input parameter.\n LOG_FATAL(\u0026lt;component_class_name\u0026gt;, message text ) LOG_ERROR(\u0026lt;component_class_name\u0026gt;, message text ) LOG_WARN(\u0026lt;component_class_name\u0026gt;, message text ) LOG_INFO(\u0026lt;component_class_name\u0026gt;, message text ) LOG_DEBUG(\u0026lt;component_class_name\u0026gt;, message text ) LOG_TRACE(\u0026lt;component_class_name\u0026gt;, message text )  The following example adds DEBUG-level logging messages to the predefined logger SigGen_i.\n... LOG_DEBUG(SigGen_i, \u0026#34;serviceFunction() example log message\u0026#34;); In addition to the resource’s predefined logger, you can request a new logger object using the rh_logger interface and named logger macros.\n RH_FATAL(logger_object, message text) RH_ERROR(logger_object, message text) RH_WARN(logger_object, message text) RH_INFO(logger_object, message text) RH_DEBUG(logger_object, message text) RH_TRACE(logger_object, message text)  The following example creates a new logger object (myLogger) and adds DEBUG-level logging messages to myLogger using the rh_logger interface.\n// local named logger LOGGER myLogger = rh_logger::Logger::getLogger(\u0026#34;AnotherLogger\u0026#34;); ... RH_DEBUG(myLogger, \u0026#34;serviceFunction() example log message\u0026#34;); Java For Java implementations, the log4j logger module must be imported for use before the logging capability can be established and configured.\nSetup The following example describes how to import the log4j logger module.\n//component.java import org.apache.log4j.Logger; class MyComponent { // gets logger object based on the class name...  public final static Logger logger = Logger.getLogger(component.class.getName()); ... } Use The following example describes how to enable the logger with DEBUG-level logging messages.\nvoid someMethod() { logger.debug(\u0026#34;serviceFunction() example log message\u0026#34;) }; Log4j supports the following severity levels for logging and enables you to programmatically change the severity level of the logger object.\nlogger.fatal(...) logger.warn(...) logger.error(...) logger.info(...) logger.debug(...) logger.trace(...) logger.setLevel(Level.WARN) Python Setup All REDHAWK resources inherit from the Resource class, which defines the _log data member.\nUse An example logging method call for Python is:\nself._log.debug(\u0026#34;process() example log message\u0026#34;) REDHAWK has extended the Python logging support to include the trace method functionality. As with the other logging capabilities, you can programatically change the logging level.\nself._log.fatal(...) self._log.warn(...) self._log.error(...) self._log.info(...) self._log.debug(...) self._log.trace(...) self._log.setLevel(logging.WARN)"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/multiout-ports/",
	"title": "Multi-out Ports",
	"tags": [],
	"description": "",
	"content": "Each output BurstIO port type provides the ability to filter burst data from the resource based on stream id and connection id. To use the multi-out capability of the ports, a resource must include code similar to the following:\n\u0026lt;structsequence id=\u0026#34;connectionTable\u0026#34;\u0026gt; \u0026lt;struct id=\u0026#34;connectionTable::connection_descriptor\u0026#34; name=\u0026#34;connection_descriptor\u0026#34;\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::connection_id\u0026#34; name=\u0026#34;connection_id\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::stream_id\u0026#34; name=\u0026#34;stream_id\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::port_name\u0026#34; name=\u0026#34;port_name\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;/struct\u0026gt; \u0026lt;configurationkind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/structsequence\u0026gt; To steer a particular stream of data to a particular connection, pass the connectionTable object to the port’s updateConnectionFilter method. With the routing mode set to ROUTE_CONNECTION_STREAMS, the port will then apply the filter state to any burst traffic as it is passed out the resource’s BurstIO port. For the burst to be passed to an existing connection, there must exist a match in the port’s filters table for the burst’s stream id and connection id of the resource downstream.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/node-editor/",
	"title": "Node Editor",
	"tags": [],
	"description": "",
	"content": " To open the Node Editor, double-click a DCD file from the Project Explorer View. It presents all the content that can be found within the dcd.xml file in an editing environment designed for ease of use. The Node Editor contains an Overview, Devices / Services, Diagram, and a raw XML tab, which contains the DCD file content.\nOverview Tab Node Editor Overview Tab The Overview tab provides general information about the node, and hyperlinks to additional node-related sections within the IDE. In the top-right corner, the Generate Node button is used to generate supporting files for the node. To produce an RPM spec file for the node, click the button.\n The General Information section provides controls to set the ID, Name, and Description of the node. The Project Documentation section displays a Header hyperlink, which if clicked, provides the option to create and edit the file \u0026ldquo;HEADER\u0026rdquo; in the project. When code generation is performed, the header is applied to your project files. The Testing section is currently under development and is presently not supported. The Exporting section provides a hyperlink to the Export Wizard, which steps through the process of deploying the node into the SDR root.  Devices/Services Tab Node Editor Devices/Services Tab The Devices/Services tab enables a user to add devices and services from the SDR Root into the node and to configure the properties for the devices and services. When a property is set or changed here, it is specific to this node and does not impact other nodes or instances of this device or service.\nThe following steps explain how to add a device to the node:\n Click Add….\n Select the device or service to add.\n Click Finish.\n  Use the table in the Details section to configure the properties of the device or service.\nDiagram Tab Node Editor Diagram Tab The Diagram section (along with the Properties View) provides the same features as the Devices/Services tab.\nTo zoom in and out on the diagram, press and hold Ctrl then scroll up or down. Alternatively, press and hold Ctrl then press + or -.\n Adding a Device and Editing Device Properties in a Node The following steps explain how to add a device to the node and configure its properties:\n Drag the device from the Palette onto the diagram.\n Select the device.\n Open the Properties View and verify the Properties tab is selected.\nProperties View  From the Properties View, change the desired properties.\n Press Ctrl+S to save the changes.\n  If you want to quickly find a device in the Palette, you can replace the text type filter text in the text field at the top of the Palette with a keyword to filter the device list.\n Like the Devices/Services tab, any property modified from the Diagram section is specific to this node and does not impact the device’s execution in other environments.\nEditing the deployerrequires Set in a Node The deployerrequires set for a Node is managed through the Requirements tab of the Properties view. When these Requirements are set, they become specific to the node and are written to the *.dcd.xml file.\nThe following steps explain how to edit the deployerrequires set.\n On the Diagram tab of the Node, select the Device In the Properties View, verify the Requirements tab is selected.\nProperties View Requirements  To add an ID and value, click + and add the ID and value. The ID and value can be any alphanumeric string value. This assigns a devicerequires key/value pair to the Node.\n To remove an ID and value, select the ID and click X.\n  Using the Find By Feature From the Diagram tab, a user may also use the Find By feature. The Find By feature enables a user to find a resource by name, a service by name or type, or an Event Channel by name.\nMaking Connections Connections may be made from input to output ports by clicking and dragging from one port to the other. ports may have more than one connection drawn to or from them. Any unsupported or erroneous connection detected by the IDE is marked with an appropriate indicator. Hovering over the indicator provides information concerning the error.\nStart Order Each of the Devices/Services within the node contains a number with a circle around it, which represents that device’s/service’s start order. The start order represents the order in which its start() method is called by the Device Manager on startup and the stop() method is called by the Device Manager on shutdown. The start order ’0’ is called first. Start order is optional and may be changed by right-clicking a Device/Service and selecting Move Start Order Earlier or Move Start Order Later from the context menu. Devices/Services without a start order will not be started or stopped automatically.\nThe dcd.xml tab The dcd.xml tab displays the raw XML data, which describes the node fully. Although not recommended, manually editing the XML file is supported.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/shared-libraries/packaging-shared-libraries/",
	"title": "Packaging Shared Libraries",
	"tags": [],
	"description": "",
	"content": " The REDHAWK code generators for components support locating and building against REDHAWK shared libraries in C++, Python, and Java. This section covers the conventions for packaging shared libraries to allow the REDHAWK build system to find, build, and run with shared libraries. The REDHAWK IDE provides a C++ shared library project type that automatically manages the build and installation of C++ libraries; however, in some cases, it may be necessary to create a REDHAWK shared library manually.\nGeneral A shared library has an SPD but does not include a PRF or SCD.\nThe implementation has a localfile element but no entrypoint. The localfile points to the directory or file that contains the library.\nShared libraries are installed in $SDRROOT/dom/deps/\u0026lt;library name\u0026gt;/. Libraries may be namespaced; for example, a library named rh.example would be installed to $SDRROOT/dom/deps/rh/example/.\nC++ Libraries The implementation of a C++ shared library is a .so file, or a directory containing multiple .so files. For building and linking components, C++ shared libraries also contain header files and a .pc file.\nHeader files are installed in include/ under the top-level soft package directory. Libraries are installed in the implementation directory, typically cpp/lib/. The shared library must include a .pc file that is installed in pkgconfig/ under the library directory (for example, cpp/lib/pkgconfig/mylib.pc).\nThe following example shows a file list for a C++ library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/include/mylib.h $SDRROOT/dom/deps/mylib/cpp/lib/libmylib.so $SDRROOT/dom/deps/mylib/cpp/lib/pkgconfig/mylib.pc  At runtime, the implementation directory is added to LD_LIBRARY_PATH.\nPython Libraries The implementation of a Python shared library is one or more .py modules. The modules may be standalone, or organized into packages.\nPython code is installed in the implementation directory, python. The library must be importable from that location.\nThe following example shows a file list for a Python library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/python/mylib/__init__.py $SDRROOT/dom/deps/mylib/python/mylib/utils.py  At runtime, the implementation directory is added to PYTHONPATH.\nJava Libraries The implementation of a Java shared library is a single .jar file.\nThe .jar file is installed in the implementation directory, java/.\nThe following example shows a file list for a Java library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/java/mylib.jar  At runtime, the .jar file is added to CLASSPATH.\nOctave Libraries The implementation of an Octave shared library is a directory of .m files.\nOctave code is installed in the implementation directory (typically noarch).\nThe following example shows a file list for an Octave library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/noarch/func1.m $SDRROOT/dom/deps/mylib/noarch/func2.m  At runtime, the implementation directory is added to OCTAVE_PATH.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/port-access/",
	"title": "Port Access",
	"tags": [],
	"description": "",
	"content": "A port belongs to a component or device (devices are specialized components - see Working With Devices for additional information). To retrieve a port, an external entity needs to call getPort() on the component that owns that port. The argument to the getPort() function is the string name for the port, and the return value is a CORBA pointer to that port object. Both uses and provides ports are retrieved from components through this function call. Base supported interfaces are not retrieved through the getPort(), because they are not ports. Instead, these references are retrieved directly from an entity like the Domain Manager or the Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/stream-api/",
	"title": "Stream API",
	"tags": [],
	"description": "",
	"content": " The BulkIO stream API provides a high-level interface to sending and receiving data via BulkIO ports. Each stream is tied to a port, and encapsulates both the SRI and the data associated with it.\nStreams are automatically managed by the port that creates them. User code does not own the stream itself; instead, user instances are opaque stream handles. This allows them to be passed around by value or safely stored in other data structures.\nAll numeric BulkIO port types support the stream API. UDP multicast (SDDS and VITA49) and string-based (string, file and XML) interfaces do not.\nMost stream methods are not thread-safe; it is assumed that each stream will be written to or read from by a single thread. However, it is safe to use multiple streams simultaneously.\nThe BulkIO stream API is C++-only in REDHAWK 2.1.3\n Output Streams Each numeric output port type has a corresponding stream type (e.g., bulkio::OutFloatStream for bulkio::OutFloatPort) that provides the interface for sending stream data. Using streams ensures that data is always associated with an active SRI and simplifies management of stream lifetime.\nCreate an output stream via the port:\n// Create a new stream with ID \u0026#34;my_stream_id\u0026#34; and default SRI bulkio::OutFloatStream stream = dataFloat_out-\u0026gt;createStream(\u0026#34;my_stream_id\u0026#34;); Output streams provide convenience methods for modifying common SRI fields:\n// Stream is complex data at a sample rate of 250Ksps, centered at 91.1MHz stream.complex(true); stream.xdelta(1.0 / 250000.0); stream.setKeyword(\u0026#34;CHAN_RF\u0026#34;, 91.1e6); The SRI can be updated in its entirety with the sri() method. Updates to the SRI are stored and pushed before the next packet goes out.\nIt is not necessary to manually call pushSRI() when using streams.\n Data is sent with the write() method:\n// Assume data is of type std::vector\u0026lt;float\u0026gt; stream.write(data, bulkio::time::utils::now()); // Assume buffer is a pointer to std::complex\u0026lt;float\u0026gt; stream.write(buffer, size, bulkio::time::utils::now()); Complex data should be written with a vector of or pointer to std::complex values to ensure that an integral number of samples is sent. When writing scalar data to a complex stream, make sure that the size is a multiple of 2.\nClosing an output stream sends and end-of-stream packet and dissociates the stream from the output port.\nstream.close(); Input Streams An input stream encapsulates SRI and all received packets associated with that stream ID. Buffering and overlap are built in, removing the need for client code to implement these features. Each numeric input port type has a corresponding stream type (e.g., bulkio::InFloatStream for bulkio::InFloatPort).\nInput streams are created automatically by the input port when an SRI is received with a new stream ID. Only one stream per port can exist with a given stream ID; in the event that an input stream has an unacknowledged end-of-stream waiting, a new SRI with the same stream ID will be queued until the end-of-stream has been reached.\nMethods that accept or return a number of samples take the input stream’s complex mode into account. For example, requesting 1024 samples from a complex stream returns 1024 complex pairs, which is equivalent to 2048 scalar values.\nThere are two ways of retrieving an input stream: Stream Polling or Stream Callback.\nStream Polling For the basic case, the getCurrentStream() method returns the next input stream that is ready for reading. Similar to getPacket(), the next packet in the queue is consulted; however, if any stream has buffered data from a prior read (such as when using fixed-sized reads), it is given priority. Developers accustomed to using getPacket() will find that getCurrentStream() provides a familiar flow, while extending the available functionality.\nThe optional timeout argument is identical to the timeout argument for getPacket. If the timeout is omitted, getCurrentStream() defaults to blocking mode:\n// Wait indefinitely for a stream to become ready bulkio::InFloatStream stream = dataFloat_in-\u0026gt;getCurrentStream(); if (!stream) { return NOOP; } If there are no streams ready, such as when the timeout expires or the component receives a stop() call, the returned stream will be invalid. The boolean not (!) operator returns true if the stream is invalid; no other operations are safe to call on an invalid stream.\nAdvanced Polling For more advanced use, the input port’s pollStreams() family of methods allow you to wait for one or more streams to be ready to read. Like getCurrentStream(), pollStreams takes a timeout argument to set the maximum wait time.\nThe ready streams are returned as a list:\n// Wait up to 1/8th second for a stream to be ready bulkio::InFloatPort::StreamList streams = dataFloat_in-\u0026gt;pollStreams(0.125); if (streams.empty()) { return NOOP; } for (bulkio::InFloatPort::StreamList::iterator stream = streams.begin(); stream != streams.end(); ++stream) { // Handle each stream; note that stream is an iterator  LOG_TRACE(Component_i, \u0026#34;Reading stream \u0026#34; \u0026lt;\u0026lt; stream-\u0026gt;streamID()); } If no streams are ready, the returned list is empty. pollStreams() returns as soon as one stream is ready.\nIf a minimum number of samples is required, it may be provided in the pollStreams() call:\nbulkio::InFloatPort::StreamList streams = dataFloat_in-\u0026gt;pollStreams(1024, bulkio::Const::BLOCKING); Stream Callback As opposed to polling, callback functions may be registered with the input port to be notified when a new stream has been created. Using a callback supports more sophisticated patterns, such as handling each stream in a separate thread or disabling unwanted streams.\nThe callback has no return value and takes a single argument, the input stream type:\nvoid MyComponent_i::newStreamCreated(bulkio::InFloatStream newStream) { // Store the stream in the component, set up supporting data structures, etc. } Register the callback with the port in the REDHAWK constructor:\nvoid MyComponent_i::constructor() { ... dataFloat_in-\u0026gt;addStreamListener(this, \u0026amp;MyComponent_i::newStreamCreated); ... } Data Blocks In BulkIO input stream-based code, data is retrieved from data streams as blocks. Each input stream data type has a corresponding data block type, such as bulkio::FloatDataBlock. Data blocks can be retrieved on a per-packet basis, or they can be retrieved as a definite-sized buffer, with or without overlap.\nReading Data Blocks The read() family of methods synchronously fetch data from a stream. The basic read() returns the next packet worth of data for the stream, blocking if necessary:\nbulkio::FloatDataBlock block = stream.read(); You may request a set amount of data by supplying the number of samples:\nbulkio::FloatDataBlock block = stream.read(1024); The read() call blocks until at least the requested number of samples is available. Packets are combined or split as necessary to return the correct amount of data. The returned block may contain less than the requested number of samples if the stream has ended or the component is stopped.\nFor algorithms that require data to overlap between iterations, you may also pass the number of samples to consume:\n// Read with 1K samples with 50% overlap bulkio::FloatDataBlock block = dataFloat_in-\u0026gt;read(1024, 512); The input stream’s read pointer is advanced up to the consume length. The next call to read() will return data starting at that point.\nIf the an end-of-stream flag is received, or the component is interrupted, read() may return early. In the overlap case, if end-of-stream is reached before receiving the requested number of samples, all remaining data is consumed and no further reads are possible.\nif (!block) { if (stream.eos()) { // Stream has ended, no more data will be received  } } Data can be dropped with skip():\n// Drop the next 256 samples size_t skipped = stream.skip(256); The returned value is the number of samples that were dropped. If the streams ends or the component is stopped, this may be less than the requested value.\nNon-Blocking Read The read() family of methods is always blocking. For non-blocking reads, use tryread():\nbulkio::FloatDataBlock block = stream.tryread(2048); tryread() will only return a valid block of data if the entire request can be satisfied, or if no more data will be received. In the case that the stream has ended or that component has been stopped, all remaining queued data in the stream will be returned.\nInteracting with Data Blocks Data blocks contain the data as an array of sample data, as well as the SRI that describes the data. The memory is managed automatically inside the object to minimize copies, so there is no need to explicitly delete data blocks. A variety of functions are contained in data blocks that help the developer manage and interact with the data block’s contents.\nVerifying Correctness The boolean not (!) operator returns true if a block is invalid. This occurs when the stream is unable to read the requested data, such as when the component receives a stop() call.\nbulkio::FloatDataBlock block = stream.read(); // Check if a valid block was returned if (!block) { return; } // Operate on the block Metadata  sri() returns the SRI at the time the data was received xdelta() returns the SRI xdelta  Occasionally, the input stream’s state may change between data blocks. To handle this situation, the data block provides methods to check these conditions:\n inputQueueFlushed() sriChanged() sriChangeFlags() returns the changed SRI fields as a bit field  if (block.inputQueueFlushed()) { // Handle data discontinuity... } if (block.sriChangeFlags() \u0026amp; bulkio::XDELTA) { // Update processing... } Scalar Data  data() returns a pointer to the first element size() returns the number of values  std::float* data = block.data(); for (size_t index = 0; index \u0026lt; block.size(); ++index) { data[index] = std::abs(data[index]); } Complex Data If the input stream is complex, the returned data buffer should be treated as complex data. Data block objects provide convenience methods to make it easy to work with complex data:\n complex() returns true if the data is complex (i.e., SRI mode is 1) cxdata() returns a pointer to the first element as a complex value cxsize() returns the number of complex values  if (block.complex()) { // Take the complex conjugate of each sample  std::complex\u0026lt;float\u0026gt;* data = block.cxdata(); for (size_t index = 0; index \u0026lt; block.cxsize(); ++index) { data[index] = std::conj(data[index]); } } Time Stamps Because a single data block may span multiple input packets, it can contain more than one time stamp. Data blocks returned from an input stream are guaranteed to have at least one time stamp.\nTime stamps are accessed with the getTimestamps() method:\nstd::list\u0026lt;bulkio::SampleTimestamp\u0026gt; timestamps = block.getTimestamps(); BULKIO::PrecisionUTCTime time = timestamps.front().time; The bulkio::SampleTimestamp class contains three fields:\n time - a BULKIO::PrecisionUTCTime time stamp offset - the sample number at which this time stamp applies synthetic - is true if the time stamp was calculated based on a prior data block  When the start of a data block does not match up exactly with a packet, the input stream will use the last known time stamp, the SRI xdelta and the number of samples to calculate a time stamp. Only the first time stamp in a data block can be synthetic.\nIgnoring Streams Some components may prefer to only handle one stream at a time. Unwanted input streams can be disabled, typically in a new stream callback:\nstream.disable(); All data for the stream will be discarded until end-of-stream is reached, preventing queue backups due to unhandled data.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/workbench/",
	"title": "The Workbench",
	"tags": [],
	"description": "",
	"content": " The Eclipse introductory screen displays a Workbench button that takes the user to the ide’s development environment: the workbench. The workbench is made up of multiple, smaller windows, which are referred to as views in the Eclipse context.\nAt the center of the IDE workbench is the editor window, which is empty at initial startup. The editor is the primary window used when developing code within the REDHAWK IDE. An Eclipse editor is a context-sensitive window within the workbench; the language of opened files dictates the type of editor that is opened, impacting editing features such as syntax highlighting.\nFor a more detailed understanding of the Eclipse environment and nomenclature, consult the online Eclipse documentation at http://help.eclipse.org/ or the embedded documentation within the REDHAWK IDE by selecting Help \u0026gt; Search.\nPerspectives The views that makeup the workbench, along with the particular layout of those views, are referred to as a perspective. By changing perspectives throughout the development process, a developer may optimize his/her work environment based on the requirements of the particular task at hand. The default perspective in the REDHAWK IDE is the REDHAWK perspective, which is discussed in the following section. A user may switch from the REDHAWK perspective to any other perspective whenever needed.\nThere are two primary methods for changing perspectives:\n Click Open Perspective from the top right of the workbench.\nOpen Perspective  Select Window \u0026gt; Open Perspective \u0026gt; Other.\n  A view may be resized, moved, and closed within a given perspective to allow for personal customization.\nTo reset the current perspective to its default state:\n Click Window \u0026gt; Reset Perspective…  The REDHAWK Perspective The REDHAWK perspective is comprised of seven views and the editor window. Five of these views are provided by Eclipse IDE, while the remaining two views are REDHAWK-specific.\nThe following five Eclipse-provided views are in the REDHAWK perspective:\n Project Explorer View: Provides a hierarchical view of the resources in the Workbench. Outline View: Displays an outline of a structured file that is currently open in the editor area. Properties View: Displays property names and basic properties of a selected resource. Problems View: Automatically logs problems, errors, or warnings when working with various resources in the workbench. Console View: Displays a variety of console types depending on the type of development and the current set of user settings.  The following two REDHAWK-specific views are in the REDHAWK perspective:\n REDHAWK Explorer View: Allows a user to navigate the contents of a REDHAWK domain. It provides capabilities for viewing the contents of the domain, configuring instantiated resources, and launching applications in a target SDR environment. It also provides access to the Sandbox, which is an environment for running components and applications without a Domain Manager or a Device Manager.\nREDHAWK Explorer View  CORBA Name Browser View: Maps names to specific CORBA Servants. The CORBA Name Browser View is used to examine the current contents of the Naming Service as well as perform basic manipulation of that context. The view displays all currently bound name contexts (folders) and objects. The CORBA Name Browser View is displayed in .\nCORBA Name Browser View   Programming Language Specific Perspectives While the REDHAWK perspective combines views that are commonly used while viewing domain objects, creating REDHAWK resources, and launching applications, many other perspectives are available that are optimized for code development. Because the REDHAWK IDE is built on top of the Eclipse platform, it takes advantage of standard Eclipse, as well as third party, IDE perspectives for the purpose of supporting language-specific development. Specifically, the IDE contains perspectives that support C/C++, Java, and Python development.\nFor example, the Java perspective combines views that are commonly used while editing Java source files, while the Debug perspective contains the views that are used while debugging Java programs.\nFor more information on perspectives, particularly the Eclipse default and the programming language-specific perspectives packaged with the REDHAWK IDE, refer to http://help.eclipse.org/.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/running-components/",
	"title": "Using Devices to Run Components",
	"tags": [],
	"description": "",
	"content": " The Sandbox runs components without needing a device proxy; it forks the component process and manages its lifecycle. When running in a domain, however, the deployment of components in an application requires the domain to search for available host computers that can run the components in the application. The search requires each host computer to have a program that can publicize the host computer’s capabilities (for example, operating system, processor type, or available memory). This proxy is referred to as an Executable device. REDHAWK includes a default Executable device, the General Purpose Processor (GPP), which is automatically configured by the create_node.py script whenever a new node is installed on the host computer. GPP is written in C++ and can serve any node that supports x86 32 and 64-bit architecture. In cases where a more specialized proxy is required, REDHAWK includes base classes that can be extended in Python or C++. However, a detailed discussion of this process is beyond the scope of this document.\nControlling the Cache and Working Directory When a component is deployed by the GPP, it operates as a separate entity, either as a forked process or an operating thread (in the case of C++). Each component has a corresponding cached file or set of cached files and a working directory from which the program executes. The GPP manages the cached files and working directory settings through the cacheDirectory and workingDirectory properties, respectively. These properties can be reconfigured using the node’s configuration file (DCD).\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/interacting-with-hardware/using-fei-device-ide/",
	"title": "Using an FEI Device in the IDE",
	"tags": [],
	"description": "",
	"content": " After you have created the FEI device, you can launch the device in the sandbox or launch it in a domain as part of a node. For more information, refer to Launching Components in the IDE Sandbox or Creating a New Node and Launching a Domain. After launching the device, the FrontEnd Tuners folder is displayed under the device in the REDHAWK Explorer view and the available tuners are displayed under it with a tuning fork icon:\nAvailable FEI Tuners Allocating a FrontEnd Tuner The usage status of a FrontEnd Tuner device is IDLE until a successful allocation has been made. Allocation is the process where a specific tuner is requested for use, and initial setup of the tuner is performed. When at least one channel has been allocated, but there is one channel not allocated, the device is ACTIVE. If all channels have been allocated, the device is BUSY.\nThe following procedure explains how to allocate a FrontEnd tuner using the Allocate Tuner wizard.\n Right-click the FrontEnd Tuners folder and select Allocate:\nAllocating an FEI Tuner The Allocate Tuner wizard is displayed. In this wizard, you specify the desired tuner properties such as frequency, bandwidth, and so forth.\nAllocate Tuner Wizard  In the Allocation drop-down box, verify Control New Tuner is selected.\n Optionally, in the New Allocation ID field, modify the text if needed.\n In Tuner Type, select the appropriate tuner type. You have the following options:\n RX_DIGITIZER CHANNELIZER DDC RX RX_DIGITIZER_CHANNELIZER TX RX_SCANNER_DIGITIZER  In Center Frequency (MHz), specify the center frequency. Bandwidth and sample rate must be specified during allocation. For an allocation to be successful, the tuner must be able to provide a value that is greater than or equal to the requested value without exceeding the appropriate tolerance value specified. Requesting a bandwidth or sample rate of zero (0.0) indicates to the tuner that any value is acceptable and that the tolerance values can be ignored. Requesting 0 typically results in the lowest value the tuner is capable of providing while still satisfying the remainder of the allocation request. If the Any Value checkbox is selected, a value of 0 is requested.\n  In Bandwidth (MHz), specify the bandwidth, or if a specific bandwidth is not required, select the Any Value checkbox.\n In Sample Rate (Msps), specify the sample rate, or if a specific sample rate is not required, select the Any Value checkbox.\n Optionally, adjust the Bandwidth Tolerance (%) or Sample Rate Tolerance (%) (Refer to Optional Status Elements).\n Optionally, specify the ID of the analog feed in RF Flow ID or the device\u0026rsquo;s Group ID.\n If allocating a scanner, click Next. For any other allocation, click Finish.\nFor a scanner allocation, the Scanner Allocation page is displayed:\nScanner Allocation You must complete the following for the scanner:\n In Minimum Frequency (MHz) and Maximum Frequency (MHz), specify the lower and upper bounds of the frequencies that will be scanned.\n In Mode, select SPAN_SCAN to request scanning ranges of frequencies, or DISCRETE_SCAN to enumerate individual frequencies.\n In Control Mode, select TIME_BASED to specify the minimum dwell time of the scanner in seconds, or SAMPLE_BASED to specify the minimum dwell time in samples.\n In Control Limit, specify a lower bound on the dwell time.\n Click Finish.\n  The tuner is allocated and is displayed under the FrontEnd Tuners folder with the truncated Allocation ID and an active tuning fork icon. If you left-click or hover over the allocated tuner, the full Allocation ID is displayed. A successful allocation tunes the hardware to the requested frequency and establishes a BulkIO data stream containing the content. In the case of a multi-out BulkIO port, the data stream will only be pushed over a connection with a Connection ID that is identical to the Allocation ID associated with the data stream. In cases where the BulkIO port is not a multi-out port, all data streams are pushed over all connections, regardless of Connection id.\n  Allocated Tuner Deallocating a Tuner If a tuner was previously allocated, it can be deallocated. To deallocate a tuner, right-click the allocated FrontEnd tuner and select Deallocate. The tuner is deallocated and displays an inactive tuning fork icon along with a status of Unallocated.\nAttaching a Listener to a Tuned Receiver Sometimes, it is necessary for multiple different applications to share a single FEI source. To support this concept, FEI includes both allocation owners and listeners. The allocations that have been discussed so far are owners; they maintain complete control over the allocated hardware. Listeners, on the other hand, allow for an arbitrary number of applications to receive the same data that the allocation owner receives. However, listeners have no control over the source. Listener allocations can be made against a particular allocation (through the allocation id) or by parameters (i.e.: center frequency).\nTo allocate a listener, right-click the allocated FrontEnd tuner and select Add Listener. The Listener Allocation dialog is displayed:\nListener Allocation Dialog It is possible to specify an allocation ID for the listener, but that is strictly optional (note that the listener allocation id is needed as the connection id when consuming the listener data). Click Finish to exit the wizard and allocate the listener. When the process is complete, the listener is associate with the receiver, and is displayed under the appropriate FrontEnd tuner.\nMetadata from the Tuner Device An FEI device provides metadata along with its data stream. This metadata is attached to the SRI’s keywords passed along BulkIO. A total of 5 SRI elements have been defined, and they are described below:\nFEI Data Passed as SRI    Identifier Value Type     COL_RF The center frequency (in Hz) for the receiver that was used to receive the data. double   CHAN_RF The center frequency (in Hz) for the tuned receiver. double   FRONTEND::RF_FLOW_ID The identifier for the stream (usually the antenna), if available. string   FRONTEND::BANDWIDTH The bandwidth (in Hz) for the tuned signal. double   FRONTEND::DEVICE_ID The identifier for the device acquiring the data. string    Deallocating a Listener If a listener was previously allocated, you can deallocate it. To deallocate a listener, right-click the allocated listener and select Deallocate.\nPerforming a Scan After a tuner has been allocated in a scanning mode (RX_SCANNER_DIGITIZER), it can be given a scanning plan to execute.\n Right-click the allocated FrontEnd tuner and select Scan. The Tuner Scan wizard is displayed:\nTuner Scan  In Mode, select the type of scan to be performed. Use MANUAL_SCAN to specify a single frequency, DISCRETE_SCAN to provide a list of frequencies, or SPAN_SCAN to provide ranges of frequencies to step through.\n In Control Mode, select TIME_BASED to specify the minimum dwell time of the scanner in seconds, or SAMPLE_BASED to specify the minimum dwell time in samples.\n In Control Value, specify the dwell time.\n In Delay (s), provide the number of seconds until the scan should start.\n Click Next.\nIf MANUAL_SCAN was selected, the Manual Scan page is displayed and the single dwell frequency can be provided:\nManual Scan If DISCRETE_SCAN was selected, the Discrete Scan page is displayed and a list of frequencies can be provided:\nDiscrete Scan If SPAN_SCAN was selected, the Span Scan page is displayed and ranges of frequencies can be provided. Each range has a low (start) frequency, a high (ending) frequency, and the step width the scanner should use while scanning the range:\nSpan Scan  After entering the scan plan, click Finish. The scanning starts after the delay specified on the first page.\n  To save the data entered in the wizard to an XML file that can later be loaded, click the save button at the bottom of the wizard. To load a previously saved XML file, click the load button at the bottom of the wizard.\nControlling a Tuned Receiver FEI devices can be controlled using a FrontEnd Tuner port. The port provides an interface to modify parameters such as center frequency, bandwidth, gain, and sample rate.\nThis tuner interface provides the ability to set parameters like center frequency and bandwith for the receiver. Any FEI compliant device may not output any data until the transients from any receiver setting change have settled to steady state. In short, all data output from an FEI compliant device must correspond to unambiguous receiver settings.\nThere is a custom view under each tuned receiver that sends commands over the control port. This custom view is mapped to the properties view. Note that this is not a device property, but instead it is the use of the property view as the artifact for interacting with the port.\nThe following procedure explains how to control an allocated tuner.\n Select the allocated tuner.\n Select the properties tab if available. Otherwise, from the top IDE Menu, select Window \u0026gt; Show View \u0026gt; Properties.\nProperties View of an Allocated Tuner  Select the entry, or entries, to change from this view.\n Press Enter to have the change take affect or Esc to cancel.\n  Even though it is the property view, the Tuner port is exercised to effect the requested changes. If successful, the view updates and displays the new value.\nPlotting a Tuned Receiver The process described in only applies to a single-channel system. In multi-channel devices, a single port is used to send out all the data, so additional structures are used to identify which channel to plot.\n To plot an FEI device, right-click the allocated FrontEnd tuner and select Plot Port Data, or any other Plot Port option:\nPlotting an Allocated Tuner  If the FrontEnd tuner has multiple BulkIO ports, the Ambiguous Data Port dialog is displayed. Select the port to plot.\nFor more information about interacting with the plots, refer to REDHAWK Plot View.\n  Plotting a Tuned Receiver with Multiple Channels In multi-channel devices, all data is pushed out of a single port. To disambiguate the traffic, additional structures are used. When a device or component contains both a BulkIO output port and the well-defined property connectionTable, different data streams can be directed out of different connections on the port. When the multi-out selection is checked on the output selection of the FEI wizard, the connectionTable property is automatically added to the FEI device.\nDeclare the association between a connection ID, a stream ID, and a port name:\n// create an association between an allocation, a stream ID, and a port // the request data structure contains the allocation id // \u0026#34;my_data\u0026#34; is some arbitrary stream id // my_port is whatever output port the data is pushed out of std::string stream_id = \u0026#34;my_data\u0026#34;; this-\u0026gt;matchAllocationIdToStreamId(request.allocation_id, stream_id, this-\u0026gt;my_port-\u0026gt;getName()); // at this point, also push SRI that contains information relevant to this connection (i.e.: bandwidth) BULKIO::StreamSRI SRI = bulkio::SRI::create(stream_id); redhawk::PropertyMap\u0026amp; keywords = redhawk::PropertyMap::cast(SRI.keywords); keywords[\u0026#34;FRONTEND::BANDWIDTH\u0026#34;] = request.bandwidth; keywords[\u0026#34;FRONTEND::DEVICE_ID\u0026#34;] = this-\u0026gt;_identifier; this-\u0026gt;my_port-\u0026gt;pushSRI(SRI); Send data with the stream ID associated with a particular allocation:\n// push the data out using the arbitrary stream ID defined in the allocation id/stream id/port association this-\u0026gt;my_port-\u0026gt;pushPacket(data, bulkio::time::utils::now(), false, \u0026#34;my_data\u0026#34;); While this example is in C++, this functionality is also supported in Python and Java. Unfortunately, the allocation_csv element of the frontend_tuner_status structure pre-dates the availability of sequences as elements in structures (added in REDHAWK 2.0), so it is a comma-separated value whose first value is the owner allocation.\nconnectionTable is a readonly property, so software running outside the scope of the device can inspect but not change these associations.\n The state of the connectionTable is managed by the FEI base classes. The device developer must set up the state of connectionTable when a new tuner is added. However, when a listener is added to a tuner that is already on the connectionTable, the listener entry is managed automatically.\nWhen plotting an allocated tuner on a multi-channel device, the IDE automatically creates a listener allocation so that the correct stream is routed to the plot.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/messaging/viewing-messages/",
	"title": "Viewing Messages",
	"tags": [],
	"description": "",
	"content": "Messages are events with their payload definition tied to structures in component properties. Viewing messages can be done with the same techniques that are used to view events.\nTo view events and messages sent to an EventChannel in a terminal window:\neventviewer \u0026lt;domain name\u0026gt; \u0026lt;event channel\u0026gt; Help for the utility:\neventviewer --help Example output:\neventviewer REDHAWK_DEV testchan Receiving events. Press \u0026#39;enter\u0026#39; key to exit [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 0.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 2.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 3.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 4.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 5.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 6.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 7.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 8.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 9.0}]}]"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/waveforms/deployment-resources/",
	"title": "Waveform Deployment and Computing Resources",
	"tags": [],
	"description": "",
	"content": " Components are processes that run on a computer. As such, each component takes up some arbitrary, often time-varying amount of spare capacity (for example, CPU computing load, memory, network I/O). REDHAWK manages computing resources on every computer under its domain to minimize the likelihood that computing resources are over-subscribed. Each computer under REDHAWK’s domain is managed through the GPP process.\nGPP Device The GPP device is a specialized REDHAWK device that manages the deployment of components onto the computer and can be inspected like any other REDHAWK device.\nGPP can be in three possible usage states: IDLE, ACTIVE, or BUSY.\n IDLE indicates the GPP is not running any REDHAWK components. ACTIVE indicates the GPP is running at least one component, but has spare capacity to run additional components. BUSY indicates the GPP does not have any spare capacity to run additional components.  The usage state of any device can be accessed through its usageState member. To inspect the usage state:\n In the IDE, select the “Advanced” tab of the “Properties” tab for the deployed device. In a Python session, run the following script (assuming a domain is running):\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; dom=redhawk.attach() \u0026gt;\u0026gt;\u0026gt; dev = dom.devMgrs[0].devs[0] \u0026gt;\u0026gt;\u0026gt; print dev._get_usageState()  The GPP contains several properties that are critical for the deployment of components to a device. When a waveform is deployed, the framework scans through all IDLE and ACTIVE GPP devices. The component’s os and/or processor elements from its SPD file are compared against the GPP’s os_name and/or processor_name properties, respectively. If there is a match, the component is assigned to that GPP. This search/assignment is performed for all components in the waveform. Once all components have been assigned to specific GPPs, the deployment process begins.\nDeployment Process The deployment of a component to a GPP begins by copying all relevant files from $SDRROOT/dom/components/\u0026lt;component\u0026gt;/ to the GPP’s cache. The GPP cache is a temporary directory on the computer used to run each component (recall that REDHAWK is designed to support distributed processing). The cache is located in the local computer’s $SDRROOT/dev/.\u0026lt;Device Manager name\u0026gt;/\u0026lt;Device Name\u0026gt;. Note that the component’s working directory is the GPP’s cache directory.\nAfter all files are copied, the component is started in its own process space using the fork system call. At program startup, the component registers with the Domain Manager and the initial property state is applied to the component’s property values. Next, connections are created as defined in the waveform file. The waveform is successfully deployed when all waveform components are registered with the Domain Manager and all component initialization is complete.\nShared Address Space Components Shared address space components (C++ only) are deployed differently than executable components. The component files are still copied, but an additional specialized component called ComponentHost is deployed to the GPP to manage the components. The GPP only executes the ComponentHost via fork and exec. Once the ComponentHost registers with the Domain Manager, all of the shared address space components assigned to the GPP are executed in the ComponentHost. The remainder of the deployment process is the same as for executable components.\nUsing Valgrind to Debug Components The GPP supports launching components using Valgrind, an open source tool that helps detect memory errors and leaks.\nThe VALGRIND environment variable controls this behavior:\n If VALGRIND is not set, components launch as usual. If VALGRIND is set but has no value, the GPP searches the path for valgrind. If VALGRIND has a value, it is assumed to be the full path to the valgrind executable.  Valgrind log files are written to the same directory as the component entry point within the GPP’s cache. For example, if the component, MyComponent, has an entry point of cpp/MyComponent, the logs are written to MyComponent/cpp. The log file name follows the pattern valgrind.\u0026lt;PID\u0026gt;.log, where PID is the process ID of the component.\nMonitoring Computing Resources per Application Each application object has a metrics function that provides access to application-level metrics. The available metrics include:\n cores: number of cores used memory: amount of memory occupied processes: how many processes make up the component files: how many file handles the component has open threads: how many threads the component has open shared: whether or not it is a shared address space component (C++ only) componenthost: The id for the component’s host  Component id for C++ components generated in RH 2.0 or earlier, and Python and Java components ComponentHost_GPP_1 for shared address space C++ components   The metrics are available on a per-component basis or aggregated for the whole application.\nThe metrics function takes two arguments, the list of components to report and the metrics to report, where the id \u0026ldquo;application utilization\u0026rdquo; is used to retrieve the application’s aggregated metrics. Both arguments to the metrics function are lists of strings. To retrieve all metrics for all components as well as the aggregated application, use empty lists for both arguments.\nTo display metrics in the IDE, select a running waveform, and in the Properties view, select the Metrics tab.\nWaveform Metrics Monitoring Computing Resources per GPP The GPP monitors the following resources:\n System: CPU utilization, memory usage, nic usage, total number of threads, and number of open files For each component: CPU usage, memory usage, and process state  When a component fails (for example, segfault), the GPP issues a AbnormalComponentTerminationEventType message on the IDM_Channel. The message contains the component ID of the component that failed, the application ID for the component’s waveform, and the device ID for the GPP that is running the component.\nThe GPP contains a thresholds structure with five elements. If at any point any of these thresholds is exceeded (because of any process’s usage, not just those forked by the GPP), the GPP usage state changes to BUSY.\nThe following table describes the elements of the thresholds structured property:\nThresholds Structured Property    Element Description     mem_free Amount of free memory available that triggers a threshold condition (default units in MB).   nic_usage Amount of network capacity used by the NIC interface that triggers a threshold condition.   threads Percentage of threads available to the GPP that triggers a threshold condition.   files_available Percentage of file handles remaining to the GPP that triggers a threshold condition.   cpu_idle Amount of CPU idle percentage that triggers a threshold condition.   ignore Ignore all thresholds and never enter into a BUSY state.    To disable the GPP’s response to any threshold, set thresholds.ignore to True. If thresholds.ignore is True, the GPP will either be in an IDLE state if no components are deployed, or an ACTIVE state if one or more component is deployed, but never BUSY, irresepecitve of the overall computer usage.\nSetting any element of the thresholds structure to -1 disables the GPP’s response to that particular element.\nFor example, to ignore the processor’s usage, set thresholds.cpu_idle to -1. The GPP state will be IDLE if no components are deployed, and ACTIVE if one or more component is deployed, irrespective of the cpu idle percentage. 254a406,467\nSetting any element of the thresholds structure to 0 changes the GPP usage state to BUSY, and thus, the GPP cannot launch any addtional components.\nThe GPP contains a utilization structured property that shows the overall system utilization at any time. The following table describes the elements of the utilization structured property.\nUtilization Structured Property    Element Description     description Human-readable description of the content. In the case of CPU usage, this element’s content is “CPU cores”. The numbers in this structure reflect the effective number of cores that are being utilized.   component_load Overall load by all the components that were forked by the GPP.   system_load Total load from every process, irrespective of whether or not it was forked by this GPP.   subscribed Sum of the total system load and however much is reserved. (Refer to Capacity Reservation).   maximum Maximum load that the GPP will accept before switching to a BUSY state.    ComponentHost ComponentHost is a specialized REDHAWK component that launches and manages shared address space components in a waveform. It is installed in $SDRROOT on the DomainManager and deployed to the GPP as required. There is no need to explicitly include ComponentHost in a sad file, as the applicationfactory automatically creates one (or more) as part of the waveform deployment.\nOne ComponentHost instance is created per GPP, per waveform; all shared address space components assigned to the same GPP in a waveform reside within the same ComponentHost. Within ComponentHost, each started component runs as a separate thread, named according to the component’s label. The individual component’s main threads may be viewed in common Linux utilities such as top by enabling the display of threads. Other threads, such as those used for I/O by the middleware layer, are typically named according to the ComponentHost instance.\nBinding Components to Executable Devices For standard Application/Component deployment, the Application Factory searches the Domain to find a matching Executable Device using the OS and architecture implementation properties and optional implementation dependencies. The first available Executable Device matching those properties is selected as the deployment Device for the Component. The Software Assembly Definition (SAD) and Device Configuration Definition (DCD) files now allow system integrators to define additional id/value pairs to match against when deploying a Component to an Executeable Device. The following example describes the new xml elements (devicerequires and deployerrequires), that allow Component_1 to be deployed only on RED_NODE:GPP_1.\n\u0026lt;!-- example of ID/value pairs for a component in a SAD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;Component_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Component_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Component_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;devicerequires\u0026gt; \u0026lt;simpleref refid=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;simpleref refid=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/devicerequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;\u0026lt;!-- example of ID/value pairs for a GPP in a DCD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;GPP1_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;RED_NODE:GPP_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;RED_NODE:GPP_1\u0026lt;/usagename\u0026gt; \u0026lt;deployerrequires\u0026gt; \u0026lt;requires id=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;requires id=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/deployerrequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; During the deployment process, when a Component has a devicerequires id/value set defined in a SAD file, the list of available Executable Devices in the Domain is filtered based on the entire id/value set. The Application Factory performs a match against the devicerequires id/value pairs and the Executable Devices’s devicerequires id/value pairs. If there is an exact match between both sets, that Executable Device is selected as the deployment Device. If no matching Executable Devices are found, then the Waveform fails to deploy and an exception is raised.\nIn addition to allowing Components to select deployment Devices, an Executable Device with a devicerequires id/value set restricts deployment to only Components with a matching id/value set. All other requests for deployment to that Executable Device fail.\nFor Host Collocation and regular deployment requests, the following table explains the deployment behavior for devicerequires and deployerrequires id/value sets:\nDeployment Matching    device requires deployer requires Host Collocation Match Deployment     Yes Yes No Yes Yes, deploy on matching Device.   Yes Yes No No No, matching failed.   Yes No No No No, Device not used for deployment.   No Yes No No No, skip this Device.   Yes (single set) Yes Yes Yes Yes, entire host collocaton on this Device.   Yes (mixed sets) Yes Yes Yes No, different devicerequire sets will fail.   Yes (same sets) Yes Yes Yes Yes, entire host collocation on this Device.   No Yes Yes Yes No, skip this Device.    Capacity Reservation A non-reservation strategy assumes that each process is running at full capacity at the time of execution. This is clearly not the case when the waveform is initially deployed because all of the waveform’s components are in a stopped state, thus taking little to no system resources. Only after the waveform is switched to a started state do the components begin to consume system resources. Those system resources that are monitored for threshold changes by the GPP will directly affect the Device’s usageState: IDLE, ACTIVE, or BUSY.\nA non-reservation strategy with a deployment pattern where multiple waveforms are launched and not initially started but are delayed due to system events or predefined behavior, can create an over-utilized system. For example, a system may initially create twenty instances of a waveform and later, start them as a result of an aperiodic event. All twenty waveforms are created, but starting the 15th instance causes the CPU utilization for the entire system to reach 100%. When the next five waveforms are started, the system will be over utilized, and all running components will be affected leading to degraded system performance, such as data loss or lack of timely response to message events.\nTo mitigate this issue, the GPP maintains a reservation-based strategy to properly forecast the CPU load for each component it manages. During initial waveform deployment, the forecasted load for each component of the waveform is reserved against the current system’s available CPU capacity. As components are moved to the start state, the forecasted load is tabled, and the actual load or a minimum utilitization load (whichever is greater), is used for determining the system load, and thus, the available CPU capacity. The available CPU capacity is one of the system resources that will directly determine the system’s usageState, (i.e., IDLE, ACTIVE, or BUSY ). The GPP’s utilization.subscribed property maintains the runtime value of the total reservation for the system.\nExample Reservation Schema In the figure above, an example of the reservation schema is shown where actual usage is shown in green, reserved capacity is shown in blue, and the maximum for the host is shown in orange. In the figure shown, the GPP’s capacity calculation is affected by the components deployed and whether or not its host application is started.\nThe Property, reserved_capacity_per_component, is the default forecasted load for every component deployed by the GPP.\nSpecialized Reservation The generalized reservation schema based on a common value set for all components is functional but often too generic. Furthermore, as the load imposed by a component changes (for example, as the noise environment changes), a floor for the component’s load is needed. For such a case, a per-component load floor can be set. This floor is maintained when the component’s load is lower than the specified value. However, the component’s load is computed as the actual load when it exceeds the floor value set. In other words, the component’s effective load is the higher of the floor or actual load. Currently, this floor is only available through the REDHAWK Python package when the waveform is created. The following example describes how to set the reserved forecasted load for a component. In this example, the component, my_comp_1, on the waveform, my_wave, has a reservation floor of 4 cpu cores.\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;my_comp_1\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect In other cases, an aggregate load for a whole waveform is needed rather than loads for individual components. To support this need, it is possible to provide a reservation floor on a per-host collocation basis rather than on a per-component basis. The reservation floor can be set through the sad file or as a waveform creation parameter.\nWhen the reservation is based on the sad file, it is added through an additional child element to the hostcollocation element. The additional child element is reservation, with two attributes: kind (“cpucores\u0026rdquo; for processing) and value (in this case, the number of cores that should be reserved). For example, if a host collocation were to include a reservation for a hostcollocation with component “some_comp\u0026rdquo; and an aggregate reservation of 3 cores, it would follow a pattern similar to this:\n\u0026lt;hostcollocation id=\u0026#34;ID_TEST_SET1\u0026#34; name=\u0026#34;COLLOC_SET1\u0026#34;\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;some_comp_ref\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;SigGen_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;SigGen_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;reservation kind=\u0026#34;cpucores\u0026#34; value=\u0026#34;3\u0026#34;/\u0026gt; \u0026lt;/hostcollocation\u0026gt; Alternatively, the reservation can be made in the IDE by selecting a host collocation in the SAD editor diagram and editing the reservation in the Properties view. The following procedure explains how to set the reservation using the IDE.\n Create a new Waveform project. In the SAD diagram, add a host collocation. Edit the host collocation’s name to match the XML (COLLOC_SET1). Add rh.SigGen to the host collocation. Select the host collocation. Open the Properties view, select the Reservations tab.\nProperties View Reservations Tab  Click the + button.\n Set the Kind and Value to match the XML (cpucores and 3, respectively).\n  When a waveform contains a single host collocation, it is possible to provide an override value for that host collocation by providing an empty id to the SPECIALIZED_CPU_RESERVATION.\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize for the host collocation _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect If the waveform contains more than one host collocation, it can be overloaded through the host collocation’s id. For example, if the sad example above were to be overloaded with 4 cores rather than 3, the code would look as follows:\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize for the host collocation _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;ID_TEST_SET1\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect Resource Affinity Modern Linux kernels support the ability to define memory and processor affinity using the Non Uniformed Memory Access (NUMA) library. REDHAWK has added support to define processor affinity during the Component deployment process as specified in a Waveform’s SAD file. The affinity element can be added to the componentplacement/componentinstantiation element for the resource. During deployment, the REDHAWK GPP recognizes these options and performs the appropriate affinity requests when the resource is executed. An affinity request is defined by the following two intrinsic Property identifiers added to the affinity element.\n affinity::exec_directive_class - The context classification of affinity directive to perform. affinity::exec_directive_value - Value to use when processing the affinity directive.  Affinity Class Directives    Directive Class Description Values     socket Processor affinity using a processor socket identifier set. Supported values are defined by the numa library’s numa_parse_nodestring method; consult the numa man page for further clarification.   cpu CPU affinity using a cpu identifier set. Supported values are defined by numa library’s numa_parse_cpustring method; consult the numa man page for futher clarification.   nic Determine which CPU manages the nic’s interrupts then assign processor affiliation to that cpu. Name of a host’s network interface. Processor identification is resolved by processing/proc/interrupts for the requested interface name.    The current REDHAWK development tool set does not support the inclusion of the affinity element into a SAD file. Adding this element requires manual editing of the file with a text editor. The following example restricts the processor affinity for component C2_1 to CPU number 5.\n\u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;C2_5fb7296e-b543-43fc-bc14-88a9299b458b\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;C2_1\u0026#34; startorder=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;C2_1\u0026lt;/usagename\u0026gt; \u0026lt;affinity\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_class\u0026#34; value=\u0026#34;cpu\u0026#34; /\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_value\u0026#34; value=\u0026#34;5\u0026#34;/\u0026gt; \u0026lt;/affinity\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;C2_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/working-with-complex-data/",
	"title": "Working with Complex Data",
	"tags": [],
	"description": "",
	"content": " Each BurstPacket of the incoming data provides the getComplex() method to denote if the vector contains complex samples (It is comprised of real and imaginary parts.) Complex data is sent as alternating real and imaginary values. A developer can work with this data in any fashion; however, this section describes the common methods for converting the data into a more workable form.\nConverting Complex Data in C++ In C++, the incoming BurstIO data vector may be typecast into a std::vector of complex values. For example:\nBurstShortIn::BurstPacket *pkt = myShortPort-\u0026gt;getPacket(bulkio::Const::BLOCKING); if ( pkt-\u0026gt;isComplex() ) { BurstShortIn::ComplexType cplx_data = pkt-\u0026gt;getComplexData(); // ... do some processing with cplx_data } Converting Complex Data in Python The helper functions bulkioComplexToPythonComplexList and pythonComplexListToBulkioComplex, defined in the module ossie.utils.bulkio.bulkio_helpers, provide an efficient translation to and from lists of Python complex numbers.\nConverting Complex Data in Java Unlike with C++ and Python, Java does not have an ubiquitous means for representing complex numbers; therefore, when using Java, users are free to map the incoming BurstIO getData() method to the complex data representation of their choosing.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/working-with-wavefroms/",
	"title": "Working with Waveforms on a Running Domain",
	"tags": [],
	"description": "",
	"content": " If you have a running Domain Manager and Device Manager, you may create and work with waveforms. You can launch the waveform on the domain, launch additional components into the running waveform, stop the running waveform, and release the waveform from the domain.\nLaunching a Waveform To launch a waveform:\n Right-click the domain and from the domain context menu, select Launch Waveform…:\nDomain Context Menu The Launch Waveform wizard is displayed:\nLaunch Waveform Wizard  On the Select a Waveform page of the Launch Waveform wizard, perform the following procedure:\n Select the waveform to launch.\n Select the Start the waveform after launching checkbox to start the waveform and all of its contained components immediately after launch.\n Click Next.\n  The Assign Initial Properties page is displayed.\nAssign Initial Properties  On the Assign Initial Properties page, set the properties of the components within the waveform. Any property modified here is specific to this waveform and does not impact the component‘s execution in other environments. As the properties are changed from their default values, the now non-default values appear in bold as shown below:\nApplication Properties: Non-Default When you are finished assigning properties, click Next. The Assign Components to Devices page is displayed:\nAssign Components to Devices  The Assign Components to Devices page enables you to specify what executable device on which each of the components launches. If the device setting is Auto, REDHAWK determines the executable device based on any allocation properties and dependencies set on the components and devices.\n To launch the waveform, click Finish.\nIn the REDHAWK Explorer View, the Domain Manager now displays the launched waveform within the Waveforms folder.\n If you did not select the Start the waveform after launching checkbox, the waveform has not been started. To start the waveform, in the REDHAWK Explorer View, right-click the waveform from the domain’s waveforms folder and select Start.\n Once the waveform is started, the REDHAWK Explorer View indicates that the waveform and components within the waveform are in the started state by displaying STARTED next to the waveform’s instance and the instance of each component:\nStarted Waveform   Launching Additional Components into a Running Waveform Once a waveform has been started, additional components may be launched into the running waveform. These additional components run on the local machine and not on the domain.\n In the REDHAWK Explorer View, right-click the waveform and select Open With \u0026gt; Chalkboard:\nOpening a Running Waveform in the Chalkboard This displays the running waveform in the Chalkboard:\nRunning Waveform in the Chalkboard  From the Palette, add additional components to the waveform.\nStandard runtime actions (Plot, Start, Stop, Terminate, and Connect) are available on the newly added components. These components are added only to the currently running instance of the waveform and are launched on the local machine, NOT in the domain.\n   Stopping a Waveform To stop a running waveform but keep it on the domain, in the REDHAWK Explorer View, right-click the running waveform and select Stop from the context menu:\nStopping a Waveform Releasing a Waveform To stop a running waveform and release it from the domain, in the REDHAWK Explorer View, right-click the running waveform and select Release from the context menu:\nReleasing a Waveform It is not necessary to select Stop prior to releasing the waveform. The IDE stops the waveform before releasing it.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/adjusting-logging-at-runtime/",
	"title": "Adjusting Logging at Runtime",
	"tags": [],
	"description": "",
	"content": " The logging level for the root logger of a component/device can be adjusted at runtime in the IDE. The following procedure explains how to adjust the logging level.\n Right-click the running component or device and select Logging \u0026gt; Log Level.\nThe Set Debug Level dialog displays the current logging level:\nSet Debug Level  Select the new logging level you want to use and click OK.\nThe new log level is used.\n  After a component or device has been launched, its logging configuration can also be dynamically modified.\n Right-click the running component or device and select Logging \u0026gt; Edit Log Config. If this is the first time you have used the editor, a warning is displayed.\n If a warning is displayed, click Yes. The Edit Log Config editor is displayed.\nEdit Log Config The editor shows the resource’s logging configuration. Saving changes to the editor performs a live update of the resource’s logging configuration.\n  Changing the logging configuration for a running application instance can affect the Domain Manager process. When changing the logging configuration for an application, restrict the configuration to an application’s logging instance, Application_impl; as in the following example.\nlog4j.logger.Application_impl=TRACE,applogonly log4j.appender.applogonly=org.apache.log4j.FileAppender log4j.appender.applogonly.layout=org.apache.log4j.PatternLayout log4j.appender.applogonly.layout.ConversionPattern=%d {yyyy-MM-dd HH:mm:ss} %-5p %c:%L - %m%n log4j.appender.applogonly.File=/tmp/applog.out log4j.appender.applogonly.Append=true "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/applications/",
	"title": "Applications",
	"tags": [],
	"description": "",
	"content": " Applications are software objects representing waveforms. They are used to organize a group of components that are linked together to accomplish a useful computational task. Applications provide a convenient way to move data around in order to achieve these different tasks by allowing for components to easily be interchanged.\nApplication Class Each application contains a unique application name and profile, which describes the application’s configuration. This profile is a SAD file that is referenced by a File Manager.\nAn Application object is responsible for providing control, configuration, and status of any application that is instantiated in the domain. In order to accomplish this, each Application object maintains various data structures to monitor all aspects of its execution.\nA list of SPD implementation IDs and a list of pids are kept for each component that makes up the application in order to manage their life cycles. Since every component has to be associated with at least one device, each component is also stored in a list with the device that it uses, is loaded on or is executed on.\nUpon completion, the Application’s releaseObject() function is responsible for various clean up tasks. Any task or process allocated on Executable devices are stopped using the terminate() function. All memory allocated by component instances on Loadable devices is freed using the unload() function. Finally, any additional capacities or resources that were allocated during creation are released using the device’s deallocateCapacity() method. These changes return the devices to the state they were in before the application was launched (the state of the devices may not have changed during application execution).\nAll object references to components that make up the application are released and all connected ports are disconnected. Any consumers or producers that were connected to a CORBA Event Channel are removed. Finally, all component’s naming contexts are unbound from the Naming Service.\nSAD File The SAD File is where information about a waveform’s composition and configuration is stored. It is an XML file that contains tags for all of the elements required for the application to be built and is located in: $SDRROOT/dom/waveforms/WAVE_NAME. This file is parsed by the runtime environment and used by an ApplicationFactory to construct the desired waveform.\nIndividual elements of the file include:\n References to all required component’s SPD and their locations Required connections between the component’s ports and interfaces External ports Required connections to devices Name given in Naming Service Co-Location (deployment) dependencies Assembly Controller Start order of the components  Within the SAD file, each component instantiation has a unique ID, which allows support for multiple instantiations of the same component. In this situation, each component would have the same file reference, a unique ID, as well as a unique name in the Naming Service that is based off of the component’s usage name. For multiple instantiations of the same component, the trailing digit on the usage name is simply incremented.\nAssembly Controller and Start Order Each waveform has only one Assembly Controller that serves as the starting point for the application. The component that is marked as the Assembly Controller is responsible for delegating implementations of the inherited CF::Resource functions that include:\n start() stop() configure() query()  By default, the first component added to a waveform is the Assembly Controller. However, the Assembly Controller can be changed to any component in the waveform by right-clicking on the component in the waveform diagram and selecting Set As Assembly Controller from the context menu.\nAssembly Controller Assignment In the waveform diagram, the circled number in the component indicates the component’s designated start order. This is the order that the start() function is called on the components within the waveform.\nThe Assembly Controller is always started first.\n To modify the start order:\n In the waveform diagram, right-click the component for which you want to change the start order. Select Move Start Order Earlier to start the component earlier. Select Move Start Order Later to start the component later.\nStart Order Assignment   Host Collocation To address varying performance considerations, some application designs may require multiple components be deployed on the same piece of hardware. To meet this type of requirement, in the sad.xml file, you can specify that a set of components be collocated on a single host at runtime.\nTo collocate components in the IDE:\n Open the Advanced section of the Palette. Select Host Collocation.\nSelect Host Collocation  Drag Host Collocation onto the Diagram. The collocation area is displayed.\nCollocation  Add desired components to the collocated area.\nAdd Components to Host Collocation  Finalize other component connections.\nFinalize Other Component Connections   External Ports Within the REDHAWK Framework, a particular component’s port can be designated as an external port so that it is accessible to external waveform objects. Using external ports, a complex waveform may be subdivided into smaller more manageable waveforms. Marking a port as external adds an external ports tag in the SAD XML file containing the component instance that owns the port in question. Additionally, the color of the port’s block in the diagram changes color to mark it as externally accessible. For information about marking a Port as external, refer to Waveform Editor Diagram Tab.\nExternal ports can be renamed in the Overview tab of the application’s SAD file. Renaming a port enables other applications to access the port with a different name instance than the one specified in the components SCD file, thus preventing naming collision. For information about renaming an external port, refer to Waveform Editor Overview Tab).\nExternal Properties Individual component properties can be promoted as external in the properties tab of the application’s SAD file, which enables other applications to access these internal property values through configure() and query(). To prevent naming collision, the property ID can also be assigned an external id. If no external ID is specified, the internal property ID from the components PRF file is used as its external id. For information about making a property external, refer to Waveform Editor Properties Tab).\nUsing the Find By Feature A Find By represents an object within a REDHAWK domain that will be available at runtime (when the waveform is launched in a domain). Find Bys contain details that describe the object. For example, the details may specify that it is a domain manager or it is a Service with a specific name. When a waveform is launched in a domain, the Find By details help to locate the appropriate object, and then any connections the user specified in the waveform are established. Those connections are sometimes directly to the object itself, or sometimes to ports on the object, depending on the context. You can search for a resource by name, a service by name or type, or an Event Channel by name.\nFind By Name To find a resource in the domain by name:\n From the Palette, in the Find By folder, select Find By Name and drag it onto the diagram. The Find By Name dialog is displayed.\nFind By Name  Enter the name of the component you want to find.\n Optionally, enter the component’s ports names that you want to use. For Provides ports, enter the name and click + next to Provides Port. For Uses ports, enter the name and click + next to Uses Port.\n Click Finish.\nThe Find By Name is displayed in the diagram.\n  Find By Service To find a service in the domain:\n From the Palette, in the Find By folder, select Service and drag it onto the diagram. The Find By Service dialog is displayed.\nFind By Service  If you want to search for a service Name, select the Service Name radio button and enter the service Name you want to find.\n If you want to search for a service Type, select the Service Type radio button and enter the service Type you want to find. The service Type indicates the interface (IDL) provided by the service. Click Browse to select an IDL type the IDE recognizes.\n Optionally, enter the component’s ports names that you want to use. For Provides ports, enter the name and click + next to Provides Port. For Uses ports, enter the name and click + next to Uses Port.\n Click Finish.\nThe Service Name or Service Type is displayed in the diagram.\n  Find By Event Channel To find an event channel in the domain:\n From the Palette, in the Find By folder, select Event Channel and drag it onto the diagram.\nThe Event Channel dialog is displayed.\nEvent Channel  Enter the name of the Event Channel you want to find and click OK.\nThe Event Channel is displayed in the diagram.\n  usesdevice Relationship An application may require that specific devices are running in order for the application to be deployed. The usesdevice relationship is a mechanism for expressing such a requirement. The usesdevice relationship also enables the application to connect ports of components within the SAD file to ports of devices running in a node. These specifications are handled through tags in the application’s SAD XML, which can contain any number of usesdevice relationships. Each usesdevice relationship has a unique ID with a set of allocation property dependencies required for the relationship to be satisfied..\nThe following example XML expresses the usesdevice relationship and must reside within the softwareassembly element of the SAD XML file. The usesdevicedependencies element must be the last element within the softwareassembly element.\n\u0026lt;usesdevicedependencies\u0026gt; \u0026lt;usesdevice id=\u0026#34;uses_device_1\u0026#34;\u0026gt; \u0026lt;propertyref refid=\u0026#34;os\u0026#34; value=\u0026#34;linux\u0026#34;/\u0026gt; \u0026lt;/usesdevice\u0026gt; \u0026lt;usesdevice id=\u0026#34;uses_device_2\u0026#34;\u0026gt; \u0026lt;structref refid=\u0026#34;struct_alloc_prop\u0026#34;\u0026gt; \u0026lt;simpleref refid=\u0026#34;long_capacity\u0026#34; value=\u0026#34;10\u0026#34;/\u0026gt; \u0026lt;simpleref refid=\u0026#34;float_capacity\u0026#34; value=\u0026#34;0.1\u0026#34;/\u0026gt; \u0026lt;/structref\u0026gt; \u0026lt;/usesdevice\u0026gt; \u0026lt;/usesdevicedependencies\u0026gt; In the above example, there are two usesdevice dependencies with IDs of uses_device_1 and uses_device_2. The first requires a property with an ID of os that matches the value of linux. The second requires a struct with an ID of struct_alloc_prop with members long_capacity and float_capacity that have the necessary available capacity specified in the value tag.\nOnce these dependencies have been declared, port connections can be made in the connections section of the SAD XML file. The following example makes two connections. The first connection is from the port: output_port of Component_1 to the port: input_port of the device that satisfies the uses_device_1 relationship. The second is from the port: output_port of the device that satisfies the uses_device_2 relationship to the port: input_port of Component_2.\n\u0026lt;connections\u0026gt; \u0026lt;connectinterface id=\u0026#34;connection_1\u0026#34;\u0026gt; \u0026lt;usesport\u0026gt; \u0026lt;usesidentifier\u0026gt;output_port\u0026lt;/usesidentifier\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/usesport\u0026gt; \u0026lt;providesport\u0026gt; \u0026lt;providesidentifier\u0026gt;input_port\u0026lt;/providesidentifier\u0026gt; \u0026lt;deviceusedbyapplication usesrefid=\u0026#34;uses_device_1\u0026#34;/\u0026gt; \u0026lt;/providesport\u0026gt; \u0026lt;/connectinterface\u0026gt; \u0026lt;connectinterface id=\u0026#34;connection_2\u0026#34;\u0026gt; \u0026lt;usesport\u0026gt; \u0026lt;usesidentifier\u0026gt;output_port\u0026lt;/usesidentifier\u0026gt; \u0026lt;deviceusedbyapplication usesrefid=\u0026#34;uses_device_2\u0026#34;/\u0026gt; \u0026lt;/usesport\u0026gt; \u0026lt;providesport\u0026gt; \u0026lt;providesidentifier\u0026gt;input_port\u0026lt;/providesidentifier\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;Component_2\u0026#34;/\u0026gt; \u0026lt;/providesport\u0026gt; \u0026lt;/connectinterface\u0026gt; \u0026lt;/connections\u0026gt; HostCollocation and usesdevice Relationship To further refine the deployment of an Application, the SAD file allows for the specification of a usesdeviceref within the context of a HostCollocation. If a HostCollocation is defined with a set of Components and a usesdeviceref, all the Components can be deployed on the ExecutableDevice that resides on the same host as the Device that was satisfied by the usesdevicedependency section.\n\u0026lt;hostcollocation name=\u0026#34;collocation_1\u0026#34;\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Component_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Component_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;usesdeviceref refid=\u0026#34;uses_device_2\u0026#34;/\u0026gt; \u0026lt;/hostcollocation\u0026gt; To add a usesdevice to or remove a usesdevice from a host collocation:\n Double-click the the host collocation area.\nThe Edit Host Collocation dialog is displayed.\nEdit Host Collocation  To add a Device, under Available uses devices, select the Device, click Add, and click Finish. The Device is added to the host collocation.\nHost Collocation Including a usesdevice  To remove a Device, under Collocated uses devices, select the Device, click Remove, and click Finish. The Device is removed.\nHost Collocation without a usesdevice   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/source-installation/",
	"title": "Building and Installing REDHAWK from Source",
	"tags": [],
	"description": "",
	"content": " Building the Framework Installing Build Dependencies Building REDHAWK from source requires a few additional dependencies beyond those required to run REDHAWK. The following procedure explains how to build REDHAWK from source.\n First, ensure your system has the necessary dependency software provided by RHEL / CentOS and Fedora EPEL. Ensure the REDHAWK Yum repository is set up using the process described in Setting Up the REDHAWK Repostiory. Install the dependencies distributed with the REDHAWK tarball.  Installing the Framework from Source In order to install the Core Framework from source, the redhawk-src-\u0026lt;version\u0026gt;.tar.gz must be downloaded.\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-src-\u0026lt;version\u0026gt;.tar.gz You must set the OSSIEHOME and SDRROOT environment variables (recommended defaults shown below) before running the installation script. You must have write permission for the locations of OSSIEHOME and SDRROOT or the installation will not work.\nThe installation script is interactive and will prompt you to continue before performing certain tasks.\n To compile the source, execute the following commands:\nexport OSSIEHOME=/usr/local/redhawk/core export SDRROOT=/var/redhawk/sdr tar zxvf redhawk-src-\u0026lt;version\u0026gt;.tar.gz cd redhawk-src-\u0026lt;version\u0026gt;/ ./redhawk-install.sh . $OSSIEHOME/environment-setup If you wish to preserve the environment used to compile the source, the following lines should be added to .bashrc:\nexport OSSIEHOME=/usr/local/redhawk/core export SDRROOT=/var/redhawk/sdr . $OSSIEHOME/environment-setup Setting Environment Variables REDHAWK expects several environment variables to be set to run. REDHAWK installs a set of scripts that appropriately set these variables in the etc/profile.d directory in your installation. Source the appropriate files for your shell before running. For example, if you installed to the default OSSIEHOME location (/usr/local/redhawk/core) and are using bash/dash:\n. /usr/local/redhawk/core/etc/profile.d/redhawk.sh . /usr/local/redhawk/core/etc/profile.d/redhawk-sdrroot.sh or copy them to your system’s /etc/profile.d directory to make them global for all users:\nsudo cp /usr/local/redhawk/core/etc/profile.d/* /etc/profile.d Remember to restart your terminal if you modify the system’s /etc/profile.d directory for changes to take effect.\n Configuring omniORB Refer to Configuring omniORB for information on how to edit the omniORB configuration file (/etc/omniORB.cfg) to provide information about how to reach the CORBA event service.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/",
	"title": "Component Structure",
	"tags": [],
	"description": "",
	"content": "This chapter discusses more advanced topics related to component development. Prior to reading this content, familiarize yourself with the information in Components.\n Auto-Generated Component Files     Auto-Generated Component Methods     Base Component Members     Component Implementations     Java Version     Managing and Defining Properties     Working with Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/messaging/connecting-producers-consumers/",
	"title": "Connecting Producers and Consumers",
	"tags": [],
	"description": "",
	"content": " Producers and consumers can be connected either point-to-point or through an Event Channel in the IDE. Connecting a producer directly to a consumer does not require an application and can be done in the Sandbox:\nfrom ossie.utils import sb sb.catalog() #[\u0026#39;structs_test\u0026#39;, \u0026#39;m_in\u0026#39;, \u0026#39;prop_changes\u0026#39;, \u0026#39;m_out\u0026#39;,\u0026#39;pass\u0026#39;] prod=sb.launch(\u0026#34;m_out\u0026#34;) cons=sb.launch(\u0026#34;m_in\u0026#34;) prod.connect(cons) #True sb.start() Output: foo 0 hello foo 1 hello foo 2 hello foo 3 hello foo 4 hello foo 5 hello foo 6 hello Connecting producers to consumers through an Event Channel requires an application. An application can also support point-to-point connections.\nBelow is a description of how to connect producers through point-to-point and through an Event Channel:\n Add producer and consumer components. For point-to-point messaging, connect the output MessageEvent port, message_out in this example, to the input MessageEvent port of the receive component. For messaging via an Event Channel, add an Event Channel to the waveform and connect to it.\n In the waveform Diagram, under Palette \u0026gt; Find By:  Select EventChannel and drag it onto the diagram. The New Event Channel dialog is displayed.\nNew Event Channel  Enter the Event Channel you want to find and click OK. The EventChannel is displayed in the diagram.\n  Connect the Uses (Output) MessageEvent port of the sending component, message_out in this example, to the Event Channel. Connect the Uses (Output) MessageEvent port of the receiving component, message_in, to the Event Channel. This is the black Output port that must be connected to the Event Channel.   In this example, connections are made point-to-point and through the Event Channel. Therefore, for every message sent, two messages are received.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/dynamic-connections/",
	"title": "Dynamic Connections",
	"tags": [],
	"description": "",
	"content": "Unless a component is in the process of being terminated, it is valid to retrieve a port reference at any other point in the component’s life cycle. Anyone may call getPort() on the component at any time. In the case of a uses port, anyone may call connectPort() or disconnectPort() at any time. In the case of a provides port, anyone may cast to that port reference and start making calls on it. It is the task of the component developer to make sure that the component handles changes like this smoothly. The base classes and code generators provided with REDHAWK handle the vast majority of the issues arising from this change, especially when the provides port implements one of the REDHAWK standard interfaces.\nThis dynamic connection behavior provides huge benefits to an application developer. For example, if one wanted to inspect the data being passed from one component to the next, a temporary provides-side implementation can be created and a new connection established. The standard behavior of a uses port is to send the same data to all its existing connections. This means of dynamic connecting is essential for REDHAWK’s plotting mechanism.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/",
	"title": "Editors and Views",
	"tags": [],
	"description": "",
	"content": "This section discusses the most commonly used Editors and Views provided with the REDHAWK IDE.\n SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/example-interaction/",
	"title": "Example Sandbox Interaction",
	"tags": [],
	"description": "",
	"content": " The code below provides an example of component interaction in the Sandbox:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_comp \u0026lt;local component \u0026#39;\u0026lt;component name\u0026gt;_1\u0026#39; at 0x\u0026lt;hex address\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; my_comp.api() Component [example]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- input_s IDL:BULKIO/dataShort:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- output_s IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- my_float (float/SF/32f) [None] None my_string (string) [None] None some_shorts (ShortSeq) [None] None \u0026gt;\u0026gt;\u0026gt; my_comp.my_float \u0026gt;\u0026gt;\u0026gt; my_comp.my_float = 5.0 \u0026gt;\u0026gt;\u0026gt; my_comp.my_float 5.0 \u0026gt;\u0026gt;\u0026gt; my_comp.api() Component [example]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- input_s IDL:BULKIO/dataShort:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- output_s IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- my_float (float/SF/32f) [None] 5.0 my_string (string) [None] None some_shorts (ShortSeq) [None] None Connecting Components Connecting components is done by invoking a connect() function on the uses-side (output-side) component with the provides-side (input-side) component as the argument of the call.\n\u0026gt;\u0026gt;\u0026gt; another_comp = sb.launch(\u0026#34;repeater\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_comp.connect(another_comp) True If the connections are ambiguous (multiple uses ports or multiple provides ports have matching types), an error occurs. To resolve the ambiguity, usesPortName and/or providesPortName must be specified as arguments to the function. For example, the following call specifies providesPortName as an argument.\n \u0026gt;\u0026gt;\u0026gt; my_comp.connect(another_comp, providesPortName=\u0026#34;float_in_1\u0026#34;) Connection Manager A REDHAWK DomainManager contains a Connection Manager that provides systemic benefits for the management of connections between endpoints that can come and go. The underlying endpoints are specialized data strutures and CORBA references required to complete the connection, which complicates the creation of endpoints. The Python Sandbox already contains Pythonic representations of these Domain objects, which reduce the need to retrieve the CORBA references. The Python Sandbox contains helpers that use these representations for the creation of endpoints.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import rhconnection \u0026gt;\u0026gt;\u0026gt; dom = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; app = dom.createApplication(\u0026#39;/waveforms/my_app/my_app.sad.xml\u0026#39;) \u0026gt;\u0026gt;\u0026gt; dev = dom.devices[0] \u0026gt;\u0026gt;\u0026gt; uses = rhconnection.makeEndPoint(app, \u0026#39;out_portname\u0026#39;) \u0026gt;\u0026gt;\u0026gt; prov = rhconnection.makeEndPoint(dev, \u0026#39;in_portname\u0026#39;) \u0026gt;\u0026gt;\u0026gt; dom.getConnectionMgr().connect(uses,prov,\u0026#39;user_id\u0026#39;,\u0026#39;connection_id\u0026#39;) Sending and Receiving Data Multiple helpers are available in the Sandbox that can be connected to running components and devices.\nSetting Component Log Levels The log level of the component may be set using the execparams argument in the component constructor.\n\u0026gt;\u0026gt; myComponent = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;, execparams={\u0026#34;DEBUG_LEVEL\u0026#34;:1})"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/getting-started/further-reading/",
	"title": "Further Reading",
	"tags": [],
	"description": "",
	"content": " The REDHAWK manual explains the use of REDHAWK to build, deploy, and manage data streaming applications. The principal REDHAWK features are outlined in the following sections, and a reference to the corresponding REDHAWK documentation is provided for further reading.\nReferences for Application Developers The following chapters are particularly useful for application developers:\n Component development is introduced in Components. Greater detail related to component development is discussed in the following chapters:\n Component Structure\n Connections\n Logging\n  Waveforms, including a demonstration of creating a REDHAWK waveform and launching it as an application using the IDE, are discussed in-depth in Waveforms\n The Sandbox, which is used to run components on a local host without any additional runtime infrastructure such as the Domain Manager, is described in-depth in Sandbox\n  References for System Developers The following chapters are useful to system developers:\n Managing and interacting with hardware through Devices\n Devices and Device Managers make up individual nodes, which are used to deploy and manage devices in a REDHAWK system. Devices are used to determine whether or not a host can deploy any given component. Devices and Device Managers are discussed in-depth in Devices, Nodes, and The Runtime Environment.\n The Domain Manager and Device Manager are the foundation for The Runtime Environment for the deployment of distributed applications. Runtime Environment Inspection describes additional tooling.\n Services, are programs that provide some system-specific always-on software support to components. An example of a service is a web server.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/shared-libraries/manually-including-external-libraries/",
	"title": "Manually Including External Libraries",
	"tags": [],
	"description": "",
	"content": " Occasionally, a C++ component may require building and linking with a library that is not packaged as a REDHAWK shared library. This section details how to manually configure the compiler and linker flags. Two examples are given:\n using a pkg-config (.pc) file to find and link against a library - enables your project to check for the presence of the library and issue an error while running configure if the library is not found. Also lets you avoid hard-coded options. directly linking against a library - enables you to directly supply the compiler/linker flags and can be used if a pkg-config file is not available.  Adding a Library by Referencing a pkg-config File To add a library by referencing a pkg-config (.pc) file, edit the configure.ac file in your component’s implementation directory.\n Open the configure.ac file in your component’s implementation directory.\n Locate the following line referencing PROJECTDEPS in the code:\n  PKG_CHECK_MODULES([PROJECTDEPS], [ossie \u0026gt;= 2.0 omniORB4 \u0026gt;= 4.1.0])  Add your library to the list of requirements. For example, if you need version 1.2.3 or greater of the foo library:  PKG_CHECK_MODULES([PROJECTDEPS], [ ossie \u0026gt;= 2.0 omniORB4 \u0026gt;= 4.1.0 foo \u0026gt;= 1.2.3 ])  If your pkg-config file is not on the pkg-config path, you can augment the pkg-config search path by adding a line just before the call to PKG_CHECK_MODULES:  export PKG_CONFIG_PATH=/custom/path:$PKG_CONFIG_PATH Adding a Library Directly To add a library, edit the Makefile.am file in your component’s implementation directory.\n Open the Makefile.am file in your component’s implementation directory.\n Append compiler and linker flags to the end of the CXXFLAGS and LDADD lines, respectively. For example:\nMyComponent_CXXFLAGS += -I/usr/local/include/foo MyComponent_LDADD += -L/usr/local/lib64 -lfoo   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/multiout-ports/",
	"title": "Multi-out Ports",
	"tags": [],
	"description": "",
	"content": " A multi-out port allows a component to select specific streams to be sent over specific connections out of arbitrarily-selected ports. To use multi-out ports, a component must include the following property:\n\u0026lt;structsequence id=\u0026#34;connectionTable\u0026#34;\u0026gt; \u0026lt;struct id=\u0026#34;connectionTable::connection_descriptor\u0026#34; name=\u0026#34;connection_descriptor\u0026#34;\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::connection_id\u0026#34; name=\u0026#34;connection_id\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::stream_id\u0026#34; name=\u0026#34;stream_id\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::port_name\u0026#34; name=\u0026#34;port_name\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;/struct\u0026gt; \u0026lt;configurationkind kindtype=\u0026#34;property\u0026#34;/\u0026gt; \u0026lt;/structsequence\u0026gt; To steer a particular stream out of a particular connection through a particular port, an element must be added to the connection table structure that identifies the stream ID/connection ID/port name set. After this element is added to the structure, any data pushed to a particular port is filtered by that port in the appropriate fashion.\nA port does not filter its output until an element in the connection table sequence mentions the port name. If a port is listed on the connection table, then data is pushed out only if both the stream ID and connection ID match.\nThe multi-out capability is supported only for BulkIO and BurstIO output (uses) ports.\n Multi-out Port Support in the IDE When interacting with FrontEnd devices, it is easiest to perform an operation (for example, Plot Port Data) directly on the desired tuner. For more information, refer to Plotting a Tuned Receiver.\nOtherwise, the REDHAWK IDE provides support for the following operations using multi-out ports:\n Creating connections to downstream devices or components Plotting Tracking SRI data Data List feature Snapshot feature Play port feature  When performing an operation on a multi-out port, if there is only one connection ID, it is used by the IDE. If there are multiple connection IDs in the connection table, the IDE displays the Multi-out Port Connection Wizard dialog with the option to either select a connection ID from the entries in the connection table or input one manually.\nMult-out Port Connection Wizard "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/nextmidas-plot-editor/",
	"title": "NeXtMidas Plot Editor",
	"tags": [],
	"description": "",
	"content": "Any Midas BLUE files can be opened with the NeXtMidas Plot Editor. Any files in the workspace with the extensions .prm or .tmp are automatically opened in the NeXtMidas Plot Editor.\nThe NeXtMidas Framework has an in plot menu system and mouse zoom functionality that may be used within the plot window. The full use and features of the plotting menus are beyond the scope of this guide and are explained within the official NeXtMidas documentation.\nInteract with the plot in the following ways:\n Zoom In: Left-click and drag to form a box to zoom in on a portion of the plot. Zoom Out: Right-click to zoom out a single level. Open Menu: Center-click to bring up the NeXtMidas plot menu. Close Menu: Right-click an open menu to close the pop-up menu.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/plotting-bulkio-ports/",
	"title": "Plotting BulkIO Ports",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE contains the ability to plot using the NeXtMidas plotting framework. If the output port uses the BulkIO interface, it can take advantage of this feature and plot a line graph or a falling raster.\nTo bring up a plot within the IDE:\n Make sure that the component is currently in the started state.\n Right-click the desired port to plot.\n Select either Plot Port Data or Plot Port FFT.\nA new view is created, and it contains the plot of the port’s output data.\n  The new view has the same name as the source port. To view additional source information, hover the mouse over the title.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/running-a-component/",
	"title": "Running a Component",
	"tags": [],
	"description": "",
	"content": "To run a component, use one of the following mechanisms: the REDHAWK Sandbox or the REDHAWK domain. When using the Sandbox, a component is run from within a Python shell or a graphical environment, all operating on a single computer. When using the domain, a component is run in the context of an application that can be deployed over an arbitrarily large number of computers. The Sandbox is useful for tasks such as signal processing development and analysis, component debugging, and data inspection.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/time-stamps/",
	"title": "Time Stamps",
	"tags": [],
	"description": "",
	"content": "The following code segment provides an example of how to construct a BULKIO::PrecisionUTCTime time stamp to be sent in the burst SRI.\n/** * To create a time stamp from the current time of day */ BULKIO::PrecisionUTCTime tstamp = burstio::utils::now();"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/interface-with-fpgas/",
	"title": "Using Devices to Interface with FPGAs",
	"tags": [],
	"description": "",
	"content": "Many SDR systems depend on custom hardware solutions implemented on FPGAs and GPUs. REDHAWK has developed a design pattern to interface with these custom hardware solutions that enables users and the REDHAWK Framework alike to change the behavior of an FPGA at run-time to meet the needs of the application. Refer to REDHAWK Persona Device Pattern for more information.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/working-with-complex-data/",
	"title": "Working with Complex Data",
	"tags": [],
	"description": "",
	"content": " If the StreamSRI mode field of the incoming data is set to 1, the associated input data is complex (i.e., it is comprised of real and imaginary parts). Complex data is sent as alternating real and imaginary values. A developer can work with this data in any fashion; however, this section provides common methods for converting the data into a more workable form.\nConverting Complex Data in C++ In C++, the incoming BulkIO data block provides a complex() method to check whether the data is complex, and cxdata() and cxsize() methods to provide access to the sample data as an array of std::complex values. For example:\nbulkio::ShortDataBlock = stream.read(); if (block.complex()) { const std::complex\u0026lt;short\u0026gt;* data = block.cxdata(); const size_t size = block.cxsize(); } Converting Complex Data in Python The helper functions bulkioComplexToPythonComplexList and pythonComplexListToBulkioComplex, defined in the module ossie.utils.bulkio.bulkio_helpers, provide an efficient translation to and from lists of Python complex numbers.\nConverting Complex Data in Java Unlike with C++ and Python, Java does not have a ubiquitous means for representing complex numbers; therefore, when using Java, users are free to map the incoming BulkIO data to the complex data representation of their choosing.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/sources-and-sinks/",
	"title": "Built-in Sources and Sinks",
	"tags": [],
	"description": "",
	"content": " REDHAWK includes a variety of helpers that allow a developer to inject data into or extract data from components deployed through the Sandbox. The following section describes each of these helpers and how they are used.\nData Sources The DataSource module provides a mechanism for producing BulkIO data to be sent to a provides (input) port. Once instantiated, a Python vector of data can be pushed to the DataSource.\nAn example instantiation and use of the Data Source module can be seen below:\n\u0026gt;\u0026gt;\u0026gt; input_source = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; input_source.connect(my_comp) \u0026gt;\u0026gt;\u0026gt; my_data = range(10000) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_source.push(my_data) When the DataSource sends data, it attempts to match the data type to the type of the associated provides (input) port. Alternatively, the data type may be set explicitly in the DataSource constructor. Note that the default type for the DataSource is short, which implies that values over 32768 may induce an exception.\nThe default setting for number of bytes per pushPacket() is 512000 bytes. Data is broken up into chunks of this size before being sent via the port’s pushPacket() method. To change this default size, set the bytesPerPush argument in the DataSource constructor.\nA specific module is provided for reading data from a file. This module, FileSource, is used and instantiated much like the DataSource module. The most significant difference between the two modules is the presence of a file name in the FileSource constructor.\n\u0026gt;\u0026gt;\u0026gt; input_file = sb.FileSource(\u0026#34;~/short_file.tmp\u0026#34;, dataFormat=\u0026#34;short\u0026#34;) SRI keywords may be generated and sent with data from the DataSource module.\nAn example generate/send can be seen below:\n\u0026gt;\u0026gt;\u0026gt; kw = sb.SRIKeyword(\u0026#34;SOME_RF\u0026#34;,155000000.0,\u0026#34;double\u0026#34;) \u0026gt;\u0026gt;\u0026gt; kw2 = sb.SRIKeyword(\u0026#34;EFFECTIVE_BITS_PER_SAMPLE\u0026#34;,16,\u0026#34;long\u0026#34;) \u0026gt;\u0026gt;\u0026gt; keywords = [kw, kw2] \u0026gt;\u0026gt;\u0026gt; input_data = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; data = range(1000) \u0026gt;\u0026gt;\u0026gt; input_data.connect(my_comp) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_data.push(data,SRIKeywords=keywords) The SRIKeyword() constructor takes in the following arguments:\n name - A string representing the name of the keyword being set. value - The value to be set. format - A string indicating the data type of the value. Valid data types are short, ushort, float, double, long, ulong, longlong, ulonglong, char, octet, string, boolean.  Messages can be sent to components using the MessageSource module. messages sent to the sendMessage() method can be one of four types: struct, dictionary, CORBA Any, and data types that can be mapped to a CORBA Any.\nThe default message ID is sb_struct:\n\u0026gt;\u0026gt;\u0026gt; mySource = sb.MessageSource() \u0026gt;\u0026gt;\u0026gt; myComponet = sb.launch(\u0026#34;test_message_rx_cpp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; mySource.connect(myComponent) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; msg = {\u0026#34;val1\u0026#34;:\u0026#34;test string\u0026#34;, \u0026#34;val2\u0026#34;:123} \u0026gt;\u0026gt;\u0026gt; mySource.sendMessage(msg) Data Sinks The Sandbox provides a DataSink module, which simply reads data from a uses (output) port. Below is an example instantiation and use of the DataSink module. In this example, data sent from myComponent’s uses (output) port is assembled to the stream object. The stream object can be used for actions like retrieving data or viewing the SRI.\n\u0026gt;\u0026gt;\u0026gt; output_data = sb.DataSink() \u0026gt;\u0026gt;\u0026gt; myComponent.connect(output_data) \u0026gt;\u0026gt;\u0026gt; stream = output_data.getCurrentStream() \u0026gt;\u0026gt;\u0026gt; received_data = stream.read() \u0026gt;\u0026gt;\u0026gt; received_SRI = stream.SRI() To block until a certain amount of data is received, specify the data length as an argument to the read() method:\n\u0026gt;\u0026gt;\u0026gt; received_data = stream.read(100) The eos() method indicates whether or not an eos was received:\n\u0026gt;\u0026gt;\u0026gt; stream.eos() False The consume argument may be used to configure the read() method to move the read pointer forward a different length than what was read.\nSimilar to the DataSource’s FileSource counterpart, the DataSink has an associated FileSink module for writing data to a file:\n\u0026gt;\u0026gt;\u0026gt; output_file = sb.FileSink(\u0026#34;~/some_file.tmp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; another_comp.connect(output_file) Messages may be displayed using the MessageSink module. Data sent to a running MessageSink is printed in the Python interpreter.\nBelow is an example of MessageSink usage:\n\u0026gt;\u0026gt;\u0026gt; myComponent = sb.launch(\u0026#34;test_message_send_cpp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; myMessageSink = sb.MessageSink() \u0026gt;\u0026gt;\u0026gt; myComponent.connect(myMessageSink) \u0026gt;\u0026gt;\u0026gt; sb.start() # assume that message_src sends a message In the above example, the received message is printed to the screen. MessageSink can either use a callback or a polling mechanism to retrieve messages.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; message_src = sb.launch(\u0026#39;test_message_send_cpp\u0026#39;) \u0026gt;\u0026gt;\u0026gt; def msgCallback(msg_id, msg): ... print msg_id, msg \u0026gt;\u0026gt;\u0026gt; callback_msg = sb.MessageSink(messageCallback=msgCallback) \u0026gt;\u0026gt;\u0026gt; retrieve_msg = sb.MessageSink(messageCallback=None, storeMessages=True) \u0026gt;\u0026gt;\u0026gt; message_src.connect(callback_msg) \u0026gt;\u0026gt;\u0026gt; message_src.connect(retrieve_msg) \u0026gt;\u0026gt;\u0026gt; sb.start() # assume that message_src sends a message \u0026gt;\u0026gt;\u0026gt; rcv_message = retrieve_msg.getMessages() In the above example, a message source component (created at some previous time), is connected to two instances of MessageSink, one instance implements a callback function and the other instance does not. When the message sink implementing the callback function receives a message, it triggers the callback function. The message sink that does not have a callback implementation stores the messages until they are retrieved through the getMessage function.\nPlotting Data Example Note that for plotting data, the REDHAWK IDE must be installed and the path to the eclipse directory of the installed IDE must be specified to the Sandbox.\nThis can be done through the IDELocation() function:\n\u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) This can also be done by setting the RH_IDE environment variable prior to starting the Python session.\n\u0026gt;\u0026gt;\u0026gt; input_source = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; my_data = range(10000) \u0026gt;\u0026gt;\u0026gt; my_plot = sb.Plot() \u0026gt;\u0026gt;\u0026gt; input_source.connect(my_plot) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_source.push(my_data) Continuous Data Flow Example \u0026gt;\u0026gt;\u0026gt; input_source.push(my_data,loop=True)  To display a falling raster of the data being pushed, click Show Raster in the upper right of the plot window To stop looping data, enter the following command:\n\u0026gt;\u0026gt;\u0026gt; input_source.stop()  File Data Plotting Example \u0026gt;\u0026gt;\u0026gt; input_file = sb.FileSource(\u0026#34;~/short_file.tmp\u0026#34;, dataFormat=\u0026#34;short\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_plot = sb.Plot() \u0026gt;\u0026gt;\u0026gt; input_file.connect(my_plot) \u0026gt;\u0026gt;\u0026gt; input_file.start() Passing a Struct to sendMessage Example from ossie.utils import sb from ossie.properties import simple_property class MessageProp(object): val1 = simple_property(id_=\u0026#34;val1\u0026#34;, type_=\u0026#34;string\u0026#34;, defvalue=\u0026#34;trm\u0026#34;) val2 = simple_property(id_=\u0026#34;val2\u0026#34;, type_=\u0026#34;double\u0026#34;, defvalue=1211) def __init__(self): \u0026#34;\u0026#34;\u0026#34;Construct an initialized instance of this struct definition\u0026#34;\u0026#34;\u0026#34; for attrname, classattr in type(self).__dict__.items(): if type(classattr) == simple_property: classattr.initialize(self) def __str__(self): \u0026#34;\u0026#34;\u0026#34;Return a string representation of this structure\u0026#34;\u0026#34;\u0026#34; d = {} d[\u0026#34;val1\u0026#34;] = self.val1 d[\u0026#34;val2\u0026#34;] = self.val2 return str(d) def getId(self): return \u0026#34;message_prop\u0026#34; def isStruct(self): return True def getMembers(self): return [(\u0026#34;val1\u0026#34;,self.val1),(\u0026#34;val2\u0026#34;,self.val2)] testmessage = MessageProp() testmessage.val1 = \u0026#34;test string\u0026#34; testmessage.val2 = 123 a = sb.MessageSource() b = sb.launch(\u0026#34;test_message_rx_cpp\u0026#34;) a.connect(b) sb.start() a.sendMessage(testmessage) Custom Sinks If there is a need to create a custom sink with specialized behavior, the DataSink object can be modified with a customized sink service function that allows tailoring the DataSink instance to special circumstances. The sink service function needs to inherit from bulkio_data_helpers.ArraySink, and can overload whatever functions’ functionality needs to be specialized.\nThe following example is a sink specialization in which the effective xdelta for the received data needs to change by a factor of two.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils.bulkio import bulkio_data_helpers \u0026gt;\u0026gt;\u0026gt; class customSink(bulkio_data_helpers.ArraySink): ... def __init__(self, porttype): ... bulkio_data_helpers.ArraySink.__init__(self, porttype) ... def pushSRI(self, H): ... _H = H ... _H.xdelta = H.xdelta * 2 ... self.SRI = _H ... self.SRIs.append([len(self.data), _H]) \u0026gt;\u0026gt;\u0026gt; src=sb.DataSource(dataFormat=\u0026#39;float\u0026#39;) \u0026gt;\u0026gt;\u0026gt; snk = sb.DataSink(sinkClass=customSink) \u0026gt;\u0026gt;\u0026gt; src.connect(snk)"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/component-implementations/",
	"title": "Component Implementations",
	"tags": [],
	"description": "",
	"content": "Components may specify particular dependencies such as Operating System (OS), processor architecture, or required device properties (e.g., processor speed or memory capacity). Setting these dependencies ensures that a component is deployed to an appropriate device at runtime.\nWhile REDHAWK supports multiple implementations for a single component, it can be confusing, especially when debugging a system. Except for some limited scenarios, it is recommended that developers associate a single implementation with each component.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/creating-redhawk-projects/",
	"title": "Creating REDHAWK Projects",
	"tags": [],
	"description": "",
	"content": " This section describes the different types of REDHAWK projects and how to create them using the provided Wizards. Before creating a new project, it is recommended that the IDE be in the REDHAWK perspective so that the proper menus are available.\nTo create a new REDHAWK project, click File \u0026gt; New \u0026gt; Project, and then select the project type.\nThe IDE displays the Select a wizard window, which prompts the user to select from multiple project types. Each project type has a custom Wizard to guide users through the initial creation process.\nCommon Fields Some basic fields within the new project Wizard are common to all project types and include:\n Project Name: A project name that is unique to the current workspace. Projects can be namespaced by adding dots in the name. Project names may not begin with a number and may not contain special characters other than dots for the namespace. Namespacing projects provides the ability to uniquely identify projects that share the same base name but have different implementations and also provides a logical grouping of resources. For example, the REDHAWK basic assets are namspaced as rh.xxxx. The Wizard dialog detects errors and informs the user if there is an invalid entry.\n  Location: By default the location of the project is set to the current workspace. This may be changed by deselecting the Use default location check box and providing a custom location.\n Working sets: A working set is an Eclipse concept and provides an additional layer of organization to the project workspace. A user may put common projects into a single “working set” to visually organize the Project Explorer. Additional options become available when projects are placed in working sets allowing the user to build, refresh, and search based on a specific working set. While it may resemble a folder, a working set does not create a new directory on the file system and the same project may belong to multiple working sets.\n  REDHAWK Component Project The New Component Project Wizard is a three page wizard that walks the user through creating a new REDHAWK component, selecting a programming language, and selecting a code generator. Many of the fields found within the component project wizard are also found within the device project wizard. Fields common to all new project wizards are defined in Common Fields.\nPage one of the component wizard contains:\n Contents: A REDHAWK component is defined by an SPD file. By default, when creating a new component, the SPD file created is an empty skeleton. A new component may be based off of a previous component’s SPD file by selecting it from the file system. Component ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the component’s implementation, the programming language used and the code generation template.\nThe content found on this page includes:\n Prog. Lang: A component’s implementation may be written in either C++, Java, or Python. Code Generator: The REDHAWK IDE provides a single code generator for each of the programming languages. It is possible to augment the IDE with additional code generators. A user may choose to forgo automatic code generation and instead choose to create their implementation manually.\n ID: Each language implementation has a project unique ID. By default the language chosen is used as the ID.\n Description: A component’s implementation may contain a description. The description is written into the component’s SPD file.\n  Page three of the wizard allows the user to customize the properties of the code generator and template.\nWizard page three contains fields for:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties that may be set from the properties section. Output Directory: The folder created to house the generated code. Package: Available only for Java implementations. The Java package to place auto-generated code within. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Click Finish to complete the new project creation wizard.\nREDHAWK Control Panel Project The New Control Panel Project Wizard is a two to three page wizard that walks the user through creating a new Plug-in project and optionally, generating a fully functioning project based off of supplied template projects. The New Control Panel Project Wizard is taken directly from the Eclipse New Plug-in Project Wizard and contains identical fields. Refer to the Eclipse documentation for more information.\nREDHAWK Device Project The New device Project Wizard is a three page wizard that walks the user through creating a new REDHAWK device, selecting a programming language, and selecting a code generator. Many of the fields found within the device project wizard are also found within the component project wizard. Fields common to all new project wizards are defined in .\nPage one of the wizard contains:\n Device: The user may select whether this is a standard device, Loadable device, or an Executable device. The checkbox below indicates if this is an Aggregate device. Contents: A REDHAWK device is defined by an SPD file. By default, when creating a new device, the SPD file created is an empty skeleton. The new device may be based off of a previous device’s SPD file by selecting it from the file system. Device ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the device’s implementation, the programming language used and the code generation template.\nWizard page two contains:\n Prog. Lang: A device’s implementation may be written in either C++, Java, or Python. Code Generator: The REDHAWK IDE provides a single code generator for each of the programming languages. It is possible to augment the IDE with additional code generators. A user may choose to forgo automatic code generation and instead choose to create their implementation manually. ID: Each language implementation has a project unique ID, by default the language chosen is used as the ID. Description: A description for this implementation may be provided. The description is written into the device’s SPD file.  Page three of the wizard allows the user to customize the properties of the code generator and template.\nWizard page three contains:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties which may be set in the properties section. Output Directory: The folder created to house the generated code. Package: Available only for Java implementations. The Java package to place auto-generated code within. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Click Finish to complete the new project creation wizard.\nREDHAWK Front End Device Project The FEI Wizard enables users to quickly create an FEI compliant RX or TX tuner device. In the wizard, the user specifies the physical properties of the device, including whether the device ingests or outputs GPS and if the device has digital or analog input and output ports. Additionally, the user can choose to augment the required tuner status properties with additional optional properties.\nREDHAWK IDL Project The IDL Project Wizard is a one page wizard that walks the user through creating a new REDHAWK IDL project. Fields common to all new project wizards are defined in Common Fields.\nWhen creating a new IDL project, avoid using reserved names as specified in the Object Management Group Language Mapping Specifications (IDL to Java Language Mapping, Python, and C++).\n Page one of the wizard contains:\n Module Name: The module to place this IDL into. Version: IDL Version Import existing IDL Files: Specifies IDL files on disk which are included in this new IDL.  Click Finish to complete the new project creation wizard.\nIf you upgrade to REDHAWK version 2.0, and your custom IDL project references the Core Framework IDLs, compiler errors may be displayed. To resolve the errors, create a new IDL project and import your IDL files into the new project. The new project contains an updated Makefile.am that accounts for changes in the REDHAWK 2.0 IDL files.\n REDHAWK Node Project The New Node Project Wizard is a one to two page wizard that walks the user through creating a new REDHAWK node and optionally, placing devices/services into the new node. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Domain Manager: Select the Domain Manager this node is assigned.\n Contents: A REDHAWK node is defined by a DCD file. By default, when creating a new node, the DCD file created is an empty skeleton. The new node may be based off of a previous node’s DCD file by selecting it from the file system.\n Node ID: Every DCD contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.\n  The wizard may be completed at this point by clicking Finish or the user may continue to the optional second page.\nOn page two the user chooses what devices/services make up this node. This may be changed after the node’s creation from the node’s Editor.\nSelect Finish to complete the new project creation wizard.\nREDHAWK Octave Project The Octave Wizard enables users to import existing Octave M-files for easy conversion into REDHAWK C++ components. The user imports an existing M-file, as well as any required dependent M-files, and then maps the M-file’s inputs and outputs to REDHAWK ports and properties.\nREDHAWK Service Project The New service Project Wizard is a three page wizard that walks the user through creating a new REDHAWK service selecting a programming language, and selecting a code generator. Many of the fields found within the service project wizard are also found within the component and device project wizard. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Service Interface: Select, from the Core Framework’s list of installed IDLs the interface which this service uses. Contents: A REDHAWK service is defined by an SPD file. By default, when creating a new service, the SPD file created is an empty skeleton. The new service may be based off of a previous service’s SPD file by selecting it from the file system. Service ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the service’s implementation, the programming language used and the code generation template.\nWizard page two contains:\n Prog. Lang: The service’s implementation may be written in either C++, Java, or Python. Code Generator: A Python code generator is available for REDHAWK service code generation. It is possible to augment the IDE with additional code generators. ID: Each language implementation has a project unique ID, by default the language chosen is used as the ID. Description: A description may be provided for this implementation. The description is written into the service’s SPD file.  Page three of the wizard provides customization to the configuration values of this implementation’s code generation properties and template.\nWizard page three contains:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties which may be set in the properties section. Output Directory: The folder created to house the generated code. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Select Finish to complete the new project creation wizard.\nREDHAWK Shared Library Project The REDHAWK Shared Library Project Wizard enables users to quickly create a C++ shared library for use in REDHAWK. In the wizard, the user specifies the project name and can then generate a simple set of code files to begin adding in library functions.\nREDHAWK Waveform Project The New waveform Project Wizard is a one to two page wizard that walks the user through creating a new REDHAWK waveform and optionally, assigning an Assembly Controller. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Contents: An waveform is defined by an SAD file. By default, when creating a new waveform, the SAD file created is an empty skeleton. The new waveform may be based off of a previous waveform’s SAD file by selecting it from the file system. REDHAWK Waveform ID: Every SAD file contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  The user may choose to complete the wizard at this point or continue on to the optional second page. Page two allows the user to set an Assembly Controller for the new waveform. The Assembly Controller may be set, or changed after the waveforms creation from within the Assembly Controller editor.\nClick Finish to complete the new project creation wizard.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/fei-data-structures/",
	"title": "Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators",
	"tags": [],
	"description": "",
	"content": "   Function/Data Structure Description     setNumChannels Used to size various FrontendTunerDevice class data structures.   frontend_tuner_status This is the FrontEnd tuner status property, which is a vector of structs. The indices match the tuner_id or index of the tuner used by the FrontEnd Tuner device. The developer is responsible for maintaining all fields with the sole exception of the allocation_id_csv, which is managed internally by the FrontendTunerDevice class.   getControlAllocationId Returns the control Allocation ID for the tuner specified, or an empty string if not allocated.   getTunerMapping Returns the tuner ID or tuner index of the tuner associated with the Allocation ID, or -1 if the Allocation ID is not associated with any tuner.   create Returns a StreamSRI object constructed using the frontend_tuner_status for a tuner, including the required SRI keywords. Only required FrontEnd tuner status fields are used in constructing the StreamSRI, and any additional information that affects StreamSRI must be manually modified. In the case of DDC tuners, there is an optional parameter accepted by create for specifying the collector frequency since this information cannot be gathered from the frontend_tuner_status struct.   printSRI Used for debug purposes to print the values of a StreamSRI object to stdout.   addModifyKeyword Used to add a keyword to a StreamSRI object, or modify an existing keyword.   uuidGenerator Used to generate a new uuid string.   floatingPointCompare Used to handle potential errors introduced by floating-point math. Default precision is to the tenths place, and there is an optional parameter that can be used to specify a different precision.   matchAllocationIdToStreamId Only available when multi-out ports are specified. Multi-out capability of a BulkIO port only pushes stream data with a particular Stream ID to connections that have a connection ID that matches the Allocation id. It is recommended that this function be called in deviceSetTuning.   validateRequest Used to verify that a value falls within the specified range. This function is overloaded to accept a range as well, to verify that it falls within a second range.   validateRequestVsSRI Used to check that the input data stream can support the allocation request. The output mode (True if complex output) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown. If the CHAN_RF and FRONTEND::BANDWIDTH keywords are not found in the SRI, FRONTEND::BadParameterException is thrown.   validateRequestVsRFInfo Used to check that the analog capabilities can support the allocation request. The mode (True if complex) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown.   validateRequestVsDevice Used to check that the input data stream and the device can support an allocation request. The mode (True if complex output) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown. This function is overloaded to accept RFInfoPkt for an analog input data stream, and StreamSRI for a digital input data stream. For StreamSRI, if the CHAN_RF and FRONTEND::BANDWIDTH keywords are not found in the SRI, FRONTEND::BadParameterException is thrown.    "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/increasing-bulkio-connection-bandwidth/",
	"title": "Increasing the Bandwidth of BulkIO Connections",
	"tags": [],
	"description": "",
	"content": " In the presence of high data rates, plots of BulkIO ports may not be able to keep up with the data stream. To increase the bandwidth of BulkIO CORBA connections, it is possible to connect using native omniORB libraries. This ability is currently disabled by default. The following procedure explains how to enable this ability from within the IDE:\n Select Window \u0026gt; Preferences.\nThe Preferences dialog is displayed:\nPreferences Dialog  Expand REDHAWK.\n Select BulkIO.\n Set Port Factory to omnijni.\n Click OK.\n  This option should only be enabled if the domain matches the version of the IDE, and your application requires the increased performance of omnijni.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/optimization/",
	"title": "Optimization",
	"tags": [],
	"description": "",
	"content": " As a system framework, REDHAWK is affected by system settings beyond the scope of REDHAWK. System optimization is sensitive to the set of applications that the system is intended to support. However, there are some simple settings that can apply to a wide set of applications. This chapter describes some of the effects of these generalized settings.\nConfiguring omniORB By default, omniORB configuration relies on the loopback interface of the operating system. While easy to use and manage, the loopback interface is not the fastest default transport that omniORB supports. omniORB also supports Linux Domain Sockets. Linux Domain Sockets are configured through the omniORB configuration file (/etc/omniORB.cfg).\nThe following steps explain how to configure Linux Domain Sockets.\nRoot permissions are required to perform the following steps.\n  In the omiORB configuration file (/etc/omniORB.cfg), set the endpoints where the server is listening by adding the following lines to the endPoint section of the file:\nendPoint = giop:tcp:127.0.0.1: = giop:tcp:\u0026lt;computer IP address\u0026gt;: = giop:unix: giop(General Inter-ORB Protocol) is the scheme used by the endpoint. tcp is the transport name followed by an IP address or host name. The port is specified after the last colon. Since no port is specified here, the operating system chooses the port. The Unix transport name uses a filename as the name of the socket in the filesystem. Since a name is not specified here, a name based on the process ID and timestamp is used.\n  Set the endpoints that are published in an object’s IOR by adding the following lines to the endPointPublish section of the file:\nendPointPublish = all(addr) After changing these settings, the name and event services must be reset, and their associated log files must be deleted. If the log files are not deleted, they preserve iors that are no longer valid.\n Use the following command to reset the name and event services and delete the associated log files:\nsudo $OSSIEHOME/bin/cleanomni Run this script with the -v or --verbose option to print the cleanup process.\n To verify that Linux Domain Sockets are being used, go to /tmp, and verify that the omni-omni and omni-root directories exist. These two directories contain the files for the Linux Domain Sockets. Given that communications are now over file descriptors, verify that read permissions are open when communicating between objects owned by different users. This change in the omniORB configuration greatly improves data transport rates.\n  Packet Transfer Size REDHAWK transfers data using BulkIO, which is an RPC mechanism. The size of the data sequence that is passed on each of these calls has an effect on the data rate. The size of the transfer is not controlled by the REDHAWK runtime environment; instead, data producers can pass any arbitrary length less than giopMaxMsgSize.\nTo demonstrate how throughput is affected by the configuration of omniORB and data transfer size, tests were performed on a system with the specifications shown below.\nComputer Hosting Experiments    Parameter Value     Number of cores 8   CPU clock speed 3.40 GHz   Cache size 8192 kB    The figure below shows the supported data rate in Giga-bytes per second at different transfer sizes when using the loopback interface (the default setting for omniORB). Data rates on the experiment platform plateau when transfer size approaches approximately 500 kB. Using higher transfer sizes, data rate does not improve, while latency increases. The value at which data rates plateau is system-specific.\nThroughput for BulkIO When Using the Loopback Interface Another result derived from this experiment is that there is a substantial impact when the number of component pairs transferring data increases.\nBy following the steps in Configuring omniORB, it is possible to achieve higher data rates. The following figure shows the same experiment as the one shown above, but with omniORB configured for Linux Domain Sockets. The sustained data rates on the computer used in this experiment are roughly four times higher when using Linux Domain Sockets compared to using the loopback interface. Even when heavily loaded, the Linux Domain Socket configuration is as fast or faster than the lightly-loaded loopback configuration.\nThroughput for BulkIO When Using Linux Domain Sockets Messaging Latency Much like BulkIO, messaging is subject to performance issues as the transfer size changes. Testing was performed to determine the impact of message size on the latency per message. The size of the message was modified and the latency per message was measured. The average latency was measured for sets of 1000 messages. The two figures below show the latency results when using the loopback interface and when using Linux Domain Sockets. Latency is a function of the size of the message, where the measured latency ranges between 40-150 microseconds and 50-160 microseconds for Linux Domain Sockets and loopback interface, respectively.\nMessage Latency When Using the Loopback Interface Message Latency When Using Linux Domain Sockets Note that in both figures latency is linear as a function of the message size. Furthermore, the number of concurrent messaging components has no discernible impact on the message latency. Finally, the difference shown between Linux Domain Socket performance and loopback interface performance is, while measurable, relatively small.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/port-statistics/",
	"title": "Port Statistics",
	"tags": [],
	"description": "",
	"content": " All BurstIO ports support the BulkIO statistics interface with additional keywords to track burst-specific metrics. Statistics are tracked over a window of 10 pushBurst calls. An input port contains a single PortStatistics structure, whereas, an output port contains a sequence of PortStatistics structures; one structure per connection. For more information on BULKIO::PortStatistics, see Port Statistics. The additional BurstIO metrics for both input and output ports are described in the following tables:\nC++ The following example illustrates a component that performs a transform on the incoming burst data and pushes the results downstream.\nburstio::BurstShortIn::PacketType *pkt; pkt = inShortPort-\u0026gt;getPacket(bulkio::Const::NON_BLOCKING); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check for EOS if ( pkt-\u0026gt;getEOS() ) { outShortPort-\u0026gt;pushBurst(pkt-\u0026gt;getSequence(), pkt-\u0026gt;getSRI(), pkt-\u0026gt;getEOS()); } // do some processing.....to the burst contents BurstShortOut::SequenceType data = do_some_magic(pkt-\u0026gt;getSequence()); // we changed the data so calc new time stamp.... BULKIO::PrecisionUTCTime newTS = calc_timestamp(pkt-\u0026gt;getTime()); outShortPort-\u0026gt;pushBurst(data, pkt-\u0026gt;getSRI(), newTS, pkt-\u0026gt;getEOS()); Java The following example illustrates a component that generates 10 bursts objects containing 100 samples of data and sends the array downstream.\n/** This example demonstrates a Component that uses the pushBursts method to generate data */ int nbursts=10; String sid = new String(\u0026#34;stream-1-1\u0026#34;); BURSTIO.LongBurst [] bursts = new BURSTIO.LongBurst[nbursts]; // allocate space for 10 bursts to push downstream  // generate bursts with 100 samples of data for downstream for ( int j=0; j \u0026lt; nbursts; j++ ) { BURSTIO.LongBurst burst = new BURSTIO.LongBurst(); burst.SRI = SRI make_SRI( sid ); // generate a Burst SRI object for use...  burst.EOS = false; burst.T = burstio.Utils.now(); burst.data = generate_samples( 100 ); bursts[j] = burst; } longOutPort.pushBursts( bursts ); Python The following example illustrates a component that generates burst samples that will be filtered out by the port’s routing table when at least 10 bursts are queued for delivery.\nfrom redhawk.burstioInterfaces import BURSTIO from redhawk.burstio import * def initialize(self): # # Send bursts to downstream resource using connection filtering # **you will need to set the routing table in a Property change event # callback for the resource\u0026#39;s connection table object** # self.outShortPort.setRoutingMode( ROUTE_CONNECTION_STREAMS ) self.outShortPort.setMaxBursts(10); def generate_burst_samples(self, nsamps=10 ): # # generate number of sample data.. return range(nsamps) def process(self): # data = self.generate_burst_samples(100) SRI = burstio.utils.createSRI(\u0026#34;test_stream_id\u0026#34;) SRI.xdelta = 1.0/1000.0 SRI.mode = 0 self.outShortPort.pushBurst( data, SRI, burstio.utils.now() ) return NORMAL"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/redhawk-explorer-view/",
	"title": "REDHAWK Explorer View",
	"tags": [],
	"description": "",
	"content": "The REDHAWK Explorer View enables users to navigate the contents of a REDHAWK domain. It provides capabilities for viewing the contents of the domain, configuring instantiated resources, and launching applications in a target SDR. It also provides access to the IDE Sandbox, which is an environment for running components and applications without launching a Domain Manager or Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": " This section briefly describes how to use the sandbox either from a Python shell or via the REDHAWK IDE; a more detailed description is available in the Sandbox chapter.\nPython Sandbox The sandbox can be accessed directly from the command line and is used to manipulate new components and waveforms. This provides a very powerful means of testing and scripting tests for REDHAWK systems.\n Open a Python session and import the sandbox:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb Running a component\n To get a list of available components, type:\n\u0026gt;\u0026gt;\u0026gt; sb.catalog() [\u0026#39;rh.HardLimit\u0026#39;, \u0026#39;rh.SigGen\u0026#39;, ...] The displayed list is derived by scanning $SDRROOT. HardLimit and SigGen are examples of existing components.\n  Create the component object by typing:\n\u0026gt;\u0026gt;\u0026gt; hardLimit = sb.launch(\u0026#34;rh.HardLimit\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sigGen = sb.launch(\u0026#34;rh.SigGen\u0026#34;) After the constructor is finished, the components run as their own processes. If an absolute file path for a component’s SPD file (\u0026lt;component.spd.xml) is given as a constructor argument for the component instance, then that component is started irrespective of whether or not it is present in $SDRROOT.\n   Support widgets are available in the sandbox to help the developer interact with running components. There are a variety of widgets, including data sources and sinks, a speaker interface, and plotters. In this example, the plot widget is used.\n To use plotting, the path to the eclipse directory of the installed IDE must be specified in the sandbox (this can also be done by setting the RH_IDE environment variable to the absolute path of the Eclipse directory prior to starting the Python session):\n\u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) \u0026gt;\u0026gt;\u0026gt; plot = sb.Plot() Create two plot objects by instantiating the Plot class twice and assigning the objects to local variables:\n\u0026gt;\u0026gt;\u0026gt; plot1 = sb.Plot() \u0026gt;\u0026gt;\u0026gt; plot2 = sb.Plot()  Connect the components together and connect the plots. The connect() method tries to match the port; ambiguities can be resolved with the parameters usesPortName and providesPortName. Connecting the plots to the components displays the Plot Application window.\n\u0026gt;\u0026gt;\u0026gt; sigGen.connect(hardLimit) \u0026gt;\u0026gt;\u0026gt; sigGen.connect(plot1) \u0026gt;\u0026gt;\u0026gt; hardLimit.connect(plot2) In this tutorial, the SigGen component is configured before it is started to get a better visual. Set the frequency of the SigGen Component equal to 5006:\n\u0026gt;\u0026gt;\u0026gt; sigGen.frequency = 5006 Start everything in the sandbox:\n\u0026gt;\u0026gt;\u0026gt; sb.start() The property values can now be set on the HardLimit component. The plot reflects the property change:\n\u0026gt;\u0026gt;\u0026gt; hardLimit.upper_limit = .8 To inspect the properties and input/output ports of a component, invoke the component’s api() method:\n\u0026gt;\u0026gt;\u0026gt; sigGen.api() To clean up, type Ctrl+D to end the Python session. The Python sandbox releases all components and cleans up whatever plots or additional widgets were created during the session.\n  The IDE Sandbox This section provides an overview of how to use the sandbox in the REDHAWK IDE. The IDE sandbox provides a graphical environment for launching, inspecting, and debugging components, devices, nodes, services, and waveforms. In addition, via the REDHAWK Console, you can use the Python-based sandbox API to interact with objects that are running within the IDE sandbox.\nThe following procedure provides an example of launching and interacting with a component in the sandbox in the REDHAWK IDE.\n In the REDHAWK Explorer View:\n Expand the Sandbox to expose the Chalkboard.\n Double-click the Chalkboard.\nOpen Chalkboard   From the Chalkboard:\n Select the palette on the right; drag the SigGen (cpp) component onto the Chalkboard. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue. SigGen will be used to help test the new HardLimit component.\n If the SigGen component is not displayed, left-click the rh folder to display the list of available components.\n If the cpp implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name and select the cpp implementation. To zoom in and out on the diagram, press and hold Ctrl; then scroll up or down. Alternatively, press and hold Ctrl; then press + or -.\n  Right-click the SigGen component, and select Start.\nStart Component  Left-click the dataFloat_out port to select it, then right-click the port to open the port context menu, and select Plot Port Data.\nPlot Port Data  Open the Properties View and change the following signal properties:\n frequency: 100 magnitude: 10\nChange Property Value   Select the palette on the right, drag the HardLimit component onto the Chalkboard.\n Right-click the HardLimit component, click Start.\n Connect the dataFloat_out port on the SigGen component to the dataFloat_in port on the HardLimit component by clicking and dragging from the solid black output port to the input port.\nConnect Ports  Right-click the dataFloat_out port on the HardLimit component, click Plot Port Data\n Notice that the output has been hard limited by the HardLimit component\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/shared-libraries/",
	"title": "Shared Libraries",
	"tags": [],
	"description": "",
	"content": "Shared libraries are a way to share common code between multiple REDHAWK projects, both at development and run time. When developing components or devices, REDHAWK shared libraries are automatically integrated into the build system. At run time, a component’s dependencies are copied to the GPP as required, eliminating the need to install dependencies on each system in a domain.\nUsing shared libraries reduces the development, maintenance, and deployment costs of REDHAWK systems.\n Creating a REDHAWK Shared Library Project     Using a REDHAWK Shared Library Project     Packaging Shared Libraries     Manually Including External Libraries     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/standardized-data-interfaces/",
	"title": "Standardized Data Interfaces",
	"tags": [],
	"description": "",
	"content": "Data flow between REDHAWK resources (components and devices) is managed through two sets of interfaces: BulkIO and BurstIO. The BulkIO module is designed for streaming data and maximizes the efficiency for bulk data transfers between resources, whereas, BurstIO is designed for applications that require small and possibly non-contiguous chunks of data transfers. Both interfaces also allow for the association of metadata, Signal Related Information (SRI), and a Precision Time Stamp, which describe the content being transferred in support of content processing. The following 3 sections detail the capabilities for both BulkIO and BurstIO implementations and the interfaces they provide.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/application-factory/",
	"title": "The Application Factory",
	"tags": [],
	"description": "",
	"content": "The Application Factory is responsible for the creation of applications within a domain. Whenever an application is installed by the Domain Manager, an Application Factory is created from tags in the application’s SAD file, in order to deploy components of the application to devices based on their implementation dependencies.\nWhen the create() function is called, the Application Factory uses the SPD implementation element to locate devices that are capable of loading and executing the given component. The Application Factory does this by first assembling a list of all of the allocation properties required by the components that make up its application. It then searches through each of the candidate devices for properties whose kindtype is allocation and action is not external. It attempts to use that devices allocateCapacity() function in order to compare the requested capacities with the devices available resources.\nThe creation of the application fails if the Application Factory is unable to deploy all of the components in compliance with the components’ dependencies and host-collocation requirements given the available devices.\nOnce the resource marshaling has been successfully completed, the filemanager copies the appropriate component files into the specific Device Manager’s File System and the Application Factory performs the load() and execute() operations in order to launch the component on its assigned device. It then continues to initialize, connect and configure the components. properties can also be overridden from the componentproperties tags in the waveform’s SAD file.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/time-stamps/",
	"title": "Time Stamps",
	"tags": [],
	"description": "",
	"content": " BulkIO uses BULKIO::PrecisionUTCTime time stamps that denote the time since 12:00 AM January 1, 1970 (Unix epoch) in UTC. The time stamp contains several elements. In BulkIO, a time stamp corresponds to the date of birth of the first element in the data being pushed. The table below describes the different elements making up the BULKIO::PrecisionUTCTime structure.\nElements in BULKIO::PrecisionUTCTime    Identifier Value Type     tcmode timecode mode short   tcstatus timecode status short   toff Fractional sample offset double   twsec Number of seconds since 12:00 AM January 1, 1970 (Unix epoch) double   tfsec Number of fractional seconds (0.0 to 1.0) to be added to twsec double    Two of the elements described in the table correspond to predefined values. tcstatus can only take two values, TCS_INVALID (0), and TCS_VALID (1), showing whether the time stamp is valid or not. Invalid time stamps do not contain valid time data and should be ignored. tcmode is the method by which the timestamp was obtained, but this use has since been deprecated, and this value is ignored. The default value for tcmode is 1.\nThe following code snippets provide examples of how to construct a time stamp to be sent in the pushPacket() call. The now() method returns the current time of day.\nC++:\nBULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); Python:\ntstamp = bulkio.timestamp.now() Java:\nBULKIO.PrecisionUTCTime tstamp = bulkio.time.utils.now(); Timestamp Operators (C++) In C++, BULKIO::PrecisionUTCTime supports common arithmetic, comparison and stream operators.\nAdding an offset to a time stamp:\n/** * Add 1/8th of a second to the current time */ BULKIO::PrecisionUTCTime time1 = bulkio::time::utils::now(); time1 += 0.125; Subtracting two time stamps returns the difference in seconds:\n/** * Check if time2 is less than a second after time1 */ if (time2 - time1 \u0026lt; 1.0) { ... } Comparing two time stamps:\n/** * Check if the second time stamp occurs before the first */ if (time2 \u0026lt; time1) { ... } Stream formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n/** * Write the current time out to the console */ std::cout \u0026lt;\u0026lt; bulkio::time::utils::now() \u0026lt;\u0026lt; std::endl; Timestamp Operators (Python) In Python, BULKIO.PrecisionUTCTime supports common arithmetic, comparison and string conversion operators.\nAdding an offset to a time stamp:\n# Add 1/8th of a second to the current time tstamp = bulkio.timestamp.now() tstamp += 0.125 Subtracting two time stamps returns the difference in seconds:\n# Check if time2 is less than a second after time1 if (time2 - time1) \u0026lt; 1.0: ... Comparing two time stamps:\n# Check if the second time stamp occurs before the first if time2 \u0026lt; time1: ... String formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n# Write the current time out to the console print str(bulkio.timestamp.now()) Timestamp Helpers (Java) In Java, the bulkio.time.utils class provides static helper methods for common arithmetic, comparison and string conversion operations.\nAdding an offset to a time stamp with increment() modifies the original time stamp:\n// Add 1/8th of a second to the current time BULKIO.PrecisionUTCTime tstamp = bulkio.time.utils.now(); bulkio.time.utils.increment(tstamp, 0.125); Adding an offset to a time stamp with add() returns a new time stamp with the result, leaving the original time stamp unmodified:\n// Add a second to the current time BULKIO.PrecisionUTCTime time1 = bulkio.time.utils.now(); BULKIO.PrecisionUTCTime time2 = bulkio.time.utils.add(time1, 1.0); Calculating the difference in seconds between two time stamps:\n// Check if time2 is less than a second after time1 if (bulkio.time.utils.difference(time2, time1) \u0026lt; 1.0) { ... } Comparing two time stamps:\n// Check if the second time stamp occurs before the first if (bulkio.time.utils.compare(time2, time1) \u0026lt; 0) { ... } The compare() method follows the same rules as java.util.Comparator.\nString formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n// Write the current time out to the console System.out.println(bulkio.time.utils.now());"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/viewing-logging-events/",
	"title": "Viewing Logging Events",
	"tags": [],
	"description": "",
	"content": " A live view of events logged by components or devices can be displayed in the IDE. The component or device provides logging events to an event channel, and the IDE displays them as it receives them. To view the log:\n Right-click the running component or device and select Logging \u0026gt; Tail Log. The Specify logging details dialog is displayed:\nEdit Log Config  Select the logging level.\n If desired, specify the logger to which the IDE should attach. Leave the field blank to attach to the root logger.\n Click OK.\nA new Console view displays logging events as they are received.\n To no longer view events, click the Stop icon on the Console toolbar.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/sdds-data/",
	"title": "Working with SDDS Data",
	"tags": [],
	"description": "",
	"content": " SDDS Data via REDHAWK Components The Sandbox along with the SourceSDDS and SinkSDDS REDHAWK components allow a user to ingest and emit SDDS data during a user’s session. These two components provide a fully-compliant capability when processing SDDS network traffic. Consult the appropriate documentation for the SDDS specification and each of the components.\n SourceSDDS - Ingests SDDS packets from the network and repackages the data for BULKIO port transmission. The component creates the proper BULKIO SRI, time stamps, and data vectors from the SDDS packet headers and payloads.\n SinkSDDS - Emits SDDS packets from a connected BULKIO port to the network. The component uses the BULKIO SRI, time stamps, and data vectors to produce valid SDDS packets.\n  Each of these components requires a network address specification to access the appropriate host interface. The following table describes the two different network addresses supported by these components.\nSDDS Address Specification    Protocol Address Port VLAN     UDP IPv4 address 1024 - 65535 number (optional)   MULTICAST 224.0.0.0 - 239.255.25.255 1024 - 65535 number (optional)    Writing SDDS Data to a Network Interface To generate SDDS packet data, the rh.SinkSDDS component is used to send BULKIO data over the network interface as SDDS packets. This component accepts three different BULKIO data types (octet, short and float) and then formats the data, SRI, and time stamp information into valid SDDS packets.\nThe following example uses the Sandbox’s DataSource and the rh.SinkSDDS component to generate SDDS packets to be sent over interface eth0, the IP address 127.0.0.1, and port 29000.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; sig=sb.DataSource() \u0026gt;\u0026gt;\u0026gt; sdds_out = sb.launch(\u0026#34;rh.SinkSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.interface=\u0026#34;eth0\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.ip_address=\u0026#34;127.0.0.1\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.port=29000 \u0026gt;\u0026gt;\u0026gt; sig.connect(sdds_out, usesPortName=\u0026#34;shortOut\u0026#34;) \u0026gt;\u0026gt;\u0026gt; data=range(1024) \u0026gt;\u0026gt;\u0026gt; SRI=sig.SRI() \u0026gt;\u0026gt;\u0026gt; SRI.xdelta = 1/1000.0 \u0026gt;\u0026gt;\u0026gt; sig.push(data, SRI=SRI, EOS=False, loop=False) Reading SDDS Data from a Network Interface To read SDDS packet data, the rh.SourceSDDS component is used to receive SDDS data from a network interface. This component transforms the SDDS packet data into BULKIO data, SRI, and time stamps for downstream connections.\nThe following example configures a rh.SourceSDDS component to read data from interface eth0, send it to IP address 127.0.0.1 and port 29495, and forward the data to a Sandbox DataSink over a short typed port.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; dsink=sb.DataSink() \u0026gt;\u0026gt;\u0026gt; sdds_in = sb.launch(\u0026#34;rh.SourceSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.ip_address=\u0026#34;127.0.0.1\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.port=29495 \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.enable=True \u0026gt;\u0026gt;\u0026gt; sdds_in.interface=\u0026#34;eth0\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_in.connect(dsink,usesPortName=\u0026#34;dataShortOut\u0026#34;) In lieu of the attachment_override property, both components support the BULKIO dataSDDS interface and BULKIO::SDDSStreamDefinition structure. This interface defines an attach method, which is implemented by each component, and performs the necessary actions to connect to the SDDS source defined in the BULKIO::SDDSStreamDefinition structure.\nBULKIO::SDDSStreamDefinition    Name Type Description     id string Stream id to identify the data or allocation id for attachment   dataFormat SDDSDataDigraph Payload type of SDDS packet   multicastAddress string Multicast address   vlan long Virtual LAN number   port long Port number   sampleRate long Sampling frequence of SDDS payload data (egress only)   timeTagValid boolean Marks packets with valid time stamp field (egress only)   privateInfo string User-generated text    The following example configures the rh.SourceSDDS component to read data using the address specification defined by the BULKIO::SDDSStreamDefinition structure, and forward the data to a Sandbox DataSink over it’s short typed port.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; from bulkio.bulkioInterfaces import BULKIO \u0026gt;\u0026gt;\u0026gt; dsink=sb.DataSink() \u0026gt;\u0026gt;\u0026gt; sdds_in = sb.launch(\u0026#34;rh.SourceSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_in.connect(dsink,usesPortName=\u0026#34;dataShortOut\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_port=sdds_in.getPort(\u0026#34;dataSddsIn\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sd = BULKIO.SDDSStreamDefinition(\u0026#34;my_stream\u0026#34;, BULKIO.SDDS_SI, \u0026#34;127.0.0.1\u0026#34;, 0, 29495, 8000, True, \u0026#34;testing\u0026#34;) \u0026gt;\u0026gt;\u0026gt; attach_id = sdds_port.attach(sd, \u0026#34;username\u0026#34;) Capturing SDDS Data and the Sandbox’s DataSourceSDDS SDDS Data and the Sandbox’s DataSourceSDDS Independent of the components, the Sandbox also provides a snapshot and introspection capability through the DataSourceSDDS class. The following commands create the DataSourceSDDS object.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; ds=sb.DataSourceSDDS() Using this object, the user can capture an arbitrary number of packets and then introspect their contents. The content analysis and packet decomposition is provided through the SDDSAnalyzer class. To initiate a data capture, call the DataSourceSDDS’s getData or getStreamDef. By default, these methods return a SDDSAnalyzer object that contains all the raw packet data.\ngetData( mgroup, hostip, port=29495, pkts=1000, pktlen=1080, block=True, returnSddsAnalyzer=True) Parameters: mgroup = multicast address or IP address hostip = address of host interface to use port = port number to listen on pkts = number of packets to capture pktlen = length in bytes of a single packet block = will block until all packets are read returnSddsAnalyzer = returns SDDS analyzer object instead of raw data Returns: SDDSAnalyzer: provides SDDS packet introspection and tracking or tuple: data - converted raw data to a list of numbers rawdata - actual data read from socket pktlen - packet length provided during capture pkts - number of packets read totalRead - total number of bytes read Using the SDDSAnalyzer Using the SDDSAnalyzer, you can perform the following actions:\n dumpPackets - Displays packet data as readable SDDS packets with header breakout.\ndumpPackets(pkt_start=0, pkt_end=None, payload_start=0, payload_end=40, raw_payload=False, header_only=False, use_pager=True) Displays SDDS packet header and payload in human readable format. Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) payload_start = starting payload sample to display payload_end = ending payload sample to display raw_payload = dump payload data as raw bytes header_only = only display header information for each packet use_pager = display data using pager to limit number of packets that are displayed dumpRawPackets - Displays packet data as bytes.\ndumpRawPackets(pkt_start=0, pkt_end=None, row_width=80, bytes_per_group=2, pkt_len=None, use_pager=True) Displays SDDS packet data in hexidecimal format Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) row_width = 80 the number of bytes to display per row bytes_per_group = the number of bytes to group when hexify-ing pkt_len = the number of bytes in a packet, None defaults to 1080 or length when getData method was called use_pager = display data using pager to limit number of packets that are displayed getPacketIterator - Returns a Python iterator that can be used in loops.\ngetPacketIterator(pkt_start=0, pkt_end=None) Returns a Python iterator that will traverse the set of packets managed by the SDDSAnalyzer object Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) getPackets - Returns a list of SDDS packet objects.\ngetPackets(pkt_start=0, pkt_end=None) Returns a list of sdds_packet objects Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) trackChanges - Tracks changes in header fields.\ntrackChanges(pkt_start=0, pkt_end=None, repeat_header=20, use_pager=True) Tracks changes to the following SDDS packet fields: sequence numbers, data mode, complex flags, bits per sample, frequency, rate, time tag valid, time slips No changes in the data field are displayed as: - Changes in the data field are displayed as: *** Valid TimeStamps are denoted as: + Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) repeat_header = displays column header every Nth packet displayed use_pager = display data using pager to limit number of packets that are displayed  SDDS Packets The resulting SDDS packet objects, provided by the SDDSAnalyzer, allow for inspection and manipulation of each packet’s underlying data. The python help utility for ossie.utils.sdds.sdds_packet module describes these methods in more detail. The following sample code creates a SDDS packet object and sets the sample rate and payload contents of the packet.\nfrom ossie.utils.sdds import * pkt=sdds_packet() pkt.header.set_rate(10e6) pkt.header.get_rate() # OUT: 10000000.0 pkt.payload.sb.set_data(1024*[100]) # diplay the payload contents as list of numbers pkt.payload.sb.get_data() # OUT: [100, 100, 100, 100, 100, .... 100, 100, 100, 100, 100 ] # print out the entire contents of the sdds packet as array of octets pkt.asBuffer() DataSinkSDDS in the Sandbox The rh.SinkSDDS component provides a fully compliant capability for ingesting BULKIO’s data streams and publishing SDDS packets to a network. To support use cases that do not require this level of compliance, the Sandbox provides the DataSinkSDDS object that can capture the stream definitions and SRI data from a BULKIO SDDS interface that publishes this information. Below is a sample code session showing how to connect to a DataSinkSDDS object and capture the stream definition.\nfrom ossie.utils import sb from bulkio import BULKIO def inStreamDef(sd,userid): print \u0026#34;stream def: \u0026#34;, sd print \u0026#34;user: \u0026#34;, userid sink=sb.DataSinkSDDS() src=sb.DataSourceSDDS() src.connect(sink) sd=BULKIO.SDDSStreamDefinition(\u0026#34;data1\u0026#34;, BULKIO.SDDS_SB,\u0026#34;239.1.1.0\u0026#34;,0,29495,1000000,False,\u0026#34;\u0026#34;) # # triggers default process to print out stream definition and user id src.attach(sd,\u0026#34;stream1\u0026#34;) # # setup callback for attachment sink.registerAttachCallback(inStreamDef) src.attach(sd,\u0026#34;stream2\u0026#34;)"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/namespaces/",
	"title": "Adding/Changing/Removing REDHAWK Project Namespaces",
	"tags": [],
	"description": "",
	"content": " Existing REDHAWK projects can be renamed to include a namespace. Projects can be namespaced by adding dots in the name. Project names may not begin with a number and may not contain special characters other than dots for the namespace. Namespacing projects provides the ability to uniquely identify projects that share the same base name but have different implementations and also provides a logical grouping of resources. For example, the REDHAWK basic assets are namspaced as rh.xxxx.\nThe following procedure explains how to rename a project to include a namespace.\nThe IDE only supports automatic refactoring of project namespaces, not project base-names. If you want to change the base-name of a project, create a new project with the new base-name, and then manually move code into the new project.\n  In Project Explorer, right-click the project, select Rename.\nThe Rename Resource dialog is displayed:\nRename Resource Dialog  Enter the new project namespace and click Preview.\nThe Rename Resource window is displayed:\nRename Resource Window  Click OK.\nThe IDE updates all relevant references, directories, and file names to match the new namespace.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/",
	"title": "BulkIO",
	"tags": [],
	"description": "",
	"content": "BulkIO is designed to provide a standardized methodology and to maximize efficiency for bulk data transfers between REDHAWK resources (components/devices). This interface supports the transfer of data vectors (float, double, char (int8), octet (uint8), short (int16), ushort (uint16), long (int32), ulong (uint32), longlong (int64), ulonglong(uint64)), character strings (char *), and out-of-band connection descriptors for SDDS data streams.\nThese interfaces also allow for metadata, Signal Related Information (SRI), and a precision time stamp (described in detail in the following subsections), which describe the content being transferred and support content processing. Part of the required methodology for passing data between REDHAWK components is that all data transfers via pushPacket() are preceded by at least one call to pushSRI() with an appropriate SRI object. SRI data is passed out-of-band from the content data to reduce the overhead for transferring data between components. The precision time stamp represents the birth date for data and is part of the pushPacket() method call for those components that require this information.\nThe data flow implementation for a component’s BulkIO port interface is provided by a shared bulkio base class library. The resulting component code instantiates a bulkio base class object and makes use of the shared library during deployment and execution.\n Data Transfers     Signal Related Information (SRI)     Stream API     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/",
	"title": "Connections",
	"tags": [],
	"description": "",
	"content": "When discussing connections, there are several terms that are thrown around in REDHAWK: uses, provides, port, interfaces, IDL, among others. This section demystifies connections and presents the key concepts that enable a REDHAWK-based system to easily interact with other REDHAWK systems and external tools developed outside the scope of REDHAWK.\n The Connection Process     Why Ports?     Port Access     Dynamic Connections     Standardized Data Interfaces     BulkIO    Data Transfers     Signal Related Information (SRI)     Stream API     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples      BurstIO    Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics      Messaging    Message Producer     Message Consumer     Viewing Messages     Connecting Producers and Consumers      Connection Callbacks     Custom IDL Interfaces     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/components/hello-world-component/",
	"title": "Creating and Running a Hello World Component",
	"tags": [],
	"description": "",
	"content": "Use the following procedure to create a simple component that prints hello world to the terminal upon startup.\n Create a new REDHAWK component Project:\n File \u0026gt; New \u0026gt; REDHAWK Component Project  Name the project: HelloWorld\n Click Next.\n Select:\n Prog. Lang: C++  Click Next.\n Click Finish.\n If a dialog asks to switch to CPP perspective, click No.  Generate Code:\n In the editor tool bar, click Generate All Component Implementations  In the HelloWorld.cpp file, add the following include to the beginning of the file:\n#include \u0026lt;iostream\u0026gt; In the HelloWorld.cpp file, add the following code to the serviceFunction() method:\nstd::cout\u0026lt;\u0026lt;\u0026#34;Hello world\u0026#34;\u0026lt;\u0026lt;std::endl; Compile the project:\n Project \u0026gt; Build Project  Drag the project to the Target SDR section of the REDHAWK Explorer.\n On a terminal, start a Python session.\n Run the following commands:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; hello_world = sb.launch(\u0026#34;HelloWorld\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sb.start()  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/displaying-port-statistics/",
	"title": "Displaying Port Statistics",
	"tags": [],
	"description": "",
	"content": "In addition to port plotting, a user may want to monitor the amount of data flowing out or into a particular port. The Port Monitor view displays these link statistics, which are helpful when debugging and can help identify which component is slowing down or dropping information during data processing. The diagram also visually reflects the port statistics.\nTo display the Port Monitor view:\n Make sure that the component to be monitored is currently in the Started state.\n Right-click the port to monitor.\n Select Monitor Port.\nThe Port Monitor view is displayed and contains the following information:\n Name: The name of the port or port connection. Elements/sec: The rate of CORBA elements transferred in the pushPacket data call. mbps: Mega Bytes transferred per second. calls/sec: Number of push calls per second to the port. Stream IDs: List of all active stream ids. Avg. Queue Depth: For components that queue data before processing/sending, the average queue depth measured as a percentage. If a port does not queue data this value is set to zero. Time: The elapsed time, in seconds, since the last packet was transferred via a push packet call.   In the diagram, for uses (out) ports, the color of the connection (the arrow) to the provides port reflects the statistics. Green indicates that data is flowing. Yellow indicates it has been more than 1 second since the port pushed data, which may indicate a data flow issue. For provides (in) ports, the color of the box on the side of the component, which represents the port, reflects the statistics. A green port indicates the queue has plenty of space left. After the queue depth reaches 60 percent, the port color changes to yellow, and the port color slowly changes to red as the queue depth approaches 100 percent. Additionally, if there is a queue flush, the port remains red for 30 seconds after that queue flush.\nTo configure the colors displayed for the various port statistics:\n Select Window \u0026gt; Preferences.\n Select the REDHAWK Port Statistics preference page.\n Change the values.\n Click OK.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/fei/",
	"title": "FrontEnd Interfaces",
	"tags": [],
	"description": "",
	"content": " FrontEnd Interfaces is a module containing interfaces designed to standardize the interaction between applications and radio hardware. This appendix specifies the requirements of an FEI 2.0 compatible device, explains best-practices, provides advice for development, and provides device structures. This appendix is not intended to be an API reference for FEI or an exhaustive description of the idls. This appendix is intended to provide an additional resource for developers.\nTheory of Operations FEI were developed to standardize the allocation, operation, and development of tuner devices within the REDHAWK Core Framework. Tuner devices in this context may consist of RF, if, or purely digital tuning equipment or software. Explicit types for tuners have been defined, so that devices can be easily categorized by the capabilities they provide.\nTuner devices can provide individual tuners to other REDHAWK entities through tuner allocation. To allocate an individual tuner, the allocateCapacity() function of a device is called with an appropriate allocation structure as the only argument. devices then allocate physical resources and, once a valid connection has been made, begin flowing data out of the device.\nFEI Terminology    Terminology Description     device A REDHAWK device.   FEI device devices that have a device_kind of FRONTEND and implement one of the FEI idls. Typically, GPS and navigation devices fall into this category.   Tuner A specific tuner capability in an FEI device.   FEI Tuner device devices that have a device_kind of FRONTEND::TUNER. These devices must implement the TunerControl IDL and contain Tuners for allocation.    Required Properties    Name / ID Description     device_kind / DCE:cdc5ee18-7ceb-4ae6-bf4c-31f983179b4d Must be set to FRONTEND or FRONTEND::TUNER.   device_model / DCE:0f99b2e4-9903-4631-9846-ff349d18ecfb Used to specify the model of the hardware device.   frontend_tuner_status / FRONTEND::tuner_status A struct sequence where each struct in the sequence represents a single tuner. The structure is defined further in Status Elements.    Types of Tuners Tuner types are defined so that device developers and users can categorize the basic behavior of disparate hardware. Behavior of each of these types is described below and must be adhered to during development to allow for interoperability between different hardware baselines.\nPhysical devices often need to be split into multiple logical REDHAWK tuners to fully describe their functionality. Splitting physical devices often involves multiple tuners of the same, or mixed, types. Common pairings are described in each of the type descriptions.\nRX Tuner A simple receiver, or RX tuner, is an RF to IF conversion only. This conversion implies an analog to analog translation, typically down-converting an RF signal to a new if. devices often have multiple RX devices corresponding to each of the independent analog channels provided. Single channels that have selectable RF input ports should be represented as a single RX tuner and utilize an RF Flow ID to select between the input options.\nRX devices have an analog output port. RX devices that output digital-IF (SDDS, VITA-49, etc.) are considered RX_DIGITIZERS, which are a distinct tuner type and should be classified as such.\nRX_DIGITIZER Tuner An RX_DIGITIZER tuner is an RX device that also samples the analog data and provides it as a digitized stream. The stream can be either real samples (typically referred to as digital-IF) or complex baseband data. Multiple RX_DIGITIZER channels in a singular physical device should be treated like RX devices, including using the RF Flow ID to differentiate between which external RF source to use.\nRX_DIGITIZER tuners can also optionally provide access to the analog-IF output. If the device in question provides access to the analog-IF output, an additional analog output port should be added to the device. Users can optionally connect to and use that port, although the existence of the port is not guaranteed for all RX_DIGITIZER tuners.\nCHANNELIZER Tuner A CHANNELIZER tuner takes a digital wideband input and provides tuned, filtered, and decimated narrowband output. A CHANNELIZER device acts as a token to allocate and control the wideband input, which then can have individual narrowband channels allocated as well. Each of these narrowband tuners is its own tuner of type ddc.\nAllocating a CHANNELIZER establishes control over the input to a CHANNELIZER and allows users to understand that they have the ability to attach a new stream to the wideband input. Typical operation is to allocate a CHANNELIZER to gain control over the input prior to connecting a data stream to the input, though the order is not mandatory.\nAllocating a DDC provides the tuned, filtered, and decimated narrowband output. A DDC is allocated by calling allocateCapacity() with the tuner type set to DDC and also specifying the frequency, bandwidth, sample rate, and any other desired aspects of the resulting ddc. Optionally, the RF Flow ID is used during allocation to specify the wideband input connection and CHANNELIZER desired. Allocation of a DDC succeeds only if the information specified during allocation can be supported by an allocated CHANNELIZER with a successful matching input connection. Changing the CHANNELIZER input can cause attached DDC tuners to be dropped.\nDDC Tuner DDC tuners provide a narrowband output from an existing channelizer capability. These narrowband channels are typically selectable in terms of the center frequency and bandwidth/sample rate within the constraints of the wideband input to the channelizer.\nAllocating a DDC tuner against a device with multiple CHANNELIZER (or RX_DIGITIZER_CHANNELIZER) tuners can specify which tuner to use in two different ways. One method is to specify an RF Flow ID of the specific CHANNELIZER to be allocated against. The other method is to allow the device to match by using the requested center frequency and/or bandwidth/sample rate. The device matches the DDC to the first channelizer capability that meets those criteria.\nRX_DIGITIZER_CHANNELIZER Tuner The RX_DIGITIZER_CHANNELIZER tuner is a combination of an RX_DIGITIZER and CHANNELIZER capability into a single tuner type. Input is through an analog-RF input port, and output is through DDC tuners.\nRX_DIGITIZER_CHANNELIZER tuners have the optional ability to output both analog-IF as well as digital-IF data. The analog-IF ports are represented just like the output of an RX or RX_DIGITIZER tuner. The digital-IF data is accessed by allocating a listener to the RX_DIGITIZER_CHANNELIZER, which then starts flowing digital data just like an RX_DIGITIZER.\nThe primary RX_DIGITIZER_CHANNELIZER allocation does not put out wideband digital data by default. These are optional ports, and each may or may not be present on each device.\n TX Tuner Although the exact functionality of the TX tuner is not yet defined, it is reserved for transmitter devices.\nAllocation Allocation is the process where specific tuners are requested for use, and initial setup of the tuner is performed. Allocation of FrontEnd devices always occurs by calling allocateCapacity() on the device with the argument of the allocateCapacity() call being a FrontEnd allocation property.\nID A number of different IDs are used in REDHAWK and FEI devices. The most important types of IDs are described in this section.\nAllocation ID The Allocation ID is a string used as an unique ID for each allocated FEI tuner. The Allocation ID is passed in as part of the allocateCapacity() call and is used as identification for all subsequent interaction. Allocation IDs are used to identify tuners in the FEI Status structure and in the TunerControl idl.\nAllocation IDs can be any unique string, but typically UUID values are used. If human readable Allocation IDs are required, the preferred approach is to append the UUID onto a base human-readable string. With this approach, allocations for non-coordinated devices are not likely to create identical allocations.\nStream ID In all REDHAWK BulkIO ports, Stream ID is used to separate unique data streams that are passed in a single BulkIO port. This methodology is also utilized in FEI devices to allow devices to pass the output of multiple tuners through a single BulkIO port. REDHAWK does not mandate any uniqueness requirements on Stream ids, but it is recommended that developers attempt to make the Stream IDs unique by appending an uuid.\nStream IDs can only be changed after an EOS is sent, and in FEI devices, an EOS is only sent when deallocating or disabling the tuner.\nAn EOS should only be sent on an externally commanded tuner disable and not one that is handled internally to the device. Therefore, if the device must temporarily disable output to tune, an EOS should not be sent.\n Connection ID In all REDHAWK BulkIO connections, there is a specific string ID for the connection. For FEI devices, the connection to the output port of the device must have a Connection ID, which can be assigned as described in Connect Wizard, that is equal to the Allocation ID of the tuner to be accessed. Because the Connection ID is equal to the Allocation ID, the output port can be constructed as a multi-out port.\nRF Flow ID RF Flow IDs are used to differentiate between RF input streams, similarly to how Stream IDs are used to differentiate between BulkIO streams. For FrontEnd devices, these RF Flow IDs are used to match allocation requests to specific RF sources.\nUnlike Allocation IDs and Stream ids, RF Flow IDs are often human readable. Typically, they describe specific inputs to a device or feed names. RF Flow IDs for a device can be set as a device property, which is set as part of the node configuration. System developers can create a node that sets the individual FrontEnd device with the RF Flow IDs that are appropriately set to the current state of the physical RF connections.\nDevice Group ID device Group ID is similar to RF Flow ID in that it is used as an additional ID to allow allocations against a specific pool of devices. In this case, each FEI device can have its Group ID set, and individual allocations can request specific Group ids. devices with the same Group ID are considered to be in the same group, and only devices that are part of that group allow those allocations. Group IDs are strings that are often human readable. A device typically has its Group IDs set as a property, so it can be configured as part of a node.\nTuner Allocation Overview FrontEnd tuners are allocated by calling the device’s allocateCapacity() method with a particular FrontEnd Allocation structure. The call acts as a request to the device for allocation of a tuner that meets the specifications in that structure. If the request is able to be met by that device, then the tuner is allocated, and True is returned by the allocateCapacity() call. If the tuner cannot be allocated, then an appropriate exception is thrown. Returns and exceptions are shown in Allocation Return Types.\nTwo different FrontEnd Allocation structures can be used. The Tuner Allocation structure is primarily used for allocating new tuners of an FEI device. The Listener Allocation structure is used for allocating listener tuners that piggyback on existing control tuners. Listener tuners are logical tuners that simply mirror the output of existing control tuners. Therefore, FrontEnd devices can keep track of how many consumers are attached to each of the tuner outputs and handle requests appropriately. The Tuner Allocation structure is described in Tuner Allocation Properties, and the Listener Allocation structure is described in Listener Allocation Properties.\nAllocation Return Types The values returned, and exceptions thrown, by the allocateCapacity():\nAllocation Return Types    Return Type Description Notes     True Tuner was successfully allocated. Returned if the tuner was successfully allocated. Indicates that the tuner has been added to the status structure, the underlying hardware/software has been set up, and the tuner is now enabled.   CF::Device::InvalidCapacity Capacity request was malformed. Indicates that there was an error in parsing the capacity (FrontEnd Allocation Structure) that was passed in. The error is typically the result of a missing Allocation ID or other critical field but can also indicate a duplicate Allocation ID request.   CF::Device::InvalidState Device is in an invalid state for allocation. Returned when the device is in an Error or Disabled state.   False Tuner was not successfully allocated. Indicates the device is unable to meet the request in the allocation structure.    Tuner Allocation Properties Each allocateCapacity() call passes in a single FrontEnd Tuner Allocation structure. If multiple tuners are allocated, each tuner needs an independent allocateCapacity() call. Each field in the allocation structure needs to be matched against the available tuners in the device. Each field must correctly match for the allocation to be successful. If any of the properties cannot be met, the allocation throws an exception.\nThe following table describes the tuner properties and how to handle requests.\nTuner Allocation Properties    Name Type Notes Description     tuner_type string Type of tuner requested. The tuner type must match exactly and cannot be a super set of the request (e.g., an RX_DIGITIZER is not a match for an RX request).   allocation_id string Used by the caller to reference the tuner uniquely. Reject any requests with an Allocation ID already in use with the InvalidCapacity exception.   center_frequency double Requested center frequency in Hz. It is up to the device developer to determine the error tolerance of the true tuned center frequency. For CHANNELIZER tuners only, this is the expected input frequency of the stream that is provided.   bandwidth double Requested Bandwidth in Hz. The minimum bandwidth that must be provided to allocate the channel. See tolerance for the upper bound of bandwidth. A value of zero indicates any bandwidth is acceptable.   bandwidth_tolerance double Allowable Percent above requested bandwidth. The acceptable amount of excess bandwidth used to allocate the channel. This amount is defined as a percentage of the requested band-width. For example, if a 1kHz bandwidth was required, and the tolerance was set to 50%, then any bandwidth between 1-1.5kHz is acceptable. For the CHANNELIZER only, this should be the expected bandwidth of the provided input stream.   sample_rate double Requested complex sample rate in Hz. The minimum sample rate that must be provided to allocate the channel expressed in terms of complex sample rate. Refer to the tolerance for the upper bound of sample rate. A value of zero indicates any sample rate is acceptable. The sample_rate value can be ignored for such devices as analog tuners, which do not provide digital (sampled) data. For the CHANNELIZER only, this is the expected sample rate of the provided input stream.   sample_rate_tolerance double Allowable percent above requested sample rate. The amount of excess sample rate that is acceptable to allocate the channel as a percentage of the requested sample rate.   device_control boolean Indicates if this tuner has modification control. Describes if the requested tuner has control over the tuner and can make changes to tuner parameters. Setting device_control to false indicates that the device should attempt to find an existing channel and add the allocated tuner as a listener. If no suitable tuners exist, the request fails. For CHANNELIZER tuners, device_control must always be set to true and, if not, an InvalidCapacity exception is thrown.   group_id string Unique ID that specifies a group of devices. Must match group_id on the device; otherwise, allocation fails. The matching must be explicit, but a blank string is typically used to indicate a default group.   rf_flow_id string Specifies a certain RF flow to allocate against. Must match rf_flow_id on the device input used; otherwise, allocation fails. A blank string indicates that no channel is requested.    After successfully matching the allocation properties, the FrontEnd device needs to perform a number of tasks prior to returning from the allocateCapacity() call. First, the actual hardware or software should then be allocated with the values requested. Then, the internal status properties need to be updated to show the new channel. Once the status is set, the allocateCapacity() call can return.\nAfter a successful allocation, the tuner is enabled and data is flowing though the device and out the output port. It is not required that the allocateCapacity() call return prior to the first data packet being pushed through the device.\nIn the event that a device has an RFInfo input port, the center frequency for allocation should be the true RF frequency of the signal even if the RFInfo port indicates that some frequency translation has occurred before input to the device. In this case, the tuner allocation frequency and status frequency will be different than the actual tuned frequency to which the hardware device was tuned. The center frequency and bandwidth of the RFInfo packet should be used to validate the requested center frequency. The requested center frequency should fit within the bandwidth of the incoming analog signal as described by the RFInfo packet. However, the requested bandwidth from the FEI allocation should be interpreted as the requested bandwidth of the receiver or receiver digitizer and can include bandwidth that is outside the bandwidth specified by the RFInfo packet.\nListener Allocation Properties There are two methods used to perform listener allocations. The first method is to use a standard FrontEnd Allocation Structure as shown in Tuner Allocation Properties with the control property set to False. Setting the control property to False causes the device to look for existing tuners that meet the required properties in the rest of the FrontEnd Allocation Structure and assign a new listener tuner to that master tuner. If no tuners already exist, the request fails.\nThe second way of allocating a listener tuner is by using a FrontEnd Listener Allocation structure in the allocateCapacity() call. Passing in this FrontEnd Listener Allocation structure causes the device to create a new listener tuner that is attached to the tuner with the Allocation ID given in the structure.\nFrontEnd Listener Allocation Structure    Name Type Description Notes     existing_allocation_id string Allocation ID for an existing allocation. The Allocation ID of the tuner to which the new listener should attach. The tuner can be either a control or listener.   listener_allocation_id string New Listener ID The Allocation ID of the new listener tuner. All typical Allocation ID requirements apply.    The requirements for tuner setup of a listener tuner are the same as those for a control tuner. The status structure must be updated, and the output must be enabled. These actions are expected to be performed prior to returning from allocateCapacity().\nTuner Deallocation Tuners are deallocated using the deallocateCapacity() call. There is no return from the deallocateCapacity() function, but exceptions are thrown if deallocation is unsuccessful. The only exceptions that can be thrown are InvalidCapacity, which indicates that the Allocation ID provided is not valid, or InvalidState, indicating the device is in an error state.\nThe deallocateCapacity() call can accept either a Tuner Allocation or a Listener Allocation structure as only the Allocation ID field is utilized. All other fields are ignored and have no impact on the deallocation. The concept is that the same allocation structure provided to allocateCapacity() can be sent to deallocateCapacity() to remove the tuner.\nTuners that are deallocated need to have their status entries removed, the underlying hardware/software disabled, and all output stopped. A final BulkIO packet containing an EOS SRI flag is sent prior to the return from the deallocateCapacity() call. More information on the BulkIO SRI information can be found in FrontEnd-specific Keywords. No more data from that tuner flows though the BulkIO port.\nAutomatic Listener Deallocation When a control tuner is deallocated, its attached listeners are expected to also be deallocated. Therefore, both status cleanup and EOS information flows over the BulkIO port.\nCommand and Control Command and Control of existing allocated tuners is performed through the Digital or Analog Tuner port on the FEI device. These commands allow external users to get and set specific settings for each of the tuners. Each FrontEnd Tuner device must have a DigitalTuner port named DigitalTuner_in (or AnalogTuner_in for an AnalogTuner port) that allows for command and control. All of the functions in the Tuner Control IDL need to be implemented even if only to report that the capability is not supported. Each of these IDL functions uses the Allocation ID to uniquely identify the tuners.\nTuner Control IDL The tuner control IDL describes two interfaces for control. The first is the AnalogTuner, which describes all of the functions common for Digital and Analog tuners. DigitalTuner inherits from AnalogTuner and adds setOutputSampleRate() / getOutputSampleRate() functionality. The functions and potential exceptions are described in the following tables.\nTuner Control Functions    Function Prototype Description     string getTunerType(in string id) Get the type of tuner (e.g., RX or DDC) associated with this Allocation ID.   boolean getTunerDeviceControl(in string id) Returns whether this Allocation ID has control (modification privileges) over the tuner.   string getTunerGroupId(in string id) Retrieves the group ID (may be empty) for this Allocation ID.   string getTunerRfFlowId(in string id) Retrieves the RF flow ID (may be empty) for this Allocation ID.   CF::Properties getTunerStatus(in string id) Key/Value pair of entire tuner status structure. Note: The return is a sequence of simple properties, not a single struct property.   void setTunerCenterFrequency(in string ID, in double freq) Set the current center frequency in Hz.   double getTunerCenterFrequency(in string id) Get the current center frequency in Hz.   void setTunerBandwidth(in string ID, in double bw) Set the current bandwidth in Hz.   double getTunerBandwidth(in string id) Get the current bandwidth in Hz.   void setTunerAgcEnable(in string ID, in boolean enable) Enable or disable the Auto Gain Control (AGC). True indicates that the AGC should be enabled.   boolean getTunerAgcEnable(in string id) Get the current status of AGC. True indicates enabled.   void setTunerGain(in string ID, in float gain) Set tuner gain in dB.   float getTunerGain(in string id) Get current tuner gain in dB.   void setTunerReferenceSource(in string ID, in long source) Set the tuner reference source. Zero is defined as internal and one is defined as external.   long getTunerReferenceSource(in string id) Get the current tuner reference source.   void setTunerEnable(in string ID, in boolean enable) Set the output enable state of the tuner. True indicates output is enabled.   boolean getTunerEnable(in string id) Get the current output enable state of the tuner. True indicates output is enabled.   void setTunerOutputSampleRate(in string ID, in double sr) Set the output sample rate in samples/sec.   double getTunerOutputSampleRate(in string id) Get the output sample rate in samples/sec.    Tuner Control Exceptions    Exception Description Notes     BadParameterException Parameter provided is invalid. Indicates the value provided is out of bounds for the capability of the device or that the value was invalid (e.g., a negative frequency).   NotSupportedException Capability is not supported. Indicates the tuner does not support the setting (or getting) of this capability.   FrontendException Generic FrontEnd exception. Indicates there is a FrontEnd issue preventing the command, often because the Allocation ID does not match any currently allocated tuners.    Data Flow By default, FEI devices can provide BulkIO data. Data flow into FEI devices is typically constrained to digital-IF data for CHANNELIZER tuners. Digital-IF data is consumed regardless of Stream ID and it is the responsibility of the CHANNELIZER allocator to make the connection from the source into the FrontEnd device.\nOutput data flow is managed by the FEI device and multiple tuners can have output through a single BulkIO port. In general, there should only be one BulkIO port for each data type (int, float, etc.). All streams of any data type must pass through this BulkIO port. The allocator of each tuner is responsible for connecting to the device output port. The Connection ID of the BulkIO connection must match the Allocation ID of the tuner for data to flow through that connection. Thus, the output port must be a multi-out port, one that only passes data packets to specific connections rather than all connections.\nMulti-Output Multi-out ports are a specific implementation of a BulkIO output port. The defining characteristic is that multi-out ports are selective in which connection each piece of data is sent to rather than having each piece of data broadcast to every connection. This behavior is typically implemented by creating a custom BulkIO port implementation that handles data routing for each connection.\nConstructing the custom port is easiest if the internal pushPacket() call does not need to be modified, which is why Stream ID is the easiest field on which to differentiate. As long as the Stream ID is equal to the Allocation ID, the Stream ID can simply be matched to the Connection ID to make a multi-out port. Hence, a REDHAWK best practice is to maintain a one-to-one relationship between Stream and Allocation ids.\nIf the IDs are the same, there are only two required changes to the standard port implementation. The first change is that as the port iterates over the list of connections, a simple check needs to be performed to only do the remote pushPacket() or pushSRI() call on connections where the Connection ID matches the Allocation ID associated with the current packet. The second change is that the internal storage of previous SRI states needs to become a vector rather than a single element so that a new connection gets the correct previous SRI for its stream rather than just the most recent stream that has had data sent.\nSRI and Keywords FrontEnd devices use both the basic BulkIO SRI fields and the Keywords field for additional items. All standard SRI fields are filled out as appropriate in accordance with the existing BulkIO IDL descriptions.\nFrontEnd-specific Keywords    Name Type Description Notes     COL_RF double Collector center frequency in Hz. Center frequency of the collector, which is typically thought of as the center frequency of the wideband receiver used to generate the IF data. In the case of a DDC tuner, the value of COL_RF is the center frequency of the input to the CHANNELIZER.   CHAN_RF double Channel center frequency in Hz. The center frequency of the stream. The value of CHAN_RF is equal to the COL_RF for RX and RX_DIGITIZER tuners but should still be included.   FRONTEND::BANDWIDTH double Effective bandwidth in Hz. The effective bandwidth of the stream.   FRONTEND::RF_FLOW_ID string RF Flow ID of data. Always include even if the RF Flow ID is blank.   FRONTEND::DEVICE_ID string The ID of the device. Component ref ID, which allows downstream users to gain a reference to the device that created the data.    Status All FEI Tuner devices must report the status of each tuner as an entry in the frontend_tuner_status property. The frontend_tuner_status property is a struct sequence where each element represents a single tuner as a structure containing all of the required status elements and a subset of the optional status elements. The frontend_tuner_status property should contain entries for both allocated and un-allocated tuners so users can see additional available tuners for allocation.\nStatus Elements The frontend_tuner_status property consists of a sequence of frontend_tuner_status_struct structures. Each of these structures must contain all of the required elements listed below and may contain any number of the optional elements listed below. Additional elements are permitted in the structures if a suitable element is not already defined.\nRequired Status Elements The table below describes the required status elements for each tuner of an FEI Tuner device. In some cases, null, zero, or blank values may be used to indicate that a value is not set for this device, but each of these properties must be in the status structure.\nRequired Status Elements of an FEI Tuner Device    Name Type Description Notes     tuner_type string Type description of tuner. Defined in Types of Tuners   allocation_id_csv string Comma separated list of current Allocation ids. Contains a list of both control and listener Allocation ids. In effect, the length of the allocation_id_csv list is the number of independent consumers of the tuner output. The control Allocation ID must be the first in the comma separated list.   center_frequency double Current center frequency in Hz. Actual tuned frequency rather than the desired frequency (if those values are not the same).   bandwidth double Current bandwidth in Hz Actual bandwidth rather than the desired bandwidth (if those values are not the same).   sample_rate double Current sample rate in Hz. Actual sample rate rather than the desired sample rate (if those values are not the same). Can be ignored for such devices as analog tuners   group_id string Unique ID that specifies a group of devices. Actual Group ID, regardless whether it was requested in the tuner allocation or not.   rf_flow_id string Specifies a certain RF flow to allocate against. Actual RF Flow ID, regardless whether it was requested in the tuner allocation or not.   enabled boolean Indicates if tuner is enabled. Enabled refers to the output state not any internal hardware/software state.    Optional Status Elements The table below describes the optional status elements for each tuner of an FEI Tuner device. In some cases, null, zero, or blank values may be used to indicate that a value is not set for an individual Tuner, but all Tuners of the same device must have the same set of properties in their status structure.\n   Name Type Description Notes     bandwidth_tolerance double Allowable percentage over requested bandwidth. Tolerance provided by the requester.   sample_rate_tolerance double Allowable percentage over requested sample rate. Tolerance provided by the requester.   complex boolean Indicates if the output data is complex. True for complex; False for real.   gain double Current gain in dB. N/A   agc boolean Indicates if the tuner has Automatic Gain Control enabled. Even if AGC is enabled, the device still reports the current gain in the gain property.   valid boolean Indicates if the tuner is in a valid state. When the tuner is of type ddc, False indicates that the ddc channel is no longer able to tune to the appropriate frequency because the CHANNELIZER it is attached to has been moved.   available_frequency string Valid potential center frequencies for the tuner in Hz. In range(XX-YY) or csv (X,Y,Z) format.   available_bandwidth string Valid potential bandwidth for the tuner in Hz. In range(XX-YY) or csv (X,Y,Z) format.   available_gain string Valid potential gain for the tuner in dB. In range(XX-YY) or csv (X,Y,Z) format.   available_sample_rate string Valid potential sample rates for the tuner. In range(XX-YY) or csv (X,Y,Z) format.   reference_source long Indicates internal vs external reference source. 0 = internal reference; 1 = external reference.   output_format string Indicates current output data format. Uses the SDDS digraph format.   output_multicast string Multicast address for SDDS output. Multicast address in dotted quad notation (e.g., \u0026ldquo;192.168.0.1\u0026rdquo;).   output_vlan long vlan number for SDDS output. If there is no vlan used, indicate that with a zero.   output_port long port number for SDDS output. N/A   decimation long Current decimation of tuner. Decimation values for DDC tuners. Defined as the ratio of input sample rate to output sample rate regardless of data format.   tuner_number short Physical tuner id. Tuner ID number within device. May represent physical tuner ordering or virtual ordering in software.    RFSource Interface FrontEnd devices that have RFInfo output ports and that flow RF metadata to other FrontEnd devices also have an RFSource interface. Such devices include antennas and RF distribution/switches. The RFSource interface is used to determine the currently selected RF Flow and all possible RF flows that a device can provide. The interface has two attributes:\n RFInfoPktSequence available_rf_inputs - A list of all possible RF inputs to which this source could switch.\n RFInfoPkt current_rf_input - The currently selected source that is being output.\n  Typical consumers of the RFInfo can read these values to know if other RF flows are possible. A device with the RFSource interface may get the information about its RF flows in multiple ways. The device may get the information through a non-REDHAWK interface to the actual switch, it may be stored as a configuration item or a property, or it may be set through the RFSource interface by another entity in the system with knowledge of the current RF configuration. If an external entity has knowledge of the RF configuration and sets the two attributes on a device, the device should push out an updated RFInfoPacket to any connected users.\nThe allocateCapacity() interface of RFSource devices is used to request a particular RF flow. Allocation is performed by setting the FRONTEND::RFSource::rf_flow_id allocation property equal to the rf_flow_id of the RF flow requested.\nRFSource Request Property    Name Type Description Notes     FRONTEND::RFSource::rf_flow_id string Requested rf_flow_id. Will return true if source can satisfy the request.    If the requested RF flow can be switched to the output, the RFSource device will make the switch and the allocateCapacity() call will return true. If the device cannot provide the RF flow or has already been allocated to another RF flow, the allocateCapacity() call will return false. If the device is already allocated to the requested RF flow, the allocateCapacity() call will return true and increment the count of the total number of allocations received for that rf_flow_id. Once allocated, the device will not switch RF flows until the number of deallocateCapacity() calls received is equal to the total number of allocations for that rf_flow_id. The total number of allocations for the selected RF flow is stored in a readonly property named allocationCount.\nallocationCount Property    Name Type Description Notes     allocationCount long Total number of successful allocations against the current output. Always \u0026gt;0 if the device is allocated.    Even when the allocationCount is zero and no switch allocations are allocated, the current_rf_input and the RFInfoPacket should reflect the current state of the RF Flow. For example, even without allocation, if real RF data is still being output, the status should reflect that. If no data is being output, then the current_rf_input attribute should be empty. Setting the current_rf_input attribute does not imply allocation or a request to switch an input. It assumes that this would only be set if the input had already switched to that new value from outside of the device. If the device allocationCount is not zero, it is not recommended to change the switch configuration and thus set the current_rf_input.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/java-version/",
	"title": "Java Version",
	"tags": [],
	"description": "",
	"content": "The default supported version for the Java language for Java components is 1.7. The Java version for any specific component can be changed by changing the argument to the RH_PROG_JAVAC macro in the component’s configure.ac file.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/misc/",
	"title": "Miscellaneous FrontEnd Tuner Library Implementation Details",
	"tags": [],
	"description": "",
	"content": " The tolerances specified in an allocation request are checked after deviceSetTuning returns True using the frontend_tuner_status values, and then deallocates if the tolerances are not met. The allocation fails without attempting the allocation on additional tuner channels that may be able to satisfy the request. Optionally, the developer can check the tolerances within the deviceSetTuning function and return False without configuring the tuner to indicate that the tuner could not meet the request. At this point, the allocateCapacity function will continue attempting to allocate using the next tuner channel that is available.\n An allocation request can specify zero (0) for either the bandwidth or sample rate or both if a specific value is not required. (This is the Any Value option.) The result of a successful allocation will be the lowest bandwidth or sample rate that the device can provide while meeting the other requirements in the allocation request.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/plotting-data/",
	"title": "Plotting Data",
	"tags": [],
	"description": "",
	"content": " The Sandbox includes tools for plotting BulkIO data from components and devices. The built-in matplotlib plots support visualizing BulkIO data in the time and frequency domains, as well as constellations. The plots are fully integrated into the Sandbox, support all numeric BulkIO data types, and may be used as the provides side for component connections.\nThe following example plots the data from a component as a line plot:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; my_comp.connect(plot) \u0026gt;\u0026gt;\u0026gt; sb.start() Before displaying data, plots must be started either by calling their start() method or by calling sb.start(). If the Sandbox is already started when the plot is created, then the plot’s initial state is started.\nFrame Size By default, all the plots display 1024 input samples at a time. To override this default setting, set the frame size by using the frameSize argument:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot(frameSize=8192) Larger frame sizes allow the plot to keep up with a higher rate of input data.\n FFT Size Plots that display the psd of input data use a default fft size of 1024 points. To increase the frequency resolution, set the nfft argument to a larger fft size:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePSD(nfft=8192) The frame size defaults to the fft size, but can be overridden with frameSize. It may be smaller than the fft size; however, it cannot exceed the fft size. If the frame size is smaller than the fft size, the data is zero-padded.\nLine Plots Line plots display signal or psd data as a series of colored line segments, similar to an oscilloscope display. Each input signal is represented by a different line color. A new trace is created for each connect() call, and traces may be added and removed dynamically.\nAll input signals must have the same sample rate or the sources may get out of sync.\n The X range is based on the frame size and input SRI. By default, the Y range is determined automatically per-frame based on the input data. A fixed minimum and maximum may be set independently with the ymin and ymax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot.ymin, plot.ymax = (-2.5, 2.5) Automatic scaling can be re-enabled by setting ymin or ymax to None.\n\u0026gt;\u0026gt;\u0026gt; plot.ymin = None The LinePlot plot displays one or more input signals. Time and value are displayed on the X and Y axes, respectively.\nThe LinePSD plot displays the psd of one or more input signals. The frequency is represented by the X axis, while the magnitude is represented by the Y axis using a logarithmic scale.\nRaster Plots Raster plots display signal or psd data as a two-dimensional image. Each horizontal line represents one frame of data. This plot type is most useful for visualizing an input signal in the frequency domain over time.\nAll raster plots allow configuration of the image size at creation time. The default image size is 1024x1024; height and width can be overridden with the imageHeight and imageWidth arguments:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.RasterPSD(imageHeight=512, imageWidth=768) The plot X and Y ranges are fixed based on the fft or frame size (X) and image height (Y). The Z range (magnitude) can be set at creation time or changed dynamically with the zmin and zmax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.RasterPSD(zmin=1e-12) \u0026gt;\u0026gt;\u0026gt; plot.zmax = 1e4 The RasterPSD plot displays the PSD of an input signal as a falling raster. Time and frequency are displayed on the Y and X axes, respectively. The magnitude of a given frequency bin is represented by a logarithmic colormap. The default Z (magnitude) range is [1e-18, 1].\nThe RasterPlot plot displays a falling raster of an input signal. Inter-frame time is displayed on the Y axis, while intra-frame time is displayed on the X axis. The sample value of a given point is represented by a linear colormap. The default Z (magnitude) range is [-1, 1].\nX/Y Plot The XYPlot plot displays a series of complex samples as points on a two-dimensional plane. The real and imaginary components of a given sample are mapped to the point’s X and Y coordinates. This plot type is designed for viewing signal constellations, though it may be useful for other purposes.\nBy default, the plot is centered at the origin, and both the X and Y ranges are [-1, 1]. The minimum and maximum X and Y values may be set at creation time or changed dynamically with any combination of the xmin, xmax, ymin and ymax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.XYPlot(xmin=-2.0, xmax=2.0) \u0026gt;\u0026gt;\u0026gt; plot.ymin, plot.ymax = -2.0, 2.0"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/port-statistics/",
	"title": "Port Statistics",
	"tags": [],
	"description": "",
	"content": " All BulkIO ports contain a read only attribute called statistics. The statistics attribute is of type BULKIO::PortStatistics, and it contains information regarding the performance of the port. The table below contains a description of a statistics structure:\nFields in Returned Port Statistics    Name Type Description     portName string Name of this port   elementsPerSecond float A moving average describing the rate at which elements are arriving.   bitsPerSecond float This is the same as elementsPerSecond * bits per elements.   callsPerSecond float Number of pushPacket() calls per second.   streamIDs CF::StringSequence List of all stream IDs where a pushSRI() has occurred but no eos has been received.   averageQueueDepth float Moving average calculation of the percentage queue depth.   timeSinceLastCall float The elapsed time, in seconds, since the last packet was transferred via a pushPacket() call   keywords sequence \u0026lt;CF::DataType\u0026gt; Additional statistics information provided by the port.    The provides-side port contains a single PortStatistics structure. The uses-side port contains a sequence of PortStatistics structures; each one associated with a single connection.\nAn interesting exercise is to create components that generate and consume data in the three languages supported by REDHAWK. The data generator and consumer generate/consume data as fast as possible. The statistics data structure can provide metrics regarding data transfer rates, average latency, and other relevant data. Shifting the transfer length (by changing the size of the sequence in the pushPacket() call) and seeing its effects on the performance of the connection is also instructive.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/redhawk-plot-view/",
	"title": "REDHAWK Plot View",
	"tags": [],
	"description": "",
	"content": " Plot View When a user plots a port, the REDHAWK Plot view displays a NeXtMidas Plot.\nWithin the plot, users can manipulate the plot as follows:\n Zoom In: Left-click and drag to form a box to zoom in on a portion of the plot. Zoom Out: Right-click to zoom out a single level.  The REDHAWK IDE contains the following controls for interacting with the active plot:\n Change Plot Mode: Changes the mode of the current plot. The plot options include:\n Auto Imaginary Magnitude Phase Real Real and Imaginary Real vs Imaginary 10 Log 20 Log  Change FFT Size: Changes the FFT size.\n Change Plot Type: Changes the plot type. The types include:\n Dot Line Point Raster Change Frame Size: Changes the frame size.  The red icon next to the Change Plot type arrow is a toggle button that when clicked, changes the active plot to display either the Line or the Raster plot.\n  The View Menu contains the following options:\nView Menu  New Plot View: Displays an identical plot view. This option is useful to view both the Line and Raster plots of the same data simultaneously. Plot Type: Changes the plot type. Plot types include: Dot, Line, Point and Raster. Display SRI: Displays the SRI View. Settings\u0026hellip;: Displays the Plot Settings Dialog   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/device-manager/",
	"title": "The Device Manager",
	"tags": [],
	"description": "",
	"content": " The Device Manager interface is used to manage a set of logical devices, services and a File System. The Device Manager is responsible for parsing the node’s DCD XML in order to fork processes for all devices and services in the node. Each process gets passed a list of command-line character strings as executable parameters that are node-specific configuration variables read from the DCD file.\nOnce a child process has been forked, its reference is added to a pending list in the Device Manager, while the child process is initialized and configured (possibly with overloaded property values). After that, it registers itself with the Device Manager, moving its reference from the pending list into a registered list. These lists allow the Device Manager to have knowledge of the status of all devices and services contained within its node. Once all children have been launched, instantiated, and configured, the Device Manager connects the devices as described by the DCD file.\nThe Device Manager also responds to signals from any of its child processes. Upon exit of a child, the Device Manager cleans up the bookkeeping by removing any references to the process from the pending or registered lists and unbinding its name from the Naming Service.\nThe Device Manager also has a signal handler for SIGINT, SIGQUIT and SIGTERM that triggers a shutdown of the node. The node shutdown process unregisters and calls releaseObject on all services and devices, kills off all of the child processes, and unbinds any remaining names, including itself, from the Naming Service.\nLaunching a Device Manager from the Command Line To launch a device from the command line, a Domain Manager must be up and running.\nnodeBooter -d /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DeviceManager - Starting Device Manager with /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DeviceManager_impl - Connecting to Domain Manager REDHAWK_DEV/REDHAWK_DEV INFO:DeviceManager - Starting ORB! INFO:DCE:9d9bcc38-d654-43b1-8b74-1dc024318b6f:Registering Device INFO:DeviceManager_impl - Registering device GPP_localhost_localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Initializing device GPP_localhost_localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Registering device GPP_localhost_localdomain on Domain Manager DCD File The DCD file is an XML file that contains the necessary information to configure a node, which is a specific instance of a Device Manager, as well as all devices and services associated with that Device Manager instance. The DCD file contains information about the devices and services associated with a Device Manager, where to look for a Domain Manager, and other configuration information for devices and services. The file is named: DeviceManager.dcd.xml and is located at: $SDRROOT/dev/nodes/NODE_NAME.\nInformation that is covered in this file includes:\n Device Manager name Device Manager id References to required devices SPD files References to required services SPD files The Domain Manager’s Naming Service name Any required device connections Start order of the devices/services  Nodes Nodes are the collection of devices, services, and connections associated with a single Device Manager instance. There is always only one Device Manager per node. Nodes are deployed on a domain to give the applications the ability to communicate with the systems hardware. Upon creation of an application, the Application Factory attempts to place each required component on a device that is deployed in a node.\nDevices In REDHAWK, devices are specialized components that perform command and control of hardware. They are proxies that are able to run in the domain and provide a single point to interact with one or more pieces of physical hardware.\nDevices communicate with various pieces of hardware in order to keep track of their capacities. When waveforms are deployed and the hardware resources are allocated, the devices keep track of the amount of any specific resource that was used, and what is still currently available. This is a important because it keeps components from attempting to over-allocate on any one piece of hardware.\nUsing Valgrind to Debug Devices The Device Manager supports launching devices using Valgrind, an open source tool that helps detect memory errors and leaks.\nThe VALGRIND environment variable controls this behavior:\n If VALGRIND is not set, devices launch as usual. If VALGRIND is set but has no value, the Device Manager searches the path for valgrind. If VALGRIND has a value, it is assumed to be the full path to the valgrind executable.  Valgrind log files are written to the device’s cache directory (e.g., $SDRROOT/dev/.MyNode/MyDevice). The log file name follows the pattern valgrind.\u0026lt;PID\u0026gt;.log, where PID is the process ID of the device.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/burstio/",
	"title": "BurstIO",
	"tags": [],
	"description": "",
	"content": "For those applications that require small, and possibly non-contiguous, chunks (or bursts) of data with frequently-varying metadata, BurstIO provides the data transfer containers and interfaces to meet those requirements. This interface only supports the transfer of data vectors: float, double, octet (int8/uint8), short (int16), ushort (uint16), long (int32), ulong (uint32), longlong (int64), and ulonglong(uint64). Similar to BulkIO, BurstIO provides Burst Signal Related Information (SRI), and a Precision Time stamp but provides this information in-band with each data burst. With the increased overhead requirement for metadata, BurstIO can achieve its highest throughput by grouping multiple bursts into a single transfer, either programmatically or through configurable policy settings, to try and maximize efficiency and limit latency.\n Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/debugging/",
	"title": "Debugging REDHAWK Components and Devices with Eclipse",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE uses the debugging capabilities from the JDT, CDT, PyDev, and REDHAWK Sandbox. The debugger provides tools to detect and diagnose errors in an application during execution. The debugger allows control of execution of the program by setting breakpoints, suspending launched programs, stepping through source code, and examining the contents of variables.\nFor more details on debugging concepts, consult the Eclipse documentation at http://help.eclipse.org/ or view the embedded documentation from within the REDHAWK IDE by selecting Help \u0026gt; Help Contents.\nIn the Eclipse documentation browser refer to the following sections for additional debugging concepts and details:\n Java development user guide \u0026gt; Concepts \u0026gt; Debugger Java development user guide \u0026gt; Concepts \u0026gt; Breakpoints Java development user guide \u0026gt; Tasks \u0026gt; Running and Debugging C/C++ Development User Guide \u0026gt; Concepts \u0026gt; Debug C/C++ Development User Guide \u0026gt; Tasks \u0026gt; Running and debugging projects \u0026gt; Debugging  Running Unit Tests Component and device projects created with the IDE have a tests folder that contains a functional example test case. This test case checks that the resource can be started, stopped, and released without error.\nTo run the unit test case:\n From the Project Explorer View, expand the project folder then the tests folder to display the existing test cases. Right-click the test script, select Run As \u0026gt; Python unit-test. Check the test results from the Console and PyUnit views.  Running a Component or Device from the REDHAWK Sandbox The REDHAWK Sandbox provides an environment to run components and devices without the need for a domain or device manager. When running a component or device from the Sandbox, it is started as its own forked process. A new Console View is created for logging and error messages.\nTo launch a REDHAWK component or device in the Sandbox:\n Open the project’s spd.xml file. From the Overview tab, in the Testing section, click Launch a local component. From the REDHAWK Explorer View, expand the Sandbox. To view a running component, expand or double click the Chalkboard. To view a running device, expand the Device Manger. To display the corresponding console, right-click the component or device, select Show Console.  Releasing a Component/Device from the REDHAWK Sandbox Releasing a resource invokes a graceful shutdown, which follows the object lifecycle sequence. Release makes a call to the resource’s releaseObject() method to initiate the sequence. There are two ways to release a component using the IDE and one to release a device:\n Releasing using REDHAWK Explorer View:\n In the REDHAWK Explorer View, expand Sandbox \u0026gt; Chalkboard to display the running component or Sandbox \u0026gt; Device Manager to display a running device. Right-click the component/device, select Release.  Releasing using Chalkboard Diagram:\n In the REDHAWK Explorer View, expand the Sandbox, double-click Chalkboard. In the Chalkboard Diagram, right-click the REDHAWK component, select Release.   Terminating a Component from the REDHAWK Sandbox Sometimes a REDHAWK component fails to respond to input. In these cases the component may need to be terminated. Terminate kills the processes of the resource.\nTo terminate a component:\n Terminating using REDHAWK Explorer:\n In the REDHAWK Explorer View, expand the Sandbox \u0026gt; Chalkboard. Right-click the REDHAWK component, select Terminate.  Terminating using the Chalkboard:\n In the REDHAWK Explorer View, expand the Sandbox, double-click Chalkboard. In the Chalkboard Diagram, right-click the REDHAWK component, select Terminate.  Terminating using the Console View:\n In the Console View, click the Display Selected Console drop down. Select the launched REDHAWK component from the drop-down list to switch to its console. Click the Terminate icon, indicated by a red square.   Using the Debugger with the Sandbox The REDHAWK IDE provides an infrastructure-free way to use, test, and debug a REDHAWK components. This section describes how to use the debugging features of the IDE.\nSetting Breakpoints in Component source code A breakpoint suspends the execution of a program at the location where the breakpoint is set. Breakpoints can be enabled and disabled via the Breakpoints View or from the source code editor.\nTo set a breakpoint from the source code editor:\n Open the source code file. Choose a line to set the breakpoint. Directly to the left of the line of code, in the vertical marker bar, perform one of the following actions:  Right-click, select Add Breakpoint or Toggle Breakpoint. Double-click in the marker bar.  A small solid blue (for C/C++/Java code) or green (for Python code) circle marks the breakpoint location.  Launching a Component in the REDHAWK Sandbox in Debug Mode To use the REDHAWK IDE’s debugger, a REDHAWK component can be launched in the Sandbox in debug mode.\nA component can be launched in debug mode in several ways:\n From the SPD file Editor:\n Open the project’s spd.xml file. From the Overview tab of the SoftPkg Editor, in the Testing section, click Debug a component in the Sandbox. The REDHAWK component is now launched in the Sandbox in debug mode.  From the Project Explorer:\n In the Project Explorer View, expand the project. Right-click project’s spd.xml file and select Debug As \u0026gt; 1 Launch component in Sandbox. The REDHAWK component is now launched in the Sandbox in debug mode.   There are two ways to confirm that the REDHAWK component has been launched in debug mode:\n From the Chalkboard Diagram, there is a small bug icon at the top right corner of the REDHAWK component. From the REDHAWK Explorer View, expand the Sandbox \u0026gt; Chalkboard and a \u0026lt;DEBUGGING\u0026gt; decorator is displayed to the right of the REDHAWK component.  The debugger can switch between Python, C++, and Java while debugging. The REDHAWK IDE can also launch other components in the Sandbox to interact with components in debug mode.\nNote that there are three separate debuggers for C++, Python, and Java. They all support the basic debugging capabilities such as setting breakpoints, stepping through executing code, and viewing variables. However, some debuggers have additional features that are not available to the others. For example, the Java debugger has the ability to hot swap code as it is executing.\nIf there are breakpoints set and triggered, a Confirm Perspective Switch dialog prompts the user to open the Debug perspective. Clicking Yes rearranges the workbench so it is geared towards debugging source code.\nThe Debug perspective displays these additional views:\n Debug View: The Debug View displays the stack frame for the suspended threads in debug mode. Each thread in the program appears as a node in the tree. It displays the process for each target that is running. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details. Variables View: The Variables View displays information about the variables associated with the stack frame selected in the Debug View. New values can be assigned to variables while stepping through the source code. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details. Breakpoints View: The Breakpoints View lists all the breakpoints currently set in the workspace. Double-click a breakpoint to display its location in the editor. Breakpoints can be enabled, disabled, deleted, created, grouped by working set, triggered by a user supplied hit count, triggered only in certain conditions, or triggered by exceptions. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/bulkio/examples/",
	"title": "Examples",
	"tags": [],
	"description": "",
	"content": " These two examples illustrate high-speed data exchange between two C++ components and basic data manipulation through the Sandbox.\nHigh-speed data In this example, two C++ components are created: a source and a sink. We will then deploy these components through the Sandbox and evaluate the statistics of the data transfer between them.\n Create a C++ component called source with a uses port called output of type dataShort. Add a simple property with ID xfer_length, type ulong, and default value of 100000. Generate the component code.\n Open the file source.h and add the following members to the source_i class:\nstd::vector\u0026lt;short\u0026gt; data; bulkio::OutShortStream stream; Open the file source.cpp and edit it in the following ways:\n In the source_i constructor:\ndata.resize(0); In serviceFunction() comment-out the LOG_DEBUG statement and add the following lines:\nif (data.size() != this-\u0026gt;xfer_length) { data.resize(xfer_length); } if (!stream) { stream = output-\u0026gt;createStream(\u0026#34;sample\u0026#34;); } BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); stream.write(data,tstamp); return NORMAL;  Compile the component source and install it on Target SDR.\n Create a C++ component called sink with a provides port called input of type dataShort. Generate the component code.\n Open the file sink.cpp and edit it in the following ways:\n In serviceFunction(), comment-out the LOG_DEBUG statement\n Add the following lines:\nbulkio::InShortStream stream = input-\u0026gt;getCurrentStream(); if (!stream) { return NOOP; } bulkio::ShortDataBlock block = stream.read(); if (!block) { return NOOP; } return NORMAL;  Compile the component sink and install it on Target SDR.\n Start a Python session in a command line terminal and run the following commands:\nfrom ossie.utils import sb source = sb.launch(\u0026#34;source\u0026#34;) sink = sb.launch(\u0026#34;sink\u0026#34;) source.connect(sink) sb.start() print source._ports[0]._get_statistics()[0].statistics  The output of the print statement is an instance of the PortStatistics structure in BulkIO. This structure contains the statistics gathered from this connection. A measure of data rate is bits per second.\nTo display the number of Gigabits per second, run the following command:\nprint source._ports[0]._get_statistics()[0].statistics.bitsPerSecond/1e9 The resulting value is the measured data transfer rate between the two components. The current xfer_length property can be viewed by typing the following:\nsource.xfer_length The default value is 100000. Update the property to 200000 by running the following command:\nsource.xfer_length = 200000 Check the new data rate by repeating the call to _get_statistics(). The resulting data rate is now different.\nOctet Ports Octets are unsigned 8-bit units of data. In Java and C++, these map easily. However, that is not the case in Python, which treats a sequence of characters as a string. The following is an example of pushing Octet data out of a dataOctet port:\nimport numpy outputData = [1,2,3,4,5] outputDataAsString = numpy.array(outputData, numpy.uint8).tostring() self.port_output.pushPacket(outputDataAsString, T, EOS, streamID) Data manipulation In this example, a Python component is created that takes vectors of floats as inputs, multiplies the vector by some arbitrary number, and then outputs the resulting vector. This example demonstrates some basic data manipulation as well as the interaction between the Python environment and the running component.\n Create a Python component called mult with a provides port called input of type dataFloat and a uses port called output of type dataFloat. Add a simple property with ID factor, type float, and default value of 1. Generate the component code.\n Open the file mult.py and add the following lines:\ndata, T, EOS, streamID, sri, sriChanged, inputQueueFlushed = self.port_input.getPacket() if data == None: return NOOP outData = [] for value in data: outData.append(value*self.factor) if sriChanged: self.port_output.pushSRI(sri) self.port_output.pushPacket(outData, T, EOS, streamID) return NORMAL Save the project and drag the mult project to REDHAWK Explorer \u0026gt; Target SDR.\n Start a Python session in a command line terminal and run the following commands:\nfrom ossie.utils import sb mult = sb.launch(\u0026#34;mult\u0026#34;) source = sb.DataSource(dataFormat=\u0026#34;float\u0026#34;) sink = sb.DataSink() source.connect(mult) mult.connect(sink) sb.start() source.push([1,2,3,4,5]) sink.getData() Output:\n[1.0, 2.0, 3.0, 4.0, 5.0] The multiplication factor can be changed while the Sandbox is up.\nmult.factor = 2 source.push([1,2,3,4,5]) sink.getData() Output:\n[2.0, 4.0, 6.0, 8.0, 10.0]  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/getting-error-condition-details/",
	"title": "Getting Details About Error Conditions",
	"tags": [],
	"description": "",
	"content": " If an error condition occurs within the Domain Manager which prevents a component, device, Domain Manager, or Device Manager from running correctly, the object’s representation in the REDHAWK Explorer is marked with a decorator in the lower left corner. Mouse hovering over the item’s icon provides a short description of the issue; however, if more than one problem has occurred, the hover text reads “Multiple Problems exist with this item”.\nMouse Hovering Over Error Decorator More detail about an error can be found within the properties view of the item.\n To view the details about an error condition:\n With the item selected, select or open the Properties View.\n From the Properties View, select the Advanced tab\n Select the status row. This causes the Details button to appear.\n Click Details to bring up a detailed dialog of the current error conditions.\n  Error Event Details "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/managing-defining-properties/",
	"title": "Managing and Defining Properties",
	"tags": [],
	"description": "",
	"content": " Properties are defined by their structure, kind, and type. The four different property structures include:\n simple - single value such as 1.0, or “a string\u0026rdquo; simple sequence - list/array of zero or more simples such as [1, 2, 3], or [“first\u0026rdquo;, “second\u0026rdquo;] struct - groups several simples and simple sequences together struct sequence - list/array of zero or more instances of a struct  Three commonly used kinds of properties in REDHAWK include:\n property - denotes properties that are used for configuration and status allocation - expresses requirements that will be satisfied by a REDHAWK device message - used only with structs and indicates that the struct will be used as an event message within REDHAWK  The property’s type corresponds with basic programming language primitive types such as floats, long integers, booleans, etc. Additionally, numeric types can be complex.\nThrough the use of generated code and the REDHAWK libraries, manipulation of properties uses fundamental types provided by C++, Python, or Java, as seen in Properties. For example, a simple sequence, complex-float property is manipulated via a std::vector\u0026lt; std::complex\u0026lt;float\u0026gt; \u0026gt; variable in C++ and a list of Python complex objects in Python. Generated component code provides a class data field representing each property for that component.\nThe primitive data types supported for simple and simple sequence properties are: boolean, octet, float, double, short, ushort, long, longlong, ulong, ulonglong, string, objref, char, and utctime. The utctime type is used to describe time and can be used to synchronize property change events and queries on the component or device. To set a default value for a time as a property, use a string of the form \u0026ldquo;YYYY:MM:DD::hh:mm:ss.sss\u0026rdquo;. Where YYYY is the year, MM is the month, DD is the day, hh is the hour (0-23), mm is the minutes, and ss.sss is the fractional seconds\u0026rdquo;.\nIn some cases, it is desirable for the utctime property to be initialized to the current time. To do so, the default value (in either the component’s default property value or as an overload at the waveform level) is set to \u0026ldquo;now\u0026rdquo;, which is the time when the component is deployed. The string \u0026ldquo;now\u0026rdquo; can also be used in the Python Sandbox to set the utctime property’s value to the current time. Inside the component code, helpers are available to set the utctime property value to the current time; for example, in C++, the following code sets the property to now:\nmy_prop = redhawk::time::utils::now(); The following primitive data types can be marked as complex values: boolean, octet, float, double, short, ushort, long, longlong, ulong, and ulonglong.\nEach component implements the CF::PropertySet interface, which provides remote access to the component’s properties through the query() and configure() methods. The query() method provides a means for reading a component’s current property settings and the configure() method provides a means for setting a component’s property values. Properties identified in these methods will use the property identifier value to resolve identifier access.\nProperties can be readonly, writeonly, or readwrite. properties with read privileges can only be accessed using the query() method and properties with write privileges can only be set using the configure() method.\nThe REDHAWK library base classes provide a complete implementation of configure(), with the creation of specific properties handled per component by the generated base classes. Beyond the basic updating of local values, the standard configure() implementation provides:\n Thread-safe updates via mutual exclusion Automatic conversion of numeric types Notification on changes to property values External reporting of changes via events Exception throwing for invalid input  Because of these enhancements, developers are strongly discouraged from overloading either the query() or configure() methods.\nProperty ID Properties are identified by ID and name. The ID must be unique to the scope of the component or device. This uniqueness applies to all properties, including the members of struct and struct sequence properties. Therefore, if two different struct properties in the same component each have a member with the name abc, both members cannot use the ID abc.\nTo eliminate ID conflicts, REDHAWK provides a naming convention that allows for multiple struct properties to use the same member names without creating ID conflicts. For members of a struct, the ID is created by combining the name of the member and the ID of the struct. For example, if struct property foo has a simple member bar, the member would have the name bar and ID foo::bar. The naming convention also applies to struct sequence properties as well.\nProperty Name The property name, if provided, is used for member variables in generated code and for display within the IDE. If not provided, the ID is used instead.\nProperty Access Summary The combination of property types and their related attributes, such as readwrite and command-line, can be confusing. Furthermore, different properties whose values are overloaded are initialized at different points in the component lifecycle. To clarify the behavior of these different properties, the table below is included.\nProperty Summary  Setting Behavior (Yes/No/Undefined)   kind mode command line overload config query initialization         language constructor generated constructor   property readwrite No Yes Yes Yes No Yes   property readonly No Yes No Yes No Yes   property writeonly No Yes Yes No No Yes   property readwrite Yes Yes Yes Yes No Yes   property readonly Yes Yes No Yes No Yes   property writeonly Yes Yes Yes No No Yes   allocation readwrite N/A No No U U U   allocation readonly N/A No No U U U   allocation writeonly N/A No No No U U   message any N/A No No No U U   There are several aspects of the table that are of note. The language-specific constructor (for example, __init__ in Python) never has the correct overloaded default value for a property; that value is only available when the generated constructor function is invoked. The use of the command-line marker for a property does not make it available at the language-specific constructor. The command-line marker is used to pass a property value in the command-line to services.\nA service normally does not support interfaces necessary to initialize properties over CORBA. In order to support properties in services, a property can be defined for a service and set as command-line, allowing the property to be overloaded for the specific service instance. The resulting command line argument will resolve from the service’s PRF file, and optionally be overridden from the DCD file. Standard property processing will apply to all types with the exception of the boolean type; in which case the exact contents supplied in either the PRF or DCD file will be passed on the command line.\nAllocation properties are not to be used as value containers; they are to be used to describe allocations to the device. While it is technically possible to query allocation properties, and while they may hold a value in the device implementation, that value is undefined, and could be anything. Allocation properties only have meaning in the context of allocateCapacity calls, and by extension have meaning only when servicing an allocation callback function.\nMessage properties have no storage meaning at all. They are prototypes describing structure message formats to be sent over MessageEvent ports. Furthermore, message properties can only be structures; they cannot be simple, simplesequence, or structsequence.\nProperty Change Listeners Often, it is useful to trigger additional actions when the value of a property changes. components support a type of notification called property change listeners that enable the developer to register callback methods that are executed whenever configure() is called with new values for the particular property.\nProperty change listeners are executed while holding the lock that protects access to all properties for the component. This ensures that no outside changes can occur while responding to property changes. The callback may alter the value of the property or call additional functions; however, avoid computationally expensive or blocking operations.\nC++ C++ components support notification of property value changes using member function callbacks.\nThe following example explains how to add a property change listener for the freqMHz simple property of type float, of a component named MyComponent.\nIn [component].h, add a private method declaration for your callback. The callback receives two arguments, the old and new values:\nvoid freqMHz_changed(float oldValue, float newValue); Implement the function in [component].cpp.\nThen, in the component constructor(), register the change listener:\nthis-\u0026gt;addPropertyListener(freqMHz, this, \u0026amp;MyComponent_i::freqMHz_changed); addPropertyListener takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nWhen defining a property listener for struct or sequence property, the new and old values are passed by const reference:\nvoid taps_changed(const std::vector\u0026lt;float\u0026gt;\u0026amp; oldValue, const std::vector\u0026lt;float\u0026gt;\u0026amp; newValue); Python Like C++, Python components allow registering listeners by property. The callback is typically a member function.\nThe following example explains how to add a property change listener for the freqMHz property.\nDefine the callback as a member function on your component. Excluding the implicit self argument, the callback receives three arguments: the property ID and the old and new values.\ndef freqMHz_changed(self, propid, oldval, newval): # Perform action based on change In your component constructor() method, register the change listener:\nself.addPropertyChangeListener(\u0026#34;freqMHz\u0026#34;, self.freqMHz_changed) Java Java properties support an idiomatic listener interface for responding to changes. As opposed to C++ and Python, listener registration is performed directly on the property object.\nThe following example explains how to add a property change listener for the freqMHz property of a component named MyComponent.\nDefine your callback that will respond to changes for the property as a member function on your component class. For simple numeric properties, the old and new value arguments can be the primitive type (for example, float):\nprivate void freqMHz_changed(float oldValue, float newValue) { // Perform action based on change } In your component’s constructor() method, define an anonymous subclass of org.ossie.properties.PropertyListener that connects the property’s change notification to your callback. For simple numeric properties, the type parameter of the PropertyListener class must be the boxed type (for example, Float).\nthis.freqMHz.addChangeListener(new PropertyListener\u0026lt;Float\u0026gt;() { public void valueChanged(Float oldValue, Float newValue) { MyComponent.this.freqMHz_changed(oldValue, newValue); } }); Customizing Query and Configure This feature is C++-only in REDHAWK 2.1.3.\n The REDHAWK libraries and generated component code automatically handle query() and configure() for all defined properties. However, in some cases, it may be preferable to retrieve the current value of a property in response to a query(), such as when fetching status from an external library. A developer may also want more control over how the property value is set. components support per-property callbacks to customize query and configure behavior.\nThe query callback is called when the component receives a query() for that property, in lieu of consulting the local state. Likewise, the configure callback is called when the component receives a configure() for that property, instead of updating the component local state.\nUnlike property listeners, the configure callback is always called regardless of whether the new value is equal to the old value.\n Query and configure callbacks are executed while holding the lock that protects access to all properties for the component. This ensures that the callback has exclusive access to the component properties. If possible, avoid computationally expensive or blocking operations to ensure that the component remains responsive.\nC++ In C++, query and configure callbacks are registered on the components. Registering a new callback replaces the old one.\nQuery Callbacks To create a query callback, in [component].h, add a private member function declaration. It takes no arguments and returns the value:\nfloat get_freqMHz(); Implement the function in [component].cpp.\nThen, in the body of constructor(), register the query function:\nthis-\u0026gt;setPropertyQueryImpl(freqMHz, this, \u0026amp;MyComponent_i::get_freqMHz); setPropertyQueryImpl takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nConfigure Callbacks To create a configure callback, in [component].h, add a private member function declaration. It takes one argument, the new value, and returns void:\nvoid set_freqMHz(float value); Implement the function in [component].cpp.\nThen, in the body of constructor(), register the configure function:\nthis-\u0026gt;setPropertyConfigureImpl(freqMHz, this, \u0026amp;MyComponent_i::set_freqMHz); setPropertyConfigureImpl takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nWhen a configure callback is set, the member variable is not updated automatically. It is up to the component developer to update the member variable, if desired.\nOverriding the configure() Method For the vast majority of cases, the standard configure() implementation is sufficient. Developers are strongly discouraged from overriding configure(). However, in the event that additional functionality beyond what is provided is required, the overridden method should call the base class configure() method to ensure that the behavior expected by the library and framework is preserved. Whether the base class method is pre- or post-extended is left to the discretion of the component developer.\nSynchronization External listeners to properties can be informed of changes in component properties by using the registerPropertyListener function on the component. The registerPropertyListener function allows an event consumer to register with the component. Upon registration, the component begins a thread that monitors the value of the requested properties. When the value of any of the monitored properties changes, an event is issued notifying the consumer what property changed on what component, when, and to what new value.\nTo maintain synchronization between property change events and query calls to the component, it is possible to add a QUERY_TIMESTAMP property to the query. The QUERY_TIMESTAMP property on the query() is populated with the timestamp for this query. The returned timestamp can be compared to asynchronously received property change events to assess what is the most recent known value for the requested property\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/python/misc/",
	"title": "Miscellaneous",
	"tags": [],
	"description": "",
	"content": " Saving and Loading Waveforms The components making up a waveform can be loaded into the workspace by passing the path and name of the waveform’s SAD XML file to the loadSADFile() method. Note that usesdevice relationships are ignored when loading a SAD file onto the Sandbox.\n\u0026gt;\u0026gt;\u0026gt; sb.loadSADFile(\u0026#34;/path/to/sad/file/waveform.sad.xml\u0026#34;) The instantiated components and their associated connections can also be saved as a waveform. To perform this operation, pass the desired waveform name to the generateSADXML() method.\nThis method returns an XML string representing the contents of the SAD file; this string may then be written to a file:\n\u0026gt;\u0026gt;\u0026gt; sadString = sb.generateSADXML(\u0026#34;waveform_name\u0026#34;) \u0026gt;\u0026gt;\u0026gt; fp=open(\u0026#34;/path/to/sad/file/waveform_name.sad.xml\u0026#34;,\u0026#34;w\u0026#34;) \u0026gt;\u0026gt;\u0026gt; fp.write(sadString) \u0026gt;\u0026gt;\u0026gt; fp.close() Debug Statements and Standard Out Standard out and standard error can be redirected to a file:\n\u0026gt;\u0026gt;\u0026gt; sb.redirectSTDOUT(\u0026#34;/path/to/file/file.txt\u0026#34;) Debug statements can be set explicitly.\nTo set the debug output status, pass True or False to the setDEBUG() method:\n\u0026gt;\u0026gt;\u0026gt; sb.setDEBUG(True) To get the current state of the debug output, use the getDEBUG() method:\n\u0026gt;\u0026gt;\u0026gt; sb.getDEBUG() True Processing Components from the Command Line To process individual components from the command line, use the proc() function. The following command is an example of the proc() function call with sample arguments:\n\u0026gt;\u0026gt;\u0026gt;sb.proc(\u0026#34;my_component\u0026#34;,\u0026#34;input_file\u0026#34;,sink=\u0026#34;output_file\u0026#34;,sourceFmt=\u0026#34;16t\u0026#34;,sinkFmt=\u0026#34;8u\u0026#34;,sampleRate=10000,execparams={\u0026#34;execprop1\u0026#34;:5},configure={\u0026#34;prop2\u0026#34;:4},providesPortName=\u0026#34;input\u0026#34;,usesPortName=\u0026#34;output\u0026#34;,timeout=10) proc() Function Arguments    Name Description     \u0026lt;first argument\u0026gt; Specifies the name of the component to run (required).   \u0026lt;second argument\u0026gt; Specifies the name of the input file (required).   sink Specifies the name of the output file (optional). If this argument is omitted, exit the proc() function with Ctrl+C.   sourceFmt Specifies the format for the input file (optional).    - 8/16/32/64 bit resolution    - u/t: unsigned/signed    - c: complex (real if omitted)    - r: big endian (little endian if omitted)   sinkFmt Specifies the format for the output file (optional).   sampleRate Specifies the sampling rate for the input file (optional).   execparams Specifies the dictionary describing properties (of kind execparam or property) to be passed as command-line arguments (optional).   configure Specifies the dictionary describing properties (of kind configure or property) to be over-ridden (optional).   providesPortName Specifies the component input port name (optional).   usesPortName Specifies the component output port name (optional).   timeout Specifies how long the proc() function runs before exiting (optional).    "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/plot-settings-dialog/",
	"title": "Plot Settings Dialog",
	"tags": [],
	"description": "",
	"content": " The Plot Settings dialog enables the user to adjust certain plot settings.\nPlot Settings Plot Selecting Plot in the left-hand navigation pane displays the Plot section. The Plot section enables you to change various settings on how the data is displayed within the plot.\n Mode: Select the Mode of the plot. Min: Set the minimum value for the plot. The default value is to automatically determine the minimum. Max: Set the maximum value for the plot. The default value is to automatically determine the maximum. Refresh Rate (fps): Set the desired refresh rate in frames per second (fps) to perform smart thinning of the data. Enter 0 to disable smart thinning. The default value is 30 fps. Enable plot configure menu using mouse: This checkbox enables the NeXtMidas plot configure menu using the mouse. Enable quick access control widgets: This checkbox enables the quick access control widgets to change plot settings from the View. When enabled, Plot Port FFT has a quick control widget for adjusting the FFT number of averages directly in the View.  Output Port Name Selecting the Output Port Name in the left-hand navigation pane displays the Output Port Settings dialog:\nOutput Port Settings The Output Port Settings enable you to modify how the source is being displayed.\n The Show checkbox enables you to turn the plotting of individual data streams on and off. The Stream ID displays the Stream ID for each data stream in the plot. Clicking on Color brings up the color palette window, which enables you to select a color for the specified stream on the plot.\nColor Palette  Framesize: Enables you to override the displayed default frame size.\n The IF and RF radio buttons enable you to toggle between IF and RF frequency values for the x-axis on FFT plots.\n Center Freq: Enables you to override the center frequency value for RF plots. This field is grayed out for IF plots.\n  Expanding the Output Port Name in the left-hand navigation pane makes the BULKIO and FFT settings available.\nBULKIO Selecting BULKIO in the left-hand navigation pane displays the BULKIO settings dialog:\nBULKIO Settings The BULKIO settings dialog enables you to modify how the data is received via the CORBA Bulk Data.\n Connection ID: Displays the Connection ID of the current connection. Sample Rate: Enables you to set a custom sample rate to override the value in StreamSRI. Enter 0, or leave on AUTO, to use the value from StreamSRI. Remove on ‘End of Stream’: This checkbox enables you to select whether the stream is removed from the plot when an eos is received for the selected Stream ID. Blocking Option: This enables you to select a blocking option for pushPacket when the plot is not able to keep up with the data stream by selecting one of the radio buttons.  non-blocking - Do not block incoming data. blocking - Block incoming data. use SRI.blocking (default) - Set the blocking based on the StreamSRI.blocking field received from the pushSRI() call.   FFT Selecting FFT in the left-hand navigation pane displays the FFT settings dialog:\nFFT Settings The FFT section enables you to change various settings on the FFT primitive.\n Num Averages: Enables you to change the number of averages in the FFT. Overlap: Enables you to change the overlap of the FFT. Sliding Num Averages: Enables you to change the sliding number averages of the FFT. Transform Size: Enables you to change the transform size of the FFT. For best results the entry should be a power of 2. Window Type: Enables you to change the window type of the FFT.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/persona-device-pattern/",
	"title": "REDHAWK Persona Device Pattern",
	"tags": [],
	"description": "",
	"content": " In REDHAWK, you can manage and maintain the lifecycle of programmable devices, such as FPGAs, by implementing a specific design pattern: the Persona Pattern. This design pattern is rooted heavily in the concept of REDHAWK devices, proxies used to interface physical hardware with the REDHAWK Framework.\nTo accurately represent the dynamic nature of programmable hardware, two unique roles have been established: the Programmable role and the Persona role. These roles are represented in REDHAWK as two separate REDHAWK devices: Programmable Devices and Persona Devices.\nPotential Benefits Persona Devices provide the following benefits:\n Enables the REDHAWK Framework to manage and maintain the lifecycle of programmable hardware. Ability to add/remove programmable hardware loads without the need to modify/rebuild source. Reduced development time and costs. Support for reuse and portability. Scalability across embedded, lightweight, and heavyweight architectures.  Theory of Operation The Programmable and Persona Roles The Programmable role and the Persona role attempt to model the polymorphic behavior of programmable hardware within the REDHAWK Framework. The Programmable role can be thought of as a controller that may also provide generic functionality, whereas the Persona role can be thought of as a standalone representation of a single hardware load. This delineation provides two distinct areas to accurately define functionality and assign responsibilities.\nThe Programmable Role The Programmable role has a handful of responsibilities associated with it, but most important are its controller responsibilities. The Programmable role has the ability to control which persona has permission to load the programmable hardware while also blocking subsequent personas from attempting to re-program loaded, running hardware. This simple controller role may also be extended to contain generic functionality that is common among all personas or that does not apply to the Persona role.\nThe Persona Role The Persona role is responsible for defining the hardware load and any interfaces pertaining to that specific load. This may include register definitions and/or data IO channels. The Persona role supplies the bulk of the control over the programmable hardware, representing the state of the loaded programmable hardware.\nREDHAWK Devices The Programmable and Persona roles can be implemented via REDHAWK devices. Representing these roles as their own independent devices allows for more granular control and for a more precise representation of each role without needing to shoe-horn the two independent roles together into a single, complex entity.\nRelationship between Programmable Devices and Persona Devices REDHAWK Programmable Device The Programmable role may be implemented in REDHAWK as a standard REDHAWK executable device. The Device Manager is responsible for launching this device, following the typical REDHAWK device lifecycle. What makes the programmable device unique is that it provides hooks for maintaining and managing the lifecycle of the persona devices registered to it.\nREDHAWK programmable devices also implement functionality to instantiate REDHAWK persona devices from shared libraries. This is achieved by using dlopen to load the shared library and dlsym to access/instantiate the device object contained within the shared library. This mechanism occurs when the following requirements are met:\n Programmable/Persona devices are associated together using the compositepartofdevice tag in DCD file. Aggregate (parent) device is an executable device. Composite (child) device is a shared library.  REDHAWK Persona Device A REDHAWK persona device is simply the XML representation of one specific behavior that may be assigned to a programmable device. This XML representation may include unique properties and/or ports that are only relevant to the persona. Each persona device is visible in the REDHAWK domain, which allows for run-time configuration of persona devices in a standardized way.\nREDHAWK persona devices may be built as shared objects rather than executables, therefore, allowing persona devices to exist within the same process space as a programmable device.\nDynamic Loading of Persona Devices onto a Programmable Device Associating Programmable/Persona Devices Programmable devices and persona devices are linked together via the REDHAWK DCD files. Within these DCD files, the aggregate device relationship tag defines which persona devices should be associated to a programmable device. The advantage of describing this relationship within the DCD file comes with the added ability to dynamically add/remove/ modify the possible personalities of programmable hardware without the need to rebuild source.\nAggregate Persona Device In the SCA 2.2.2, aggregate devices are defined as devices that are loosely coupled together within a parent-child relationship. The extent of this relationship is left up to the developer and the Persona Pattern attempts to take full advantage of this loose coupling.\nBecause a single piece of programmable hardware can take on many personalities, the programmable device is said to have a one-to-many relationship with its loads. The DCD file, via the aggregate relationship tags, enables users to properly define this one-to-many relationship between a single programmable device and many available persona devices.\nDCD File Example In the following example DCD file, the compositepartofdevice tag is used to associate TestPersonaChild1 and TestPersonaChild2 to PersonaParent1.\n... \u0026lt;componentfiles\u0026gt; \u0026lt;componentfile id=\u0026#34;test_persona_parent\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/devices/programmable/programmable.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;componentfile id=\u0026#34;test_persona_child\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/devices/persona_device/persona_device.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;/componentfiles\u0026gt; \u0026lt;partitioning\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_parent\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_parent_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;persona_parent_1\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_child\u0026#34;/\u0026gt; \u0026lt;compositepartofdevice refid=\u0026#34;persona_node:persona_parent_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_child_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;test_persona_child_1\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_child\u0026#34;/\u0026gt; \u0026lt;compositepartofdevice refid=\u0026#34;persona_node:persona_parent_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_child_2\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;test_persona_child_2\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;/partitioning\u0026gt; ... Hardware-Accelerated Components Hardware-accelerated components are REDHAWK components that are proxies into only a portion of hardware. An example for FPGAs is having multiple demodulator components within the fabric that all have their own register sets and data IO channels. Each individual register set and/or data IO channel may be represented within a single REDHAWK component that has a dependency on a specific behavior or persona.\nThe pattern used for hardware-accelerated components is very similar to the pattern used for persona devices. These components may be built as shared libraries and share state the same way Programmable and Persona devices share state.\nDynamic Loading of Hardware-Accelerated Components to a Persona Device Code-Generation Support The persona code-generation support includes templates for both the persona device and the programmable device. These templates have been setup to allow for the easy redefinition of the entry-point method to share state from device-to-device as well as device-to-component. The code generation provides the following benefits:\n Provides C++ and Python templates for Persona/Programmable devices and harware-accelerated components. Allows for custom definition of the entry-point method to pass state and/or other parameters from device-to-device as well as device-to-component. Generic shared library functionality tucked into base classes for ease of development. Manages and maintains generic functionality between device-to-device and device-to-component behavior.  Persona Pattern Development Programmable Device Development Developing REDHAWK programmable devices is based heavily on interfacing with a manufacturer’s driver/API and/or custom drivers/APIs. If the driver/API is to be shared, the programmable device may be responsible for the initial construction/opening of the driver/API and the destruction/closing at the end of the lifecycle. The REDHAWK programmable device must also include properties that exist on that specific hardware (for example, temperatures) and any allocation properties that may exist (for example, tuner cards using FEI 2.0). Any persona device that attempts to reserve the hardware may configure/allocate these properties to put the device into a known usable state for that persona.\nPersona Device Development Developing persona devices uses the code-generation support to abstract away the hooks and functionality used to associate persona devices with their parent programmable device.\nPersona devices, in theory, must contain any ports and/or properties that are strictly related to the hardware personality. These ports and properties must be unique to the load and must not overlap with the programmable device. The persona device may then choose to access the driver/API as needed for operations such as reading/writing registers.\nSystem Developers System developers may assign the programmable device behavior on the fly while also maintaining persona sets for a specific programmable device dynamically. The relationship definition between persona devices and programmable devices is defined at the node level within the DCD file. With programmable devices and persona devices defined, a system developer may chose to create/modify DCD files to dynamically add/remove/modify the personas that may be loaded onto the programmable hardware without the need to generate/build source.\nWhen to Use the Persona Pattern Persona devices are useful for programming hardware dynamically but may not be ideal for every programmable device situation. The following cases describe some common scenarios and explain why the Persona Pattern may or may not be practical for the scenarios.\n Case 1: You have a single FPGA that you want to always operate as X.\n Solution: Develop a single REDHAWK device without persona devices. In this scenario, a single device is adequate enough to represent both the hardware and the programmable behavior of the hardware. We are essentially treating the hardware and programmable behavior as a single unit because that behavior is static.  Case 2: You have a single fpga that you want to operate like X, Y, and Z, where X, Y, and Z do not exhibit any of the same behavior.\n Solution: Develop a REDHAWK programmable device that interfaces with the hardware and develop X, Y, and Z REDHAWK persona devices that represent the unique behaviors. Using persona X, Y, and Z allows for all differences between X, Y, and Z to be represented properly while also allowing generic functionality to be retained within the programmable device.  Case 3: You have a single fpga that you want to operate like X1, X2, and X3, where X1, X2, and X3 exhibit common behavior.\n Solution: There are multiple solutions and the best solution depends on the specific use-case and whether the behaviors are similar. Some possible solutions include:  Solution 1: Develop a REDHAWK programmable device that interfaces with the hardware and develop a REDHAWK persona device for each behavior. This requires the most amount of effort but will yield the most amount of flexibility if the behaviors wind up not being as similar as originally expected Solution 2: Develop a single REDHAWK device that interfaces with the hardware and maps the differences in X1, X2, and X3 behavior via the standard REDHAWK properties. This simplest solution can quickly yield \u0026ldquo;spaghetti\u0026rdquo; code if the house-keeping becomes more complex. Solution 3: Develop a REDHAWK programmable device that interfaces with the hardware and develop a dynamic REDHAWK persona device that can be configured to represent X1, X2, and/or X3. This approach allows the REDHAWK programmable device to maintain its appropriate role while offloading the housekeeping code to the dynamic REDHAWK persona device. This option also lends itself to adding additional REDHAWK persona devices further down the road to include a new behavior that was not originally intended.    Sharing Hardware Driver/API When using a single driver/API, it is possible to pass a single instance of the driver/API to each persona device and/or hardware-accelerated component. The programmable device is the layer closest to the physical hardware and is typically in charge of opening/instantiating the driver/API.\nThe REDHAWK Framework allows for Softpkg dependencies, packages used to distribute shared libraries/headers amongst numerous resources. The Persona Pattern does not mandate the use of Softpkg, but it may be beneficial to create a REDHAWK Softpkg dependency for the driver/API libraries/headers instead of manually including/linking headers/libraries.\nOnce the headers and libraries are shared, it is possible to share a single instance of the library/API by using one of the following options.\nOption 1: Modifying the construct Method Because persona devices are shared objects, you can modify the entry-point method into those shared objects and append any additional arguments. The following procedure explains how to modify the construct method.\n For the programmable device, update any entry-point typedefs and pass in additional arguments to the entry-point method. For the persona devices, update the extern C construct method as follows:  extern \u0026#34;C\u0026#34; { Device_impl* construct(int argc, char* argv[], Device_impl* myParent, MyNewArg1Ptr* myNewArg1, MyNewArg2Ptr* myNewArg2){ . . // Standard construct logic  . . // Use myNewArg1 and myNewArg2 here  devicePtr-\u0026gt;setMyArg1(myNewArg1); devicePtr-\u0026gt;setMyArg2(myNewArg2); } } Option 2: Defining a Programmable Device Interface The following procedure explains how to define a programmable device interface.\n Create a programmable device interface that exposes desired state. Include the interface with the persona devices and cast the parent reference into the interface. Update the persona device entry-point construct method as follows:  extern \u0026#34;C\u0026#34; { Device_impl* construct(int argc, char* argv[], Device_impl* myParent) { . . // Standard construct logic  . . // Cast Programmable Device into interface  Interface myDevice = static_cast\u0026lt;Interface\u0026gt;(myParent); // Give Programmable Device interface to Persona  devicePtr-\u0026gt;setMyDeviceInterface(myDevice); } }"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/allocation-manager/",
	"title": "The Allocation Manager",
	"tags": [],
	"description": "",
	"content": " The Allocation Manager provides a single point for creating, inspecting, and delegating allocations.\nUsing the Allocation Manager Performing an allocation is more than just allocating against a device; the allocation process involves searching for a device that will satisfy the allocation, making the allocation itself, and then storing the allocation such that it can be deallocated at some later arbitrary time. The Domain Manager uses the Allocation Manager to resolve allocations during application deployment. For example, if an application requires a specific resource, during deployment, the Allocation Manager searches the domain for resources that satisfy the requirement. Alternatively, the Allocation Manager can also be used programmatically through the Allocation Manager interface and the REDHAWK API.\nCreating Allocations The REDHAWK FEI specification is a powerful tool that allows developers to generalize the selection of RF hardware for use by the system applications. Although it is possible to create any allocation, the set of allocations associated with FEI is the only standardized set of allocations in REDHAWK. While associating a specific FEI allocation with an application is useful, so is creating allocations to be used at a system level (beyond the scope of just one application).\nTo create a new FEI allocation, use the following Python code (assuming an FEI device is running, in this case, the FmRdsSimulator):\n\u0026gt;\u0026gt;\u0026gt; import frontend \u0026gt;\u0026gt;\u0026gt; from ossie.cf import CF \u0026gt;\u0026gt;\u0026gt; alloc = frontend.createTunerAllocation(center_frequency=100e6, bandwidth=0.0, sample_rate=0.0, returnDict=False) \u0026gt;\u0026gt;\u0026gt; requestId = \u0026#39;my_request\u0026#39; \u0026gt;\u0026gt;\u0026gt; pools = [] \u0026gt;\u0026gt;\u0026gt; devices = [] \u0026gt;\u0026gt;\u0026gt; sourceId = \u0026#39;my_script\u0026#39; \u0026gt;\u0026gt;\u0026gt; request = CF.AllocationManager.AllocationRequestType(requestId, [alloc], pools, devices, sourceId) The following table describes the parameters used in this Python code.\nParameters    Name Description     requestId Unique string the caller can use to identify the request.   alloc Parameterized request.   pools Currently unused parameter.   devices List of devices to search over (an empty list searches through all devices in the domain).   sourceId String that can be used to identify the application generating the request.    The Allocation Manager uses the parameters requestId and sourceId to help manage the allocations. For example, in complex systems with multiple subsystems, to manage all the allocation requests for a single application, requestId would be used. If an allocated device unexpectedly terminates, sourceId can be used to determine which allocations are no longer used by any subsystem and then the allocations can be deallocated. Because such management/cleanup is CONOP-specific, it is outside the scope of REDHAWK and must be implemented by system developers to suit their unique needs and environment.\nOnce the allocation is formulated, a list of requests can be submitted to the Allocation Manager using the allocate method. The allocate function returns a list of AllocationStatusType. This list contains one status for each successful allocation, along with the original allocation properties requested as well as the resulting allocation id. This AllocationProperties member can be useful when inspecting FEI allocations because it contains the values requested in the allocation. The response also contains the allocation ID (generated by the Allocation Manager to guarantee uniqueness within the context of the Allocation Manager). This is required because requestIds can be duplicated. If the request is successful, it is added to the Allocation Manager’s allocations list.\nThe following Python code demonstrates a successful allocation using the allocation request in the previous code example. In this case, a response is returned; the response contains the submitted request id. The allocation is then deallocated by using the deallocate function on the Allocation Manager; the only required argument is the allocation ID because that allocation ID is unique to the Allocation Manager.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; am = domain.getAllocationMgr() \u0026gt;\u0026gt;\u0026gt; responses = am.allocate([request]) \u0026gt;\u0026gt;\u0026gt; response = responses[0] \u0026gt;\u0026gt;\u0026gt; print response.requestID \u0026#39;my_request\u0026#39; \u0026gt;\u0026gt;\u0026gt; print response.allocationID \u0026#39;DCE:d46ce82b-31de-4010-95de-435aaa1f17c5\u0026#39; \u0026gt;\u0026gt;\u0026gt; am_allocs = am.allocations() \u0026gt;\u0026gt;\u0026gt; print len(am_allocs) 1 \u0026gt;\u0026gt;\u0026gt; print am_allocs[0].sourceID \u0026#39;my_script\u0026#39; \u0026gt;\u0026gt;\u0026gt; print am_allocs[0].allocationID \u0026#39;DCE:d46ce82b-31de-4010-95de-435aaa1f17c5\u0026#39; \u0026gt;\u0026gt;\u0026gt; am.deallocate([am_allocs[0].allocationID]) \u0026gt;\u0026gt;\u0026gt; print len(am.allocations()) 0 For allocations against an FEI device, the allocatedDevice member of the AllocationStatusType can be used to inspect the tuner status structure. The tuner status structure provides the actual values that were allocated, which may be different from what was originally requested.\nInspecting Allocations through the Python Sandbox To inspect the current allocations through the Python Sandbox:\nFirst, a reference to the running domain is needed. From the Domain Manager, the Allocation Manager can be retrieved:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; am = domain.getAllocationMgr() If no applications are running, an application must be specified.\n\u0026gt;\u0026gt;\u0026gt; domain.createApplication(\u0026#39;/waveforms/rh/basic_components_demo/basic_components_demo.sad.xml\u0026#39;,\u0026#39;hello\u0026#39;) \u0026lt;ossie.utils.redhawk.core.App object at 0x33092d0\u0026gt; In this case, the default basic_components_demo application was selected. This application instance was given the name \u0026ldquo;hello\u0026rdquo; to simplify the subsequent output.\nThe Allocation Manager tracks which device has a component assigned to it, even if no explicit allocations against the device were made. In the case of basic_components_demo, there are a total of six components on the waveform. Viewing the current allocations on the Allocation Manager yields a list of six allocations:\n\u0026gt;\u0026gt;\u0026gt; allocs = am.allocations() \u0026gt;\u0026gt;\u0026gt; len(allocs) 6 Each allocation description returned is a CF.AllocationManager.AllocationStatusType instance, which contains the allocation ID, requesting domain, any properties allocated, the device that satisfied the allocation, the Device Manager that hosts the device that satisfied the allocation, and the ID for the requester for the allocation.\n\u0026gt;\u0026gt;\u0026gt; allocs[0] CF.AllocationManager.AllocationStatusType(allocationID=\u0026#39;DCE:15c3ad3e-dbfa-48b6-b0d7-c12b450f9806\u0026#39;, requestingDomain=\u0026#39;REDHAWK_DEV\u0026#39;, allocationProperties=[], allocatedDevice=\u0026lt;ossie.cf.CF._objref_ExecutableDevice object at 0x28cc110\u0026gt;, allocationDeviceManager=\u0026lt;ossie.cf.CF._objref_DeviceManager object at 0x28cc250\u0026gt;, sourceID=\u0026#39;DCE:d4d99400-1a11-11e5-a6ce-3417ebc4aab5:hello_1\u0026#39;) \u0026gt;\u0026gt;\u0026gt; allocs[0].allocationProperties [] \u0026gt;\u0026gt;\u0026gt; allocs[0].sourceID \u0026#39;DCE:d4d99400-1a11-11e5-a6ce-3417ebc4aab5:hello_1\u0026#39; In this example, allocationProperties is an empty list because the deployment required the device to match an allocation requirement and no explicit capacity allocation was made. The source ID is a concatenation of the application’s sad.xml file softwareassembly id (the file’s globally unique identifier), a \u0026ldquo;:\u0026ldquo;, and the application name followed by an instance number.\nInspecting Allocations using the IDE To inspect the current allocations using the IDE:\n In the REDHAWK Explorer view, right-click a Domain Manager and select Allocation Manager.\nThe Allocation Manager view is displayed. The following figure displays the allocation manager view based on the results of following the instructions in Inspecting Allocations through the Python Sandbox\nAllocation Manager  To view the allocation properties associated with an allocation, select the allocation in the Allocation Manager view.\nThe Properties view displays the allocation properties.\nThe following figure displays the allocation properties from an FEI device allocation.\nAllocation Manager Properties  To view the device associated with an allocation, from the Allocation Manager view, right-click the allocation and select Find Device.\nThe device is highlighted in the REDHAWK Explorer View.\n To view the Device Manager associated with an allocation, from the Allocation Manager view, right-click the allocation and select Find Device Manager.\nThe Device Manager is highlighted in the REDHAWK Explorer View.\n  Delegating Allocations If an allocation resolution cannot be satisfied, the Allocation Manager delegates an available resource.\nA Domain Manager can register with other Domain Managers. If a Domain Manager is registered with another Domain Manager, then any usesdevice relationship allocation that cannot be satisfied by the Domain Manager is delegated to the remote Domain Managers. Through these registrations, it is possible for multiple Domains to share hardware resources. Sharing between Domains is limited to non-computing resources, like FEI devices. The AllocationStatusType instance returned by the allocate function on the Allocation Manager includes a requestingDomain member. The requestingDomain member shows the name of the Domain Manager that performed the allocation request that is currently satisfied by this Allocation Manager.\nTo perform multi- domain allocations, a Domain Manager first needs to be registered with a remote Domain Manager:\n\u0026gt;\u0026gt;\u0026gt; domain_1 = redhawk.attach(\u0026#39;First_Domain\u0026#39;, location=\u0026#39;\u0026lt;\u0026lt;some IP address\u0026gt;\u0026gt;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; domain_2 = redhawk.attach(\u0026#39;Second_Domain\u0026#39;, location=\u0026#39;\u0026lt;\u0026lt;some other IP address\u0026gt;\u0026gt;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; domain_1.registerRemoteDomainManager(domain_2.ref) In this example, once the Domain Manager is registered, any allocations made onto domain_1 that cannot be satisfied by domain_1, are then delegated to domain_2.\nThe allocate function on the Allocation Manager returns a list of all allocations. To simplify this list, the Allocation Manager also contains the localAllocations function, which returns a list of all allocations that were requested and satisfied by this local domain.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/waveforms/",
	"title": "Waveforms",
	"tags": [],
	"description": "",
	"content": "This chapter discusses the construction and execution of waveforms within REDHAWK. An application is the software object that represents an instance of a waveform. A waveform is an XML file that describes the deployment, inter-connection, and configuration of components. It is possible to launch waveforms in the Sandbox as well as in the REDHAWK domain. This chapter discusses the mechanisms for launching a waveform as a running application in a domain.\nTo complete the procedures in this chapter, the SigGen and HardLimit components must be installed in $SDRROOT/dom/components.\n  Waveform Editor     Create and Deploy a Sample Waveform     Waveform Deployment and Computing Resources     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/deploying-projects/",
	"title": "Deploying Projects to the SDRROOT",
	"tags": [],
	"description": "",
	"content": "The following methods may be used to deploy a REDHAWK project into the target SDRROOT.\n Drag-and-drop from the Project Explorer:\n In the Project Explorer View, drag the top-level REDHAWK project onto the Target SDR in the REDHAWK Explorer View. In the REDHAWK Explorer View, expand Target SDR, then expand the appropriate sub-area: Components, Devices, Nodes, Services, or Waveforms, to display the deployed project.  From the Project Menu:\n In the Project Explorer View, select the top-level REDHAWK project. From the Project menu, select Export to SDR.  From the Context Menu:\n In the Project Explorer View, right-click the top-level REDHAWK project. Select Export to SDR.  From the Overview page of the SPD Editor:\n Open the project’s spd.xml file. From the Overview tab of the SoftPkg Editor, in the Exporting section, click Export Wizard. In the Export Wizard, from the Available REDHAWK Projects section, check the desired projects to deploy. The Destination directory is prepopulated with the Target SDR. Click Finish to deploy selected projects into the Target SDR.  From the File Menu:\n From the File menu, select Export. From the Export Wizard, expand REDHAWK Development and select Deployable REDHAWK Project. Click Next. From the Available REDHAWK Projects section, check the desired projects to deploy. The Destination directory is prepopulated with the Target SDR. Click Finish to deploy the selected projects into the Target SDR.   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/event-viewer-view/",
	"title": "Event Viewer View",
	"tags": [],
	"description": "",
	"content": " The Event Viewer view is used to listen to any event channel (for example, the default IDM_Channel or ODM_Channel for a domain) as well as message events emitted by MessageEvent ports. It also provides a means of filtering, sorting, and exporting the event traffic collected.\nThe following figure displays the Event Viewer View for the ODM channel.\nEvent Viewer View To listen to a channel from the REDHAWK Explorer View:\n Expand the domain.\n Expand the Event Channels folder.\n Right-click the desired channel, and select Listen to Event Channel.\nThe Event Viewer View for the selected channel is displayed and new events are added to the table.\n  To listen to a channel from the CORBA Name Browser View View:\n Expand the Naming Service.\n Expand the domain.\n Right-click the desired channel, and select Listen to Event Channel.\nThe Event Viewer View for the selected channel is displayed, and new events are added to the table.\n  To listen to message events emitted by a uses (out) port from the Diagram tab:\n Right-click the port and select Listen to Message Events.\nThe Event Viewer View for the selected port is displayed and the message events are added to the table.\n  The controls in the upper right of the Event Viewer View provide the following functionality:\n To view details for events, click the See Details icon. The Properties tab is displayed with the all of the details for the selected event.\nProperties tab with Event Details for the ODM Channel  To stop listening to a channel, click the Disconnect icon.\n To clear the logs, click the Clear icon.\n To ensure the view does not scroll automatically to the top as new events are received, click the Scroll Lock icon.\n  The controls at the bottom of the Event Viewer View enable the user to filter and search the event log.\nTo filter the event log:\n In the Filter field, enter the filter text for the event log. To remove the filter, click the Clear icon. To enable regular expressions in the Filter field, check the RE checkbox.  To search the event log:\n In the Search field, enter the text for which you want to search. To clear the search highlights from the event log, click the Clear icon. To enable regular expressions in the Search field, check the RE checkbox.  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/messaging/",
	"title": "Messaging",
	"tags": [],
	"description": "",
	"content": "Messaging relies on CORBA’s event structure as a transport structure. In CORBA’s event API, messages are passed as an Any type using the function push().\nWhile CORBA manages marshaling and delivery of the data, it does not provide any mechanisms inherent to events to describe the contents of the Any type. REDHAWK decided to leverage an existing payload structure descriptor to describe the payload of messages, the properties IDL. The selection of this interface eliminates the need to create a new IDL describing messages. Furthermore, there is already an XML structure that is mapped to efficient binary data structures, allowing the use of XML to describe message contents while eliminating the need for introducing XML parsers in the message delivery mechanism.\nTo support this additional functionality, REDHAWK has expanded the properties descriptor to allow a property to have the kind message. The only property that can have a valid message kind is a structure.\n Message Producer   Message Consumer   Viewing Messages   Connecting Producers and Consumers   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/connection-manager/",
	"title": "The Connection Manager",
	"tags": [],
	"description": "",
	"content": " The Connection Manager provides a single point for creation and inspection of connections between domain objects. Connections between domain objects can be defined on the Connection Manager irrespective of whether or not these objects are currently deployed. If one or more of the endpoints defined in a connection are not available, the connection is pending. Connections are resolved anytime domain objects enter or leave the domain.\nEndpoints can be applications, devices, services, Event Channels, or CORBA object references.\nInspecting Connections using the IDE To inspect the current connections using the IDE:\n In the REDHAWK Explorer view, right-click a Domain Manager and select Connection Manager.\nThe Connection Manager view is displayed. If a green check mark is displayed in the Connected column, this indicates that the connection has been made; otherwise, it is pending.\nConnection Manager  To view the connection properties, select the connection in the Connection Manager view.\nThe Properties view displays the connection properties.\nConnection Manager Properties  To view the source (provides/out port) of a connection, from the Connection Manager view, right-click the connection and select Find Source.\nThe source is highlighted in the REDHAWK Explorer View.\n To view the target (uses/in port) of a connection, from the Connection Manager view, right-click the connection and select Find Target.\nThe target is highlighted in the REDHAWK Explorer View.\n  Disconnecting Connections using the IDE To disconnect a current connection using the IDE:\n From the Connection Manager view, right-click the connection and select Disconnect.\nThe connection is disconnected.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/troubleshooting/",
	"title": "Troubleshooting",
	"tags": [],
	"description": "",
	"content": " This appendix explains how to troubleshoot and resolve omniNames/omniEvents failures.\nPerforming a Hard Reset Using the cleanomni Script The cleanomni script is used to perform a hard reset of omniNames and omniEvents and delete the associated log files. To run this script, enter the following command:\nsudo $OSSIEHOME/bin/cleanomni The cleanomni script performs the following commands:\nsudo /etc/init.d/omniEvents stop sudo /etc/init.d/omniNames stop sudo rm -rf /var/log/omniORB/* /var/lib/omniEvents/* sudo /etc/init.d/omniNames start sudo /etc/init.d/omniEvents start Diagnosing Problems Using the rh_net_diag Script The rh_net_diag script is a Python script used to diagnose various omniORB-related problems and to perform other system checks to diagnose potential problems that may impact a REDHAWK installation. To run this script, enter the following command:\nrh_net_diag By default, the --ns (naming service), --dom (Domain Manager), and --dev (Device Manager) options are enabled when the script is executed. These options assume that omniNames, the Domain Manager, and the Device Manager are all running on the host executing the script. For help with rh_net_diag, enable the -h option. For more detailed output, enable the -v option. The four test categories include:\n Standard tests performed every time rh_net_diag is executed.\n Check if OSSIEHOME, SDRROOT, and /etc/omniORB.cfg are readable. Check that omniORB is installed. If /etc/omniORB.cfg is not readable or if omniORB is not installed, the script terminates.  Tests that diagnose potential problems with the naming service. They are performed if --ns is enabled.\n Check if omniNames is running. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Retrieve entries currently stored in the naming service. Refer to Common Causes for omniNames Failure for further assistance. Check /etc/omniORB.cfg to ensure that all defined endPoints are correct. If all the above checks pass but the Domain Manager and Device Manager still cannot communicate with the naming service, manually check the firewall settings on the host running omniNames.  Tests that diagnose potential problems with the Domain Manager. They are performed if --dom is enabled.\n Attempt to retrieve entries currently stored in the naming service. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Check /etc/omniORB.cfg to ensure all defined endPoints are correct.  Tests that diagnose potential problems with the Device Manager. They are performed if --dev is enabled.\n Check if InitRef was overwritten with the rh_net_diag script --ORBInitRef option or if we are using the InitRef specified in /etc/omniORB.cfg. If InitRef is valid, attempt to retrieve entries currently stored in the naming service. Refer to Common Causes for omniNames Failure for further assistance. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Try to connect to the Domain Manager if one exists in the naming service. Check that the IP address for the host running this script is listed in ifconfig. If there is no matching entry with the Device Manager, then the Java components fail on initialization.   Performing a Soft Reset of omniNames and omniEvents If the runtime-error indicates a naming service failure, enter the following command to attempt a soft reset on omniNames:\nsudo /sbin/service omniNames restart This process first performs a stop and then performs a start. If the stop process fails, omniNames was never started, stopped due to an error condition, or is in a non-recoverable state. If the start process fails, omniNames is either misconfigured or already running (i.e., omniNames was not stopped).\nomniNames can potentially report a successful start and then fail soon after. If the omniNames service appears to fail after reporting a successful start, a reconfiguration and hard reset of omniNames may be necessary. For more information, refer to Common Failures and Using cleanomni.\n A restart of omniEvents may be necessary when restarting omniNames. To perform a soft reset of omniEvents, enter the following command:\nsudo /sbin/service omniEvents restart Setting Omni Log Levels When diagnosing omniNames/omniEvents problems, it is often useful to set the omni logging levels. Use the following procedure to set the omni logging levels (requires root permissions):\n Open the /etc/omniORB.cfg file. Set a traceLevel value. For example: bash traceLevel = 10   Details on the available trace levels can be found in Chapter 4 of the omniORB User’s Guide (http://omniorb.sourceforge.net/omni41/omniORB/omniORB004.html or on your local system at file:///usr/share/doc/omniORB-devel-4.1.6/doc/omniORB/omniORB004.html).\nFor the changes to take effect, restart omniNames/omniEvents.\nLog messages are displayed in the terminal and in the files contained in /var/log/omniORB and /var/lib/omniEvents.\nCommon Causes for omniNames Failure IP Version 6 Conflicts Certain combinations of IP Version 6 (IPv6) configurations and /etc/omniORB.cfg configurations can cause omniNames failures.\nSpecifically, if the InitRef section of /etc/omniORB.cfg is set to point to localhost rather than pointing explicitly to 127.0.0.1, the operating system may resolve localhost to ::1 (the IPv6 localhost) and not to 127.0.0.1 (the IPv4 localhost). If this occurs, omniNames fails. There are three options for preventing this failure condition:\n Explicitly set 127.0.0.1 in the InitRef section instead of using localhost. Disable IPv6 in the operating system (refer to operating system documentation). Modify the /etc/hosts file to prevent localhost from being resolved as ::1.  Preventing IPv6 localhost Resolution Below is an example /etc/hosts file from an older CentOS distribution:\n127.0.0.1 localhost.localdomain localhost ::1 localhost6.localdomain6 localhost6 Below is an example /etc/hosts file from a newer CentOS distribution:\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 In the older /etc/hosts file, localhost resolves unambiguously to 127.0.0.1. In the newer /etc/hosts file, localhost can resolve to either 127.0.0.1 or ::1 (where resolving to ::1 causes an omniNames failure).\nThe newer /etc/hosts file can be modified to read:\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost6 localhost6.localdomain6 Alternatively, localhost4 can be used in the InitRef section of /etc/omniORB.cfg.\nThe line pertaining to IPv6 can also be completely removed from the file; however, some operating systems, depending on IPv6 configurations, may automatically repopulate IPv6 localhost settings on reboot.\nInvalid IP Addresses in /etc/hosts Invalid entries in the /etc/hosts file may induce an omniNames failure. Invalid entries may be in the form of an IP address that cannot be reached or in the form of an entry that is not valid according to the /etc/hosts grammar. Firewall IP and port settings on both the server and client side may cause the target omniNames service to be unreachable.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/devices/",
	"title": "Working with Devices",
	"tags": [],
	"description": "",
	"content": "Devices in REDHAWK are generally used as proxies for hardware. As such, devices can be used to interact with the physical world, to run a component, or to interface with FPGAs.\n Using Devices to Interact with Hardware    Creating an FEI Device in the IDE     Interacting with an FEI Device with the Python Package     Using an FEI Device in the IDE      Associating a Waveform with an FEI Device     Using Devices to Run Components     Using Devices to Interface with FPGAs     Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators     Miscellaneous FrontEnd Tuner Library Implementation Details     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/component-structure/working-with-events/",
	"title": "Working with Events",
	"tags": [],
	"description": "",
	"content": " In addition to using message event Properties and message Ports, the REDHAWK library enables developers to interface with Event Channels to send and receive non-REDHAWK structured messages using the CORBA Any object. The library provides both Publisher and Subscriber interfaces for sending and receiving data. The libraries make use of existing marshaling and unmarshaling support for simple data types (i.e., int, float, string, etc.), REDHAWK Core Framework event messages, and defined structured messages used by your Component. For custom structured data, it is the developer’s responsibility to implement the marshaling and unmarshaling methods into and out of a CORBA Any or serialize the data structure into string type that can be marshaled. This API is considered an advanced topic to support custom behavior using CORBA’s Event Channels.\nPublisher Support To publish data to an Event Channel, the Publisher role provides the following method:\n push - Accepts data to forward to an Event Channel. For C++, structured data types require the overload of \u0026ldquo;operator\u0026lt;\u0026lt;=\u0026ldquo;. For Python and Java, structured data should be marshaled into the CORBA Any object.  C++ Example of Publisher Component.h struct MsgData { int id; std::string data; }; redhawk::events::ManagerPtr ecm; redhawk::events::PublisherPtr pub; Component.cpp Component::constructor { // get access to the Event Channel Manager  ecm = redhawk::events::GetManager( this ); // request a Publisher object for an Event Channel  if ( ecm ) { pub = ecm-\u0026gt;Publisher(\u0026#34;test1\u0026#34;); } } // required to marshall data into the CORBA::Any void operator\u0026lt;\u0026lt;=( CORBA::Any \u0026amp;any, const MsgData \u0026amp;msg ) { // marshall MsgData to Any }; Component::serviceFunction { // create a structured message  MsgData my_msg = generateMsg(); if ( pub ) { pub-\u0026gt;push( my_msg); } // or simple text based messages  if ( pub ) pub-\u0026gt;push( \u0026#34;simple message to send\u0026#34; ); } Python Example of Publisher Component.py from omniORB import CORBA, any from ossie.events import Manager class MsgData(object): def __init__(self): self.id = 0; self.data = \u0026#34;\u0026#34; # convert message to a dictionary def encode(self): return { \u0026#39;id\u0026#39;, : self.id, \u0026#39;data\u0026#39; : self.data } class Component: def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ); if self.ecm: # request a Publisher object for an Event Channel self.pub = self.ecm.Publisher(\u0026#34;test1\u0026#34;); def process(self): msgdata = self.generateMsgData() if self.pub: self.pub.push( msgdata.encode() ) // or simple text based messages if self.pub : self.pub.push( \u0026#34;simple text message\u0026#34;); Java Example of Publisher Component.java // add required imports import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Publisher; // add members to your component\u0026#39;s class private org.ossie.events.Manager ecm; private org.ossie.events.Publisher pub; public class MsgData { public int id; public String data; } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if (this.pub == null ) { this.pub = ecm.Publisher(\u0026#34;test1\u0026#34;); } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle registration error  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle registration error  } } catch( org.ossie.events.Manager.OperationFailed e) { logger.error( e.getMessage()); } } public void encodeMsg(Any a, MsgData msg) { // perform encoding of msg to CORBA any,  } protected int serviceFunction() { MsgData msg = generateMsg(); if ( this.pub != null ) { try { this.pub.push( encodeMsg( msg ) ); } catch( Exception ex ) { // handle exception  } } } Subscriber Support The Subscriber role provides two modes (polling vs callback), for receiving data from an Event Channel. Both methods require the developer to unmarshal data from a CORBA Any. For C++, structured data types require the overload of \u0026ldquo;operator\u0026gt;\u0026gt;=\u0026rdquo;. For Python and Java, structured data should be unmarshaled from the CORBA Any object.\n getData - (polling) Grab a message from the Event Channel. If no messages are available then return -1. For Python, a CORBA Any is returned or None for no messages available.\n callback - Provide a callback to the Subscriber object. As data arrives from the Event Channel, this callback is notified.\n  Example of C++ Subscriber Role Using getData Method Component.h Polling Example redhawk::events::ManagerPtr ecm; redhawk::events::SubscriberPtr sub; struct MsgData { int id; std::string data; }; Component.cpp Polling Example // required to unmarshall data from the CORBA::Any bool operator\u0026gt;\u0026gt;=( const CORBA::Any \u0026amp;any, const MsgData *\u0026amp;msg ) { //unmarshall Any into MsgData }; Component::constructor { // get access to the Event Channel Manager  ecm = redhawk::events::GetManager( this ); // request a Subscriber object for an Event Channel  if ( ecm ) { sub = ecm-\u0026gt;Subscriber(\u0026#34;test1\u0026#34;); } } Component::serviceFunction { MsgData msgin; if ( sub \u0026amp;\u0026amp; sub-\u0026gt;getData( msgin ) == 0 ) { RH_NL_INFO(\u0026#34;mylogger\u0026#34;, \u0026#34;Received msg =\u0026#34; \u0026lt;\u0026lt; msgin.id); } } Example of C++ Subscriber Role Using callback Method Component.h Callback Example redhawk::events::ManagerPtr ecm; redhawk::events::SubscriberPtr sub; struct MsgData { int id; std::string data; }; void my_msg_cb( const CORBA::Any \u0026amp;data ); Component.cpp Callback Example // required to unmarshall data from the CORBA::Any bool operator\u0026gt;\u0026gt;=( const CORBA::Any \u0026amp;any, const MsgData *\u0026amp;msg ) { //unmarshall Any into MsgData }; void Component::my_msg_cb( const CORBA::Any \u0026amp;data ) { // structure msg  MsgData msg; if ( data \u0026gt;\u0026gt;= msg ) { LOG_INFO( Component, \u0026#34;Received message \u0026#34; \u0026lt;\u0026lt; msg.id ); } } Component::constructor { // get access to the Event Channel Manager  ecm = redhawk::events::GetManager( this ); // request a Subscriber object for an Event Channel  if ( ecm ) { sub = ecm-\u0026gt;Subscriber(\u0026#34;test1\u0026#34;); sub-\u0026gt;setDataArrivedListener( this , \u0026amp;Component::my_msg_cb ); } } Example of Python Subscriber Role Using getData Method Component.py Polling Example from ossie.events import Manager from omniORB import CORBA, any class MsgData(object): def __init__(self): self.id = 0 self.data = \u0026#34;\u0026#34; def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ) if self.ecm: # request a Subscriber object for an Event Channel self.sub = self.ecm.Subscriber(\u0026#34;test1\u0026#34;) def decodeMsg(self, raw ): # unpack message back into mdict = any.from_any(raw) ret = MsgData() ret.id = mdict[\u0026#39;id\u0026#39;] ret.data = mdict[\u0026#39;data\u0026#39;] return ret def process(self): if self.sub: raw = self.sub.getData() if raw: msgin = self.decodeMsg(raw) self._log.info(\u0026#34;Received message = \u0026#34; +str(msgin.id)) Example of Python Subscriber Role Using callback Method Component.py Callback Example # Callback snippet example, define in Component.py from ossie.events import Manager from omniORB import CORBA, any class MsgData(object): def __init__(self): self.id = 0 self.data = \u0026#34;\u0026#34; def msg_cb(self, data): if data: # unpack message back into mdict = any.from_any(data) msg = MsgData() msg.id = mdict[\u0026#39;id\u0026#39;] msg.data = mdict[\u0026#39;data\u0026#39;] # do something with msg def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ); if self.ecm: # request a Subscriber object for an Event Channel self.sub = self.ecm.Subscriber(\u0026#34;test1\u0026#34;) self.sub.setDataArrivedCB( self.msg_cb ) Example of Java Subscriber Role Using getData Method Component.java Polling Example // add required imports  import org.omg.CORBA.Any; import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Subscriber; // add members to your component\u0026#39;s class  private org.ossie.events.Manager ecm; private org.ossie.events.Subscriber sub; public class MsgData { public int id; public String data; } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if ( this.sub == null ) { this.sub = ecm.Subscriber(\u0026#34;test1\u0026#34;); } } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle exceptions  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle exceptions  } } catch( org.ossie.events.Manager.OperationFailed e) { // handle exceptions  } } public void decodeMsg( org.omg.CORBA.Any any, MsgData msg ) { // decode message from CORBA.Any;  } protected int serviceFunction() { if ( this.sub != null ) { if ( this.sub.getData( any ) == 0 ) { MsgData msg = new MsgData(); decodeMsg( any, msg ); logger.info(\u0026#34;Received message = \u0026#34; + msg.id); } } } Example of Java Subscriber Role Using callback Method Component.java Callback Example // add required imports import org.omg.CORBA.Any; import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Subscriber; import org.ossie.events.Subscriber.DataArrivedListener; // add members to your component\u0026#39;s class private org.ossie.events.Manager ecm; private org.ossie.events.Subscriber sub; public class MsgData { public int id; public String data; } public class MsgArrived implements DataArrivedListener { public Component parent=null; public MsgArrived ( Component inParent ) { parent = inParent; } public void processData( final Any data ) { // decode message from CORBA.Any;  // do something with the message  } } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if ( this.sub == null ) { this.sub = ecm.Subscriber(\u0026#34;test1\u0026#34;); this.my_ch = new MsgArrived(this); this.sub.setDataArrivedListener(this.my_cb ); } } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle exceptions  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle exceptions  } } catch( org.ossie.events.Manager.OperationFailed e) { // handle exceptions  } }"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/connection-callbacks/",
	"title": "Connection Callbacks",
	"tags": [],
	"description": "",
	"content": " Within a component, many of the Uses ports classes in REDHAWK support notification when a connection is made or broken. The supported port types and syntax vary by language.\nC++ In C++, the connection notification mechanism is standardized for BulkIO, BurstIO, and Messaging Uses ports in C++. Connect and disconnect callbacks are registered with the port.\nThe following examples assume a C++ component with a BulkIO float output port, dataFloat_out; however, the syntax is the same for BurstIO and Message ports.\nIn the component header file, declare the callbacks as private member functions. Both connect and disconnect callbacks receive a single argument, the connection ID (a std::string by reference):\nvoid dataFloatConnected(const std::string\u0026amp; connectionId); void dataFloatDisconnected(const std::string\u0026amp; connectionId); In the component source file, implement the callback functions:\nvoid MyComponent_i::dataFloatConnected(const std::string\u0026amp; connectionId) { LOG_INFO(MyComponent_i, \u0026#34;New connection \u0026#34; \u0026lt;\u0026lt; connectionId \u0026lt;\u0026lt; \u0026#34; on dataFloat_out\u0026#34;); } void MyComponent_i::dataFloatDisconnected(const std::string\u0026amp; connectionId) { LOG_INFO(MyComponent_i, \u0026#34;Disconnected \u0026#34; \u0026lt;\u0026lt; connectionId \u0026lt;\u0026lt; \u0026#34; on dataFloat_out\u0026#34;); } Then, in the component constructor(), register the callback functions:\ndataFloat_out-\u0026gt;addConnectListener(this, \u0026amp;MyComponent_i::dataFloatConnected); dataFloat_out-\u0026gt;addDisconnectListener(this, \u0026amp;MyComponent_i::dataFloatDisconnected); addConnectListener() and addDisconnectListener() take two arguments: the target object (typically this) and a pointer to a member function.\nIt is not necessary to register both a connect and disconnect callback.\n Java In Java, BulkIO and BurstIO Uses ports support connection notification using the listener pattern. The recommended style for Java connection notification is to define the callbacks as private methods on the component class, and use an anonymous subclass of the listener interface to dispatch the notifications to your callbacks.\nMessage ports do not support connection notification in Java.\nBulkIO BulkIO connection notification uses the bulkio.ConnectionEventListener interface, which has connect() and disconnect() methods that are called when the port makes or breaks a connection, respectively. Both methods receive a single argument, the connection ID (a string).\nAdd to the list of imports:\nimport bulkio.ConnectionEventListener; Implement the callbacks as methods on the component class:\nprivate void dataFloatConnected(String connectionId) { this._logger.info(\u0026#34;New connection \u0026#34; + connectionId + \u0026#34; on dataFloat_out\u0026#34;); }private void dataFloatDisconnected(String connectionId) { this._logger.info(\u0026#34;Disconnected \u0026#34; + connectionId + \u0026#34; on dataFloat_out\u0026#34;); } In the constructor() method, register a ConnectionEventListener to dispatch connect and disconnect notifications to your callbacks:\nport_dataFloat_out.setConnectionEventListener(new ConnectionEventListener() { public void connect(String connectionId) { MyComponent.this.dataFloatConnected(connectionId); } public void disconnect(String connectionId) { MyComponent.this.dataFloatDisconnected(connectionId); } }); BurstIO BurstIO connection notification is similar to BulkIO but with a different listener interface, burstio.ConnectionListener. The connect and disconnect methods are named portConnected() and portDisconnected(), respectively.\nAdd to the list of imports:\nimport burstio.ConnectionListener; Implement the callbacks as methods on the component class:\nprivate void burstFloatConnected(String connectionId) { this._logger.info(\u0026#34;New connection \u0026#34; + connectionId + \u0026#34; on burstFloat_out\u0026#34;); }private void burstFloatDisconnected(String connectionId) { this._logger.info(\u0026#34;Disconnected \u0026#34; + connectionId + \u0026#34; on burstFloat_out\u0026#34;); } In the constructor() method, register a ConnectionListener to dispatch connect and disconnect notifications to your callbacks:\nport_burstFloat_out.addConnectionListener(new ConnectionListener() { public void portConnected(String connectionId) { MyComponent.this.burstFloatConnected(connectionId); } public void portDisconnected(String connectionId) { MyComponent.this.burstFloatDisconnected(connectionId); } }); Python In Python, only BurstIO Uses ports support connection notification.\nBurstIO Implement the callbacks as methods on the component class. Both methods receive a single argument, the connection ID (a string):\ndef burstFloatConnected(self, connectionId): self._log.info(\u0026#39;New connection %son burstFloat_out\u0026#39;, connectionId) def burstFloatDisconnected(self, connectionId): self._log.info(\u0026#39;Disconnected %son burstFloat_out\u0026#39;, connectionId) In the constructor() method, register the callbacks:\nself.port_burstFloat_out.addConnectListener(self.burstFloatConnected) self.port_burstFloat_out.addDisconnectListener(self.burstFloatDisconnected) It is not necessary to register both a connect and disconnect listener.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/data-list-statistics-view/",
	"title": "Data List and Statistics Views",
	"tags": [],
	"description": "",
	"content": " The Data List and Statistics views are designed for simple runtime debugging of component ports.\n To open the Data List view, right-click a port of a started component.\nPort Context Menu  From the context menu, select Data List.\nThe Data List View is opened:\nData List View  Select the preferred capture type:\n Number of Samples: Select a sample size Indefinitely: Collect until the user stops the process.  Select the Number of Dimensions of the sample data:\n Real Complex any positive integer number of dimensions  Click Start Acquire.\nAfter all desired samples have been acquired and displayed in the Data List table, two additional options are displayed:\n Save Chart  To open a wizard and write the data to a Midas BLUE file or a binary file, click Save.\n To open the Statistics view, which features a histogram and basic statistics of the sample data, click Chart:\nStatistics View  There are two ways to change the dimensions displayed in the Statistics View:\n In the Data List view, click the column headers. In the Statistics view, click View Menu and select Settings. This opens the Chart Options dialog. In the Chart Options dialog, change the categories displayed in the chart:\nStatistics View Chart Options The chart and basic statistics refresh with each new collection of data in the Data List view.\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/events/",
	"title": "Events",
	"tags": [],
	"description": "",
	"content": " Events are heavily leveraged by REDHAWK to provide system awareness and exchange both synchronous and asynchronous data. This chapter describes the mechanics of creating and consuming Events as well as standard Event types defined in REDHAWK and how they are used. The methodology used to exchange synchronous and asynchronous data, although reliant on Events as the communications mechanism, is discussed in Messaging.\nEvent Definition CORBA defines an interface for the transport of Events as well as an interface for the creation of Event Channels that can support a publish/subscribe pattern; within REDHAWK, publishers are often described as producers, and subscribers are often described as consumers.\nIn REDHAWK, an Event is defined as the payload sent on a single call to the push() function in the PushConsumer interface of the CosEventComm IDL module.\nThe PushConsumer interface is as follows:\ninterface PushConsumer { void push (in any data) raises(Disconnected); void disconnect_push_consumer(); }; The description of the Event Channel interface and its use is complicated but luckily unnecessary for the use of Events in REDHAWK. The main thing to be aware of regarding channels is that they provide a logical association between a plain text string (channel name) and an object that implements the interfaces necessary to interconnect producers and consumers, CosEventChannelAdmin::EventChannel. The EventChannel interface allows a producer or consumer to register itself with the Event Channel. This registration process gives the producer a reference to a virtual consumer where Events can be pushed (recall that at the end of the day, CORBA is just an RPC mechanism). The registration process allows the consumer to give a reference to itself to a virtual producer, so that when an Event becomes available, the correct function is invoked in the consumer. It is the job of the implementer of the Event Channel interface, also known as an Event Service, to maintain the registration interface as well as the different virtual producers and consumers necessary to re-direct all Events to their appropriate destinations. The program omniEvents implements the Event Channel interface and enables the publish/subscribe pattern as described above; REDHAWK uses omniEvents as its Event Service.\nAn interesting aspect of the EventChannel interface is that there is no reason why that interface is implemented on a single central Event broker. It is possible to create a consumer that implements both a consumer interface and the Event Channel interface. This allows that consumer to consume Events either directly from a producer or indirectly through an Event Service. While a central Event broker like omniEvents allows for the fluid addition of producers and consumers into the domain, the inherent latency to the distribution of the Event can be significant (a single call for the publishing of the Event, an intermediate process queuing that Event, and then one or more pushes for the distribution of the Event to one or more consumers). On the other hand, a point-to-point connection between a producer and a consumer removes the intermediary broker and enables low-latency messaging between components. In REDHAWK, low-latency point-to-point Events are used only on messages, which are described in Messaging.\nStandard REDHAWK Events REDHAWK has defined several standard Event types that can be used to monitor the overall state of a domain or individual components. The system management Events are sent over the domain management channels. Individual component Events are associated with property changes.\nREDHAWK defines an Outgoing Domain Management (ODM) channel as well as an Incoming Domain Management (IDM) channel. The ODM channel contains Events that are generated by the Domain Manager which indicate the addition or removal of entities to and from the domain. The IDM channel contains Events that are generated by devices which indicate changes in the state of a device.\nODM Channel The ODM channel contains Event types used to describe the addition or removal of objects from the domain:\nstruct DomainManagementObjectAddedEventType { string producerId; string sourceId; string sourceName; StandardEvent::SourceCategoryType sourceCategory; Object sourceIOR; };struct DomainManagementObjectRemovedEventType { string producerId; string sourceId; string sourceName; StandardEvent::SourceCategoryType sourceCategory; }; Either Event contains information as to who had something added/removed to/from it, the ID of the entity that was added/removed, the name of the entity that was added/removed, and the category of item that was added/removed. In the case of an added object, the IOR (stringified pointer to the object) is included in the Event.\nThe category of item that was added or removed is of type SourceCategoryType, which is defined as:\nenum SourceCategoryType { DEVICE_MANAGER, DEVICE, APPLICATION_FACTORY, APPLICATION, SERVICE }; The ODM channel can also contain an Event type used to describe the state change of a resource, like an application:\nstruct ResourceStateChangeEventType { string sourceId; string sourceName; ExtendedEvent::ResourceStateChangeType stateChangeFrom; ExtendedEvent::ResourceStateChangeType stateChangeTo; } where ExtendedEvent::ResourceStateChangeType is defined as:\nenum ResourceStateChangeType { STOPPED, STARTED } IDM Channel The IDM channel can contain a StateChangeEventType Event or a AbnormalComponentTerminationEventType Event. The StateChangeEventType Event is defined as:\nstruct StateChangeEventType { string producerId; string sourceId; StandardEvent::StateChangeCategoryType stateChangeCategory; StandardEvent::StateChangeType stateChangeFrom; StandardEvent::StateChangeType stateChangeTo; }; The producerId and sourceId of the Event type are redundant; they are both the id of the device that is issuing the Event.\nThe StateChangeCategoryType and StateChangeType are:\nenum StateChangeCategoryType { ADMINISTRATIVE_STATE_EVENT, OPERATIONAL_STATE_EVENT, USAGE_STATE_EVENT }; enum StateChangeType { LOCKED, UNLOCKED, SHUTTING_DOWN, ENABLED, DISABLED, IDLE, ACTIVE, BUSY }; The two enumerated types are closely linked; an ADMINISTRATIVE_STATE_EVENT can only contain states LOCKED, UNLOCKED, and SHUTTING_DOWN, while an OPERATIONAL_STATE_EVENT can only contain states ENABLED and DISABLED, and a USAGE_STATE_EVENT can only contain states IDLE, ACTIVE, or BUSY.\nThe AbnormalComponentTerminationEventType Event is defined as:\nstruct AbnormalComponentTerminationEventType { string deviceId; string componentId; string applicationId; }; This Event is triggered when a component abnormally terminates. The Event contains the device ID that is producing the Event, the component ID that terminated abnormally, and the application ID that hosts that component.\nProperty Change Events Whenever a property changes on a component or device, either through the internal update of the component property or through an external configuration update, an event can be triggered. Any consumer can be registered onto any component or device to listen to any arbitrary set of properties that the component or device may have.\nThe event type is PropertyChangeEvent, which is defined as:\nstruct PropertyChangeEvent { string evt_id; string reg_id; string resource_id; CF::Properties properties; }; Consuming Events Event consumption is meant as a system-level monitoring process. Therefore, REDHAWK does not include component ports that allow the consumption of these Events. To monitor Events over a given channel, a simple API is available. The Domain Manager contains the function registerWithEventChannel() to register a consumer to a given channel and unregisterFromEventChannel() to unregister a consumer from an Event Channel.\nA command-line tool is available that registers with Event Channels and displays the contents of the channel, eventviewer. The arguments to eventviewer are the name of the domain and the name of the channel.\nAn example of the use of eventviewer is described below:\n Start a Domain Manager:\nnodeBooter -D In a new terminal, attach the eventviewer to the domain’s ODM channel:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit In a new terminal, start a Device Manager:\nnodeBooter -d $SDRROOT/dev/nodes/DevMgr_localhost-localdomain/DeviceManager.dcd.xml On the Eventviewer terminal, the Device Manager and device registration are shown:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;,\u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_DeviceManager instance at 0x25160e0\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_AggregateExecutableDevice instance at 0x2d46638\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} Shutdown the Device Manager (Ctrl+C on the Device Manager terminal)\n On the Eventviewer terminal, the device and Device Manager unregistration is displayed:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_DeviceManager instance at 0x25160e0\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_AggregateExecutableDevice instance at 0x2d46638\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;,\u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} Writing Your Own Event Consumer  In CORBA’s Event API, messages are passed as an CORBA::Any type, so when the Event is consumed from an Event Channel, it arrives as a CORBA::Any type. The application eventviewer contains an example of how to create an Event consumer.\nThe consumer object is an object that implements the PushConsumer interface.\nIn Python, the definition of such a class is:\nclass Consumer_i(CosEventComm__POA.PushConsumer): def __init__(self): pass def push(self, data): event = any.from_any(data) print event def disconnect_push_consumer (self): pass In the above example, the call to any.from_any converts from a CORBA::Any type to a Python dictionary.\nAn object of the class Consumer needs to be instantiated and given to the Domain Manager. In Python, the easiest way to access a running domain is to use the REDHAWK runtime package (a thorough description of the REDHAWK runtime package is available in ); in the case of a domain called REDHAWK_DEV, the process needed to associate this consumer with the Event Channel is:\nfrom ossie.utils import redhawk _consumer = Consumer_i() channel_name = \u0026#39;ODM_Channel\u0026#39; registration_id = \u0026#39;some random string\u0026#39; dom = redhawk.attach(\u0026#39;REDHAWK_DEV\u0026#39;) dom.registerWithEventChannel(_consumer._this(), registration_id, channel_name) In the example shown above, the consumer is attached to the ODM_Channel on the domain REDHAWK_DEV. The registration id is some string that can be used to uniquely identify this registration.\nUsing this id, to unregister the code the following method is invoked:\ndom.unregisterFromEventChannel(registration_id, channel_name) Cleaning up the Event Service Sometimes the system will fail in ways that the Event Service (omniEvents) will no longer be synchronized with the domain. When this happens, two utilities have been included with REDHAWK to help understand the state of the Event Service and clean it up if necessary.\nThe first tool is eventl, which lists all of the Events that are currently being handled by the Event Service. The other tool is rmeventall, which cleans up all of the Event Channels that the Event Service is currently supporting.\nThe Event Channel Manager The Event Channel Manager provides a single point for creation and inspection of Event Channels on the domain. It also provides an interface for users to register publishers or subscribers to any of the available Event Channels.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/logging-config-plugin/",
	"title": "Logging Configuration Plugin",
	"tags": [],
	"description": "",
	"content": " The DomainManager may be extended to use a loadable library that can assist in the resolution of the LOGGING_CONFIG_URI parameter during application deployments. The following code and build files provide a template to build the loadable library: libossielogcfg.so.\nThe library should be installed in $OSSIEHOME/lib64 or $OSSIEHOME/lib depending on your hardware and operating system. If you choose to install the library in a different directory, you will need to add this path to LD_LIBRARY_PATH before starting the DomainManager. To enable this feature in the DomainManager, use the —useloglib option when launching the nodeBooter program.\nnodeBooter -D --useloglib LogConfigUriResolver Class and Example The LogConfigUriResolver class is the base class that your customized class will inherit. The class contains a single method get_uri, that will be used to resolve the logging configuration file location during deployment. The method accepts a single parameter path that describes the resource’s path in the Domain. The following list describes the different resource paths:\n Component\n syntax\nrsc:\u0026lt;DomainName\u0026gt;/\u0026lt;Application ID\u0026gt;/\u0026lt;Component\u0026#39;s Naming Service Name\u0026gt; example\nrsc:REDHAWK_DEV/TestWave_2/MyComp_4  Device\n syntax\ndev:\u0026lt;DomainName\u0026gt;/\u0026lt;Node ID\u0026gt;/\u0026lt;Device\u0026#39;s Naming Service Name\u0026gt; example\ndev:REDHAWK_DEV/Node_1/MyDevice_4  Service\n syntax\nsvc:\u0026lt;DomainName\u0026gt;/\u0026lt;Node ID\u0026gt;/\u0026lt;Service\u0026#39;s Naming Service Name\u0026gt; example\nsvc:REDHAWK_DEV/Node_1/MyRedis_3   Using this path, the customized code should return the location of a logging configuration file or an empty string (use current default resolution method). Logging configuration file locations should be formatted as follows:\n sca://path/to/config/file\nsca://logcfg/comp.log.cfg file:///absolute/path/to/config/file\nfile:///var/redhawk/sdr/dom/logcfg/comp.log.cfg  The following example code creates a custom resolver class that provides logging configuration files from the local SDRROOT directory (file:///var/redhawk/sdr/dom/logcfg/device.log.cfg). The macro MAKE_FACTORY allows the class to be dyamically loaded by the Domain Manager.\n/* * This file is protected by Copyright. Please refer to the COPYRIGHT file * distributed with this source distribution. * * This file is part of REDHAWK core. * * REDHAWK core is free software: you can redistribute it and/or modify it * under the terms of the GNU Lesser General Public License as published by the * Free Software Foundation, either version 3 of the License, or (at your * option) any later version. * * REDHAWK core is distributed in the hope that it will be useful, but WITHOUT * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License * for more details. * * You should have received a copy of the GNU Lesser General Public License * along with this program. If not, see http://www.gnu.org/licenses/. */ #include \u0026lt;ossie/logging/LogConfigUriResolver.h\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;sstream\u0026gt; class ossielogcfg : public ossie::logging::LogConfigUriResolver { public: ossielogcfg(); virtual ~ossielogcfg(); std::string get_uri( const std::string \u0026amp;path ); }; class CustomLogConfigResolver : public ossie::logging::LogConfigUriResolver { public: CustomLogConfigResolver() {}; virtual ~CustomLogConfigResolver(){}; /** get_uri Return a string object that will be passed to a resource on the command line as LOGGING_CONFIG_URI parameter. An empty string will be ignored by the DomainManager. @param path Path of the resource in the domain. for components, rsc:\u0026lt;domain name\u0026gt;/\u0026lt;application name\u0026gt;/\u0026lt;component naming service name\u0026gt; e.g. rsc:REDHAWK_DEV/TestWave_2/MyComp_4 for devices, dev:\u0026lt;domain name\u0026gt;/\u0026lt;node name\u0026gt;/\u0026lt;device\u0026#39;s naming service name\u0026gt; e.g. dev:REDHAWK_DEV/Node_1/MyDevice_4 for service, svc:\u0026lt;domain name\u0026gt;/\u0026lt;node name\u0026gt;/\u0026lt;service\u0026#39;s naming service name\u0026gt; e.g. svc:REDHAWK_DEV/Node_1/MyRedis_1 */ std::string get_uri( const std::string \u0026amp;path ) { std::string sdrroot(\u0026#34;\u0026#34;); if ( ::getenv(\u0026#34;SDRROOT\u0026#34;)){ sdrroot = ::getenv(\u0026#34;SDRROOT\u0026#34;); } if ( path.find(\u0026#34;dev:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/device.log.cfg\u0026#34;; return std::string(os.str()); } if ( path.find(\u0026#34;svc:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/serviceq.log.cfg\u0026#34;; return std::string(os.str()); } if ( path.find(\u0026#34;rsc:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/comp.log.cfg\u0026#34;; return std::string(os.str()); } // an empty string return value will be ignored by the DomainManager  return std::string(\u0026#34;\u0026#34;); }; }; MAKE_FACTORY(CustomLogConfigResolver); Build Files Use the following build files to compile and build the above example code in a file called ossielogcfg.cpp. The compiled code produces a library called libossielogcfg.so that is installed in $OSSIEHOME/lib or $OSSIEHOME/lib64. The build process follows the same paradigm as standard REDHAWK generated software: reconf; configure; make install.\nreconf #!/bin/sh  rm -f config.cache [ -d m4 ] || mkdir m4 autoreconf -i configure.ac AC_INIT(ossielogcfg, 1.0.0) AM_INIT_AUTOMAKE([nostdinc foreign]) AC_CONFIG_MACRO_DIR([m4]) AC_PROG_CC AC_PROG_CXX AC_PROG_INSTALL AC_PROG_LIBTOOL AC_CORBA_ORB OSSIE_CHECK_OSSIE # TODO: Make this an installed macro OSSIE_SDRROOT_AS_PREFIX prefix=\u0026#34;${OSSIEHOME}\u0026#34; libdir=\u0026#34;${OSSIEHOME}/lib\u0026#34; AS_IF( [ test `uname -i` == \u0026#34;x86_64\u0026#34; ], [ libdir=\u0026#34;$prefix/lib64\u0026#34; ], [ libdir=\u0026#34;$prefix/lib\u0026#34; ] ) m4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])]) # Dependencies PKG_CHECK_MODULES([REDHAWK], [ossie \u0026gt;= 2.0]) OSSIE_ENABLE_LOG4CXX AX_BOOST_BASE([1.41]) AX_BOOST_SYSTEM AX_BOOST_THREAD AX_BOOST_REGEX AC_CONFIG_FILES([Makefile ]) AC_OUTPUT Makefile.am ACLOCAL_AMFLAGS = -I m4 -I${OSSIEHOME}/share/aclocal/ossie AUTOMAKE_OPTIONS = subdir-objects lib_LTLIBRARIES = libossielogcfg.la xmldir = $(prefix) dist_xml_DATA = distclean-local: rm -rf m4 libossielogcfg_la_SOURCES = ossielogcfg.cpp libossielogcfg_la_LIBADD = $(REDHAWK_LIBS) libossielogcfg_la_CPPFLAGS = -I . -I $(srcdir)/include $(REDHAWK_CFLAGS) $(BOOST_CPPFLAGS) bossielogcfg_la_CXXFLAGS = -Wall"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/services/",
	"title": "Services",
	"tags": [],
	"description": "",
	"content": " In the context of REDHAWK, infrastructure software is managed by the Device Manager. Infrastructure software can take two forms: hardware management and system services. System services are the equivalent to Linux services like an HTTP server; the service does not directly control hardware but is some facility that becomes automatically available when the host is started.\nManagement A service is managed through the Device Manager. Nodes are described as a Device Manager instance and the set of devices and services associated with that Device Manager instance. When the Device Manager instance is created, it reads its configuration file (dcd.xml), which contains a list of all devices and services that the node contains. The devices and services are forked as individual processes and remain running until the Device Manager is shut down. Devices are bound to the Naming Service under the Device Manager’s context. Services, on the other hand, are bound to the domain’s naming context.\nService API REDHAWK does not include any standard service interfaces; the SCA specification includes a logging service, but in REDHAWK, logging is performed through log4j/log4cxx.\nTo implement a service, it should use one of the standard REDHAWK interfaces, or a specialized interface to support some specific behavior. The specialized interface can be added using the SPD editor. The REDHAWK code generators provide the appropriate methods for the service’s selected interface. It is the developer’s task to implement the functionality of these methods. If the service is created with any of the following REDHAWK interfaces, LifeCycle: PropertySet, or PropertyEmitter, the same deployment behavior as used for a REDHAWK device is performed. That is, the Device Manager will try and call the service’s initializeProperties, initialize, and configure methods with the appropriate parameters.\nA service is created and torn-down by the Device Manager. Because there is no defined interface for the service, services do not support the LifeCycle interface, and more importantly, the releaseObject() method. Because there is no release method, the Device Manager issues operating-system level signals to terminate the Service. It is the developer’s task to perform whatever cleanup functionality is required in response to the receipt of a termination signal.\nFiles Defining a Service A service, much like a component or device, is a binary file and a set of XML descriptors, normally just the SPD (describing the service’s software package) and SCD (describing the service’s interfaces). The service file package resides in $SDRROOT/dev, usually in a services subdirectory or the devices subdirectory. More information can be found in the SPD editor section\nFinding a Service Application descriptor files (sad.xml) are described in The Runtime Environment; these files describe a logical collection of components that are deployed to support some system-level application. In the application descriptor file, connections between deployed entities can be described in a variety of ways. These connection descriptions are how an application, or more specifically a component in an application, can interact with a service.\nThe Find By feature enables users to find services through either their (globally unique) name or by the interface that they support. Using a globally unique name as the search key allows a developer to specify an single instance of a service to connect to. On the other hand, by searching for a service through its supported interface, a developer can create a generalized search for a service that satisfies a particular need, irrespective of how it is associated with the Domain.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/snapshot-tool/",
	"title": "Snapshot Tool",
	"tags": [],
	"description": "",
	"content": " The Snapshot Tool enables users to save data from any BulkIO port to a file. The following procedure explains how to use the Snapshot Tool.\n To open the Snapshot Wizard, right-click an output port in the Chalkboard or the REDHAWK Explorer and select Snapshot from the context menu:\nOutput Port Context Menu The Snapshot Wizard is displayed:\nSnapshot Wizard  To specify how much data is captured, select the capture mode from the first combo box. The following capture modes are supported:\n Number of Samples: Collects the number of samples specified by the text field to the right. Indefinitely: Collects samples until the user stops the snapshot or an end of stream occurs. Clock Time: Collects samples for a set period of time in real time set by the text field to the right (in seconds). Sample Time: Collects samples for a period of time as specified by the delta and number of samples (time = delta * number of samples), set in the text field to the right.  Optionally, enter a custom Connection ID in the Connection ID (Optional) field.\n To specify the the file type to use when saving data, select a file type from the File Type combo box. The supported file types include:\n Binary files (.bin \u0026amp; .SRI): Saves data from the port to a .bin file and saves the metadata (SRI, start time, end time, data type, and number of samples) to an .SRI file. Binary files (.bin \u0026amp; .xml): Saves data from the port to a .bin file and saves the metadata (SRI, start time, end time, data type, and number of samples) to an .xml file. Midas BLUE File (.tmp): Saves output data and metadata to a BLUE .tmp file.  To specify where to save the file, you have two options.\n To save the file to a location other than the workspace, deselect the Save to Workspace checkbox, click Browse, navigate to the desired location, and click OK. To save the file in the workspace, select the Save to Workspace checkbox and select the file or directory in the displayed tree of workspace files and folders. Saving the file in the workspace automatically refreshes the project, and the files can be accessed in the IDE.\nSnapshot Save to Workspace Navigation Tree To add folders to the workspace, right-click the existing folder where the new folder is desired. A New Folder window is displayed. Enter the name of the folder and click Finish.\nSnapshot New Folder Window To delete files from the workspace, right-click the item you want to delete and select Delete. When prompted, verify the deletion request.\n  To be prompted before existing files are overwritten when the new snapshot is created, select the Confirm overwrite checkbox. If this option is not selected, any existing files are automatically overwritten when the new snapshot is created.\n Click Finish.\nThe progress view is displayed. To stop a snapshot prematurely, click Cancel Operation (the red square icon) next to the job in the progress view.\nSnapshot - Progress View When the snapshot completes, the completed job is shown in the progress view:\nSnapshot - Completed Job  To view the results of the snapshot, click Finished. The following output message is displayed:\nSnapshot - Results Dialog If only a few files are written, then the output message lists all the files created by the snapshot. If a large number of files are written, the output message lists the base name of the files and the number of each type of file made.\n Click OK.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/connect-wizard/",
	"title": "Connect Wizard",
	"tags": [],
	"description": "",
	"content": " The Connect Wizard enables users to manually create a connection between two ports of compliant types and create a custom connection ID. The following procedure explains how to use the Connect Wizard.\n To open the Connect Wizard, in the Chalkboard or the REDHAWK Explorer, right-click a port and select Connect from the context menu:\nPort Context Menu in REDHAWK Explorer The Connect Wizard is displayed:\nConnect Wizard  Under Source, select a uses (output) port.\n Under Target, select a provides (input) port, or a resource such as a component or device.\n In the Connection ID text box, enter a connection ID.\n Click Finish.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/connections/custom-idl-interfaces/",
	"title": "Custom IDL Interfaces",
	"tags": [],
	"description": "",
	"content": " REDHAWK provides FEI and standard CF interfaces (like CF::Resource) to control entities and promote interoperability. There are some use cases where you may find the need to use custom IDL to control entities. For these use cases, you can create custom IDL projects in the IDE.\nAdding ports from either the FEI interface or a custom IDL interface to a component or device allows that entity to control other entities through CORBA. Because of the generic nature of these ports, it is not possible to create a language mapping like BulkIO, so interaction is through the standard CORBA API, a full description of which is outside the scope of this manual. However, the REDHAWK code generators will generate ports that simplify the interaction with the port. The following sections explain uses (output) ports because they are the most likely to be generated, for example, to control FEI devices.\nConnectivity Feedback In all three supported languages, an FEI, standard CF, or custom IDL port will have all methods and attributes mapped to the port, and the port will then delegate the call to the remote connection. In REDHAWK, it is possible for a port to have no connections, one connection, or many connections. Each of these conditions can create issues for someone using a port for communications; for example, if a control request is sent out and there are no connections, then the user should be informed that the request did not go anywhere.\nAt the same time, not all methods are the same. Some methods push data in only one direction, some methods have a return value, and some methods have arguments that are pointers to be filled with information (out or inout arguments). When a port method is called and it is not possible for the port to make a call or for the call to be unambiguous (for example, if two connections exist and the function contains a return value), then a PortCallError is raised in the user code. The table below describes the method signature criteria met and its corresponding behavior.\nControl method and error conditions based on connectivity    method signature no connection one connection many connections     No return value, only in Error ok ok   Has return value Error ok Error   has inout Error ok Error   has out Error ok Error    If a method has any kind of return value as part of its non-exception API (manifested as a non-void return value, or an out or inout argument), then an exception is raised if there is more than one connection out of the port. Furthermore, if a call is attempted with no connection in effect, an error is raised.\nConnection Selection While the generated port class triggers an error when the desired connection is ambiguous, it also contains an API to allow the developer to select which connection should be exercised. Each method has an optional argument, connection_id, that allows the caller to disambiguate which connection should be exercised. The default value behavior will use the last connection made. If the connection_id specified does not exist, a PortCallError will be raised.\nIn the following sections, the same pattern used to disambiguate the connections is provided in all three supported languages.\n The following code example uses the default behavior when calling the read method of the CF::File interface.\nCF::OctetSequence_var _data = new CF::OctetSequence(); CF::OctetSequence_out data(_data); this-\u0026gt;file_out-\u0026gt;read(data, 10); // read 10 characters from the last connection made to the port The following code example disambiguates the read call to a specific connection, connection1.\nCF::OctetSequence_var _data = new CF::OctetSequence(); CF::OctetSequence_out data(_data); this-\u0026gt;file_out-\u0026gt;read(data, 10, \u0026#34;connection1\u0026#34;); // read 10 characters from the connection called \u0026#34;connection1\u0026#34; To view the connections that are available, use the following code:\nstd::vector\u0026lt;std::string\u0026gt; _connection_ids = this-\u0026gt;file_out-\u0026gt;getConnectionIds(); Method Mapping Method name mapping follows the pattern described in Connection Selection; namely that methods have the same name as described in the IDL with an additional argument (to be optionally exercised) that can specify which connection should be used. Attributes are mapped as functions to the CORBA objects. REDHAWK provides additional APIs to disambiguate these calls for multiple connections.\nReading Attributes Reading attributes is performed by invoking the name of the attribute as a function. For example, if the port, my_port, contains the string attribute greeting, the value of greeting can be retrieved as follows:\nstd::string _greeting = this-\u0026gt;my_port-\u0026gt;greeting(); To retrieve the value from a specific connection, the _get_ prefix is needed:\nstd::string _greeting = this-\u0026gt;my_port-\u0026gt;_get_greeting(\u0026#34;some_connection_name\u0026#34;); Writing Attributes Writing attributes in C++ and Java involves invoking the function with the appropriate argument:\nthis-\u0026gt;my_port-\u0026gt;greeting(\u0026#34;hello\u0026#34;); // write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34;  this-\u0026gt;my_port-\u0026gt;greeting(\u0026#34;hello\u0026#34;, \u0026#34;some_connection_name\u0026#34;); // write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; over connection \u0026#34;some_connection_name\u0026#34; Python requires the prefix _set_ because it cannot be overloaded:\nself.my_port._set_greeting(\u0026#34;hello\u0026#34;) # write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; self.my_port._set_greeting(\u0026#34;hello\u0026#34;, \u0026#34;some_connection_name\u0026#34;) # write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; over connection \u0026#34;some_connection_name\u0026#34;"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/acronyms/",
	"title": "List of Acronyms",
	"tags": [],
	"description": "",
	"content": " AJAX  Asynchronous JavaScript and XML  API  Application Programming Interface  AST  Abstract Syntax Tree  BulkIO  Bulk Input/Output  BurstIO  Burst Input/Output  CDT  C/C++ Developer Tools  CentOS  Community Enterprise Operating System  CF  Core Framework  CORBA  Common Object Request Broker Architecture  CVS  Concurrent Versions System  DCD  Device Configuration Descriptor  DCE  Distributed Computing Environment  DDC  Digital Down Converter  DMD  Domain Manager Configuration Descriptor  DPD  Device Package Descriptor  DSP  Digital Signal Processing  DTD  Document Type Definition  EFS  Eclipse File System  EMF  Eclipse Modeling Framework  EOS  End of Stream  EPEL  Extra Packages for Enterprise Linux  FEI  Front End Interfaces  FFT  Fast Fourier Transform  FPGA  Field-programmable gate array  FM  Frequency Modulation  GMF  Graphical Modeling Framework  GPP  General Purpose Processor  GUI  Graphical User Interface  HTTP  Hyper Text Transport Protocol  IDE  Integrated Development Environment  IDM  Incoming Domain Management  IF  Intermediate Frequency  IOR  Interoperable Object Reference  ID  Identifier  IDL  Interface Description Language  JAR  Java ARchive  JDT  Java Developer Tools  JEE  Java Platform, Enterprise Edition  JTRS  Joint Tactical Radio System  MB  Megabyte  NOOP  No Operation  ODM  Outgoing Domain Management  OS  Operating System  OSGi  Open Services Gateway initiative  PDE  Plug-in Development Environment  PID  Process Identifier  POSIX  Portable Operating System Interface  PRF  Properties File  PSD  Power Spectral Density  PyDev  Python Development  RCP  Rich Client Platform  RF  Radio Frequency  RHEL  Red Hat Enterprise Linux  RPC  Remote Procedure Call  RPM  Red Hat Package Manager  SAD  Software Assembly Descriptor  SCA  Software Communications Architecture  SCD  Software Component Descriptor  SDR  Software-Defined Radio  SPD  Software Package Descriptor  SRI  Signal Related Information  SWT  Standard Widget Toolkit  UDP  User Datagram Protocol  UI  User Interface  URI  Uniform Resource Identifier  URL  Uniform Resource Locator  UUID  Universally Unique Identifier  VLAN  Virtual Local Area Network  VM  Virtual Machine  WAR  Web ARchive  XML  Extensible Markup Language  XSD  XML Schema Definition  UTC  Coordinated Universal Time  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/nodes/",
	"title": "Nodes",
	"tags": [],
	"description": "",
	"content": "In The Runtime Environment, the Device Manager is introduced along with its primary role: to deploy and manage device proxies in whatever host the Device Manager has been launched. The term Node is used to refer to the Device Manager and its associated devices and services.\nThe concept of a device and its relationship with the deployment of a set of components in an application is one of the more complicated concepts in REDHAWK. A device is a program that the Domain Manager interacts with to determine whether or not a component can run on the host where that device is located. If it is determined that the device can host that component, the device provides the Domain Manager with the API necessary to load the component binaries over the network and execute them. In short, the device provides the remote host discovery mechanism to the Domain Manager and the mechanism needed to load and execute whatever component files are needed to run the component on the device host.\nThis chapter provides a description of how to interact with devices and nodes using the REDHAWK IDE.\n Running a Node     Creating a New Node     Distributed Computing and RF Devices     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/port-monitor-view/",
	"title": "Port Monitor View",
	"tags": [],
	"description": "",
	"content": " The Port Monitor view enables you to monitor the amount of data flowing out of or in to a particular port. These link statistics are helpful when debugging and can help identify which component is slowing down or dropping information during data processing.\nTo open the Port Monitor view, right-click the port of a started component and select Monitor Ports from the context menu:\nPort Context Menu The Port Monitor view is opened:\nPort Monitor View with Monitor Ports Selected The View displays the following information:\n Name: The name of the port or port connection. Elements/sec: The rate of CORBA elements transferred in the pushPacket data call. mbps: Mega Bytes transferred per second. calls/sec: Number of push calls per second to the port. Stream ids: List of all active stream ids. Avg. Queue Depth: For components that queue data before processing/sending, the average queue depth measured as a percentage. If a port does not queue data, this value is set to zero. Time: The elapsed time, in seconds, since the last packet was transferred via a push packet call.  The following actions are available in the Port Monitor view.\n To Configure the Port Monitor view:\n Click the View Menu. Select Configure.  The Port Monitor Configuration dialog box is displayed.\nPort Monitor Configuration Dialog The following options can be configured:\n Refresh Interval (sec): The time interval between fetching the port statistics. Column Configuration: Specifies which columns are visible.  To force a refresh of any connection or port:\n Right-click the item. Select Refresh.  To stop monitoring:\n Right-click the item. Select Stop Monitoring.   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/sri-view/",
	"title": "SRI View",
	"tags": [],
	"description": "",
	"content": " The SRI View enables the user to view the SRI data from a particular port. The following procedure explains how to open the SRI View.\n To open the SRI View, right-click the port of a started component and select Display SRI from the context menu:\nPort Context Menu with Display SRI Selected The SRI View is opened:\nSRI View  The following options are available in the SRI View.\n To clear the display of specific SRI data once an EOS has been received, click Clear Selected SRI. To clear the display of all SRI data once the respective EOSs have been received, click Clear All SRIs. To pause the SRI data, click Pause Incoming SRI Data. To receive notification when new SRI data is displayed, click Notify on receiving new Push SRI. To change the active SRI data stream between different active components, click Change Active Stream. To generate both an .xml and a .SRI file for each stream being monitored, click Save SRI Data to file.   If a component is deleted from the Chalkboard, the SRI View closes automatically.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": "Components can run in either the sandbox or in a domain. The Sandbox is an environment to run components and devices without artifacts like a domain, device manager, name service, or event service.\nREDHAWK provides two sandboxes, a Python-based one or an IDE-based one. The Python-based sandbox can run from any Python session on any system with a REDHAWK install. The IDE-based sandbox can host an instance of a Python-based sandbox, with both interlinked, allowing artifacts from the Python environment to interact with those on the graphical UI.\n Python Sandbox    Working with Components, Devices, and Services     Helpers     Devices     Example Sandbox Interaction     Built-in Sources and Sinks     Working with SDDS Data     Plotting Data     Miscellaneous      IDE Sandbox     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/octave-wizard/",
	"title": "Using the Octave Wizard",
	"tags": [],
	"description": "",
	"content": " The Octave Wizard enables users to import existing Octave M-files for easy conversion into REDHAWK C++ components. The user imports an existing M-file, as well as any required dependent M-files, and then maps the M-file’s inputs and outputs to REDHAWK ports and properties. The following procedure explains how to use the Octave Wizard.\n To open the Octave Wizard, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard page is displayed:\nSelect a Wizard Dialog  Select REDHAWK Octave Project and click Next.\nThe Create a REDHAWK Component Project page is displayed:\nCreate a REDHAWK Component Project Page  In the Project name field, enter a project name and click Next.\nThe New Implementation page is displayed:\nNew Implementation Page  Enter an ID and a description for this component implementation and click Next.\nThe New M-File page is displayed:\nNew M-File Page  In the Primary M-file field, enter the location of the Octave M-file you want to import or click Browse and navigate to the file. If the primary M-file depends on non-standard methods, select Primary M-file depends on non-standard M-files and select the dependent M-files. Click Next.\nThe Map M-file page is displayed:\nMap M-file Page  The Map M-file page enables the user to map the Octave inputs and outputs to REDHAWK ports or properties. The Name/id field contains the names contained in the M-file. You have the following options for both Inputs and Outputs:\n In the Mapping field, select to map to either a Property (Simple), a Property (Sequence) or a port. In the Type field, select to map to either a String, a Double (Real) or Double (Complex) variable type.  Click Finish.\nThe Octave M-file based component is created.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/console-view/",
	"title": "Console View",
	"tags": [],
	"description": "",
	"content": "The Console view is a part of Eclipse and the basic use is well documented by the Eclipse documentation. The REDHAWK IDE uses multiple consoles for different purposes.\nThe primary consoles found in the REDHAWK IDE are:\n Domain \u0026amp; Device Manager: When a domain or Device Manager is launched, a new Console View is created. These new consoles contain an instance of a running nodeBooter. By default, log messages, standard out, and standard error messages for components and devices are written to the Device Manager console. Domain Manager related messages, including waveform creation and resource allocation are written to the Domain Manager’s console.\n C++ builds: Compiling a C++ device or component creates a C-build console, which runs the component/device build script. While Eclipse does a relatively good job of parsing build output and providing in-context error indicators, it is sometimes helpful to view the output of the build from the console.\n Code Generators: When automatically generating code for a component or device, the appropriate code generator console is displayed and contains information pertaining to the code generation.\n Python Sandbox: The Python Sandbox is a powerful tool for testing and interacting with components and devices. A Python Sandbox may be created from within the IDE to aid in testing.\n Other Consoles: Additional consoles (not described in this section) are available, including PyDev Scripting, Java Stack Trace, etc. These are part of Eclipse or part of third party plug-ins such as PyDev.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/plot-port-wizard/",
	"title": "Plot Port Wizard",
	"tags": [],
	"description": "",
	"content": " The Plot Port Wizard enables users to choose the settings for a plot before opening the Plot View. The following procedure explains how to use the Plot Port Wizard.\n In the REDHAWK Explorer or any running diagram (Chalkboard or Waveform running on a Domain), to open the Plot Port Wizard, select an output port, then right-click the selected port and select Plot Port \u0026hellip; from the context menu:\nPort Context Menu The Plot Port Wizard is displayed:\nPlot Port Wizard  Select a Type. The following types are available:\n DOT LINE POINT RASTER  Select a Mode. The following modes are available:\n Auto Imaginary Magnitude Phase Real Real and Imaginary Real vs Imaginary 10 Log 20 Log  Select a Frame Size. This enables you to override the value in StreamSRI, which is the default. You may choose one of the existing values or enter a custom value, for example, 16000.\n Optionally, enter a value for Refresh Rate (fps):. This enables you to perform smart thinning of the line plot based on screen frames per second. To disable smart thinning, enter 0. The default value of 30 fps will be used if the field is left blank.\n Optionally, enter a value for Line Plot Frame Thinning. You may thin the line plot by displaying 1 out of every n frames. For no thinning, enter -1. The default value of 8 will be used if the field is left blank.\n Optionally, in the Connection ID field, enter a custom Connection ID.\n To override the value in StreamSRI (the default), in the Sample Rate field, enter a custom sample rate.\n To select a blocking option for pushPacket when the plot is not able to keep up with the data stream, select one of the radio buttons in Blocking option:\n non-blocking - Do not block incoming data. blocking - Block incoming data. use SRI.blocking (default) - Set the blocking based on the StreamSRI.blocking field received from the pushSRI() call.  To remove the stream when an EOS is received, select the Remove Stream from Plot on End Of Stream checkbox.\n To plot an FFT of the signal, select the Take FFT checkbox. You have six options for the FFT:\n Select a Transform Size from the list or enter a custom value (Performance is best if the transform size is factorable by 2, 3, 4, and 5). Enter the Percent Overlap. Enter the Num Averages. Enter the Sliding Num Averages. Select the Output Type. The following types are available:\n Normal Magnitude Squared Power Spectral Density  Select a Window. The following windows are available:\n Bartlett Hanning Hamming Blackman-Harris Blackman   Click Finish.\n  The Plot View is displayed with the desired settings.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-environment/",
	"title": "The Runtime Environment",
	"tags": [],
	"description": "",
	"content": "The REDHAWK runtime environment provides a mechanism for managing the life cycle (creation/tear down/initialization) of components as well as the interconnection of deployed components.\nThe primary goal of the runtime environment is to support the necessary infrastructure to deploy and manage interconnected components as a running application.\nThe runtime environment is personified by two binaries, a Domain Manager program and a Device Manager program. The Domain Manager program hosts an instance of a DomainManager class as well as supporting objects (ApplicationFactory, Application, FileManager). The Device Manager program hosts an instance of a DeviceManager object and an instance of a File System. The only reason why the major classes making up these programs are imported is because their API is remotely available, so a user can arbitrarily interact with these objects. Irrespective of their API, these objects exclusively reside in either the Domain Manager or Device Manager programs.\nA single REDHAWK system instance has one Domain Manager and an arbitrary number of Device Managers. The Domain Manager’s role is as a central bookkeeper as well as a single point where applications can be deployed or torn down. A Device Manager is present in each host in the REDHAWK network area; in a purely processing context, there would be a single Device Manager in each computer that is intended to host running components. Each Device Manager has associated with it a set of devices that act as proxies for whatever hardware is running on the computer; in a purely processing context, there is a single device proxy describing the microprocessor for each hardware platform Device Manager.\nThe Domain Manager program:\n receives an XML file describing a waveform that is to be deployed. scans all running devices on all Device Managers for a suitable place to deploy the components making up the waveform. uses the File Manager / File System to copy whatever files are necessary to run the components to the target Device Managers. remotely invokes the component processes. interconnects components over the network. tears down applications appropriately.   Launching a Domain     Domain Manager     File System     Applications     The Application Factory     The Device Manager     The Allocation Manager     The Connection Manager     Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/editors-and-views/properties-view/",
	"title": "Properties View",
	"tags": [],
	"description": "",
	"content": " The Properties view provides the ability to view and edit properties of the current selection in the IDE. The view is context-specific, and will change based on the selection.\nProperties View "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/runtime-inspection/",
	"title": "Runtime Environment Inspection",
	"tags": ["sandbox"],
	"description": "",
	"content": " During runtime, there are a large number of operations that are handled under the hood by the REDHAWK Core Framework. At times though, it becomes necessary to take a closer look at these underlying parts to ensure that they are working properly or to inspect what kind of a state they are currently in. REDHAWK provides tools to help accomplish this task.\nREDHAWK Module A Python module called REDHAWK is provided with the capability to interact with running domains, devices, waveforms and components. This allows for individual control and assessment over all aspects of a runtime environment.\nIn order to use the REDHAWK utility module, begin a Python session from a terminal and enter the following command:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk The REDHAWK module is built on the same foundation as the Sandbox, and provides a compatible interface for domain objects. Sandbox objects, including plots, can be dynamically connected to devices, waveforms and components running in the domain.\nRefer to Working with Components, Devices, and Services for more information.\nAttach The module provides the ability to attach to a running domain.\nThis allows the user access to the underlying API of the Domain Manager in addition to other useful functionality: - createApplication() - install/create a particular waveform - removeApplication() - release a particular waveform\nTo attach to an existing domain, the name must be passed as an argument.\nAssuming the domain name is MY_DOMAIN, start a Python script and enter:\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach(\u0026#34;MY_DOMAIN\u0026#34;) Note that if there is only 1 Domain visible, no argument is needed for the attach call:\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() Once attached to the running domain, waveforms that are installed in the $SDRROOT can easily be launched using the createApplication() function:\n\u0026gt;\u0026gt;\u0026gt; wave = domain.createApplication(\u0026#34;/waveforms/wave/wave.sad.xml\u0026#34;) Upon success, the above call returns an Application object which gives access to the external resource API. This allows for manual operation of the application. In addition, functions exist to allow the user to connect and disconnect ports. Finally, in order to inspect the current conditions of the waveform, an API function call is available. This shows any external ports, components that are in the application, and their properties.\n\u0026gt;\u0026gt;\u0026gt; wave \u0026lt;ossie.utils.redhawk.core.App object at 0x2bfb350\u0026gt; \u0026gt;\u0026gt;\u0026gt; wave.api() Waveform [wave_025_090314360_1] --------------------------------------------------- External Ports ============== Provides (Input) Ports ============== Port Name Port Interface --------- -------------- external_in IDL:BULKIO/dataChar Uses (Output) Ports ============== Port Name Port Interface --------- -------------- external_out IDL:BULKIO/UsesPortStatisticsProvider Components ============== 1. Sink 2. Source (Assembly Controller) Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- sample_size (long/SL/32t) None None Once finished, the waveform needs to be removed from the domain by using the removeApplication() method:\n\u0026gt;\u0026gt;\u0026gt; domain.removeApplication(wave) Starting a Domain from within a Python session Normally, the REDHAWK Python package is used to either interact with a running domain, or to launch some Sandbox components. However, sometimes it may be required to launch a domain from a Python script.\nTo help in such a scenario, the REDHAWK Python package includes some helper functions. The kickDomain feature allows for an easy way to launch domain and Device Managers from within a Python script. With no arguments, the function launches and returns the Domain Manager that is installed in $SDRROOT. Additionally, all Device Managers in $SDRROOT/dev/nodes are started.\nOther arguments to the function exist to control different aspects to how the domain is started. A list of specific Device Managers to start can be passed if the user does not want to start all available. If the $SDRROOT that the user wishes to use is not in the standard location, a path can be supplied to direct the function to the desired place in the file system. Standard out and logging to a file can also be set.\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.kickDomain() INFO:DomainManager - Starting Domain Manager INFO:DeviceManager - Starting Device Manager with /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DomainManager - Starting ORB! INFO:DeviceManager_impl - Connecting to Domain Manager MY_DOMAIN/MY_DOMAIN INFO:DeviceManager - Starting ORB! \u0026gt;\u0026gt;\u0026gt; INFO:DCE:9d9bcc38-d654-43b1-8b74-1dc024318b6f:Registering Device INFO:DeviceManager_impl - Registering device GPP_localhost_ localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Initializing device GPP_localhost_ localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Registering device GPP_localhost_ localdomain on Domain Manager \u0026gt;\u0026gt;\u0026gt; domain \u0026lt;ossie.utils.redhawk.core.Domain object at 0x2da6710\u0026gt; The ability to search for domains is also available through the scan function which searches the Naming Service.\n\u0026gt;\u0026gt;\u0026gt; redhawk.scan() [\u0026#39;MY_DOMAIN\u0026#39;] Domain State The domain proxy tracks the current state of the domain. For aspects of the domain state that may take a long time to process, scanning is deferred until the first access. If the odm Channel is available, devices, Device Managers, and waveforms are tracked as they are added to and removed from the domain. Otherwise, the domain is re-scanned on access to ensure that the state is accurate.\nApplications The domain proxy provides a list of waveforms currently running via the apps attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.apps [\u0026lt;ossie.utils.redhawk.core.App object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The App class supports many of the Sandbox interfaces, such as properties, connect() and api().\nThe components within the waveform are available via the comps attribute:\n\u0026gt;\u0026gt;\u0026gt; app = domain.apps[0] \u0026gt;\u0026gt;\u0026gt; app.comps [\u0026lt;ossie.utils.redhawk.component.Component object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The REDHAWK module component class supports the same interfaces as Sandbox components. Much like in the Sandbox, ports, properties, and any other feature of a component is equally accessible from the Python environment, regardless of how the component was deployed.\nFor example, if one were to want to plot the output of a component running on the Domain:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk, sb \u0026gt;\u0026gt;\u0026gt; dom=redhawk.attach() \u0026gt;\u0026gt;\u0026gt; for app in dom.apps: ... if app.name == \u0026#34;my_app\u0026#34;: ... break \u0026gt;\u0026gt;\u0026gt; for comp in app.comps: ... if comp.name == \u0026#34;my_comp\u0026#34;: ... break \u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; plot.start() \u0026gt;\u0026gt;\u0026gt; comp.connect(plot) Device Managers The domain proxy provides a list of Device Managers registered with the domain via the devMgrs attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devMgrs [\u0026lt;ossie.utils.redhawk.core.DeviceManager object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] Each Device Manager maintains a list of its devices, accessible via the devs attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devMgrs[0].devs [\u0026lt;ossie.utils.redhawk.device.ExecutableDevice object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] Devices The domain proxy provides a list of all devices registered with the domain via the devices attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devices [\u0026lt;ossie.utils.redhawk.device.ExecutableDevice object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The device list is the concatenation of the devices for all Device Managers.\nThe REDHAWK module device class supports the same interfaces as Sandbox devices.\nEvent Channels Event Channels can be accessed through the eventChannels member of the domain object. Each of the returned objects contains the name of the channel and a reference to the channel object.\n\u0026gt;\u0026gt;\u0026gt; evt = dom.eventChannels \u0026gt;\u0026gt;\u0026gt; evt[0].name ODM_Channel \u0026gt;\u0026gt;\u0026gt; evt[0].ref \u0026lt;CosEventChannelAdmin._objref_EventChannel object at 0x1608550\u0026gt; Event Channels can be created through the Event Channel Manager:\n\u0026gt;\u0026gt;\u0026gt; channel = dom.eventChannelMgr.create(\u0026#34;TestChan\u0026#34;) Subscribers and publishers to event channels can also be created in the Python Sandbox. They can be created as entities in the Python environment, with the constructor argument being the channel that they are to publish or subscribe to.\n\u0026gt;\u0026gt;\u0026gt; from ossie.events import Subscriber, Publisher \u0026gt;\u0026gt;\u0026gt; def my_callback(data): print data \u0026gt;\u0026gt;\u0026gt; sub=Subscriber(evt[0], dataArrivedCB=callback) \u0026gt;\u0026gt;\u0026gt; pub=Publisher(evt[0]) \u0026gt;\u0026gt;\u0026gt; pub.push(data) Managing Allocations The domain has an Allocation Manager that allows the developer to offload some of the bookkeeping tasks associated with capacity allocation. Interactions with the Allocation Manager are exercised through requests and responses. The Allocation Manager responds to requests by searching through all available devices to find Devices that can satisfy the request. An example of interactions with the Allocation Manager follows:\n\u0026gt;\u0026gt;\u0026gt; am = dom.allocationMgr \u0026gt;\u0026gt;\u0026gt; from ossie.utils import allocations \u0026gt;\u0026gt;\u0026gt; prop = allocations.createProps({\u0026#39;s_prop\u0026#39;:{\u0026#39;s_prop::a\u0026#39;:\u0026#39;hello\u0026#39;,\u0026#39;s_prop::b\u0026#39;:5}}) \u0026gt;\u0026gt;\u0026gt; request = am.createRequest(\u0026#39;request id\u0026#39;, prop) \u0026gt;\u0026gt;\u0026gt; response = am.allocate([request]) \u0026gt;\u0026gt;\u0026gt; am.listAllocations(CF.AllocationManager.LOCAL_ALLOCATIONS, 100) [...] \u0026gt;\u0026gt;\u0026gt; am.deallocate([response[0].allocationID]) Managing Connections While it is simple to establish point-to-point connections, sometimes it is desirable for a connection to be established as domain objects come and go. To manage these types of connections, the domain contains a Connection Manager. Helpers have been created to make it easy to create endpoints from Python objects connected to domain objects.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import rhconnection \u0026gt;\u0026gt;\u0026gt; endpoint_1 = rhconnection.makeEndPoint(dom.apps[0], dom.apps[0].ports[0].name) \u0026gt;\u0026gt;\u0026gt; endpoint_2 = rhconnection.makeEndPoint(dom.apps[1], \u0026#39;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; cm = dom.connectionMgr \u0026gt;\u0026gt;\u0026gt; cm.connect(endpoint_1, endpoint_2) Using the Sandbox As shown briefly in section Applications, Sandbox and domain objects are inter-operable and can be connected together. This allows for inspection of different parts of the domain and more sophisticated testing of components.\nFor example, to use a Sandbox plot to view the data coming from a device, enter the following commands:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; domain.devices[1].connect(plot) \u0026gt;\u0026gt;\u0026gt; plot.start() Use the following commands to capture an approximately one second cut from a waveform to a file:\n\u0026gt;\u0026gt;\u0026gt; import time \u0026gt;\u0026gt;\u0026gt; sink = sb.FileSink(\u0026#34;/data/tuner_out.dat\u0026#34;) \u0026gt;\u0026gt;\u0026gt; domain.apps[0].connect(sink, usesPortName=\u0026#34;tuner_out\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sink.start() \u0026gt;\u0026gt;\u0026gt; time.sleep(1.0) \u0026gt;\u0026gt;\u0026gt; sink.stop() When the Sandbox exits, any connections made between Sandbox objects and domain objects are broken to limit interference with normal domain operation.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/logging/",
	"title": "Logging",
	"tags": [],
	"description": "",
	"content": "REDHAWK provides a logging capability for use by all resources (components, devices, and services). By default, the REDHAWK Framework and its support libraries have been developed to take advantage of the underlying language’s implementation: log4cxx, log4j, and log4py for C++, Java, and Python, respectively. All three libraries follow the basic premise of the log4j capabilities. A root logger definition is the parent of all loggers and configuration of the loggers is controlled through a Java style properties file. Each REDHAWK resource creates a named logger as a child of the root logger. (The name is based on the underlying resource’s name.) This chapter explains how to configure and use the logging capability. For a detailed description of log4j and its capabilities, refer to the log4j website (http://logging.apache.org/log4j/1.2/).\nAll REDHAWK-generated code for resources provides an instantiation of a logging object for use by the resource. For Java and Python implementations, the underlying logging implementation of the language is used. For C++, there is a set of macro definitions that enable a resource to use the underlying logging implementation associated with the REDHAWK Core Framework library.\n Configuring Logging Capabilities     LOGGING_CONFIG_URI Resolution     Logging Within A Resource     Adjusting Logging at Runtime     Viewing Logging Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/ide/",
	"title": "Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE is a tool that enables developers to create, test, and deploy software for REDHAWK systems. This tool is built on Eclipse, which is a generic, extensible IDE that allows developers to add custom modules. The REDHAWK IDE, therefore, leverages all of the features available in a bare-bones Eclipse IDE while also providing customized features specific to REDHAWK development.\nThe following features are included in the REDHAWK IDE:\n Eclipse - http://eclipse.org/ Eclipse JDT - Java Development Tooling for Eclipse: http://www.eclipse.org/jdt/ Eclipse CDT - C++ Development Tooling for Eclipse. Includes tools for autoconf, rpm spec file editing, and many debugging tools: http://www.eclipse.org/cdt/ Eclipse CORBA - IDL Editor for Eclipse: http://eclipsecorba.sourceforge.net/ PyDev - Python Development Tooling for Eclipse: http://pydev.org/ Eclipse Git - Git Tooling for Eclipse: https://www.eclipse.org/egit/  For signal processing developers, the REDHAWK IDE provides graphical interfaces for the auto-generation of component, device, and service code in C++, Python, and Java. Built on top of the Eclipse JDT, Eclipse PyDev, and Eclipse CDT, the IDE provides feature-rich editors for code written in any of the three languages. In addition, a drag-and-drop environment for testing these modules and constructing them into waveforms and nodes is available.\nFor system developers, the IDE provides an environment for deploying and maintaining applications onto fielded systems. Furthermore, the pluggable nature of Eclipse allows system developers to add customized system user-interface modules.\nThe REDHAWK Explorer is a lighter-weight application that includes a subset of the REDHAWK IDE’s functionality. The REDHAWK Explorer can be used to connect to a running REDHAWK domain, navigate the contents, launch and view waveforms, and so forth. It provides no development functionality, only runtime interaction with REDHAWK domains.\n  Launching the REDHAWK IDE for the First Time     PyDev Overview     The Workbench     Editors and Views    SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View      Creating REDHAWK Projects     Adding/Changing/Removing REDHAWK Project Namespaces     Debugging REDHAWK Components and Devices with Eclipse     Deploying Projects to the SDRROOT     Snapshot Tool     Connect Wizard     Using the Octave Wizard     Plot Port Wizard     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/sharing-projects/",
	"title": "Sharing REDHAWK Projects With Others",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a set of tools that allow for the collaborative development of REDHAWK capabilities. Projects can be exported or imported from the IDE or can be shared via a source code version-control system. The base REDHAWK IDE installation includes support for CVS, and Git and can easily be extended to include support for other systems, such as Mercurial.\nREDHAWK Project Metadata Files When sharing projects, it is important to include all of the source code, REDHAWK XML, and project metadata files. The project metadata files contain settings and preferences that allow the REDHAWK IDE to properly generate, build, and analyze the project.\nProject metadata files are typically hidden files (i.e., they start with a ’.’ ) and usually do not appear within the Project Explorer View. Furthermore, many project views also display or hide additional non-file content.\nTo view all of the files using the Navigator view:\n Select Window \u0026gt; Show View \u0026gt; Other….\nThe Show View dialog is displayed:  Expand General and select Navigator.\n Click OK.\nThe Navigator view is displayed:   The set of metadata files found in a project varies depending on the type of project. At a minimum, all projects contain a .project file.\nCommon metadata files are:\n .project file - Defines the basic Eclipse project settings .library file - Defines the IDL search path for the project .PROJECTNAME.wavedev file - Defines REDHAWK specific settings for the project related to code generation. .cproject file - Defines settings related to the C/C++ Development Tools .pydevproject file - Defines settings related to the Python Development Tools .classpath file - Defines settings related to the Java Development Tools  When sharing projects, be sure to include all project metadata files. When in doubt, include all files found in the project.\nExporting Projects as Source Code Archives The quickest way to share projects is to export them as an archive file. A single archive may contain one or more projects of varying types. This allows easy distribution of an archive that includes all of the relevant components, libraries, and REDHAWK XML files that another developer would require.\nTo export a project as an archive:\n Select File \u0026gt; Export….\nThe Export Select dialog is displayed:  Expand General and select Archive File\n Click Next.\nThe Export Archive file dialog is displayed:  Select the projects or files to include in the archive.\nWhen selecting a project, all files within the project are included in the archive by default. To reduce the set of files being exported, click Filter Types… and select the desired file extensions to be included in the archive.\n  Specify the output file in To archive file.\n Click Finish.\nThe archive file is created.\n  Importing Existing Projects Existing projects can be imported into a REDHAWK IDE workspace.\nTo import existing projects:\n Select File \u0026gt; Import….\nThe Import Select dialog is displayed:  Expand General and select Existing Projects into Workspace.\n Click Next.\nThe Import Projects dialog is displayed:  Select the location of the projects to import.\n If the existing projects are stored as a file system, select Select root directory, click Browse… and navigate to the directory containing the projects. If the existing projects are stored in an archive file, select Select archive file, click Browse… and navigate to the archive file containing the projects.  Select one or more projects to import.\n Click Finish.\nThe project is imported into the current workspace.\n  A common error is to attempt to import projects by choosing General \u0026gt; Archive File instead of General \u0026gt; Existing Projects into Workspace.\n When importing projects from a directory, you may choose to keep the project’s source code in its original location by deselecting Copy projects into workspace. (This may overwrite existing project files.) It is recommended to copy the project into the workspace whenever possible.\n Importing Incomplete Projects Users may forget to include the hidden files when exporting projects. As long as the SPD file and code are included in the archive, the project can be imported into a REDHAWK IDE workspace using the Redhawk Import Wizard. This wizard makes a series of assumptions for the project folder layout and format based on the content of the SPD file and dynamically generates the missing project files.\nTo import incomplete projects:\n Select File \u0026gt; Import….\nThe Import Select dialog is displayed:  Expand REDHAWK Development and select Redhawk Import Wizard.\n Click Next.\nThe Import Projects dialog is displayed:  Select the location of the projects to import.\n If the existing projects are stored as a file system, select Select root directory, click Browse… and navigate to the directory containing the projects. If the existing projects are stored in an archive file, select Select archive file, click Browse… and navigate to the archive file containing the projects.  Select one or more projects to import.\n Click Finish.\nThe project is imported into the current workspace.\n To create the missing metadata files, open the SPD file and click Generate All Implementations.\n  When importing projects from a directory, you may choose to keep the project’s source code in its original location by deselecting Copy projects into workspace. (This may overwrite existing project files.) It is recommended to copy the project into the workspace whenever possible.\n Collaborative REDHAWK Development Using a Version Control System REDHAWK projects can be shared by multiple developers by using a version-control system such as CVS or Git. When sharing projects via a version-control system, it is important to commit all of the project metadata files.\nAll version-control system integration within the Eclipse IDE is performed by the Team Capabilities. Because the REDHAWK IDE is built upon the Eclipse platform, one can easily install plug-ins that provide support for additional version-control systems. Details for installing these plug-ins can be found on the associated project web pages.\nThe details for sharing and importing projects differs for each type of version-control system. Documentation for most tools can be found on the Internet or through the built-in Eclipse help system.\nTo view full documentation:\n Select Help \u0026gt; Help Contents.\n Choose the appropriate topic:\n Workbench User Guide \u0026gt; Getting Started \u0026gt; Team CVS tutorial. Subversive User Guide. The appropriate topic for the specific tool being used.   To share a project:\n Right-click the project to share and select Team \u0026gt; Share Project….\nThe Share Project dialog is displayed:  Choose the appropriate version-control system (e.g. CVS, Git, etc.)\n Follow the steps for sharing the project as described in the relevant documentation.\n  To import a project:\n Select File \u0026gt; Import. Expand the desired item (e.g. CVS, Git, etc.) and click Next. Follow the steps for importing the project as described in the relevant documentation.  Once a project is being tracked by the Eclipse team system, many additional capabilities are exposed. For example, files that have been modified are decorated to indicate their current status. This provides an “at-a-glance” view of which files need to be committed or reverted.\nOther useful features include:\n Quick review of outgoing changes using the Eclipse “diff” viewer. Commit changes from within the IDE. Update the projects with changes from the source repository. Review the logs and commit history for files in the project. Create and merge branches.  Managing Projects Outside of the Eclipse Workspace An alternate approach is to use the version-control system’s native tools and then import the project directories into the REDHAWK IDE. It is important to ensure that projects DO NOT select Copy projects into workspace when using the method.\nExporting Projects as a Deployable REDHAWK Project To install a REDHAWK project into the Target SDR or share a “ready to run” package, it is necessary to export the project as a Deployable REDHAWK project. Unlike a source code export, a deployable export only includes the REDHAWK XML files and the files identified in the SoftPkg implementation.\nIf the SoftPkg implementation references a directory, the export includes all files within the directory.\n To export a project as a deployable REDHAWK project:\n Select File \u0026gt; Export….\nThe Export Select dialog is displayed:  Expand REDHAWK Development and select Deployable REDHAWK Project.\n Click Next.\nThe Deployable REDHAWK Project dialog is displayed:  Select the projects to export.\n Select the export destination.\n To export to a directory, select Directory, click Browse… and navigate to the directory. To export to an archive file, select Archive file, click Browse… and navigate to the archive (zip) file.  Click Finish.\nThe project has been exported as a deployable REDHAWK project.\n  Deployable REDHAWK project archives are intended to provide a stop-gap capability to easily install a project into a REDHAWK Target SDR. In general, it is recommended to use the rpm format instead of a deployable REDHAWK project archive.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-sdrroot/",
	"title": "Exploring SDRROOT Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a visualization of the file system contained within the SDR Root in the REDHAWK Explorer View The SDRROOT is referred to within the IDE as the Target SDR. The Target SDR location may be changed from within the IDE preferences page.\nTo change the Target SDR:\n Select Window \u0026gt; Preferences Select the REDHAWK \u0026gt; SDR preference page Change the Local SDR Location value Click OK  Browsing Installed SDR Objects From the REDHAWK Explorer and the Target SDR, one can browse the installed components, devices, nodes, services and waveforms. Each of these REDHAWK Objects are placed in their own folder which may be expanded to show their content. Depending on the object type, different right-click operations and tree structure manipulation are permitted.\nComponents Mouse-hovering over a component within the REDHAWK Explorer shows the full path to the SPD file in the SDR root that defines it.\nFrom the REDHAWK Explorer View, you can perform the following actions on components:\n Local Component Launch: To launch an implementation of a component with default property values, right-click the component, select Launch in Sandbox, and select an implementation of the component to start within the Sandbox’s Chalkboard. Alternately, to launch an implementation of a Component with customized property values, right-click the component, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. The Launch wizard is displayed. For more information, refer to Launching Components in the IDE Sandbox.\n View within REDHAWK Editor: To open the component’s XML files in an editor, double-click the component. This opens the REDHAWK Component Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a component from the SDR Root by right-clicking and selecting Delete. This removes all files pertaining to this component from the SDR Root including the SPD, PRF, SCD, and executable files. You can highlight multiple items and delete them at the same time. Deleting an item from the SDR Root cannot be undone.\n   Devices Mouse-hovering over a device within the REDHAWK Explorer shows the full path to the SPD file in the SDR root that defines it.\nFrom the REDHAWK Explorer View, you can perform the following actions on device objects:\n Local Device Launch: Right-click the device, select Launch in Sandbox, and select an implementation of the device to start within the Sandbox’s Device Manager. Expand Sandbox \u0026gt; Device Manager to view the running device. Alternately, to launch an implementation of a device with customized property values, right-click the device, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Devices in the IDE Sandbox.\n View within REDHAWK Editor: To open the device’s XML files in an editor, double-click the device. This opens the REDHAWK Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a device from the SDR Root by right-clicking and selecting Delete. This removes all files pertaining to this device from the SDR Root including the SPD, PRF, SCD, and executable files. You can highlight multiple items and delete them at the same time. Deleting an item from the SDR Root cannot be undone.\n   Nodes Mouse-hovering over a node within the REDHAWK Explorer shows the full path to the DCD file in the SDR root that defines it.\nFrom the REDHAWK Explorer View, you can perform the following actions on node objects:\n Launch Device Manager: You may launch a Device Manager onto a running domain for this node. Right-click the node and select Launch Device Manager to bring up a Launch Device Manager Dialog. From this dialog, you may select from a list of running domains. Pressing OK in this dialog creates a new Console view and runs an instance of nodeBooter using this node’s DCD file.\n View within REDHAWK Editor: To open the node’s XML files in an editor, double-click the node. This opens the REDHAWK Node Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Expand node: Using the tree structure to expand the node, the IDE decomposes the sections of the DCD file into the referenced devices, Device Manager, Domain Manager, and Partitioning sections. By selecting these objects with the Properties View open, all the information from the XML is displayed in tabular format.\n Delete: Delete a node from the SDR Root by right-clicking and selecting Delete. This removes only the DCD file and the folder containing it from the SDR and does not delete the referenced devices. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDR Root cannot be undone.\n   Services Mouse-hovering over a service within the REDHAWK Explorer shows the full path to the SPD file in the SDR root that defines it.\nFrom the REDHAWK Explorer View, you can perform the following actions on service objects:\n Local service Launch: Right-click the service, select Launch in Sandbox, and select an implementation of the service to start within the Sandbox’s Chalkboard. Alternately, to launch an implementation of a service with customized property values, right-click the service, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Services in the IDE Sandbox.\n View within REDHAWK Editor: To open the SPD file within an editor, double-click the SPD file. This opens the REDHAWK Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a service from the SDR Root by right-clicking and selecting Delete. This removes all files pertaining to this service from the SDR Root including any SPD, PRF, SCD, and executable files. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDR Root cannot be undone.\n   Waveforms Mouse-hovering over a waveform within the REDHAWK Explorer shows the full path to the SAD file in the SDR root that defines it.\nYou can perform the following actions from the REDHAWK Explorer View on waveform objects:\n Local waveform Launch: Right-click the waveform, select Launch in Sandbox, and select an implementation of the waveform to start within the Sandbox’s Chalkboard. Alternately, to launch an implementation of a waveform with customized property values, right-click the waveform, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Waveforms in the IDE Sandbox.\n View within REDHAWK Editor: To open the SAD file within an editor, double-click the SAD file. This opens the Waveform Editor in read-only mode. You cannot edit the fields or add any additional components.\n Expand waveform: Using the tree structure to expand the waveform, the IDE decomposes the sections of the SAD file into the referenced Assembly Controller, Component Files, and Partitioning sections. By selecting these objects with the Properties View open, all the information from the XML is displayed in a tabular format.\n Delete: Delete a waveform from the SDR Root by right-clicking and selecting Delete. This removes only the SAD file and the folder containing it from the SDR and does not delete the referenced components. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDR Root cannot be undone.\n   Browsing Installed IDL Libraries Even though the IDL Repository is displayed within the Target SDR tree structure, the deployed IDLs and the core IDL library are not stored within the SDR Root directory on the file system. All IDLs exist within the OSSIEHOME directory. However, the IDL repository is shown here so that one may browse the content and view the installed IDLs.\nExpanding the IDL Repository tree structure exposes the individual IDLs and a list of module folders which contain IDLs. To view the content of an IDL in a text editor, one may either double-click the IDL or right-click and select Text Editor or Open With… \u0026gt; Text Editor.\nOne may also expand an IDL. When an IDL is expanded, the IDE parses its content to decompose it into referenced methods and objects. By selecting these methods and objects with the properties View open one can view all the information from the IDL in a tabular format.\nGetting Details About Error Conditions If an error condition occurs within the SDR Root that the IDE can detect, it marks the object in error with a decorator in the lower left corner. Mouse hovering over the item’s icon provides a short description of the issue; however, if more than one problem has occurred the hover text reads “Multiple Problems exist with this item”.\nMore detail about an error can be found within the Properties View of the item.\nTo view the details about an error condition:\n With the item selected, select or open the Properties View. From the Properties View, select the Advanced tab Select the status row. This causes the Details key to appear. Press the Details button to bring up a detailed dialog of the current error conditions  Error Event Details "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/exploring-domain/",
	"title": "Exploring a Running Domain Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": "The Domain Manager contains knowledge of all existing CORBA-enabled objects installed or loaded onto the system. This includes references to all file systems (through the filemanager), Device Managers, and all applications (and their Resources). The Domain Manager is seen as the central bookkeeper. The REDHAWK IDE can be used to run or connect to a running domain, view the contents of a running domain, and launch and interact with applications within the domain.\n Connecting to a Domain     Viewing the Contents of the Domain in the REDHAWK Explorer View     Working with Waveforms on a Running Domain     Plotting BulkIO Ports     Increasing the Bandwidth of BulkIO Connections     Displaying Port Statistics     Getting Details About Error Conditions     "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/appendices/",
	"title": "Appendices",
	"tags": [],
	"description": "",
	"content": "  REDHAWK Yum Repository and Packages   External Dependencies   Installing a Stand-alone IDE   Building and Installing REDHAWK from Source   Optimization   FrontEnd Interfaces   REDHAWK Persona Device Pattern   Troubleshooting   Logging Configuration Plugin   List of Acronyms   "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/manual/glossary/",
	"title": "Glossary",
	"tags": [],
	"description": "",
	"content": " Allocation Manager  An implementation of the AllocationManager interface, the Allocation Manager provides a central access point for all allocations performed in the Domain.  Application  “Generically, an executable software program which may contain one or more modules. Within SCA, an application consists of one or more software modules which implement the Base Application Interfaces and which are identified within a Software Assembly Descriptor file. When loaded and executed, these modules create one or more components which comprise the application. ” Source: SCA v2.2.2.  Application Factory  “An instantiation of the ApplicationFactory interface is used to create an instance of an application. The domain manager creates an application factory for each Software Assembly Descriptor that is installed. ” Source: SCA v2.2.2.  Assembly Controller  “The assemblycontroller element of the Software Assembly Descriptor indicates the component that is the main resource controller for an application. ” Source: SCA v2.2.2.  Component  A processing module that implements the CF::Resource interface that is deployable by an Application Factory (refer to SCA v2.2.2 for a description of CF::Resource).  Connection Manager  An implementation of the ConnectionManager interface, the Connection Manager provides a central access point for connections between Domain objects.  Console View  Displays a variety of console types depending on the type of development and the current set of user settings. The Console View is a part of Eclipse and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org/. The REDHAWK IDE uses multiple Console Views for different purposes. There are also third party plug-ins within REDHAWK that have their own Console Views.  CORBA Name Browser  Maps names to specific CORBA Servants. The CORBA Name Browser can be used to examine the current contents of the Naming Service as well as perform basic manipulation of that context. The contents of the view will display all currently bound name contexts (folders) and objects. The CORBA Name Browser can be seen in Figure 14.3.  Device  “The SCA defines a Device interface class. This interface is an abstraction of a hardware device that defines the capabilities, attributes, and interfaces for that device.” Source: SCA v2.2.2. In the context of REDHAWK, a Device is is a software module that implements the Device interface class.  Device Manager  An implementation of the DeviceManager interface. The Device Manager is responsible for the creation of Devices and Services.  Domain  “A Domain defines a set of hardware devices and available applications under the control of a single Domain Manager.” Source: SCA v2.2.2.  Domain Manager  “An implementation of the DomainManager interface, a domain manager manages the complete set of available hardware devices and applications. It is responsible for the set-up and shut-down of applications and for allocating resources, devices, and non-CORBA components to hardware devices.” Source: SCA v2.2.2.  Editor  Depending on the type of file that is being edited, the appropriate editor is displayed in the editor area. For example, if a .TXT file is being edited, a text editor is displayed in the editor area. Source: http://help.eclipse.org/.  Error Log View  An Eclipse view that provides details of errors that have occurred with the running application.  Ethernet  the Local Area Network standard IEEE 802.3.  Event Channel  A software object that mediates the transfer of CORBA events between producers and consumers.  Event Channel Manager  An implementation of the EventChannelManager interface, the Event Channel Manager provides a central access point for the management of Event Channels in the Domain.  Event Service  Software that provides and manages Event Channels.  File Manager  An implementation of the FileManager interface, the File Manager provides a central access point for all of the file systems available in the Domain.  GPP  General Purpose Processor Device that manages a computing Node.  Hardware-Accelerated Component  A REDHAWK component that has the ability to access/maintain a designated portion of programmed hardware (i.e., a single modem in a multi-modem load).  Linux  A free and open-source operating system that is Unix-like.  Local Area Network  A computer network that interconnects computers within a limited area, usually a single building or smaller, using a single type of physical network technology.  Message  Key/value pairs contained in a single instance of the CORBA::Any type and passed over the CORBA event API.  Naming Service  Software that provides a mapping between human-readable names of CORBA objects and the CORBA objects themselves.  NIC  The network interface card, usually interfacing with Ethernet.  Node  A single Device Manager, its associated Devices, and its associated Services.  Node Editor  The Node Editor is opened by double clicking a DCD file from the Project Explorer View. It presents all the content that can be found within the dcd.xml file in an editing environment designed for human use. The Node Editor contain an Overview, Devices, Diagram, and a raw XML tab which contains the DCD file content.  NUMA  Non-Uniform Memory Access.  Outline View  Displays an outline of a structured file that is currently open in the editor area. The Outline View is a part of Eclipse and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org  Persona  The load or programming files used to load functionality onto programmable hardware (i.e., bit files).  Persona Device  A REDHAWK device that encapsulates a single load for specific programmable hardware and any corresponding ports/properties (defined in the REDHAWK XML descriptor files).  Perspective  Each Workbench window contains one or more perspectives. A perspective defines the initial set and layout of views in the Workbench window. Within the window, each perspective shares the same set of editors. Each perspective provides a set of functionality aimed at accomplishing a specific type of task or works with specific types of resources. For example, the Java perspective combines views that you would commonly use while editing Java source files, while the Debug perspective contains the views that you would use while debugging Java programs. As you work in the Workbench, you will probably switch perspectives frequently. Perspectives control what appears in certain menus and toolbars. They define visible action sets, which you can change to customize a perspective. You can save a perspective that you build in this manner, making your own custom perspective that you can open again later. Source: http://help.eclipse.org  Port  A CORBA object that produces or consumes data and/or commands. A Port is referred to as “uses” when it is a source/producer/output, and as a “provides” when it is a sink/consumer/input. A uses Port implements the CF::Port interface (see SCA v2.2.2 for a description of CF::Port).  Problems View  As you work with resources in the workbench, various builders may automatically log problems, errors, or warnings in the Problems view. The Problems View is a part of Eclipse and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org  Programmable Device  A REDHAWK device that is the main proxy into physical hardware. It maintains which Persona (child) device should be loaded onto the hardware.  Programmable Hardware  Hardware that may be dynamically programmed to operate with specific functionality (Such as FPGAs and some microprocessors).  Project Explorer View  Provides a hierarchical view of the resources in the Workbench. The Project Explorer View is a part of Eclipse and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org  Properties View  Displays property names and basic properties of a selected resource. The Properties View is a part of Eclipse and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org  Property  “An SCA Property is a variable that contains a value of a specific type. Configuration Properties are parameters to the configure and query operations of the PropertySet interface. Allocation Properties define the capabilities required of a Device by a Resource.” Source: SCA v2.2.2.  PyDev  PyDev is a third-party plug-in for Eclipse. It is an IDE used for programming in Python supporting code refactoring, graphical debugging, code analysis and many other features.  REDHAWK Explorer  The REDHAWK Explorer, an application built on the REDHAWK Core Framework, is used to navigate the contents of a REDHAWK Domain. It provides capabilities for viewing the contents of the Domain, configuring Domain resources, and launching Domain Waveforms.  REDHAWK Explorer View  Allows a user to navigate the contents of a REDHAWK Domain. It provides capabilities for viewing the contents of the Domain, configuring instantiated resources, and launching Applications in a target SDR environment. It also provides access to the Sandbox, which is an environment for running Components and Applications without Domain Manager and Device Manager.  Sandbox  A Python environment that can be used to easily run and interact with Components without having to create a Waveform or having to run a Domain Manager.  SCA Waveform  Deprecated. See Waveform.  Service  Software made available by the Device Manager at the Device Manager startup.  SoftPkg Editor  The SoftPkg Editor is opened by double clicking an SPD file from the Project Explorer View. It presents all the content that can be found within the spd.xml file in an editing environment designed for human use. If the SPD file references a PRF or SCD file, additional tabs are made available that represent these files in similar fashion.  System  The combination of hardware and (REDHAWK and non-REDHAWK) software necessary to accomplish a particular goal or set of goals.  Target SDR  The Target SDR refers to the REDHAWK resources which your workspace will be built and run against. It describes the platform that you are developing for. By default, points to the file location specified by the environment variable SDRROOT.  usesdevice relationship  A logical association between a Component and a specific Device that provides some capacity to that Component.  View  A view is a workbench part that can navigate a hierarchy of information or display properties for an object. Only one instance of any given view is open in a workbench page. When the user makes selections or other changes in a view, those changes are immediately reflected in the workbench. Views are often provided to support a corresponding editor. For example, an outline view shows a structured view of the information in an editor. A properties view shows the properties of an object that is currently being edited. Source: http://help.eclipse.org  Waveform  A REDHAWK Waveform is analogous to an SCA Waveform Application. A REDHAWK Waveform is defined as a composition of Components, their interconnections, and their configuration overrides. This composition is defined in a Software Assembly Descriptor file.  Waveform Editor  The Waveform Editor is opened by double clicking an SAD file from the Project Explorer View. It presents all the content that can be found within the sad.xml file in an editing environment designed for human use. The Waveform Editor contains an Overview, Diagram, and a raw XML tab which contains the SAD file content.  Workbench  The term Workbench refers to the desktop development environment. The Workbench aims to achieve seamless tool integration and controlled openness by providing a common paradigm for the creation, management, and navigation of workspace resources. Source: http://help.eclipse.org/  Workspace  In Eclipse, a workspace is a logical collection of projects that you are actively working on. Source: http://help.eclipse.org  "
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/_header/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "REDHAWK\n"
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/tags/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.1.3/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]