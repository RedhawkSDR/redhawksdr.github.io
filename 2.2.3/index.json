[
{
	"uri": "https://redhawksdr.github.io/2.2.3/",
	"title": "REDHAWK Documentation - 2.2.3",
	"tags": [],
	"description": "",
	"content": "  Getting Started With REDHAWK    REDHAWK’s Approach to Process Management and Interaction     Getting Started     IDE Quickstart     Further Reading      REDHAWK Manual - 2.2.3    Installation     Components    REDHAWK Core Assets     Creating a Component Project     Creating Octave Components     Running a Component     Sandbox     Creating and Running a Hello World Component      Component Structure    Auto-Generated Component Files     Auto-Generated Component Methods     Base Component Members     Component Implementations     Java Version     Managing and Defining Properties     Working with Events      Shared Libraries    Creating a REDHAWK Shared Library Project     Using a REDHAWK Shared Library Project     Packaging Shared Libraries     Manually Including External Libraries      Connections    The Connection Process     Why Ports?     Port Access     Dynamic Connections     Standardized Data Interfaces     BulkIO    Data Transfers     Signal Related Information (SRI)     Stream API     Bit Data     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples      BurstIO    Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics      Messaging    Message Producer     Message Consumer     Viewing Messages     Connecting Producers and Consumers      Connection Callbacks     Custom IDL Interfaces      Waveforms    Waveform Editor     Create and Deploy a Sample Waveform     Waveform Deployment and Computing Resources      Services     Working with Devices    Using Devices to Interact with Hardware    Creating a FrontEnd Interfaces Device in the IDE     Interacting with an FEI Device with the Python Package     Using an FEI Device in the IDE      Associating a Waveform with an FEI Device     Using Devices to Run Components     Using Devices to Interface with FPGAs     Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators     Miscellaneous FrontEnd Tuner Library Implementation Details      Nodes    Running a Node     Creating a New Node     Distributed Computing and RF Devices      Sandbox    Python Sandbox    Working with Components, Devices, and Services     Helpers     Devices     Example Sandbox Interaction     Built-in Sources and Sinks     Working with SDDS Data     Plotting Data     Miscellaneous      IDE Sandbox      The Runtime Environment    Launching a Domain     Domain Manager     File System     Applications     The Application Factory     The Device Manager     The Allocation Manager     The Connection Manager     Events      Runtime Environment Inspection     Logging    Logging Structure     Configuring Logger Settings     Adjusting Logging at Runtime     Logging Within A Resource     Viewing Logging Events      Using the REDHAWK IDE    Launching the REDHAWK IDE for the First Time     PyDev Overview     The Workbench     Editors and Views    SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View      Creating REDHAWK Projects     Adding/Changing/Removing REDHAWK Project Namespaces     Debugging REDHAWK Components and Devices with Eclipse     Deploying Projects to the SDRROOT     Snapshot Tool     Connect Wizard     Using the Octave Wizard     Plot Port Wizard      Exploring SDRROOT Using the REDHAWK IDE     Sharing REDHAWK Projects With Others     Exploring a Running Domain Using the REDHAWK IDE    Connecting to a Domain     Viewing the Contents of the Domain in the REDHAWK Explorer View     Working with Waveforms on a Running Domain     Plotting BulkIO Ports     Increasing the Bandwidth of BulkIO Connections     Getting Details About Error Conditions      Appendices    REDHAWK Yum Repository and Packages     External Dependencies     Installing a Stand-alone IDE     Building and Installing REDHAWK from Source     Optimization     REDHAWK System Services    AdminService    Service Configurations     Service Life Cycle      REDHAWK Core Services    REDHAWK Domain Manager Service     REDHAWK Device Manager Service     REDHAWK Waveform Service     Managing Services By Domains and Types      Configuration Files    AdminService Configuration     Domain Manager Service Configuration File     Device Manager Service Configuration File     Waveform Configuration File      rhadmin     Linux Support Files      FrontEnd Interfaces     REDHAWK Persona Device Pattern     Shared Memory Maintenance     Troubleshooting    REDHAWK Installation Issues     Connection Issues     omniNames and omniEvents Issues      Logging Configuration Plugin     List of Acronyms      Glossary      "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/getting-started/",
	"title": "Getting Started With REDHAWK",
	"tags": [],
	"description": "",
	"content": " What is REDHAWK? REDHAWK is a software package that supports the design, development, deployment, management, and upgrading of real-time, network-enabled Software-Defined Radios (SDR). This chapter provides a high-level overview of REDHAWK and its capabilities.\nOverview The REDHAWK software package is comprised of four major pieces:\n A set of programs to manage distributed deployment of software applications. A set of tools that allow developers to easily create software that is deployable within the REDHAWK environment. A set of tools for introspecting a running REDHAWK system. A set of signal processing building blocks that developers can compose into larger, customized applications.  A signal processing application developed in REDHAWK can be deployed on anything from a single Linux computer to network-enabled system of Linux computers. Typically, the integration of hardware and software required for such a form of multi-asset computing is a non-trivial undertaking, requiring a significant expenditure of resources. REDHAWK takes care of the complicated “under the hood” hardware/software integration challenges so that developers can focus on application development: an in-depth understanding of hardware and software systems is not required for basic REDHAWK use.\nREDHAWK also standardizes data interfaces, hardware management, and configuration management, which benefits non-distributed application developers. This standardization, coupled with the provided toolkit, reduces integration cost for both legacy capabilities and future development.\nApplications of REDHAWK REDHAWK was designed for the development of SDRs. SDRs have the advantage of being highly reconfigurable relative to their hardware-defined counterparts. This flexibility comes at the cost of increased size, weight, and power consumption, which leads to the use of larger, sometimes distributed, computing systems to perform the computationally-intensive signal processing tasks associated with radios. Through the use of REDHAWK, an SDR developer can focus on signal processing algorithms without worrying about the onus of deploying such algorithms in a network environment.\nThe process of software and hardware integration among disparate project teams and vendors can be a major undertaking that is often resolved with one-off, custom solutions. While designed to support the data-streaming needs of SDRs, REDHAWK also facilitates integrating additional software and hardware assets into computing systems through features such as well-defined common interfaces. REDHAWK provides a streamlined and consistent methodology to the otherwise tedious and difficult process of assimilating new technologies.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/adminservice/",
	"title": "AdminService",
	"tags": [],
	"description": "",
	"content": " The REDHAWK AdminService manages the life cycle of the REDHAWK core services (Domain Manager, Device Manager, and waveforms) using simple INI-style configuration files to define the execution environment of each core service. The REDHAWK core services definitions are the same regardless of whether the system uses systemd or init for service control. The AdminService itself follows the normal Linux system service life cycle and is controlled using the operating system\u0026rsquo;s service control.\nInstalling the AdminService To install the AdminService, enter the following command:\nyum install redhawk-adminservice Startup Process At system startup, the AdminService performs the following tasks:\n Processes all INI files in the service configuration directories under the /etc/redhawk directory.\n Creates domain groups using the DOMAIN_NAME configuration property in each service configuration file.\n Determines the start order of each domain group using the priority configuration property of each domain group\u0026rsquo;s Domain Manager service.\n Determines the start order of each core service within a domain group using the priority configuration property of each core service. The typical start order defines Domain Manager first, followed by Device Managers, and finally waveforms.\n Launches each core service within a domain group using the configuration definition and performs an initial status check of the service.\n Repeats the previous step for all remaining domain groups.\n  System Shutdown On the host system shutdown, the AdminService terminates the domain and services in the domain group in reverse priority order.\nManaging the REDHAWK Core Services Independent of system start up and shutdown, rhadmin is a command line utility used to manage the REDHAWK core services\u0026rsquo; life cycle. rhadmin supports the following commands to manage the service life cycle: start, stop, restart, and status. These commands can be used to manage an individual service or a group of services with the same service type or logical domain. The rhadmin utility can also be used to generate new configuration files for all the REDHAWK core service types.\nFor more information about using rhadmin to manage the REDHAWK core services, refer to rhadmin.\nREDHAWK AdminService Lifecycle The AdminService is configured to startup and shutdown using the operating system\u0026rsquo;s service control. The following table lists the system service scripts used to control the AdminService life cycle.\nSystem Service Scripts for the AdminService    Service System Service Script     CentOS 6 (SysV)    AdminService /etc/rc.d/init.d/redhawk-adminservice   CentOS 7 (systemd)    AdminService Setup /usr/lib/systemd/system/redhawk-adminservice-setup.service   AdminService /usr/lib/systemd/system/redhawk-adminservice.service   AdminService startup wrapper $OSSIEHOME/bin/adminserviced-start   AdminService shutdown wrapper $OSSIEHOME/bin/adminserviced-stop   Setup Wrapper $OSSIEHOME/bin/redhawk-adminservice-setup    As per the Fedora recommendations for service unit files, the AdminService is not enabled during RPM installation. System integrators may enable the service unit file and modify the activation to achieve desired start up and shutdown behavior for their systems.\nEnabling AdminService on System Startup To enable the AdminService on system boot using CentOS 6, enter the following commands as root.\nchkconfig redhawk-adminservice on To enable the Adminservice on system boot using CentOS 7, enter the following commands as root.\nsystemctl enable redhawk-adminservice-setup.service systemctl enable redhawk-adminservice.service The redhawk-adminservice-setup.service systemd service is required to create the directories in /var/run for managing process pid files. It does not need to be restarted while the system is running.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/auto-generated-files/",
	"title": "Auto-Generated Component Files",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a tool for auto-generating component code for C++, Python, or Java languages. This process takes care of REDHAWK compliance and allows the developer to insert their own custom processing algorithm for working with the data sent/received by the component. The following section provides a brief description of the generated files. Note that some files may be freely modified, while other files should not be modified.\nModifying particular files is discouraged for two reasons:\n If a user regenerates the component using the IDE (for example, to add a port), particular files are overwritten by the code generators.\n Files whose modification is not discouraged (e.g., componentName.cpp) are not affected by such an action.\n The REDHAWK IDE provides the option of not rewriting particular files.\n    Modification of files implementing REDHAWK interfaces may impact compatibility with other REDHAWK modules.\n  The word componentName is replaced with the component name provided during component creation.\nFiles Generated for All Components This section lists the files that are generated for all components regardless of the programming language in which they are written.\nBuild-Related Files The code generators create the following files for building and installing the component using Autotools:\n build.sh - Two of these files are generated: one of them resides in the top-level component directory and the other resides in the source directory. The first of the two calls the build.sh script in the source directory.\nThe build.sh script in the source directory runs ./reconf; ./configure; make. The Autotools documentation can provide more information on these commands: in short, this process creates the component entry point.\nIf you use this script, you must install the dependency rpm-build by entering the following command: sudo yum install rpm-build.\n  configure.ac - A standard Autoconf configuration file. Refer to the Autoconf documentation for more information.\n Makefile.am - A standard Automake configuration file. Refer to the Automake documentation for more information.\n Makefile.am.ide - Provides build information for the REDHAWK IDE.\n reconf - Script that is used to generate the configure script in the Autotools chain.\n componentName.spec - Provides rpmbuild configuration information for facilitating building RPMs for the component. Refer to the RPM documentation for more information.\n  Component XML Descriptors The REDHAWK IDE creates the following files for describing the properties, ports, interfaces, and descriptions for components:\n componentName.prf.xml - Describes the component’s properties. More information on the component’s prf.xml file can be found in the REDHAWK specification.\n componentName.scd.xml - Describes the component’s ports and interfaces. More information on the component’s scd.xml file can be found in the REDHAWK specification.\n componentName.spd.xml - Provides a top-level description of the component, including the names and locations of the component entry point and XML files. More information on the component’s spd.xml file can be found in the REDHAWK specification.\n  Unit Tests File The code generators create the following unit tests file for exercising components:\n test_componentName.py - Contains a unit test built on the standard Python unittest Framework. The provided test exercises the generated code. Additional tests may be added for testing algorithms produced by the developer. For more information on how to add unit tests, consult the Python unittest Framework documentation.\nTo run the unit test(s), simply execute the file from the command-line ./test_componentName.py.\n  Files Generated for C++ Components The following files contain implementation-specific code for C++ components:\n componentName.h - The appropriate place to put header-related code in support of componentName.cpp.\n componentName.cpp - The appropriate place for developers to add their own processing behavior.\n port_impl.h (Optional) - This file is only generated for ports that utilize interfaces other than Bulk Input/Output (BulkIO), Burst Input/Output (BurstIO), FrontEnd Interfaces (FEI) and Messaging. Contains the port-related code for the component. If the type of ports changes, then this file needs to be re-generated, overwriting your application-specific code.\n port_impl.cpp (Optional) - This file is only generated for ports that utilize interfaces other than BulkIO, BurstIO, FEI and Messaging. Contains the port-related code for the component. If the type of ports changes, then this file needs to be re-generated, overwriting your application-specific code.\n main.cpp - Contains the function that is used to create an instance of the component. For shared library components, this is a dynamically-loadable function called make_component(). For executable components, this is the main() function for the process. Modification of this file is not recommended.\n struct_props.h - Contains support classes for struct properties that are defined in the code-generation interface. Modification of this file is not recommended.\n componentName_base.h - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is not recommended.\n componentName_base.cpp - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is not recommended.\n  If main.cpp, struct_props.h, componentName_base.h, or componentName_base.cpp are modified, then your ability to regenerate the component is affected.\n Files Generated for Python Components The following files contain implementation-specific code for Python components:\n componentName.py - The appropriate place for developers to add their own processing behavior.\n componentName_base.py - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is not recommended.\n  If componentName_base.py is modified, then your ability to regenerate the component is affected.\n Files Generated for Java Components The following files contain implementation-specific code for Java components:\n componentName.java - The appropriate place for developers to add their own processing behavior.\n startJava.sh - Script containing the process that is started when the component is instantiated. Modification of this file is not recommended.\n componentName_base.java - Provides interface implementations for the component based on the component’s ports and properties. Modification of this file is not recommended.\n  If startJava.sh or componentName_base.java are modified, then your ability to regenerate the component is affected.\n Transitioning Java Components from REDHAWK Version 1.8 to Later Versions If componentName.java is not regenerated when migrating from REDHAWK 1.8 to later versions, the component does not inherit from the base class, so it does not take advantage of the new code pattern. In addition, in order for the component to build, the method configureOrb must be added to componentName.java because the base class makes a call on that method.\nIf you want to inherit from the base class and take advantage of the new pattern, save off the custom main class Java file, regenerate the main Java class to get the new code pattern, and for example, move source from the run() method to the serviceFunction() method to integrate the custom code in the 1.8 main class into the new main class.\nIf componentName.java is regenerated, any custom code added to it is removed.\n Add this class to the componentName.java right before the last line which is \u0026ldquo;}\u0026rdquo;\n/** * Set additional options for ORB startup. For example: * * orbProps.put(\u0026#34;com.sun.CORBA.giop.ORBFragmentSize\u0026#34;, * Integer.toString(fragSize)); * * @param orbProps */ public static void configureOrb(final Properties orbProps) { }"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/connecting-to-a-domain/",
	"title": "Connecting to a Domain",
	"tags": [],
	"description": "",
	"content": " In the IDE, you can launch and connect to a domain through the IDE interface or connect to a running domain.\nYou can also launch a domain and Device Manager from the command line.\nLaunching and Connecting Using the IDE The following procedure explains how to launch and connect to a domain through the IDE.\n In the REDHAWK Explorer view, right-click Target SDR and select Launch Domain…  Launching a Domain   The Launch Domain Manager window is displayed:  Launch Domain Manager Window    In the Domain Name field, enter a name.\n Optionally, select a Device Manager to start.\nA running Device Manager is required to launch applications.\n  Optionally, in either the Domain Manager or Device Manager section, select a Debug Level. By default, the Debug Level is set to Info, which displays any messages at the Info level or higher: (Info, Warn, Error, and Fatal message levels). If this is the first time using REDHAWK, changing the Debug Level from Info to Debug for both the domain and Device Manager may be helpful in the learning process.\n Optionally, in either the Domain Manager or Device Manager section, select Arguments for the nodeBooter process. This option is provided to advanced users who are comfortable with command line options.\n Finally, click OK to launch and connect to the new domain.\n Notice that the IDE reacts to the newly launched domain:\n The new domain has been added to the REDHAWK Explorer view\n The new domain, within a short amount of time, is connected and this connection is indicated to the right of the domain name within the REDHAWK Explorer view.\n At least one new Console view (within the IDE) has been created. One contains a nodeBooter instance for the Domain Manager that launched and one nodeBooter instance for each Device Manager.  Console Showing the Domain Manager Start Up      Connecting to a Running Domain To connect to a running domain through the IDE use the following procedure:\n Click the New Domain Connection button (i.e. the plus symbol) in the upper right of the REDHAWK Explorer view.  New Domain Connection Button   The New Domain Manager dialog is displayed:  New Domain Manager Dialog    Enter the Name Service. This is the CORBA URI of the Naming Service where the domain is registered. By default, this is populated with the value from the IDE’s preferences (set by selecting Window \u0026gt; Preferences, REDHAWK \u0026gt; Domain Connections, Default Naming Service).\n To specify the domain to which you want to connect, enter a domain name or click the + button and select a running domain. The domain name is the actual name of the domain in the Naming Service.\n Optionally, enter a different display name. The display name is used only in the IDE and does not need to match the domain name.\n Wait for the IDE to scan the Name Service for running domains. When the button next to Display Name shows a + icon, click it and select a running domain from the list.  Click one of the following options under Connection Settings:\n Don’t connect: This adds the domain to the REDHAWK Explorer view but leaves the domain in the disconnected state. When the IDE is restarted, the domain remains in the REDHAWK Explorer and is in the disconnected state. After adding a disconnected domain to the REDHAWK Explorer view, the domain may be connected by right-clicking the domain and selecting Connect.\n Connect Once: This adds the domain to the REDHAWK Explorer view and connects the IDE with the domain. When the REDHAWK IDE is restarted, the domain remains in the REDHAWK Explorer but is in the disconnected state.\n Always Connect: This adds the domain to the REDHAWK Explorer view and connects the IDE with the domain. When the REDHAWK IDE is restarted, the domain remains in the REDHAWK Explorer and attempts to connect with this domain.\n  Select Finish to close the wizard.\n The domain now appears in the REDHAWK Explorer view. If Connect Once or Always Connect was chosen, the domain is connected. If Don’t Connect was selected, right-click the domain and select Connect.\nMany of these options may be changed later through the Properties view.\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/interacting-with-hardware/creating-fei-device-ide/",
	"title": "Creating a FrontEnd Interfaces Device in the IDE",
	"tags": [],
	"description": "",
	"content": " This section explains how to create, modify, install, and test a FrontEnd Interfaces (FEI) device using the REDHAWK IDE.\nUsing the FEI Wizard to Create an FEI Device The REDHAWK Front End Device Project wizard enables users to quickly create an FEI compliant receiver or transmitter device. In the wizard, the user specifies the physical properties of the device, including whether the device ingests or outputs GPS and if the device has digital or analog input and output ports. Additionally, the user can choose to augment the required tuner status properties with additional optional properties.\n To open the wizard and create a new device, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard page is displayed:  Select a Wizard Page    Select REDHAWK Front End Device Project and click Next.\nThe Create a REDHAWK Device Project page is displayed:  Create a REDHAWK Device Project Page    In the Project name field, enter a project name and click Next.\nThe New Implementation page is displayed:  New Implementation Page    Select the programming language; enter a description for this implementation; and click Next.\nThe Setup Code Generation page is displayed:  Setup Code Generation Page    Click Next.\nThe FrontEnd Interfaces Device Type Selection page is displayed:  FrontEnd Interfaces Device Type Selection Page    Select the appropriate aspects of the device (needs GPS data or produces GPS data) and its general usage (receive/transmit, scanning capability). Click Next.\nThe FrontEnd Interface Tuner Options page is displayed:  FrontEnd Interface Tuner Options Page    Specify the types of inputs and outputs that the device supports (analog, digital float) and click Next.\nThe FrontEnd Interfaces Tuner Status Customization page is displayed:  FrontEnd Interfaces Tuner Status Customization Page    To add an optional tuner status properties, click +, select the checkboxes for the properties, and click OK. To remove optional tuner status properties, under Tuner Status Property Selection, select the properties to remove, and click X. If a required property is selected, the X button is disabled. Click Finish to exit this wizard.   Upon exiting this wizard,the FEI device project to is created, and the Overview tab of the project is displayed:  FEI Device Overview Tab   Editing an FEI Device Project After completing the wizard, you can add ports, properties, and descriptions to an FEI device using the same processes used for all other components and devices. For more information about adding ports, refer to SoftPkg Editor Overview Tab. For more information about adding properties, refer to SoftPkg Editor Properties Tab\nFor example, it may be useful to add a property used to uniquely identify the target device, such as an IP address.\nWhen editing a FrontEnd Device Project:\n Do not rename properties that were generated using the wizard. Do not modify the pre-populated values generated in the wizard (for example, the property, device_kind). You may, however, add default values to the properties without pre-populated values, such as device_model. Do not change pre-defined FEI Tuner Status properties that were generated in the wizard. You may, however, add user-defined FEI Tuner Status properties. Before adding user-defined FEI Tuner Status properties, check to see if relevant pre-defined FEI Tuner Status properties are already available. Use pre-defined FEI Tuner Status properties whenever possible.   To add or remove optional FEI Tuner Status properties using the FrontEnd Interfaces Tuner Status Customization dialog, on the Overview tab of the project, click the Edit FrontEnd properties icon. The same dialog used to define the FEI device’s tuner status property on the creation wizard is displayed. Add or remove the properties and click Finish.\nGenerating and Customizing the Source Code This section describes how to generate and customize the source code for an FEI device.\n On the Overview tab for the project, click the Generate All Implementations icon to generate the source code.\nThe Regenerate Files dialog is displayed:  Regenerate Files Dialog    Select the files to be generated and click OK.\nFiles are generated that define the classes for the FEI device. In C++, the FEI base class inherits from the frontend::FrontendTunerDevice class (or frontend::FrontendScanningTunerDevice for a scanner) to provide much of the FEI capability. The generated FEI device class must be modified to interact with the target device. During generation, intentional compiler warnings are inserted in the main class to indicate where code should be modified to reflect the behavior of the device. The output of the make command for a C++ device, including the compiler warnings, is displayed in the Console view:  FEI Device Compiler Warnings   There are five functions that contain a default implementation that should be modified to match the desired behavior. These functions are constructor, deviceEnable, deviceDisable, deviceSetTuning, and deviceDeleteTuning. The constructor function is called when the device is instantiated. During allocation of an FEI device, deviceSetTuning is called and, if successful, deviceEnable is called. During deallocation, deviceDisable is called followed by a call to deviceDeleteTuning.\nFor scanners, the additional method deviceSetTuningScan must be modified to provide the scanner capability.\n Add source code to allocate and setup a tuner channel.\nThe following table explains what is expected in each function/method.\nEach of the following functions have fts and tuner_id passed in as parameters. The tuner_id parameter specifies which tuner channel to operate on, and fts is a reference to the FEI tuner status associated with the specified tuner channel. Additionally, deviceSetTuning has a parameter called request, which defines the parameters of the tuning request.\n Functions/Methods in the Generated Code    Function/Method Description     constructor This is the REDHAWK constructor. All properties are initialized prior to this function being invoked. The default behavior when implementing a tuner is to create 1 RX_DIGITIZER channel.   deviceEnable Command the hardware to enable the output and begin generating data. The FEI tuner status element fts.enabled is updated to reflect the current state of the tuner output. This is a good place to call start to start the service function.   deviceDisable Command the hardware to disable the output and stop generating data. The FEI tuner status element fts.enabled is updated to reflect the current state of the tuner output. This is a good place to call stop to stop the service function.   deviceSetTuning When an allocation is requested against the FEI device, the base class checks to see which tuners are currently available that match the tuner type (for example, RX_DIGITIZER) and that are currently not set. The base class cycles through this list of available tuners by calling deviceSetTuning with a tuner as an argument for the callback. The search is broken when deviceSetTuning returns true. For example, if there are ten available tuners, deviceSetTuning could potentially be called ten times. The tuner is unset when a successful allocation is deallocated; deviceDeleteTuning is the notification that a particular tuner has been deallocated. There are several helper functions (validateRequest, validateRequestVsSRI, validateRequestVsRFInfo, and validateRequestVsDevice) provided in the inherited FrontendTunerDevice class of the device to assist in validation. Then, either configure the hardware with the tuner request, throw a BadParameterException if the request is outside of the capabilities of the tuner, or return false. Update the appropriate FEI tuner status elements (i.e. fts.center_frequency, fts.bandwidth, fts.sample_rate) with the actual values queried from the hardware rather than with the requested values. Push new Signal Related Information (SRI) within this function. Finally, when using the multi-out capability for Bulk Input/Output (BulkIO) ports, it is recommended that the matchAllocationIdToStreamId function be called at this point with the Stream ID and Allocation ID. Return True upon successful configuration of the tuner according to the request, or False otherwise.    Additional Functions/Methods in the Generated Scanner Code    Function/Method Description     deviceSetTuningScan Called instead of deviceSetTuning when a scanner allocation is made. If the allocation does not contain an accompanying scanning allocation, the function deviceSetTuning is called instead.    In addition to the code required for allocation and deallocation, information used to identify the target device at run-time must be added to the main class. The recommended method for dynamically identifying a target device is through configuration of a property. For example, configuring a property with an IP address or some other unique identifier allows the FEI device to identify the specific target device.\n Add source code to interact with the target hardware.\nThere are two key aspects to an FEI device: 1) how many channels does it support? and 2) how does it interact with the hardware?\nIn an FEI device, the number of channels is set through the setNumChannels function. By default, this function is included in the generated code with 1 channel. Interaction with the hardware is, obviously, specific to the hardware. The nature of the hardware (i.e.: receiver, transmitter), is specified for the supported channels as the second argument in the setNumChannels function. For more information, refer to Types of Tuners. By default, setNumChannels is populated with RX_DIGITIZER, irrespective of the selections made on the FEI wizard.\nThe other aspect of the interaction with hardware is the interaction with the actual driver code. While this interaction is hardware-specific, there are some structures that may be useful. The loop function (serviceFunction in C++ and Java, process in Python), is iteratively called after the device is started. As part of the deviceEnable callback, calling start on the device starts processing loop. Conversely, as part of the deviceDisable callback, calling the stop on the device stops the processing loop.\nThe tuner interface provides the ability to set parameters like center frequency and bandwith for the receiver. Any FEI compliant device may not output any data until the transients from any receiver setting change have settled to steady state. In short, all data output from an FEI compliant device must correspond to unambiguous receiver settings.\n In the service loop function, the implementation of, in the case of a receiver, reading data from the hardware and pushing it out a port would exist. Conversely, in the case of the transmitter, the service loop function would be used to retrieve data from a port and push it through the driver to the hardware.\n Add source code to implement FEI-related port functions.\nIf using an RFInfo port, it may be useful to store the RFInfo packet as part of the device because it is not stored within the port.\n For each function on a port definition, a callback is created in the device. This callback takes as arguments the same argument list that is provided by the port function with the exception of the types for the arguments. Where possible, the type for each of the arguments is a C++ type that is easier to use than the corresponding CORBA type. For example, in the case of a string argument, the argument on the port is of type char*, while the argument on the callback is of type std::string\u0026amp;. A thorough description of the different port functions is available in the FEI description.\n  Scanning Tuners in C++ The scanning tuner can take one of three strategies: manual, span, and discrete. These strategies have been mapped to the C++ device implementation as a set of classes, all inheriting from the ScanStrategy class. Creating a strategy requires instantiating one of these classes. For example, to create a span strategy with a single range from 1 MHz to 1.1 MHz in 10 kHz steps, use the following code:\nfrontend::ScanSpanRanges ranges; frontend::ScanSpanRange range; range.begin_frequency = 1e6; range.end_frequency = 1.1e6; range.step = 1e4; ranges.push_back(range); frontend::SpanStrategy strat(ranges); The scan status structure takes ownership of whatever strategy structure it is given. To deal with this issue, strategies can be cloned; the clone function returns a pointer to a new instance of the same strategy. The following example shows how to create a scan status structure with the strategy defined above:\nfrontend::ScanStatus status(strat.clone()); This code is applicable to callbacks for the scanning support functions of the DigitialScanningTuner port such as getScanStatus and setScanStrategy.\nInstalling the FEI Device To install the FEI device, build the project and export it to the Target SDR. After the FEI device is installed, you can use it in a REDHAWK system.\nTest-running a Sample FEI Device Create a new FEI project following the steps shown in Using the FEI Wizard to Create an FEI Device. For the purposes of this example, select Python as the language for the device and dataShort as the type for the digital output, otherwise select the defaults on the Wizard for all other settings. Follow steps 1 and 2 in Generating and Customizing the Source Code.\nIn the deviceEnable function, add the following line:\nself.start() In the deviceDisable function, add the following line:\nself.stop() In the process function, add the following lines:\ndata = range(10000) self.port_dataShort_out.pushPacket(data, bulkio.timestamp.now(), False, \u0026#34;my stream id\u0026#34;) Install and launch the device.\nTo test-run the device, follow these steps:\n In the REDHAWK Explorer tab, expand the Sandbox item.\n In the Sandbox item, expand the Device Manager item. The devices running in the Sandbox are displayed.\n Right-click the device’s output Port (probably called dataShort_out) and select Plot Port Data.\n Right-click the running device and and select Allocate. The Allocate Tuner wizard is displayed.  Allocate Tuner Wizard    Enter any arbitrary number in the Center Frequency, Bandwidth, and Sample Rate fields.\n To have the wizard perform the allocation as a background job, check the Run in background checkbox. If this checkbox is not checked, the wizard does not close until the allocation is complete.\n Click Finish. Data is plotted on the plot.\n To stop the flow, right-click the device under the Device Manager item and select Deallocate All. A deallocation warning message is displayed.\n Click Yes to confirm that you want to deallocate all.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/shared-libraries/creating-a-shared-library-project/",
	"title": "Creating a REDHAWK Shared Library Project",
	"tags": [],
	"description": "",
	"content": "The REDHAWK Shared Library Project Wizard enables users to quickly create a C++ shared library for use in REDHAWK. In the wizard, the user specifies the project name and can then generate a simple set of code files to begin adding in library functions. The following procedure explains how to use the Shared Library Project Wizard.\n To open the Shared Library Project Wizard, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard dialog is displayed:  Select a Wizard Dialog    Select REDHAWK Shared Library Project and click Next.\nThe Create a REDHAWK Shared Library Project dialog is displayed:  Create a REDHAWK Shared Library Project Dialog    In the Project Name field, enter a project name.\n Click Finish.\nThe Shared Library Project is created and the Overview tab is displayed:  Shared Library Project Overview Tab    Click the Generate All Implementations icon to generate the source code.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/data-transfers/",
	"title": "Data Transfers",
	"tags": [],
	"description": "",
	"content": " Data transfers happen through the pushPacket() method call of a REDHAWK component’s port object. This method transfers the data from the uses-side port to the corresponding connected provides-side port. The data is marshaled by the middleware (omniORB) and placed on a queue for processing by the receiving component. The implementations of the pushPacket() methods are maximized for the efficiency of data throughput while providing network-accessible ingest/egress of data and minimizing the complexity of the implementation.  BulkIO Data Flow via pushPacket()   Each implementation maintains the required behavior of providing an Signal Related Information (SRI) object before receiving any data transfers. This is accomplished by calling the pushSRI() method of the port with an SRI object. In most cases, a component takes the ingest SRI object received from an input port, makes any required modifications as necessary, and passes this object down stream over its output port. If a component does not provide an SRI object before its first pushPacket(), the port creates a default SRI object with nominal values to pass out the port.\nThe following sections explain the different methods for transferring supported data types by a component.\nFor the current implementation of omniORB, the /etc/omniORB.cfg maintains the configurable maximum transfer size defined by the value for giopMaxMsgSize. The default maximum transfer size is set to 2097152 (2 MB). For every pushPacket(), the data+headers must be less than this value; otherwise, a MARSHAL exception is raised by the middleware. This maximum value can be found during run time by using the omniORB::giopMaxMsgSize() function call or the bulkio::Const::MAX_TRANSFER_BYTES value.\n Vector Data A component usually ingests and egresses data from its ports in the service function. A component with a provides-port (input), grabs data from the port using the getPacket() method. This method returns a dataTransfer object (described in DataTransfer Member Descriptions) from the input port’s data queue or a null/None value if the queue is empty.\nThe following code snippet is an example of the getPacket() method.\n/** Grab data from the port\u0026#39;s getPacket method */ bulkio::InFloatPort::dataTransfer *pkt; pkt = inFloatPort-\u0026gt;getPacket( bulkio::Const::NON_BLOCKING ); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check if any SRI changes occurred if ( pkt-\u0026gt;sriChanged ) { outFloatPort-\u0026gt;pushSRI( pkt-\u0026gt;SRI ); } ... perform some algorithm on the data: pkt-\u0026gt;dataBuffer ... The following table describes DataTransfer members.\nDataTransfer Member Descriptions    Name Type Description     dataBuffer std::vector\u0026lt;TYPE\u0026gt; The data transferred, where TYPE is some native CORBA type (e.g., float, short). The sequence may be zero-length.   T PrecisionUTCTime The epoch birth date of the first sample of the sequence.   EOS boolean Flag describing whether this particular stream ends with this buffer of data.   streamID string Stream ID for this particular payload. This value is used to reconcile this sequence of data with a particular Stream SRI data structure.   SRI BULKIO::StreamSRI The SRI (metadata) associated with the buffer of data.   sriChanged boolean Flag that describes if a new SRI object was received for this stream.   inputQueueFlushed boolean Flag that signifies if the port’s incoming data queue was flushed (purged) because the limit was reached. This happens when the consuming component does not keep up with the incoming rate at which the data is being received.    The following code snippet is an example of the pushPacket() method call for vector data with sample parameters.\nstd::vector\u0026lt;short\u0026gt; data; ... perform algorithm and save results to data vector ... BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); outShortPort-\u0026gt;pushPacket( data, tstamp, false, \u0026#34;sample\u0026#34; ); The following table describes pushPacket() parameters for vector data.\npushPacket() Parameter Descriptions for Vector Data    Name Type Description     data sequence\u0026lt;TYPE\u0026gt; A sequence of a particular type, where TYPE is some native CORBA type (e.g., float, short). The sequence may be zero-length.   T PrecisionUTCTime The epoch birth date of the first sample of the sequence passed in this call.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    String Data/XML Document The following code snippet is an example of the pushPacket() method call for string data with sample parameters.\nstd::string data; ... generate some text data to transfer ... outStringPort-\u0026gt;pushPacket( data.c_str(), false, \u0026#34;sample\u0026#34; ); The following table describes pushPacket() parameters for string data.\npushPacket() Parameter Descriptions for String Data    Name Type Description     data char A string of characters to pass between components. Also used for passing XML documents in-line between components.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    URL/File Data The following code snippet is an example of the pushPacket() method call for file transfers with sample parameters.\nstd::string uri; uri = \u0026#34;file:///data/samples.8t\u0026#34;; ... open the file, fill with samples of data, close the file ... BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); outURLPort-\u0026gt;pushPacket( uri.c_str(), tstamp, false, \u0026#34;sample\u0026#34; ); The following table describes pushPacket() parameters for file transfers.\npushPacket() Parameter Descriptions for File Transfers    Name Type Description     url string The URL describing the file. Appropriate schemes for the URLs are file:// and sca://. The file scheme applies to the local file system, while the sca scheme applies to the Software Communications Architecture (SCA) File Manager.   T PrecisionUTCTime An appropriate time stamp for the data being passed.   EOS boolean Flag describing whether this particular stream ends with this pushPacket() call.   streamID string Stream ID for this particular payload. This string is used to reconcile this sequence of data with a particular Stream SRI data structure.    Data files may be sent via the Bulk Input/Output (BulkIO) dataFile type. When using the BulkIO dataFile type, a filename is passed to the pushPacket() method. The location of the file is specified by a URI that either points to the local file system or the Software-Defined Radio (SDR) file system. To support portability, use of the SDR file system is recommended.\nURI Options The following table describes the URI path options.\nURI Options    Protocol Format Description     file file://[localhost]/\u0026lt;path\u0026gt; A host specific absolute path of the deployed component/device/service.   sdr sdr://[ior]/\u0026lt;path\u0026gt; A path on the Domain Manager’s file system. If the optional ior is provided, this path provides the reference to the Domain Manager. If not provided, the Domain Manager is the default used by the component/device/service    SDDS Stream Definition The SDDS Stream Definition object defines a multicast connection source for data from a network interface. The methods for the SDDS Stream Definition Interface do not follow the normal BulkIO pushPacket() convention; instead, the interface defines attach() and detach() methods. The attach() and detach() methods are provided in the following code snippet.\n/** * SDDS Stream Definition Interface */ /** * attach : request to an attachment to a specified network data source */ char *attach( BULKIO::SDDSStreamDefinition stream, const char * userid ); /** * detach: unlatch from a network data source */ void detach( const char* attachId ); The following tables describe the attach() and detach() methods and the SDDS Stream Definition Member.\nchar* attach()    Name Type Description     return value char* Attachment identifier assigned to this request.   stream SDDSStreamDefinition Stream definition object describing a multicast address (SDDS Stream Definition Member Descriptions).   userid const char* Identification for the request of the attach call.    void detach()    Name Type Description     attachId char* Attachment identifier returned from attach request.    SDDS Stream Definition Member Descriptions    Name Type Description     ID string Unique identifier for the source stream.   dataFormat SDDSDataDigraph Data format of the data stream samples.   multicastAddress string IPv4 network address in dot notation form.   vlan unsigned long Virtual lan identifier as defined by 802.11q.   port unsigned long IP port number associated with the network connection.   sampleRate unsigned long Expected sample rate for the data.   timeTagValid boolean Denotes if data stream can provide valid time stamp values.   privateInfo string Allows for user-defined values to be passed as a string.    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/data-transfers/",
	"title": "Data Transfers",
	"tags": [],
	"description": "",
	"content": " Burst Input/Output (BurstIO) data transfers happen through the pushBurst() and pushBursts() method calls of a REDHAWK resource’s (component or device) BurstIO port object. A resource can use these push methods to transfer bursts and their associated meta data from one resource to another within the resource’s service function. Similar to Bulk Input/Output (BulkIO), BurstIO interfaces provide the same BULKIO::PrecisionUTCTime time stamp for each data vector of the burst. BurstIO defines a new BurstSRI Signal Related Information (SRI) object that enables developers to further describe the signaling environment and the data transformations. These fields are further described in Burst Signal Related Information (SRI).\nInput A resource with a provides-port (input), grabs data from the port using the getBurst() method. This method returns a PacketType object (described in Burst Packet Accessors) from the input port’s data queue or a null/None value if the queue is empty.\nThe following code snippet is an example of the getBurst() method.\n/** Grab data from the port\u0026#39;s getBurst method */ burstio::BurstShortIn::PacketType *pkt; pkt = inShortPort-\u0026gt;getBurst( bulkio::Const::NON_BLOCKING ); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check for EOS if ( pkt-\u0026gt;getEOS() ) { outShortPort-\u0026gt;pushBurst(pkt-\u0026gt;getSequence(), pkt-\u0026gt;getSRI(), pkt-\u0026gt;getEOS()); } ... perform algorithm on the data: pkt-\u0026gt;getData() ... or pkt-\u0026gt;getSequence() Burst Packet Accessors    Name Type Description     getSize size The number of samples in the burst. For complex data, the number of samples is half this value.   getData pointer to \u0026lt;TYPE\u0026gt; Pointer to the data samples.   getSequence container to \u0026lt;TYPE\u0026gt; Returns an iterable sequence to the data samples.   getEOS boolean Returns TRUE if this is the last burst in a stream.   getSRI BULKIO::StreamSRI The SRI (metadata) associated with the sample data.   getTime PrecisionUTCTime The epoch birth date of the first sample of the sequence.   blockOccurred boolean Returns TRUE if an incoming burst was blocked.   isComplex boolean Returns TRUE if data is complex.   getComplexData pointer to \u0026lt;TYPE\u0026gt; Pointer to a vector of complex pairs.    Output Due to the asynchronous nature of BurstIO data, the interface enables the developer to control the output (egress) of bursts from a resource. The 2 main method calls to push burst data downstream from one resource to another are: pushBursts() and pushBurst(). pushBursts() enables multiple bursts to be sent directly downstream as a sequence of BurstType objects, whereas, pushBurst() provides an interface to queue a single burst to be pushed but follows policy directives based on the number of bursts, total queue size, and send intervals. Both methods route burst data using the specified routing constraints and connection filter which are controlled using the following interface:\n// this route streams with Stream ID == \u0026#34;data-stream-one\u0026#34; to a connection // identified as \u0026#34;connection-one\u0026#34; shortBurstPort-\u0026gt;addConnectionFilter(\u0026#34;data-stream-one\u0026#34;, \u0026#34;connection-one\u0026#34;); or\n// update connection filter using the Component\u0026#39;s connection property // \u0026#34;myConnectionTable\u0026#34; shortBurstPort-\u0026gt;updateConnectionFilter(myConnectionTable); // this sets the stream filter to only route streams to specific connections shortBurstPort-\u0026gt;setRoutingMode(burstio::ROUTE_CONNECTION_STREAMS); Routing Control Directives    Routine Directive Description     ROUTE_ALL_INTERLEAVED All connections receive all streams; streams are interleaved in one buffer.   ROUTE_ALL_STREAMS All connections receive all streams; streams are buffered independently.   ROUTE_CONNECTION_STREAMS Each connection may subscribe to a set of streams; streams are buffered independently.    The major difference between the pushBurst() and pushBursts() methods is the ability to manage how and when the data is transferred. Only burst traffic that is queued using pushBurst() is controlled by the policy constraints, whereas, calls to pushBursts() are directly sent downstream to the connected resource.\n// this method will limit the maximum number of bursts that // can be queued before they are sent shortBurstPort-\u0026gt;setMaxBursts(size_t count); // this method will enable threshold monitoring for the amount of sample // data that exceeds this limit before sending data downstream shortBurstPort-\u0026gt;setByteThreshold(size_t bytes); // this method will enable the latency time between the sending of // available data downstream shortBurstPort-\u0026gt;setLatencyThreshold( long usec ); The following code snippet is an example of the pushBurst() method call for a vector data sample that is queued to the port.\nstd::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); BURSTIO::BurstSRI sri; burstio::BurstShortOut::BurstType burst; burst.SRI = sri; burst.EOS = false; burst.T = burstio::utils::now(); burst.data.length(data.size()); for(int i=0; i\u0026lt; data.size(); i++ ) burst.data[i] = data[i]; // this queues a single burst shortBurstPort-\u0026gt;pushBurst( burst ); // or  std::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); // this queues a single burst shortBurstPort-\u0026gt;pushBurst( data, sri, burstio::utils::now() ); The following code snippet is an example of the pushBursts() method call for a vector data sample. The bursts from this call are directly passed downstream to the connected resource.\nstd::vector\u0026lt; BurstShortOut::NativeType \u0026gt; data; my_transform(data); BurstShortOut::BurstSequenceType bursts; bursts.length(1); burstio::BurstShortOut::BurstType burst; burst.SRI = sri; burst.EOS = false; burst.T = burstio::utils::now(); burst.data.length(data.size()); for(int i=0; i\u0026lt; data.size(); i++ ) burst.data[i] = data[i]; bursts[0] = burst; // this pushes the burst directly downstream because // it is a sequence of bursts shortBurstPort-\u0026gt;pushBursts(bursts);"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " This chapter explains how to install the Core Framework (CF), the IDE, and the basic assets. The CF is the software back-end of REDHAWK. The IDE is a GUI for development and interaction with REDHAWK systems. The basic assets are a collection of components, devices, and waveforms that developers can use to create simple software-defined radio applications.\nTo configure and install REDHAWK and associated dependencies, you must have root permissions. The REDHAWK installation is compatible with 64-bit versions of RHEL, CentOS 6, and CentOS 7. The current REDHAWK release was tested against CentOS 6.9 (64-bit) and CentOS 7.4 (64-bit).\nInstalling REDHAWK from RPMs This section provides step-by-step instructions for installing a REDHAWK release using the YUM command-line package management tool. The installation process includes:\n Configuring the host system to install REDHAWK dependencies from Fedora EPEL Downloading and configuring the REDHAWK YUM repository on the host system Installing the REDHAWK software Setting up the user environment for immediate REDHAWK runtime or development use  Before beginning the installation process, if you are upgrading from a 1.8.x version of REDHAWK or for more information about external dependencies, refer to External Dependencies.\n Configuring the Host System to Install REDHAWK EPEL Dependencies REDHAWK has several open-source software dependencies from the EPEL repository. If your system is not configured to receive software packages from EPEL, you can configure it as follows:\nFor RHEL/CentOS 7:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm For RHEL/CentOS 6:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm Downloading and Configuring the REDHAWK Yum Repository on the Host System The following conventions are used in the instructions that follow.\n   Variable Description Example     \u0026lt;version\u0026gt; REDHAWK version 2.0.3   \u0026lt;dist\u0026gt; Linux distribution as represented by rpm macros el6 (for CentOS 6)   \u0026lt;arch\u0026gt; host architecture x86_64    Adjust the variables to match the desired REDHAWK version, host Linux distribution, and host machine architecture. For example, for REDHAWK version 2.0.3, 64-bit CentOS 6, redhawk-yum-2.0.3-el6-x86_64.tar.gz.\nDownloading the YUM Archive of REDHAWK Download the archive of the desired version of REDHAWK for your host OS and architecture.\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz Setting Up the REDHAWK Repository  In the directory that you want to use for the REDHAWK yum repository, extract the contents of the tar file.\ntar xzvf redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz cd redhawk-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt; Install the redhawk-release package (containing the REDHAWK GPG signing key):\nsudo yum install -y redhawk-release*.rpm Enter the following commands to add the following file, /etc/yum.repos.d/redhawk.repo:\ncat\u0026lt;\u0026lt;EOF|sed \u0026#39;s@LDIR@\u0026#39;`pwd`\u0026#39;@g\u0026#39;|sudo tee /etc/yum.repos.d/redhawk.repo [redhawk] name=REDHAWK Repository baseurl=file://LDIR/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhawk EOF  Installing REDHAWK Use one of the following options to install the IDE, CF, and accompanying dependencies from RPMs.\n To install only the runtime REDHAWK software, enter the following command:\nsudo yum groupinstall \u0026#34;REDHAWK Runtime\u0026#34; To install the REDHAWK development software, enter the following command:\nsudo yum groupinstall \u0026#34;REDHAWK Development\u0026#34;  If you want to be more selective about the packages you install, refer to REDHAWK Yum Repository and Packages  for a list of packages that can be installed. You can also install a stand-alone IDE.\n For installation issues with the GPP, refer to REDHAWK Installation Issues.\n Setting Up the User Environment  Enter the following commands to set up the environment variables:\n. /etc/profile.d/redhawk.sh . /etc/profile.d/redhawk-sdrroot.sh Use the following command to add each REDHAWK user to the redhawk group:\nsudo /usr/sbin/usermod -a -G redhawk \u0026lt;username\u0026gt; Where \u0026lt;username\u0026gt; is the name of a user to add to the group. If you are logged into an account that you modify with usermod, you must log out and back in for the changes to take effect.\n  Configuring omniORB The omniORB configuration file (/etc/omniORB.cfg) must be edited to provide information about how to reach the CORBA Name Service. By default, the config file contains the following entries:\nInitRef = NameService=corbaname::127.0.0.1:2809 supportBootstrapAgent = 1 The NameService line provides information about how to reach the CORBA Naming Service. The number is an IP address followed by a colon and a port number. The port number is used as a default if no other number is specified. SupportBootstrapAgent is a server side option. This enables omniORB servers and Sun’s JavaIDL clients to work together. When set to 1, an omniORB server responds to a bootstrap agent request.\n  Add the following line to the config file to configure the CORBA event service (this requires root permissions):\nInitRef = EventService=corbaloc::127.0.0.1:11169/omniEvents The first number is the IP address followed by a colon and a port number. omniEvents is the object key.\n Enter the following command to start the omniNames and omniEvents services:\nsudo $OSSIEHOME/bin/cleanomni For CentOS 6 systems, to have omniNames and omniEvents start automatically at system boot (recommended), enter the following commands:\nsudo /sbin/chkconfig --level 345 omniNames on sudo /sbin/chkconfig --level 345 omniEvents on For CentOS 7 systems, to have omniNames and omniEvents start automatically at system boot (recommended), enter the following commands:\nsudo systemctl enable omniNames.service sudo systemctl enable omniEvents.service  For more information about omniORB configuration file settings (/etc/omniORB.cfg), refer to Chapter 4 of the omniORB User’s Guide (http://omniorb.sourceforge.net/omni41/omniORB/omniORB004.html) (CentOS 6) and (http://omniorb.sourceforge.net/omni42/omniORB/omniORB004.html) (CentOS 7) or on your local system at file:///usr/share/doc/omniORB-devel-4.1.6/doc/omniORB/omniORB004.html (CentOS 6) and at file:///usr/share/doc/omniORB-devel-4.2.0/doc/omniORB/omniORB004.html (CentOS 7).\nConfiguring omniORB for Distributed Systems If you want to run a Domain Manager and Device Manager from two different computers, the following procedure explains how to configure omniORB for distributed systems.\n On the computer from which you want to run the Domain Manager, start omniNames and omniEvents and then launch a Domain Manager.\nThe firewall may need to be disabled to allow the Device Manager to connect.\n  On the computer from which you want to run the Device Manager, modify the omniORB.cfg file so that the IP address for the NameService and EventService is the address of the computer running the Domain Manager.\nThe following example is a modified Domain Manager omniORB.cfg file:\nInitRef = NameService=corbaname::127.0.0.1: InitRef = EventService=corbaloc::127.0.0.1:11169/omniEvents The following example is a modified Device Manager omniORB.cfg file:\nInitRef = NameService=corbaname::\u0026lt;IP address of Domain Manager\u0026gt;: InitRef = EventService=corbaloc::\u0026lt;IP address of Domain Manager\u0026gt;:11169/omniEvents Neither omniEvents nor omniNames needs to be running on this computer.\n  On the computer running the Device Manager, test that you can see the Domain Manager by running nameclt list.\nThe name of the Domain Manager is displayed.\n Start the Device Manager.\nAny devices in the node are registered with the Domain Manager.\n To verify that you can view both the Device Manager and Domain Manager, from either computer, run nameclt list \u0026lt;Domain Manager Name\u0026gt;.\nThe Device Manager and Domain Manager are displayed.\n  omniORB may have trouble automatically resolving its location. In this case, it may be necessary to set the endpoints in the omniORB.cfg files by adding the following to each omniORB.cfg file: endpoint = giop:tcp:\u0026lt;IP address of machine\u0026gt;. You must restart omniEvents and omniNames for these changes to take effect.\n Run rh_net_diag to help diagnose any problems. Refer to Diagnosing Problems Using the rh_net_diag Script for more information on how to use rh_net_diag.\n Configuring JacORB to Support the IDE The IDE uses JacORB version 3.3 for CORBA communication. The IDE includes a configuration file for JacORB in the IDE’s directory (in configuration/jacorb.properties). The file includes explanations and examples for many of JacORB’s configuration options. For more information, refer to chapter 3 of the JacORB 3.3 Programming Guide. Typically, there is no need to adjust any JacORB settings.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/launching-a-domain/",
	"title": "Launching a Domain",
	"tags": [],
	"description": "",
	"content": " If REDHAWK was installed from RPMs, a Domain Manager and Device Manager are ready for immediate use on the localhost. To launch a default domain in the IDE, follow these steps:\n In the REDHAWK Explorer view (by default, on the right-side of the window) right-click the Target SDR element and select Launch Domain…:  Launching a Domain    In the Device Manager section of the Launch Domain Manager window, select DevMgr_*hostname*:  Device Manager Selection    Click OK.\n  This launches both a Domain Manager and a Device Manager that manages a single GPP device. The output from both the Domain Manager and Device Manager is displayed in the Console view. If this view is not visible, select Window \u0026gt; Show View \u0026gt; Console. To stop these processes, click the Terminate icon (red square). To toggle between consoles, click the Display Selected Console icon (computer monitor):  Terminate Icon    Display Selected Console Icon   The REDHAWK_DEV domain connection is displayed in the REDHAWK Explorer view. Its state is CONNECTED and there are no errors. A Domain Manager process and a Device Manager process now exist on the host.  Domain Connections Shown in IDE   Shutting Down the Domain Normally, the Domain Manager and Device Manager remain running indefinitely; these programs are designed to remain running for extended periods of time as different parts of the overall domain (e.g., Device Managers, applications, and files on $SDRROOT) come and go. However, for the purpose of the following procedure, the process for shutting down a running domain is explained. To cleanly shutdown, it is best to disconnect the domain and stop the processes that have been started.\n In the REDHAWK Explorer view, right-click the REDHAWK_DEV domain and select Disconnect  Disconnect From Domain    In the Console view, select the Device Manager Console from the Display Selected Console icon. To stop the Device Manager, click the Terminate icon. In the Console view, select the Domain Manager Console from the Display Selected Console icon. To stop the Domain Manager, click the Terminate icon. Select File \u0026gt; Exit.  The Domain Manager and Device Manager processes no longer exist on the host. The domain entry remains in the REDHAWK Explorer view with a DISCONNECTED state indicating that the domain is no longer visible. This decoupling of the running domain from the environment enables the REDHAWK Explorer to interact with an arbitrary number of domains on a network where each domain’s life cycle is outside the control of the IDE.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/launching-the-ide/",
	"title": "Launching the REDHAWK IDE for the First Time",
	"tags": [],
	"description": "",
	"content": "This section describes the basic process for starting the REDHAWK IDE for the first time.\nBefore starting the REDHAWK IDE for the first time, the REDHAWK Core Framework (CF) and the IDE must be installed (Installation).\n  Start the REDHAWK IDE by entering the following command:  rhide At startup, the IDE may prompt for a workspace location. The workspace stores many of the IDE’s settings and also acts as a logical collection of projects under development. The IDE creates new projects in the workspace by default.\nIf you upgraded from 1.8.x, 1.9.x, or 1.10.x, it is recommended that you use a different workspace location rather than reusing a previous version’s workspace. If you set the workspace to the same workspace that you used in 1.8.x, 1.9.x, or 1.10.x, you must delete the domain from REDHAWK Explorer before launching the domain from Target SDR.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/logging-structure/",
	"title": "Logging Structure",
	"tags": [],
	"description": "",
	"content": "Java logging is based on log4j, and C++ logging is based on log4cxx, a C++ mapping of the log4j API. Python logging is based on log4py, a Python mapping between the Python loggers and log4j configuration files developed for REDHAWK. These three logging technologies were selected because they all follow the same structure, and they can all be configured using the same configuration files.\nLoggers provide the ability to associate a particular logger identifier by its string name with one or more appenders (for example, standard out) and a log level (for example, TRACE).\nLoggers are identified by their names, and the name selected for the logger determines the lineage for the logger. The root logger is the parent of all loggers. All loggers in the hierarchy are derived from this root logger; thus, all child loggers inherit the root logger settings unless the child logger is given its own configuration, in which case the settings inheritance tree is broken.\nLogger names follow the Java naming pattern, where the logger abc.def.ghi inherits from the logger abc.def, which inherits from the logger abc, which in turn inherits from the root logger.\nAll REDHAWK-generated resources, such as components and devices, contain a logger, _baseLog, that has the same name as the resource (for example, my_component_1) and is removed by one level from the root logger. Under this parent logger, three categories or namespaces are available by default: \u0026ldquo;system\u0026rdquo;, \u0026ldquo;ports\u0026rdquo;, and \u0026ldquo;user\u0026rdquo;. These three logger namespaces are created automatically, and additional namespaces may be created programmatically under the \u0026ldquo;user\u0026rdquo; namespace. The \u0026ldquo;system\u0026rdquo; namespace is the parent for the REDHAWK system services, such as property management, that log framework-level activity. The \u0026ldquo;ports\u0026rdquo; namespace is a logger that is parent to all component ports, where the specific port logger has the same name as the port (for example, my_component_1.ports.data_in). Finally, the \u0026ldquo;user\u0026rdquo; namespace is a root for all logging specific to the component or device implementation. This hierarchy is shown in the following image:\n Logger Hierarchy   Loggers inherit their parent\u0026rsquo;s settings. In other words, root logger settings are passed to all child loggers. Any change to the parent logger\u0026rsquo;s settings (such as the log level) are automatically passed down to all its child loggers. This relationship is broken if a logger\u0026rsquo;s settings are specifically changed. After a named logger\u0026rsquo;s settings are changed, if the parent logger settings change, the changes are not propagated to the child with the altered settings.\nLog messages are processed through appenders. An appender is a mechanism that provides a mapping between a message and some delivery mechanism for the message. For example, there may be file appenders and standard out appenders that write messages to a file and to a console, respectively. Appenders are managed through the log configuration file. REDHAWK systems can use a wide variety of general-purpose appenders, such as file and standard out, as well as some custom appenders, such as event channel appenders.\nThere are four main aspects to managing loggers in REDHAWK:\n configuring a logger\u0026rsquo;s start settings, creating log messages, adjusting a logger during runtime, and viewing logging events.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/messaging/message-producer/",
	"title": "Message Producer",
	"tags": [],
	"description": "",
	"content": " A message producer may be created when creating a new component or editing an existing component. After creating a message producer, you must register your code to send a message from the port. The following procedures explain how to create a message producer and send messages.\nCreating a Message Producer Use the following procedure to add a message producer port to a component or device using the REDHAWK IDE.\n From the Project Explorer View, double-click the component\u0026rsquo;s Software Package Descriptor (SPD) file.\nThe Component Editor is displayed.\n From the Component Editor, select the Properties tab.\nThe Component Editor Properties tab is displayed.  Component Editor Properties Tab    To add a struct property, click Add Struct.\nThe Struct Property section of the Properties tab is displayed.  Struct Property Section of Properties Tab    In the Struct Property section, enter the name of the message produced. The ID defaults to the name you enter.\n From the Kind drop-down, select message.\n In the All Properties section, select the struct property you added. By default, a simple member already exists. You can modify it and create additional members for the struct property. For more information about property structures, kinds, and types, refer to Managing and Defining Properties. After you modify and/or create them, the members of the structure and corresponding property information is displayed.  Struct Property and Members    Select the Ports tab, click Add, and in the Name field, enter a name.\n In the Port Details section, in the Direction drop-down, select out \u0026lt;uses\u0026gt;.\n Next to the Interface field, click Browse.\nThe Select an Interface dialog is displayed.\n From the list of interfaces displayed, select ExtendedEvent\u0026gt; MessageEvent and click OK.\nThe message producer port information is displayed.  Message Producer Port    Regenerate the component.\n  After creating a message producer, you may send a message from the message producer port.\nSending Messages The following code examples demonstrate how to send an outgoing message in C++, Java, and Python from a component\u0026rsquo;s message output port to an event channel or another component\u0026rsquo;s message input port.\nFor the purposes of the following examples, assume that the structure is as follows:\n id: foo Contains two members:  name: some_string, type: string name: some_float, type: float  The component’s uses port is called message_out The component’s name is message_producer  In each example, a message is created by declaring a variable of that type. Then, its state is set and the message is sent using the message port\u0026rsquo;s sendMessage() method with the message variable as the parameter.\nC++ To generate a message, the following code can be added in the serviceFunction() method of the implementation file.\nfoo_struct my_msg; my_msg.some_string = \u0026#34;hello\u0026#34;; my_msg.some_float = 1.0; this-\u0026gt;message_out-\u0026gt;sendMessage(my_msg); // Send a message to a specific connection by providing a `connectionId` parameter. // If `connectionId` does not match any connection, an `std::illegal_argument` exception is thrown. this-\u0026gt;message_out-\u0026gt;sendMessage(my_msg, \u0026#34;connection_1\u0026#34;); Java To generate a message, the following code can be added in the serviceFunction() method.\nfoo_struct my_msg = new foo_struct(); my_msg.some_string.setValue(\u0026#34;hello\u0026#34;); my_msg.some_float.setValue((float)1.0); this.port_message_out.sendMessage(my_msg); // Send a message to a specific connection by providing a `connectionId` parameter. // If `connectionId` does not match any connection, an `IllegalArgumentException` is thrown. this.port_message_out.sendMessage(my_msg, \u0026#34;connection_1\u0026#34;); Python To generate a message, the following code can be added in the process() method of the implementation file.\nmy_msg = message_producer_base.Foo() my_msg.some_string = \u0026#34;hello\u0026#34; my_msg.some_float = 1.0 self.port_message_out.sendMessage(my_msg) # Send a message to a specific connection by providing a `connectionId` parameter. # If `connectionId` does not match any connection, a `ValueError` is raised. self.port_message_out.sendMessage(my_msg, \u0026#34;connection_1\u0026#34;)"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/",
	"title": "Python Sandbox",
	"tags": [],
	"description": "",
	"content": " The Python-based sandbox is a Python package that is imported as any other Python package. Included in the Python package are tools that provide a means for passing Bulk Input/Output (BulkIO) data to and from components or devices. Plotting is also supported from the Python package. This section discusses how to instantiate and test a component using the provided Sandbox tools.\nThe Sandbox is Python-centric, so its use requires some basic Python knowledge.\nSetup In order to run the Sandbox, REDHAWK must be installed and the OSSIEHOME and SDRROOT environment variables must be set correctly.\nTo use the Sandbox none of the following programs need to be running: omniNames, omniEvents, Domain Manager, Device Manager, nodeBooter\nThe Python-based Sandbox includes basic analytical plotting tools based on the matplotlib Python plotting library. To use these plots, the following Python packages must be installed:\n matplotlib PyQt4  Starting the Sandbox The Python-based Sandbox, like any other Python module, may be used in another Python program or run directly within the Python interpreter. The following examples assume that the Sandbox is being used within the Python interpreter.\nTo begin, start a Python interpreter session and import the Sandbox:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb As with any other Python module, the built-in functions help() and dir() are useful when searching for available commands.\n\u0026gt;\u0026gt;\u0026gt; help(sb) \u0026gt;\u0026gt;\u0026gt; dir(sb) To exit the Sandbox, press Ctrl+D at the Python prompt. On exit, the Sandbox terminates and cleans up all of the components and helpers it creates.\nRunning the Sandbox Within the Sandbox, components and helpers are launched in an idle state. In order to begin processing (e.g., serviceFunction() in C++ components), each object must be started.\nAfter the desired components and helpers are created, the start() method starts all registered objects:\n\u0026gt;\u0026gt;\u0026gt; sb.start() It is not necessary to stop the Sandbox prior to exiting, as this is handled as part of normal exit cleanup. However, if you wish to stop processing, the stop() method stops all registered objects:\n\u0026gt;\u0026gt;\u0026gt; sb.stop() In non-interactive scripts, the Python interpreter exits after the last statement. This may be undesirable, such as in the case where a set of components should run for an arbitrary amount of time, with their output monitored via plots. The built-in Python method raw_input() can be used to prevent the interpreter from exiting:\n\u0026gt;\u0026gt;\u0026gt; raw_input() When using plots, calling raw_input() instead of time.sleep() allows the UI thread to continue updating.\n Items launched in the Sandbox are registered in the Sandbox’s internal state. To view the items that are deployed in the Sandbox, use the show command:\n\u0026gt;\u0026gt;\u0026gt; sb.show() The items shown by the show command are referenced by a unique name. To recover an item by its Sandbox internal name, use the getComponent function:\n\u0026gt;\u0026gt;\u0026gt; comp = sb.getComponent(\u0026#34;name\u0026#34;) Connecting to a Running Domain The Python Sandbox allows a developer to not only launch components, but it also allows one to interact with a live Domain. This is accomplished through the redhawk package.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/redhawk-core-assets/",
	"title": "REDHAWK Core Assets",
	"tags": [],
	"description": "",
	"content": " REDHAWK packages Core Assets that consist of starter/example components, devices, waveforms, and shared libraries.\nREDHAWK Basic Components REDHAWK basic components are a collection of starter/example REDHAWK components. These components provide simple DSP capabilities while demonstrating many of the features and use cases of REDHAWK.\nThe following basic components have been removed:\n DataWriter and DataReader have been deprecated by FileWriter and FileReader, respectively. whitenoise has been deprecated by SigGen, which includes a whitenoise generation mode. BurstDeserializer, freqfilter, medianfilter, and unwrap have been removed.  The following basic components have been updated to use the new shared library dependencies: agc, AmFmPmBasebandDemod, ArbitraryRateResampler, autocorrelate, fastfilter, psd, and TuneFilterDecimate.\n The following table contains the names and descriptions of the REDHAWK basic components.\nREDHAWK Basic Components    Component Description     rh.agc Provides automatic gain control to normalize power levels for real or complex signals.   rh.AmFmPmBasebandDemod Performs analog demodulation on complex baseband input signals.   rh.ArbitraryRateResampler Resamples a data stream at output rates that are not limited to integer multiples of the input sampling rate. This component can increase or decrease the sample rate. No anti-aliasing filtering is included, therefore, you must use this component with caution when decreasing the sampling rate to avoid aliasing or, if required, pre-filter in an upstream component.   rh.autocorrelate Performs a frequency domain implementation of a windowed autocorrelation algorithm. This algorithm works by windowing the input data to break it up into separate frames. Each frame is independently autocorrelated with each other frame using a \u0026ldquo;full\u0026rdquo; autocorrelation, which includes the full transient response. This is efficiently computed in the frequency domain.   rh.DataConverter Converts between Bulk Input/Output (BulkIO) data types in REDHAWK. With proper configuration, converts between any of the following data types; Char, Octet, Unsigned Short, Short, Float, and Double. Also capable of converting real data into complex data, and similarly, complex data into real data. By default, nothing needs to be configured. When using float or double output BulkIO ports, set the normalize_floating_point with the floatingPointRange of -1 and 1.   rh.fastfilter Provides a FIR filter implementation using the Fast Fourier Transform (FFT) -based overlap-add technique. This component includes a filter designer, which aids in impulse response creation for lowpass, highpass, bandpass, and bandstop filters. The component accepts custom impulse responses via property configuration.   rh.fcalc Enables users to perform calculations on one or two input streams simultaneously on an element by element basis. The calculation is specified in Python syntax using a and b to denote input on the a and b ports. Valid examples: 3*a+b and a*math.cos(b).   rh.FileReader Reads in a file and converts it to BulkIO data to be streamed out. Capable of sending data, regardless of file format, out of most of its ten data ports. This ability excludes the XML port. To use this component, the file_format must match that of the file and you are required to specify a source_uri (location of the file); a sample_rate; the center_frequency when applicable; and the playback state to play.   rh.FileWriter Writes out a data file from a BulkIO stream. It is not capable of changing the file format to be different from the BulkIO input stream. To use this component, you are required to specify a destinations_uri (location to write to) and a file format and set recording_enable to true.   rh.HardLimit Thresholds data so that all data is between the upper and lower limit as specified by the properties.   rh.psd Transforms data from the time domain to the frequency domain using an FFT-based Power Spectral Density (PSD). Output data is framed data where each frame contains the frequency domain representation of a subsection of the input. This component provides both the real-valued PSD and the complex FFT outputs.   rh.psk_soft Takes complex baseband pre-d data and does a PSK demodulation of either BPSK, QPSK, or 8-PSK and outputs symbols and bits. Input must be an integer number of samples per symbol (recommended 8-10).   rh.RBDSDecoder Decodes RBDS data from broadcast FM using the RBDS Standard Specification.   rh.SigGen Generates different output signals based on its configuration. Contains an implementation in each of the supported languages (Python, C++, Java) and is an example of a component with multiple implementations.   rh.SinkSDDS Accepts BulkIO data and produces a single SDDS stream over the provided multicast or unicast address.   rh.sinksocket Reads data from a BulkIO port and writes it to a TCP socket.   rh.SinkVITA49 Creates a UDP/multicast or TCP VITA49 packet stream and converts the data and Signal Related Information (SRI) Keywords to Intermediate Frequency (IF) data packets and Context packets for use within/between/outside of a REDHAWK domain application.   rh.SourceSDDS Consumes a single SDDS formatted multicast or unicast UDP stream and outputs the data via the appropriate BulkIO native type.   rh.sourcesocket Reads data from a TCP socket and writes it to a BulkIO port.   rh.SourceVITA49 Connects to a UDP/multicast or TCP VITA49 packet stream and converts the headers to SRI Keywords and data to the BULKIO interface of the user’s choice for use within REDHAWK domain applications.   rh.TuneFilterDecimate Selects a narrowband cut from an input signal. Tuning, filtering, and decimation are used to remove noise and interference in other frequency bands and reduce the sampling rate for more efficient downstream processing.    REDHAWK Basic Devices REDHAWK basic devices are a collection of starter/example REDHAWK devices. The following table contains the names and descriptions of the REDHAWK basic devices.\nREDHAWK Basic Devices    Device Description     rh.FmRdsSimulator Designed to be used in conjunction with the libRfSimulators library. Using the simulator library, this FrontEnd Interfaces (FEI) compliant REDHAWK device will generate FM modulated mono or stereo audio with RDS encoded PI (Call Sign), PS (Short Text), and RT (Full Text) data.   rh.MSDD FrontEnd Interfaces compliant device for the MSDD-X000 series receivers. Supports multiple FPGA loads for the target hardware. The device provides an RX_DIGITIZER and an RX_DIGITIZER_CHANNELIZER capability.   rh.RTL2832U Interfaces with the Realtek RTL2832U usb dongle device using the librtlsdr device dependency. Supports various tuners, including Elonics E4000, Rafael Micro R820T and R828D, Fitipower FC0012 and FC0013, and FCI FC2580.   rh.USRP_UHD FEI compliant device for the USRP that requires the UHD host code and supporting libraries to be installed.    REDHAWK Basic Waveforms REDHAWK basic waveforms are a collection of starter/example REDHAWK waveforms. The following table contains the names and descriptions of the REDHAWK basic waveforms.\nREDHAWK Basic Waveforms    Waveform Description     rh.basic_components_demo Uses a few core assets. Data from SigGen is created and manipulated to demonstrate REDHAWK.   rh.FM_RBDS_demo Processes the RBDS digitial message present in broadcast FM radio signals. Tunes and filters out this signal, performs a BPSK demodulation, and then decodes the RBDS data.   rh.FM_mono_demo Processes the mono audio channel of broadcast FM Radio.   rh.short_file_to_float_file Reads in a file containing shorts, converts them to floats in REDHAWK, and then writes out the file. Uses three components: FileReader, DataConverter, and FileWriter.   rh.socket_loopback_demo Puts REDHAWK data out onto a network socket using sinksocket and then reads it back from the socket into REDHAWK via sourcesocket.   rh.VITA49_loopback_demo Uses the sourceVITA49 and sinkVITA49 components to demonstrate how VITA49 network data can move into and out of REDHAWK.    REDHAWK Shared Libraries REDHAWK shared libraries are a collection of starter/example shared libraries.\nAll shared library (formerly soft package) dependencies have been repackaged using the new code generators, and the following basic components have been updated to use the new shared library dependencies: agc, AmFmPmBasebandDemod, ArbitraryRateResampler, autocorrelate, fastfilter, psd, and TuneFilterDecimate.\nThe following shared libraries have been renamed:\n redhawk-VITA49Libraries_V1 has been renamed VITA49. RedhawkDevUtils_v1 has been renamed RedhawkDevUtils.   The following table contains the names and descriptions of general REDHAWK shared libraries.\nREDHAWK Shared Libraries    Shared Library Description     rh.blueFileLib Provides a library for interacting with Midas BLUE files, the standard binary file format used by modern Midas frameworks.   rh.dsp Provides a DSP library for basic components. Much of the actual signal processing code is contained in this library, which is independent of REDHAWK.   rh.fftlib Provides a DSP library wrapping FFTW for basic components. Provides a higher level of functionality than what is contained in FFTW by providing classes for taking FFTs and their inverses and signal processing classes, which leverage these FFT capabilities.   rh.RedhawkDevUtils Provides a library that contains utility functions useful for REDHAWK development. Utility functions are included for working with vectors, byte swapping, file I/O, universal data types, and transforms between data types, as well as assisting with compatability across multiple boost versions. Additionally, various REDHAWK helper functions are provided for UUID generation and CORBA serialization, and working with Properties, BulkIO, base-64 characters, strings, and Domain Managers.   rh.VITA49 Provides VITA Radio Transport (VRT) libraries that represent a (nearly-complete) software-based implementation of the following ANSI specifications: VRT/VITA 49.0 VITA Radio Link Layer (VRL) / VITA 49.1    REDHAWK Device Dependencies The following table describes external shared libraries used by REDHAWK devices. These libraries are packaged and distributed with REDHAWK, but not managed by REDHAWK.\nREDHAWK Device Dependencies    Device Dependency Description     libRfSimulators Used to simulate an RF Digitizer. At present, the RF Simulators library contains a single implementation: the FM RDS Simulator. While the RF Simulators library was designed to be used within the REDHAWK Software-Defined Radio (SDR) environment, the library itself has no dependency on the REDHAWK framework and may be used as a stand alone C++ library.   librtlsdr Provides the rtl-sdr hardware driver that enables Realtek RTL2832-based DVB dongles to be used as SDR receivers. Managed by osmocom.org.   uhd Provides the USRP hardware driver (UHD) for use with the USRP product family. Managed by ettus.com. This is the version shipped with REDHAWK; however, some USRP hardware may require a more current version.    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/redhawkcoreservices/domainmanager/",
	"title": "REDHAWK Domain Manager Service",
	"tags": [],
	"description": "",
	"content": " This section explains how to manage a single REDHAWK Domain Manager service. For additional information on managing service configurations and life cycle management, refer to Device Manager Service, Waveform Service, and Managing Entire Domains.\nCreating a Domain Service Configuration To create a domain service configuration, enter the following command:\nrhadmin config domain \u0026gt; \u0026lt;output file\u0026gt;.ini A sample configuration is created, which requires the DOMAIN_NAME configuration property and the section\u0026rsquo;s name to be specified. The section name may be used with rhadmin commands. For additional configuration property settings, refer to the Domain Manager Configuration File. For the file to be recognized by the AdminService, the file must have an .ini extension and be installed into the proper service directory: /etc/redhawk/domains.d.\nDisplaying a Configuration To display the current configuration for a service, enter the following command:\nrhadmin getconfig \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Starting a Service To start a single Domain Manager service, enter the following command:\nrhadmin start \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Stopping a Service To stop a single Domain Manager service, enter the following command:\nrhadmin stop \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Requesting Status of a Service To status a single Domain Manager service, enter the following command:\nrhadmin status \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Restarting a Service To restart a single Domain Manager service, enter the following command:\nrhadmin restart \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Example Session The following example creates, activates, starts, and statuses a Domain Manager service for the domain REDHAWK_PROD, which is identified by the section name redhawk_prod.\n# generate a domain configuration file rhadmin config domain \u0026gt; redhawk-prod.ini # edit the ini file and change redhawk_prod in [domain:domain1], # and provide a value for DOMAIN_NAME=REDHAWK_PROD vi redhawk-prod.ini cp redhawk-prod.ini /etc/redhawk/domains.d rhadmin update REDHAWK_PROD rhadmin start REDHAWK_PROD:redhawk_prod rhadmin status REDHAWK_PROD:redhawk_prod # produces the following output REDHAWK_PROD:redhawk_prod RUNNING pid 1234, uptime 0:00:10"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/troubleshooting/installation/",
	"title": "REDHAWK Installation Issues",
	"tags": [],
	"description": "",
	"content": " This section explains how to troubleshoot and resolve REDHAWK installation issues.\nSetting Host Architecture/Computer Processor Name When installing RPMs, if the host architecture (computer processor) cannot be determined, the following error is displayed:\nCannot determine processor name. Run the following command with the appropriate processor name (for example, x86_64): ./gpp_setup --gppcfg --processorname \u0026lt;processor name\u0026gt; In the event of a 'Permission Denied' error, change the permissions with the following command and rerun the gpp_setup command: sudo chmod g+rw /var/redhawk/sdr/dev/devices/GPP/GPP.prf.xml  To provide a processor name, run the following command, where \u0026lt;processor name\u0026gt; is the host architecture (for example, x86_64):\n./gpp_setup --gppcfg --processorname \u0026lt;processor name\u0026gt; In the event of a Permission Denied error, run the following command (requires root permissions) to change the permissions for the file, GPP.prf.xml, which stores the processor name.\nsudo chmod g+rw /var/redhawk/sdr/dev/devices/GPP/GPP.prf.xml"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/",
	"title": "REDHAWK Manual - 2.2.3",
	"tags": [],
	"description": "",
	"content": " REDHAWK is a software framework designed to support the design, development, deployment, management, upgrade, and recycling of real-time distributed applications as well as the systems that run them.\nTo support the design and development of software applications, REDHAWK provides tools that allow development and testing of software modules, or “components”. In addition, REDHAWK provides tools to facilitate composure of components into “waveforms” that can be seamlessly deployed as “applications” on a single host computer or a network-enabled system of computers.\nDeployment, management, and upgrade of real-time distributed applications is supported by providing a runtime environment.\nThe runtime environment can:\n Deploy components to different computers on a network. Support processing hardware hot-swapping. Manage colliding software dependencies. Manage constrained/specialized hardware resources. Reduce the configuration burden on remote computing hardware. Coordinate the sharing of limited hardware resources between different applications.  Finally, REDHAWK supports the recycling of applications by establishing strong boundaries between processing stages and providing an integration path for existing libraries into the REDHAWK infrastructure.\nBenefits of Using REDHAWK REDHAWK provides the following benefits when used in a computing system:\n Defines patterns for integrating existing libraries into a common framework. Enables seamless deployment of software applications to one or more computing resources. Decouples specialized hardware from processing algorithms; this allows processing algorithms to be easily ported to new platforms. Supports language agnosticism, allowing appropriate languages to be used for various aspects of the system. Decouples processing software from the UI, allowing for any number of custom UIs to operate with the same underlying Core Framework (CF). Supports metadata-tagging of data streams. Supports precision-time-stamping of data API. Provides a powerful and flexible IDE based on the extensible Eclipse Framework. Supports dynamic inter-connection of modules, allowing redirection of data flow during runtime. Provides a data transport mechanism optimized for signal processing applications.  What Systems May Benefit from Using REDHAWK? A hardware/software system may benefit from the use of REDHAWK if it:\n Deals with multiple specialized hardware platforms but with a single software application. Integrates multiple disparate libraries into a single solution space. Emphasizes signal processing development rather than system software development. Distributes its software algorithms to more than one piece of hardware. Partitions development between geographically-separated teams. Supports shifting support work from the development team to a support team. Supports shifting deployment work from the development team to a deployment team.  Relationship to the Software Communications Architecture (SCA) REDHAWK adopts a significant number of concepts from the SCA (specifically, version 2.2.2). As a result, the SCA specification is a very useful piece of supplemental reading to the REDHAWK documentation.\nOverview of this Document REDHAWK is infrastructure that enables for the distribution of processing elements over an arbitrary number of computers connected to a network. These processing elements can be associated with different types of hardware (i.e.: data acquisition) to ingest/egress data, or to leverage some specialized coprocessors. The REDHAWK framework provides tooling for the creation, deployment, and management of these processing elements and hardware interaction elements.\nThe basic processing element in REDHAWK is a component, which is described in detail in Components and Component Structure. A component is a single linux process. Components interact with each other through connections, which are described in Connections. An application, described in Waveforms, is a logical association of interconnected components.\nHardware interaction elements are called devices. Devices are described in Working with Devices. Devices can be logically associated together in nodes, which are described in Nodes. A specialized device called GPP is used to model the processing availability of a single computer. Each node contains no more than one GPP, and is generally mapped to a single computer. By deploying components through different GPP devices, an application can be automatically distributed over multiple computers. The distributed processing aspects of REDHAWK are discussed in Distributed Computing and RF Devices.\nComponents can either be deployed through a distributed environment called a domain, as seen in The Runtime Environment, or standalone through a Sandbox.\nREDHAWK contains code generators and visualization tools. Descriptions of this tooling are available throughout this document.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/redhawk-yum/",
	"title": "REDHAWK Yum Repository and Packages",
	"tags": [],
	"description": "",
	"content": " The following sections describe the REDHAWK packages and provided dependencies.\nExternal dependencies are also necessary for development with REDHAWK and for building REDHAWK from source.\n REDHAWK Yum Repository All of the REDHAWK packages are included in a yum repository, which can be configured as described in Setting Up the REDHAWK Repository.\nREDHAWK Yum Groups The repository contains two yum groups (REDHAWK Runtime and REDHAWK Development). The yum groups are described in the following sections.\nREDHAWK Runtime The REDHAWK Runtime yum group includes the following packages:\n bulkioInterfaces burstioInterfaces frontendInterfaces GPP GPP-profile redhawk-sdrroot-dev-mgr redhawk-sdrroot-dom-mgr redhawk-sdrroot-dom-profile redhawk  REDHAWK Development The REDHAWK Development yum group includes the following packages:\n redhawk-basic-components redhawk-basic-devices redhawk-basic-waveforms redhawk-codegen redhawk-devel redhawk-ide redhawk-qt-tools  The Development group will install the Runtime group packages as dependencies.\n Dependencies Packaged with REDHAWK This section identifies the dependencies that are packaged with REDHAWK.\nDependencies for RHEL/CentOS 6 The following list of dependencies are required for RHEL/CentOS 6 systems.\n libomniEvents2 libomniEvents2-devel log4cxx log4cxx-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB uhd uhd-debuginfo uhd-devel uhd-doc uhd-firmware  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install libomniEvents2 libomniEvents2-devel log4cxx \\  log4cxx-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc \\  omniEvents-server omniEvents-utils omniORBpy-debuginfo omniORBpy-devel \\  omniORBpy-libs python-omniORB uhd uhd-debuginfo uhd-devel uhd-doc uhd-firmware Dependencies for RHEL/CentOS 7 The following list of dependencies are required for RHEL/CentOS 7 systems.\n libomniEvents2 libomniEvents2-devel omniEvents-bootscripts omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils omniORB omniORB-debuginfo omniORB-devel omniORB-doc omniORB-servers omniORB-utils omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install libomniEvents2 libomniEvents2-devel omniEvents-bootscripts \\  omniEvents-debuginfo omniEvents-doc omniEvents-server omniEvents-utils \\  omniORB omniORB-debuginfo omniORB-devel omniORB-doc omniORB-servers omniORB-utils \\  omniORBpy-debuginfo omniORBpy-devel omniORBpy-libs python-omniORB Selective Installation After you set up the REDHAWK yum repository as described in Setting Up the REDHAWK Repository, you can also install individual packages via yum for selective installations.\nFor example, to perform a selective installation that includes the GPP, enter the following command:\nsudo yum install GPP To perform a selective development installation that includes the REDHAWK IDE, enter the following command:\nsudo yum install redhawk-ide"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/getting-started/process-management/",
	"title": "REDHAWK’s Approach to Process Management and Interaction",
	"tags": [],
	"description": "",
	"content": " This chapter addresses the basic level of decomposition and deployment for REDHAWK and the middleware used to support communications between basic functional units.\nProcess Management The basic functional unit in REDHAWK is a component, which represents a single process on a host computer. The component supports the interfaces necessary to initialize, configure, query, test, connect to other components, and terminate the component. It also manages a processing thread which contains the component’s functionality and the buffering of input/output data. Components can be written in C++, Python, or Java.\nA waveform is a logical collection of components that are to be deployed as an application onto a REDHAWK system and is defined in an XML file. A waveform allows a developer to create algorithms composed of components. The composition of algorithms as separate processes allows REDHAWK to appropriately deploy these components into a network environment. REDHAWK supports distributed computing by finding an appropriate host for a component, deploying the component to that host, and managing that component once it is running.\nData Transfer Data exchange across a network is integral to REDHAWK’s core functionality. Managing the exchange of data is handled through “middleware”, which is a sophisticated software infrastructure that provides a common language for the efficient transfer of data between arbitrary languages over arbitrary media. The middleware selected for REDHAWK is omniORB, an implementation of the CORBA (Common Object Request Broker Architecture) specification. REDHAWK uses omniORB because it provides substantial technical benefits over other middleware implementations.\nThe primary benefits of using omniORB include:\n omniORB is a small package that is easy to build and install. It supports Python and C++ by default and was easily expandable to support Java. omniORB data transfers are very efficient. The pluggable nature of omniORB’s communication mechanism allows the use of multiple underlying transport protocols that can be tailored based on the deployment environment. For example, components that are located on the same host use Unix domain sockets for the transfer of data as an alternative to IP-based communications. CORBA handles the data translation between different host types (e.g., 32-bit versus 64-bit systems and big endian versus little endian). CORBA supports the Any type, allowing generic compatibility between interfaces. omniORB implements the open standard CORBA, allowing system developers to use whatever other implementation of CORBA they may want to use for their infrastructure to interact with the underlying REDHAWK system.  The technical benefits of omniORB come at the cost of CORBA’s awkward language mapping. This disadvantage is addressed in REDHAWK by mapping CORBA constructs to native language types through code generators and base classes, thus alleviating the burden of CORBA’s complexity from the REDHAWK user.\nIn conclusion, omniORB is a simple and efficient middleware package that allows programs in C++, Python, or Java to interact with each other. The disadvantages from CORBA are mitigated by the REDHAWK framework, while CORBA’s inherent benefits, such as platform independence, generic type support, strongly-typed interfaces, and open standard, bring powerful features to REDHAWK.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/nodes/running-a-node/",
	"title": "Running a Node",
	"tags": [],
	"description": "",
	"content": " As part of the REDHAWK install, a domain and node are setup by default. To launch the domain and node, refer to Launching a Domain.\nExploring the Running Node When a node is running, several attributes about the node, can be viewed in the REDHAWK IDE. The following steps explain how to explore the attributes of a device that is part of a running node.\n In the REDHAWK Explorer view, expand REDHAWK_DEV. Expand Device Managers. Expand DevMgr_\u0026lt;localhost\u0026gt;.localdomain. Select GPP_\u0026lt;localhost\u0026gt;_localdomain. Select the Properties view tab. The Properties view displays all the properties for this device, such as the operation system name, amount of available memory, and other important information, as seen below:  Properties View of a Running GPP     Creating a Component that Consumes Resources All components consume processor resources such as memory and CPU capacity. These resources are automatically tracked by the GPP, and when its thresholds are exceeded, the GPP enters the BUSY state, preventing further deployments onto the computer. However, in some cases, it is desirable for the component to consume some other capacity on the computer that is not part of the standard REDHAWK deployment model. The GPP contains several allocation properties such as mcastnicIngressCapacity or mcastnicVLANs that are available as a deployment constraint but are not used by the default component deployments.\nIn a more generalized way, when a device\u0026rsquo;s specialized capacity is added to the device as a property of kind allocation, components can be created that will allocate this attribute of the device, making this allocation property a deployment constraint for the component.\nExtending the GPP with new properties requires a modification of the GPP\u0026rsquo;s source code and risks compatibility with other developers\u0026rsquo; components.\n To create a component that consumes these kind of allocation resources:\n Create a Python component called sample. In the Project Explorer view, double-click the sample.spd.xml file. Select the Implementations tab. In the Dependencies section, next to the Dependency list, click Add\u0026hellip;. In the Dependency Wizard, select Kind=Property Reference and Type=allocation. The Refid field is more complicated; the component needs to be given some property that the component consumes when it is running on a device. An example of such a property is memory. For this example, memory is an attribute (property) of the device that the component consumes. To describe this, click the Browse button on the Refid field and select GPP:memCapacity (do not worry if there are multiple instances of the same property on the list, just pick one). After selecting this property, the globally unique ID of the property populates the Refid field, which in this case is: DCE:8dcef419-b440-4bcf-b893-cab79b6024fb (this is the id of the corresponding property of the GPP). To complete the dependency definition, provide a value for the consumption of this property: in this case, set Value=1000. Click Finish. Save the project, generate the code and drag the component project to REDHAWK Explorer \u0026gt; Target SDR.  Create a Waveform for the New Component The following steps explain how to create a waveform for the new component generated in the previous section.\n Create a new waveform called sample_deploy. Drag the component sample from the Palette onto the Diagram. Save the project and drag the project sample_deploy from the Project Explorer to REDHAWK Explorer \u0026gt; Target SDR.  Observe the Effect of Launching a Component The following steps explain how to launch and release a component.\n On the running domain, select GPP_\u0026lt;localhost\u0026gt;_localdomain and note the value for memCapacity on the Properties tab for the GPP device. Launch the application sample_deploy on the running domain (right-click domain, select Launch Waveform\u0026hellip; \u0026gt; sample_deploy \u0026gt; Finish). Note memCapacity for GPP_\u0026lt;localhost\u0026gt;_localdomain again; it is 1000 less than before the launch of the application. Release the application (REDHAWK_DEV \u0026gt; Waveforms \u0026gt; sample_deploy_\u0026lt;#\u0026gt; right-click Release). Note memCapacity for GPP_\u0026lt;localhost\u0026gt;_localdomain again; it is restored to the original value.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/softpkg-editor/",
	"title": "SoftPkg Editor",
	"tags": [],
	"description": "",
	"content": " The SoftPkg Editor presents all the content that can be found within the spd.xml file in an editing environment designed for ease of use.\n SoftPkg Editor   To open the SoftPkg Editor, double-click a Software Package Descriptor (SPD) file from the Project Explorer view. If the SPD file references a Properties File (PRF) or Software Component Descriptor (SCD) file, additional tabs are made available that represent these files in similar fashion.\nEach of the editor tabs, with the exception of the raw XML tabs, have the following buttons located in the top right corner:\n Generate All Implementations Button: This button is used to generate the code implementation of the SPD file. The generated code is based on the code generator template that was chosen during the New Project Wizard and content found in the SPD, PRF, and SCD files. Code generation is not exhaustive, and custom port types may not compile.\n  New Control Panel Button: This button is used to generate a new control panel.  The SoftPkg Editor is organized into four main tabs:\n Basic information about the SoftPkg can be edited from the Overview tab Properties and messages can be edited from the Properties tab Ports can be edited from the Ports tab Implementations and code generation settings can be edited from the Implementations tab.  The following sections describe each of these tabs.\nOverview Tab The Overview tab is a representation of content found in the SPD file and contains five sections:\n The General Information section provides the ability to view and set (if write permissions are granted) the resource’s ID and Name as well as the location of the PRF and SCD files. The initial content of these fields is auto-generated when the project is created and is generally left unaltered. The optional fields, Version, Title, and Description, may be set to aid in the project’s documentation. The Interfaces section lists the Interface Description Language (IDL) interfaces that this resource inherits. This includes IDLs used by the resource’s ports, lifecycle, and properties. This table is read only, and additional IDL interfaces cannot be added here. The Component Content section displays hyperlinks to navigate to the Properties and Implementations tabs of the SoftPkg Editor. The Testing section displays two hyperlinks. Launch a local component launches a local instantiation of this resource within the Sandbox. Launch a local component in debug mode provides additional runtime control, including the ability to place breakpoints, pause execution, and inspect and modify variables. See Debugging REDHAWK Components and Devices with Eclipse for more information. The Exporting section provides a hyperlink for deploying a project to the SDRROOT. Use the following procedure to export a project using the Export Wizard:\n Click Export Wizard. Select the projects to export. Type or browse to the export location. Click Finish.   Properties Tab The Properties tab provides a view of all of the properties defined for a component or device.\n SoftPkg Editor Properties Tab   Within the Properties tab, the All Properties section displays all of the properties defined for the selected component or device.\nTo add a property, click on one of Add Simple, Add Sequence, Add Struct or Add StructSeq to create a new property of the corresponding type. To remove a property, select it in the All Properties section and click the Remove button on the right. To clone existing properties, click Browse\u0026hellip; and select from items in the SDRROOT, projects in the workspace, or well-known properties. In addition to creating a new property from scratch, a user may also copy an existing property from a deployed resource:\n In the All Properties Section, click Browse…. Expand Target SDR. Drill down to and select the desired property. Click Finish.  When a property is selected in the All Properties section, a type-specific details section appears on the right-hand side of the tab. All property types include a few common fields:\n Name is optional, but if given, is favored over the ID for generated code. ID is an identifier that is unique from all other properties within the component or device. It must be used when accessing the property via APIs. Kind describes the intended use of the property. The default is property. Mode determines whether the property can be read and/or written. The default is readwrite. Description is optional; it documents the intended use of the property. User interfaces may present the description as help text.  Nested properties—fields in a struct, or the struct definition for a struct sequence—do not include Kind or Mode. The parent property determines these fields.\nThe Simple Property details section includes additional fields:\n Type describes the basic data type of the property (e.g., float). For complex numeric types, select complex in the combo box next to the type. Value is the initial value for the property. If not given, the initial value is undefined. Units is strictly informative, but may be displayed in user interfaces. Enumerations is a mapping of human-readable string labels to values. User interfaces may use the enumerations to present the labels in place of values. Action is only applicable to properties with a kind of allocation. Range, if enabled, sets optional lower and upper limits on the value. The range is not enforced by generated code; however, user interfaces may choose to enforce it.  Ordinarily, properties are set to their initial value via a call to the component or device’s initializeProperties() method. However, for certain use cases, simple properties may receive their initial value on the executable command line by enabling the Pass on command line checkbox, located next to Kind.\nIn the Simple Sequence details section, the fields Type, Units, Action and Range are identical to those for simple properties. The default value of a simple sequence property can be viewed or edited via the Values list.\nThe fields that make up a struct property are displayed as children of the struct in the All Properties section.\n To add a field, right-click the struct in the All Properties section, select New and then select one of Simple or Simple Sequence. To remove a field, select the field in the All Properties section and click Remove.  The default value of a struct property is the determined by the default values of its fields.\nIf any field has a default value, all fields must have a default value.\n The default value of a struct sequence may be viewed or edited via the StructValue section in the Struct Sequence Property details section.\nThe struct definition appears as a child of the struct sequence in the All Properties section. It may be modified in the same manner as a struct property.\nPorts Tab The Ports tab provides the ability to add, edit, and view port information.\n SoftPkg Editor Ports Tab   Click Add to create a new port with default values. The Port Details section shows the new port, which can be modified as needed:\n Give the port a Name unique to this component or device. Select a Direction: either input, output, or bidirectional.  Only Message Consumer ports should be bidirectional.\n  The Type is optional and strictly informative. A port may have one or more type, defaulting to control if none is selected. Select the IDL Interface that this port implements. Click Browse… to open the selection dialog. By default, the interface selection dialog only shows the most common interfaces used in REDHAWK. Select the Show all interfaces checkbox to show the complete list for IDL interfaces within the Core Framework’s (CF) install location.\n  Optionally, enter a Description of the port, such as its intended use.  An existing port may be edited by selecting it from the All Ports section and changing its options via the Port Details section.\nTo remove a port, select it from the All Ports section and click the Remove button.\nImplementations Tab The Implementations tab is a representation of content found in the SPD file. It describes the programming language implementations that are generated and the hardware dependencies required for this resource.\n SoftPkg Editor Implementations Tab   During the New Project Wizard, the initial programming language and code generation template were selected. In the All Implementations section there is the option to add additional programming language implementations.\nThe right portion of the editor is context sensitive, and displays the information pertaining to the selected implementation.\n The Implementation section defines the compiler for the selected language and provides a custom description for this implementation. The Dependencies section provides the opportunity to place limitations on a resource so that it may only execute on a suitable device. This is done through the use of property dependencies. A resource’s execution may be limited to a particular device by placing a dependency on a device’s property. To provide compatibility among different sets of users, well known properties have been created, including different OS and processor types. The OS and processor dependencies sections contain a preset list of properties to select from. The Code section indicates the local file name, priority, and executable for the implementation. The Code Generation Details section contains configuration values for the implementation’s code generation. This includes the code template used, output folder location and code generator properties.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/the-connection-process/",
	"title": "The Connection Process",
	"tags": [],
	"description": "",
	"content": "All connections take a client-server pattern. All calls are made from the client to the server. It is the role of the server to provide a set of functions that can be called by the client. It is the role of the client to understand what interfaces the server provides and to invoke (use) them. This is the basis for the uses/provides nomenclature for ports.\nAll uses ports implement the CF::Port interface. CF::Port is an interface that is part of the REDHAWK Core Framework (CF); it contains only two methods: connectPort() and disconnectPort(). To connect a uses port to a provides port, an external entity needs to invoke the connectPort() function on the uses port, where the arguments are a CORBA pointer to the provides port and a string that identifies that connection. To sever a connection, an external entity needs to invoke the disconnectPort() function on the uses port, where its only argument is the string ID used to establish the connection. In the case of an application, the connections are established/destroyed by an object in the Domain Manager process space based on the waveform\u0026rsquo;s XML file. In the case of the Sandbox, the Sandbox makes the correct calls to establish and destroy a connection based on user input.\nAll provides ports must implement an interface described in Interface Description Language (IDL). This interface implements the methods that the uses port invokes after a connection has been made. When a uses port is given a pointer to a provides port, it essentially casts this generic pointer to the interface that it believes the provides port to implement. If this casting process fails, an exception is raised during the connectPort() call.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/interacting-with-hardware/",
	"title": "Using Devices to Interact with Hardware",
	"tags": [],
	"description": "",
	"content": "REDHAWK devices can be used to interact with hardware receivers and digitizers, for example, a data acquisition board or a USRP. To have a REDHAWK component use a REDHAWK device, you can establish a usesdevice relationship between a component and a device. The usesdevice relationship requires the component to only use that particular type of device. The REDHAWK distribution includes three devices that can be used out-of-the-box: Realtek RTL2832-based DVB dongles with Osmocom’s rtl-sdr library, Ettus’s USRP, and an FM RDS simulator with the libRfSimulators library.\nThe following example explains how to use the FmRdsSimulator REDHAWK device to receive and process a generated FM signal, and provide the audio and a plot of the signal.\nThe RTL2832U REDHAWK device can be substituted for the FmRdsSimulator REDHAWK device to receive a live FM signal.\n  Open the Python Sandbox and import the frontend module.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; import frontend Launch the FmRdsSimulator device, the AmFmPmBasebandDemod component, the fastfilter component, the ArbitraryRateResampler component, the SoundSink Sandbox component, and set up the REDHAWK IDE plotter.\nTo plot data, the REDHAWK IDE must be installed and the path to the Eclipse directory of the installed IDE must be specified in the Sandbox. This can be done through the IDELocation() function.\n \u0026gt;\u0026gt;\u0026gt; sim = sb.launch(\u0026#34;rh.FmRdsSimulator\u0026#34;) \u0026gt;\u0026gt;\u0026gt; demod=sb.launch(\u0026#34;rh.AmFmPmBasebandDemod\u0026#34;) \u0026gt;\u0026gt;\u0026gt; filter=sb.launch(\u0026#34;rh.fastfilter\u0026#34;) \u0026gt;\u0026gt;\u0026gt; resample=sb.launch(\u0026#34;rh.ArbitraryRateResampler\u0026#34;) \u0026gt;\u0026gt;\u0026gt; agc=sb.launch(\u0026#34;rh.agc\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sink=sb.SoundSink() \u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse/directory\u0026#34;) \u0026gt;\u0026gt;\u0026gt; plot=sb.Plot() Connect devices and components.\n\u0026gt;\u0026gt;\u0026gt; sim.connect(demod) \u0026gt;\u0026gt;\u0026gt; demod.connect(filter, usesPortName=\u0026#34;fm_dataFloat_out\u0026#34;) \u0026gt;\u0026gt;\u0026gt; filter.connect(resample) \u0026gt;\u0026gt;\u0026gt; resample.connect(agc) \u0026gt;\u0026gt;\u0026gt; agc.connect(sink) \u0026gt;\u0026gt;\u0026gt; agc.connect(plot) Configure and start all components and devices in the Sandbox.\n\u0026gt;\u0026gt;\u0026gt; sim.addAWGN=False \u0026gt;\u0026gt;\u0026gt; demod.freqDeviation=15000.0 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.freq1=16000.0 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.Ripple=0.5 \u0026gt;\u0026gt;\u0026gt; filter.filterProps.Type=\u0026#34;lowpass\u0026#34; \u0026gt;\u0026gt;\u0026gt; resample.outputRate=32000.0 \u0026gt;\u0026gt;\u0026gt; sb.start() Create a tuner allocation structure and allocate the device.\n\u0026gt;\u0026gt;\u0026gt; alloc = frontend.createTunerAllocation(\u0026#34;RX_DIGITIZER\u0026#34;, allocation_id=\u0026#34;testing\u0026#34;, center_frequency=100.1e6, sample_rate=256e3,sample_rate_tolerance=20.0) \u0026gt;\u0026gt;\u0026gt; sim.allocateCapacity(alloc) Set the center_frequency property in the allocation structure to the radio station desired. Specifying a bandwidth of 0.0 indicates that any bandwidth is acceptable given that the other parameters are met.\n   Devices may be used within the Sandbox or within a domain, in which case devices are deployed by a Device Manager at startup. The lifecycles of the devices used within the Sandbox follow the same lifecycle as the scripting environment; when the scripting environment is shutdown, the devices are shutdown. The lifecycles of devices deployed by a Device Manager follow the lifecycle of the Device Manager; when a Device Manager is started, the devices associated with that Device Manager are launched, and when the Device Manager is shutdown, the associated devices are released.\nThe configuration of a Device Manager’s Devices is controlled through an XML file called a Device Configuration Descriptor (DCD) file. Any one DCD file associated with a Device Manager instance is often referred to as a node.\nWhen a node is deployed, the devices associated with the node become available to the domain. Applications can contain usesdevice relationships. In other words, elements in the Software Assembly Descriptor (SAD) XML file can declare that the application requires the use of a particular type of device. When the application is deployed by the domain, the domain searches through the deployed devices for any one device that can satisfy the declared dependency. Any device that satisfies an application dependency may become busy and unavailable for use by other applications. When the application is released, the device is brought back into the pool of available devices.\nGiven the radio nature of REDHAWK, the interaction between the REDHAWK environment and RF devices has been standardized through a common API, known as FrontEnd Interfaces (FEI).\nIf you have RF FrontEnd hardware that you want to model in REDHAWK, you can use the FEI module to facilitate this process. The FEI module contains interfaces designed to standardize the interaction (allocation, operation, and development) of tuner devices within the REDHAWK Core Framework (CF) (between applications and radio hardware). This standard breaks the tie between the application and the hardware and provides more flexibility.\nThe FEI module defines a number of interfaces to enable users to interact with several different generic types of tuners, including:\n Receiver (RX) tuner Receiver Digitizer (RX_DIGITIZER) tuner Channelizer (CHANNELIZER) tuner Digital Down Converter (DDC) tuner Receiver Digitizer Channelizer (RX_DIGITIZER_CHANNELIZER) tuner Transmitter (TX) tuner Receiver With Scanning Capability (RX_SCANNER_DIGITIZER) tuner  Before you can interact with the tuners, you must create a REDHAWK device that is FEI compliant. The following procedure explains how to make a REDHAWK device that is compliant with FEI version 2.4.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/waveforms/waveform-editor/",
	"title": "Waveform Editor",
	"tags": [],
	"description": "",
	"content": " The following sections further describe the definition of the waveform as well as its creation and manipulation within the IDE. Like the Properties File (PRF), Software Component Descriptor (SCD), and Software Package Descriptor (SPD) XML files of a component, a waveform is completely represented by its Software Assembly Descriptor (SAD) file (*.sad.xml). The REDHAWK IDE provides a means of modifying the XML files without the need to directly edit this file by hand.\nOverview Tab Within the Overview tab, the name, Assembly Controller, and external ports of a waveform are defined.\nThe Assembly Controller is a component instance in the waveform that is designated as the component where the waveform-level start(), stop(), configure(), and query() calls are delegated. In complex waveforms, the Assembly Controller can be used to orchestrate the life cycle of components. In trivial waveforms, the identity of the Assembly Controller is of less importance.\nExternal ports are used to make component ports available to other applications, facilitating inter-application connectivity.\nDevelopers use the Overview tab to set the Assembly Controller for the waveform and describe the waveform.\nThe following steps explain how to set the Assembly Controller and describe the waveform.\n On the Overview tab of the Waveform, from the Controller drop-down menu, ensure SigGen_1 is selected. In the Description field, enter a description for the waveform.  Waveform Overview Tab     Components Tab The Components tab displays the individual component instantiation elements and their associated details, which can be modified.  Waveform Components Tab   The All Components section displays all components currently in the waveform as well as Add\u0026hellip; and Remove buttons, which can be used to add or remove selected components from the waveform.\nThe Components section displays the following field, which can be selected to modify the current values:\n Usage Name - Edit the selected component instantiations Usage Name element and Naming Service name, which is based on the component’s usage name.  The Logging section displays the following fields, which can be selected to modify the current values:\n Enabled checkbox - Enable or disable a logging configuration element for the selected component instantiation. Log Level combo box - Select predefined logging Levels, including: OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE, and ALL. For more information, refer to Logging. Logging URI - Specify a URI of a logging configuration file.  Diagram Tab Most of the work done on waveforms takes place within the Diagram tab. The Diagram tab is very similar to the Sandbox/Chalkboard. Unlike the Sandbox, only components that exist within the $SDRROOT can be added to the waveform. The Palette contains a list of components residing within the $SDRROOT. From the Diagram tab, external ports of the waveform can be indicated and the role of Assembly Controller can be assigned to a component.\nEditing Component Properties in a Waveform From the Diagram tab, properties of components can be set. When these properties are set, they become specific to the waveform and are written to the *.sad.xml file, which describes this waveform.\nThe following steps explain how to edit the properties of a component in a waveform.\n On the Diagram tab of the waveform, select the component. In the Properties view, verify the Properties tab is selected.  Properties View    Select the property you want to set, and edit the value.  Editing the devicerequires Set in a Waveform The devicerequires set for a component is managed through the Requirements tab of the Properties view. When these Requirements are set, they become specific to the waveform and are written to the *.sad.xml file. For more information about the devicrequires set, refer to Binding Components to Executable Devices.\nThe following steps explain how to edit the devicerequires set.\n On the Diagram tab of the waveform, select the component. In the Properties view, verify the Requirements tab is selected.  Properties View Requirements Tab    To add an ID and value, click + and add the ID and value. The ID and value can be any alphanumeric string value. This assigns a devicerequires key/value pair to the component. To remove an ID and value, select the ID and click X.  Start Order Each of the components within the waveform contain a number with a circle around it which represents that component’s start order. The start order represents the order in which its start() method is called by the Assembly Controller. The only component that does not have a start order is the Assembly Controller, which always has an assumed start order of 0. The Assembly Controller has a yellow circle containing 0. The start order may be changed by right-clicking a component and selecting Move Start Order Earlier or Move Start Order Later from the context menu. The Assembly Controller may be changed by right-clicking a component and selecting Set As Assembly Controller from the context menu.\nSAD File Tab The information displayed in the Overview, Components, and Diagram tabs is represented within the XML of the SAD file. The XML can be edited manually, but it is not recommended. Each of the components used within the waveform are referenced within the SAD file by pointing to the file location of the component’s SPD file.\nInstructions for inspecting the SAD file are below:\n Open the myWaveform.sad.xml tab of the Waveform Editor. Look through the SAD file and identify:  The location of the two SPD files used in this waveform (remember that this file location is in reference to the $SDRROOT) The Assembly Controller The connection between the two components The external port is set in the Diagram Tab The start order of each component The property is changed on the SigGen component  Before continuing, return to the Diagram tab and change the dataDouble_out port so that it is no longer marked as an external port.  Application Options Two options can be set for applications in the SAD file:\n STOP_TIMEOUT - controls the time allowed before a timeout occurs. The application’s stop function is delegated to each component in the application. In some cases, the component may require an unusually long amount of time to reach a stopped state. To prevent this timeout, configure the application’s option for STOP_TIMEOUT to the desired value. The default timeout value is 3 seconds. To remove the timeout altogether, set the value to 0 or -1. AWARE_APPLICATION - controls the component’s ability for domain awareness. The default domain awareness value is true. To remove a component’s pointer to the domain, set the option AWARE_APPLICATION to false.  To set the application options from the SAD File Overview Tab in the IDE:\n SAD File Overview Tab    To add an option, expand the waveform Options section, click Add, and enter the value. To edit an option, expand the waveform Options section, select the option and edit the value. To remove an option, expand the waveform Options section, select the option and click Remove.  To set the application options using a text editor, the options section must follow the connections section in the SAD file.\nThe following example XML sets the timeout to 5 seconds and the domain awareness to false:\n\u0026lt;softwareassembly id=\u0026#34;DCE:d67ebd01-d580-47ff-9fe6-5560a9d8f5f8\u0026#34; name=\u0026#34;sample_waveform\u0026#34;\u0026gt; \u0026lt;componentfiles\u0026gt; \u0026lt;componentfile id=\u0026#34;SigGen_062a14e1-d152-4eb0-b580-821567b323c6\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/components/rh/SigGen/SigGen.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;/componentfiles\u0026gt; \u0026lt;partitioning\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;SigGen_062a14e1-d152-4eb0-b580-821567b323c6\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;SigGen_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;SigGen_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;/partitioning\u0026gt; \u0026lt;assemblycontroller\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/assemblycontroller\u0026gt; \u0026lt;connections/\u0026gt; \u0026lt;options\u0026gt; \u0026lt;option name=\u0026#34;STOP_TIMEOUT\u0026#34; value=\u0026#34;5\u0026#34;/\u0026gt; \u0026lt;option name=\u0026#34;AWARE_APPLICATION\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/options\u0026gt; \u0026lt;/softwareassembly\u0026gt; The following example Python session sets the timeout to 5 seconds and the domain awareness to false:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; d=redhawk.attach(\u0026#34;REDHAWK_DEV\u0026#34;) \u0026gt;\u0026gt;\u0026gt; app=d.createApplication(\u0026#34;sample_waveform\u0026#34;, initConfiguration={ \u0026#34;STOP_TIMEOUT\u0026#34; : \u0026#34;5\u0026#34; , \u0026#34;AWARE_APPLICATION\u0026#34; : \u0026#34;false\u0026#34; } )"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/configuration/adminservice/",
	"title": "AdminService Configuration",
	"tags": [],
	"description": "",
	"content": " This section explains how to create a custom AdminService configuration and how to configure the rhadmin script used to control the AdminService.\nCreating a Custom AdminService Configuration To create a new AdminService configuration file, enter the following commands.\ncd /etc/redhawk rhadmin config admin \u0026gt; adminserviced.cfg vi adminserviced.cfg The configuration files are located in a system privileged directory. Ensure that you have proper privileges to create and edit files in those directories.\n To start the AdminService as a local user, enter the following command.\nadminserviced To start the AdminService as a system service on CentOS 6, enter the following commands.\n/sbin/service redhawk-adminservice start To start the AdminService as a system service on CentOS 7, enter the following commands.\nsystemctl start redhawk-adminservice.service The following table describes the sections of the AdminService configuration file.\nAdminService Configuration File Sections    Section Description     [unix_http_server] Defines the Unix socket interface to the AdminService.   [rhadmin] Specifies settings for running the rhadmin client.    unix_http_server The unix_http_server section of the AdminService configuration file defines the local socket that the rhadmin can use for remote control of the AdminService.\nConfiguration Parameters This section describes the unix_http_server configuration parameters.\nparameter: file\nrequired: No\ndefault value: /var/run/redhawk/adminserviced.sock\ndescription: The absolute path to a Unix domain socket used to listen for remote commands.\nparameter: username\nrequired: No\ndefault value: redhawk\ndescription: The username for remote control of the AdminServer.\nparameter: password\nrequired: No\ndefault value: redhawk\nformat: Cleartext password or may be specified as a SHA-1 hash if prefixed by the string {SHA}. For example, {SHA}82ab876d1387bfafe46cc1c8a2ef074eae50cb1d is the SHA-stored version of the password thepassword.\ndescription: The password for remote control of the AdminServer.\nrhadmin The rhadmin control script can be configured in the main AdminService configuration file.\nConfiguration Parameters This section describes the rhadmin configuration parameters.\nparameter: serverurl\nrequired: No\ndefault value: unix:///var/run/redhawk/adminserviced.sock\nformat: unix:///path/to/file.sock\ndescription: The path to the Unix domain socket used by the AdminServer.\nparameter: username\nrequired: No\ndefault value: redhawk\ndescription: The username to use when connecting to the AdminServer.\nparameter: password\nrequired: No\ndefault value: redhawk\nformat: Clear text\ndescription: The password to use when connecting to the AdminServer.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/associating-a-waveform/",
	"title": "Associating a Waveform with an FEI Device",
	"tags": [],
	"description": "",
	"content": "Two processes can be used to associate a waveform with an FrontEnd Interfaces (FEI) device:\n Write code that creates an allocation and creates the connection between the allocated device and the waveform or component that is to receive or produce the data. Create a usesdevice relationship artifact in the waveform.  The benefit of creating a usesdevice relationship artifact is that the deployment of the waveform can be tied to the availability of hardware resources. If the usesdevice relationship cannot be established at deployment time, then the waveform deployment will fail. Also, when the waveform is torn down, the allocation created for this deployment is undone automatically.\nTo create a usesdevice relationship artifact on the waveform:\n Create a waveform\n Find and place the usesdevice relationship artifact, which is located under the Advanced tab:\n FrontEnd Tuner Device Artifact   When the artifact is dragged onto the canvas, a menu of target devices is shown. The devices shown are the result of a scan of $SDRROOT.\n Either select the desired device or select the Generic FrontEnd device, which does not have any ports (so a connection cannot be defined), but it allows an allocation to be associated with the deployment.\n Select Target Device   After selecting a device, a series of wizards are displayed. In the wizards, define the usesdevice relationship ID to use and the parameters for the allocation itself.\nThe usesdevice relationship ID is the identifier used in the waveform description to reference the usesdevice relationship artifact. It is an architectural detail that is not relevant to the developer, so use the default value given.\n  If the device has ports, connect them to the appropriate component:\n Create a Connection Between the FEI Device and a Component     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/auto-generated-methods/",
	"title": "Auto-Generated Component Methods",
	"tags": [],
	"description": "",
	"content": " This section provides an overview of noteworthy methods provided in the auto-generated component files. In some cases, the names of the methods vary by language.\nserviceFunction() The core functionality of a component resides in the serviceFunction() method in C++, the process() method in Python, and the serviceFunction() method in Java. The serviceFunction() is invoked on a recurring basis after start() is called on the component’s base class.\nWhen serviceFunction returns NORMAL, it will immediately loop back. In Java, if objects are created in the serviceFunction and no blocking calls are made, garbage collection will be deferred until no more heap space is available. Under these conditions, there are likely to be substantial CPU and JVM memory utilization issues.\n constructor() This is the component/device constructor. When this function is invoked, properties of kind property are initialized to their default or overloaded state.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/sri/",
	"title": "Burst Signal Related Information (SRI)",
	"tags": [],
	"description": "",
	"content": " BurstSRI objects are delivered with each data burst and describe the data payload and processing state from the data producer. The table below describes only the required fields of the data structure when passing burst data between resources.\nBurstSRI fields    Name Type Description     hversion long Version of the StreamSRI header. This field is typically ignored, so a default value of 1 is adequate.   streamID string Stream ID. Unique streams can be delivered over the same port, where each stream is identified by a unique string (generated or passed along by the provides side). The generation of this Stream ID is application-specific and not controlled by the REDHAWK Core Framework (CF).   xdelta double Delta between two values in the payload vector. In the case of time data, this is the sampling period. In the case of spectral data, this is the frequency difference between two adjacent Fast Fourier Transform (FFT) bins.   mode short 0-Scalar, 1-Complex. Complex data is passed as interleaved I/Q values in the sequence. The type for the sequence remains the same for both real and complex data.   expectedStartOfBurstTime BULKIO::PrecisionUTCTime The epoch birth date of the first sample of the sequence.   keywords sequence \u0026lt;CF::DataType\u0026gt; User-defined keywords. This is a sequence of structures that contain an ID of type string and a value of type CORBA Any. The content of the CORBA Any can be any type.    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/configuring-logging-capabilities/",
	"title": "Configuring Logger Settings",
	"tags": [],
	"description": "",
	"content": " A logger is configured through two mechanisms: a log configuration file and a global log level.\nThe log configuration file enables users to manage appenders and configure the settings for individual loggers. The global log level is a shortcut that allows users to set the log level for an entire resource with a single call or command-line switch. When a configuraton file and log level are used together, the configuration file describes the settings for appenders and named loggers, while the log level is applied to the resource\u0026rsquo;s main logger.\nA log configuration file can be:\n Passed as a command-line argument when the Domain Manager is started\nnodeBooter -D -logcfgfile logconfiguration.cfg  When passed through the Domain Manager, every component that does not have a logging configuration set will use the domain\u0026rsquo;s logging configuration.\n  Passed as an initialization property when an application is created\n\u0026gt;\u0026gt;\u0026gt; app = dom.createApplication(\u0026quot;/waveforms/example/example.sad.xml\u0026quot;, initConfiguration={'LOGGING_CONFIG_URI':'file:///home/user/logconfiguration.cfg'})  When passed through the createApplication function, the LOGGING_CONFIG_URI is passed to all components in the application.\n  Added to the component instance in a Software Assembly Descriptor (SAD) file\n Add Logging Configuration to a Component    Passed at runtime through the logging API\n  For devices and services, the log configuration URI is resolved using a slightly different set of rules than REDHAWK components.\n Passed as a command-line argument when the Device Manager is started\nnodeBooter -d $SDRROOT/dev/nodes/DevMgr_hostname/DeviceManager.dcd.xml -logcfgfile logconfiguration.cfg  Added to the device componentinstantiation element as element loggingconfig in the Device Configuration Descriptor (DCD) file\n Added to a device instance as property LOGGING_CONFIG_URI in the DCD file\n  The URI is resolved through 2 different methods:\n Logger found through the SCA file system. For the Domain Manager, this is $SDRROOT/dom; for the Device Manager, this is $SDRROOT/dev. For example, with the Domain Manager, the URI sca:///myfile.cfg is equivalent to $SDRROOT/dom/myfile.cfg.\n Logger found through the local file system: file:///tmp/myfile.cfg is equivalent to /tmp/myfile.cfg.\n  If the relative path to the file is provided as a command-line argument to nodeBooter, the file location is converted to an absolute path directory and then passed as a file URI to subsequent processes.\nIf no log configuration file is provided, the following log configuration is used by default:\nlog4j.rootLogger=INFO,STDOUT log4j.appender.STDOUT=org.apache.log4j.ConsoleAppender log4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout log4j.appender.STDOUT.layout.ConversionPattern=\u0026quot;%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n \\n\u0026quot;  A resource has the ability to provide a severity level (logging level) with each logging message. The following severity levels are listed in order of decreasing severity. FATAL messages describe events that are unrecoverable to the resource through a decreasing level to TRACE, which is used to log fine-grained behavior. Setting a lower severity threshold increases verbosity.\n FATAL ERROR WARN INFO DEBUG TRACE  Each different logging implementation library uses a log4j configuration file format to define the configuration context for that library. This file defines how and where the logging messages are recorded. For example, if the configuration logging level is set to INFO, then messages published at the INFO, WARN, ERROR, and FATAL severity levels are displayed in the log. All other message levels are suppressed. The following two log-level configuration options are also available.\n OFF: Suppress all logging messages from the log ALL: Allow all logging messages  The previous configuration suppresses logging levels above INFO and writes those messages to the standard out console.\nConfiguration Context Tokens For REDHAWK release 1.10 and above, the log4j configuration file can contain special tokens that expand to provide the runtime execution context of the resource. These tokens can be located anywhere in the configuration file and are resolved during resource startup. The following table describes the tokens.\nlog4j Configuration File Special Tokens    Token Definition     @@@HOST.NAME@@@ Host name returned from gethostname call (multi-homed systems may have issues).   @@@HOST.IP@@@ Dot notation IP Address of the machine on which the processing is running.   @@@NAME@@@ Name of the resource given on the command line.   @@@INSTANCE@@@ Instance name given to the resource on the command line.   @@@PID@@@ pid of the running resource.   @@@DOMAIN.NAME@@@ Name of the domain under which your resource is running.   @@@DOMAIN.PATH@@@ The contents of the DOM_PATH parameter on the command line.   @@@DEVICE_MANAGER.NAME@@@ Name of the Device Manager that started the device or service.   @@@DEVICE_MANAGER.INSTANCE@@@ Instance name of the Device Manager from the command line.   @@@SERVICE.NAME@@@ Name of the service as specified on the command line.   @@@SERVICE.INSTANCE@@@ Instance name of the service as specified on the command line.   @@@SERVICE.PID@@@ pid of the running service.   @@@DEVICE.NAME@@@ Name of the device as specified on the command line.   @@@DEVICE.INSTANCE@@@ Instance name of the device as specified on the command line.   @@@DEVICE.PID@@@ pid of the device.   @@@WAVEFORM.NAME@@@ Name of the waveform from the DOM_PATH command line variable.   @@@WAVEFORM.INSTANCE@@@ Instance name of the waveform from the DOM_PATH command line variable.   @@@COMPONENT.NAME@@@ Name of the component binding parameter as specified on the command line.   @@@COMPONENT.INSTANCE@@@ Instance name of the component identifier parameter as specified on the command line.   @@@COMPONENT.PID@@@ pid of the component.    This table lists the availability of token definitions for each REDHAWK resource type.\nAvailability of Tokens    Token Domain Manager Device Manager Device Service Component     @@@HOST.IP@@@ Y Y Y Y Y   @@@HOST.NAME@@@ Y Y Y Y Y   @@@NAME@@@ Domain Manager Y Y Y Y   @@@INSTANCE@@@ DOMAIN_MANAGER_1 Y Y Y Y   @@@PID@@@ Y Y Y Y Y   @@@DOMAIN.NAME@@@ Y Y Y Y Y   @@@DOMAIN.PATH@@@ Y Y Y Y Y   @@@DEVICE_MANAGER.NAME@@@ N DEVICE_MANAGER Y Y N   @@@DEVICE_MANAGER.INSTANCE@@@ N Y Y Y N   @@@SERVICE.NAME@@@ N Y N Y N   @@@SERVICE.INSTANCE@@@ N Y N Y N   @@@SERVICE.PID@@@ N Y N Y N   @@@DEVICE.NAME@@@ N Y Y N N   @@@DEVICE.INSTANCE@@@ N Y Y N N   @@@DEVICE.PID@@@ N Y Y N N   @@@WAVEFORM.NAME@@@ N N N N Y   @@@WAVEFORM.INSTANCE@@@ N N N N Y   @@@COMPONENT.NAME@@@ N N N N Y   @@@COMPONENT.INSTANCE@@@ N N N N Y   @@@COMPONENT.PID@@@ N N N N Y    Log Configuration Example - Simple Appender with a Named Logger In the following example, the root most logger passes logging messages with a severity level INFO or higher. Those messages are sent to the appenders called: CONSOLE and FILE. The CONSOLE appender messages are displayed in the console of the running application. The FILE appender writes log messages to a file called allmsgs.out.\nIf the resource uses a named logger, EDET_1.user.detections, then log messages to this logger with a severity of DEBUG or higher are diverted to a file called edet_log.out.\n# Set root logger default levels and appender log4j.rootLogger=INFO, CONSOLE, FILE # Console Appender log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.STDERR=org.apache.log4j.ConsoleAppender log4j.appender.STDERR.Threshold=ERROR log4j.appender.STDERR.Target=System.err # Default Log Appender log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.Append=true log4j.appender.FILE.File=allmsgs.out # Edet Appender log4j.appender.edetLog=org.apache.log4j.FileAppender log4j.appender.edetLog.Append=true log4j.appender.edetLog.File=edet_log.out # Appender layout log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.STDERR.layout=org.apache.log4j.PatternLayout log4j.appender.STDERR.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.edetLog.layout=org.apache.log4j.PatternLayout log4j.appender.edetLog.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n log4j.appender.NULL.layout=org.apache.log4j.PatternLayout log4j.appender.NULL.layout.ConversionPattern=%n log4j.category.EDET_1.user.detections=DEBUG, edetLog log4j.additivity.EDET_1.user.detections=false  Log Configuration Example - Configuring a Component with Token Macros The logging configuration information for component MEGA_WORKER is configured from $SDRROOT/dom/logcfg/component.log4j.cfg. Prior to configuring the underlying logging library, the configuration information is processed for the context macros (in this example, @@@WAVEFORM.NAME@@@, @@@COMPONENT.NAME@@@ and @@@COMPONENT.PID@@@). The root most logger passes logging messages with a severity level INFO or higher, to the appenders called: CONSOLE and FILE. The CONSOLE appender messages are displayed in the console of the running application. For the FILE appender, the destination file is: /data/logdir/MY_EXAMPLE_1/MEGA_WORKER_1.212.log.\nWaveform: MY_EXAMPLE\nComponent: MEGA_WORKER\nproperty: LOGGING_CONFIG_URI = \u0026ldquo;sca:///logcfg/component.log4j.cfg\u0026rdquo;\n$SDRROOT/\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; dev/\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; deps/\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; dom/ \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; logcfg/ \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; component.log4j.cfg \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n/data/logdir/\n# Set root logger default levels and appender log4j.rootLogger=INFO, CONSOLE, FILE # Console Appender log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender # File Appender log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.File=/data/logdir/@@@WAVEFORM.NAME@@@/@@@COMPONENT.NAME@@@.@@@COMPONENT.PID@@@.log log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=%d{ISO8601}: %p:%c - %m [%F:%L]%n  When the waveform MY_EXAMPLE is deployed on the domain, the component is launched with the following logging configuration:\nMEGA_WORKER \u0026quot;.....\u0026quot; LOGGING_CONFIG_URI sca:///logcfg/component.log4j.cfg?fs=IOR:010…\nLogging with Event Channels for Components, Devices, and Services For REDHAWK resources, the underlying logging functionality has been extended to include support for publishing log messages to a specified event channel. To include this capability, add the org.ossie.logging.RH_LogEventAppender in your log4j configuration file. This appender responds to the following configuration options (all options are string values unless otherwise noted):\nRH_LogEventAppender Configuration Options    Appender Option Description     EVENT_CHANNEL Event channel name where logging messages are published.   PRODUCER_ID Identifier of the resource producing the log message (resource name).   PRODUCER_NAME Name of the resource producing the log message.   PRODUCER_FQN Fully qualified name of the resource (domain-name/waveform-name/resource-name).   RETRIES Number of times to retry connecting to the event channel. (Integer)   THRESHOLD log4cxx log level; FATAL, WARN, ERROR, INFO, DEBUG, TRACE.    In the following example, a component configured with this log4j properties file publishes log messages with a severity of ERROR or higher to the event channel ERROR_LOG_CHANNEL in the domain REDHAWK_DEV. The threshold level for the appender supersedes the rootLogger’s logging level.\nlog4j.rootLogger=INFO,stdout,pse # Direct log messages to stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target=System.out log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n # Direct error messages to an event channel log4j.appender.pse=org.ossie.logging.RH_LogEventAppender log4j.appender.pse.Threshold=ERROR log4j.appender.pse.event_channel=ERROR_LOG_CHANNEL log4j.appender.pse.name_context=@@@DOMAIN.NAME@@@ log4j.appender.pse.producer_id=@@@COMPONENT.INSTANCE@@@ log4j.appender.pse.producer_name=@@@COMPONENT.NAME@@ log4j.appender.pse.producer_FQN=@@@DOMAIN.NAME@@@.@@@WAVEFORM.NAME@@@.@@@COMPONENT.NAME@@@ log4j.appender.pse.layout=org.apache.log4j.PatternLayout log4j.appender.pse.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c:%L - %m%n  Synchronous Logging for C++ Devices and Components In versions of log4cxx older than 0.10.0, logging messages from different sources could be interleaved in the same line when using the default file appender. To deal with this issue, the REDHAWK Core Framework (CF) libraries provide a Synchronous Rolling File Appender that will allow atomic write operations to a common file. To include this capability, add the org.ossie.logging.RH_SyncRollingAppender in your log4j configuration file. This appender responds to the following configuration options (all options are string values unless otherwise noted):\nRH_SyncRollingAppender Configuration Options    Appender Option Description     Retries Number of retries when waiting for the lock fails. (Integer)   WaitOnLock Time in milliseconds to wait when attempting to take ownership of the lock. (Integer)   MaxFileSize Maximum file size before rolling to the next file.   MaxBackupIndex Maximum number of files to keep. (Integer)   File Full local file system path.   Cleanup Clean up synchronization resources when the process ends. (Value is True or False.)    In the following example, a component configured with this log4j properties file publishes a log message to the file MP_RedhawkTest.\nlog4j.rootLogger=INFO,stdout,mp # Direct log messages to stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target=System.out log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n log4j.appender.mp=org.ossie.logging.RH_SyncRollingAppender log4j.appender.mp.Retries=2 log4j.appender.mp.WaitOnLock=30 log4j.appender.mp.MaxFileSize=5MB log4j.appender.mp.MaxBackupIndex=10 log4j.appender.mp.File=MP_RedhawkTest log4j.appender.mp.Cleanup=False log4j.appender.mp.layout=org.apache.log4j.PatternLayout log4j.appender.mp.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c:%L - %m%n  The synchronous appender only works for single GPP systems. The synchronization resources used require all the processes to reside on the same host.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/troubleshooting/connections/",
	"title": "Connection Issues",
	"tags": [],
	"description": "",
	"content": " This section explains how to diagnose connection issues.\nDiagnosing Problems Using the rh_net_diag Script The rh_net_diag script is a Python script used to diagnose various omniORB-related problems and to perform other system checks to diagnose potential problems that may impact a REDHAWK installation. To run this script, enter the following command:\nrh_net_diag By default, the --ns (Naming Service), --dom (Domain Manager), and --dev (Device Manager) options are enabled when the script is executed. These options assume that omniNames, the Domain Manager, and the Device Manager are all running on the host executing the script. For help with rh_net_diag, enable the -h option. For more detailed output, enable the -v option. The four test categories include:\n Standard tests performed every time rh_net_diag is executed.\n Check if OSSIEHOME, SDRROOT, and /etc/omniORB.cfg are readable. Check that omniORB is installed. If /etc/omniORB.cfg is not readable or if omniORB is not installed, the script terminates.  Tests that diagnose potential problems with the Naming Service. They are performed if --ns is enabled.\n Check if omniNames is running. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Retrieve entries currently stored in the Naming Service. Refer to Common Causes for omniNames Failure for further assistance. Check /etc/omniORB.cfg to ensure that all defined endPoints are correct.   If all the above checks pass, but the Domain Manager and Device Manager still cannot communicate with the Naming Service, manually check the firewall settings on the host running omniNames. Confirm there is a firewall rule that allows for new connections between hosts. For example, the following iptables rule allows new TCP connections from subnet 192.168.1.0:\nINPUT -s 192.168.1.0/24 -p tcp -m state --state NEW,ESTABLISHED -j ACCEPT\n  Tests that diagnose potential problems with the Domain Manager. They are performed if --dom is enabled.\n Attempt to retrieve entries currently stored in the Naming Service. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Check /etc/omniORB.cfg to ensure all defined endPoints are correct.  Tests that diagnose potential problems with the Device Manager. They are performed if --dev is enabled.\n Check if InitRef was overwritten with the rh_net_diag script --ORBInitRef option or if we are using the InitRef specified in /etc/omniORB.cfg. If InitRef is valid, attempt to retrieve entries currently stored in the Naming Service. Refer to Common Causes for omniNames Failure for further assistance. Check if omniEvents is running and if it is running locally. If it is not running at all, refer to Performing a Hard Reset Using the cleanonmi Script. If it is not running locally, assume it is running on another host. Try to connect to the Domain Manager if one exists in the Naming Service. Check that the IP address for the host running this script is listed in ifconfig. If there is no matching entry with the Device Manager, then the Java components fail on initialization.   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/waveforms/sample-waveform/",
	"title": "Create and Deploy a Sample Waveform",
	"tags": [],
	"description": "",
	"content": " This section describes the process of creating a waveform, deploying this waveform to the staging area, starting a Domain Manager and a Device Manager, creating an instance of an application representing this waveform, releasing the application, and shutting down the Domain Manager and Device Manager.\nThe Domain Manager and Device Manager normally remain running during the creation/destruction of different applications.\nCreate a Sample Waveform Below is a description of how to create a waveform:\n Select File \u0026gt; New \u0026gt; REDHAWK Waveform Project\n Set the Project name to demo\n Select Finish\n  This opens an editor on the demo.sad.xml file.\nTo add components to this waveform:\n Select the Diagram tab.\n In the Palette, drag the SigGen component onto the diagram.\n In the Palette, drag the HardLimit component onto the diagram.\n Drag a connection between the SigGen_1 dataFloat_out port and the HardLimit_1 dataFloat_in port\n The waveform looks like :  Demo Waveform    If SigGen_1 does not have a yellow 0, right-click the component and select Set As Assembly Controller\n Press Ctrl+S to save or select File \u0026gt; Save.\n Close the Waveform Editor by selecting the X or by selecting File \u0026gt; Close All.\n  Export the Waveform Below is a description of how to export the waveform in the IDE:\n In the Project Explorer view (typically on the left-side) select demo\n Drag the demo project onto the Target SDR in the REDHAWK Explorer view.\n  This installs the waveform into $SDRROOT/dom/waveforms. If a permissions denied error is encountered, ensure that the $SDRROOT is set up per the installation instructions in Installing the Framework from Source.\nVerify that the waveform is installed:\n In the REDHAWK Explorer view, expand Target SDR.\n Expand Waveforms.\n Verify that the demo waveform is shown.\n  Run the Waveform on the Runtime Environment This section provides an overview of how to launch a waveform as an application and release an application.\nLaunching a Domain Begin by starting a Domain Manager and Device Manager.\nLaunch the Waveform  In the REDHAWK Explorer view, right-click the REDHAWK_DEV domain connection.\n Select Launch Waveform\u0026hellip;\n Select the demo waveform, then select Finish.\n To start the waveform, select the Start Waveform (green triangle) button in the toolbar.\n  This opens the waveform explorer. A waveform is displayed in the REDHAWK Explorer by expanding the REDHAWK_DEV domain connection and the waveforms folder.\nOpen a Plot  Left-click the dataFloat_out port to select it.\n Right-click the port to open the port context menu.\n Select Plot Port Data. This opens a plot showing the plot data.\n To clearly view the sinusoid wave in the plot, reduce the frequency produced by SigGen.\n Open the Properties view and change the frequency property to a value of 50.\n  Stop and Release the Application  Select the Stop Waveform (red square) button in the toolbar. The plot stops updating.\n Select the Release Waveform (red X) button in the toolbar. The waveform explorer closes.\n  Shutdown the Domain Finally, shutdown the Domain Manager and Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/creating-a-component/",
	"title": "Creating a Component Project",
	"tags": [],
	"description": "",
	"content": " In this section, an overview of the structure of a component is presented.\nComponent Wizard In the REDHAWK IDE, development of new components, devices, or other artifacts in a REDHAWK environment is contained within an Eclipse project. Each REDHAWK-specific artifact is associated with a wizard that leads the developer through the steps necessary to create a project, which supports the minimum required pieces for proper functioning. For components, the default project settings allow the developer to choose between Python, C++, and Java as the development language. To start the IDE and begin creating a component, run the eclipse binary in the IDE installation directory. Then, select File \u0026gt; New \u0026gt; REDHAWK Component Project.\nComponent Descriptors A REDHAWK component is described through three XML files, a Software Package Descriptor (SPD) file (\u0026lt;component\u0026gt;.spd.xml), a Properties File (PRF) file (\u0026lt;component\u0026gt;.prf.xml), and a Software Component Descriptor (SCD) file (\u0026lt;component\u0026gt;.scd.xml). The role of the SPD is to describe all the files that are associated with the component: the PRF and SCD files, all binaries, and associated data files. The PRF file contains a description of all the properties that this component supports. The SCD file contains a description of the component inputs/outputs.\nThe REDHAWK IDE uses an internal model to maintain the state of the component design. This model is a Java representation of the three XML files described above as well as project-specific information (like the development language). The main screen on the component development perspective contains several tabs. Some of these tabs are for panels and some are for XML files. The different panels available for component design are used to change this model; the model is automatically and continuously mapped to the three XML files. This awareness is symmetrical; much like changes in the panels result in changes in the XML files, changes in the XML files result in automatic updates to the panels.\nPorts Data flow into and out of components is accomplished through the use of ports. Ports are described as being either a provides (input) or uses (output) port. This naming convention is often viewed as counter-intuitive, so an explanation is in order. Ports are RPC interfaces to a component. An input port, therefore, provides functionality that can be used by an output port.\nREDHAWK contains a variety of standardized interfaces that facilitate interoperability. These interfaces are implemented by ports. When a port is selected in the component generation wizard in the REDHAWK IDE, code to implement these interfaces is automatically generated.\nProperties Properties provide a way to adjust a component’s configuration or settings while also allowing external entities (e.g., programs, UIs, or status scripts) to inspect the state of the component. Properties are the primary means for component configuration.\nThere are four types of properties: simple, simple sequence, struct, and struct sequence. A simple property has a single value of a particular primitive type (e.g., short or float). A simple sequence is an array of values of a the same primitive type. A struct property is a structure that contains a set of named simple and/or simple sequence properties. A struct sequence is an array of instances of the same struct type.\nProperties also have a kind that expresses the role in which the property is used. The kind can be property, allocation, or message. The property kind is used for configuration and status. The allocation kind is used to express requirements on capabilities provided by devices. The message kind is used only with struct properties to send event messages within REDHAWK.\nLogging Components, irrespective of which language is used for their implementation, contain access to loggers. Logging in C++, Python, and Java utilizes log4j, a powerful logging framework maintained by the Apache Software Foundation.\nGenerating Code for Components After a component project is created and appropriate details for the component are entered in the SPD editor, the IDE can generate skeleton code for the project. To begin the code generation process, click the Generate All Implementations button located in the top-right of the Overview panel of the SPD editor.  Generate All Implementations Button   When you click the Generate All Implementations button, the IDE:\n Determines if your project contains any deprecated features from older versions of REDHAWK and prompts you to upgrade them. Displays the files that will be generated and enables you to select/deselect files. Generates code files and applies any headers specified in the project documentation. Updates the SPD file with the version of REDHAWK used to generate code.  Code generation is not exhaustive, and custom port types may not compile.\n Installing Components After a component is compiled, it must be installed in the staging area ($SDRROOT/dom/components). To install a component from the Project Explorer view, drag the top-level component project onto the Target SDR section of the REDHAWK Explorer view. See Deploying Projects to the SDRROOT for additional information.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/nodes/creating-a-new-node/",
	"title": "Creating a New Node",
	"tags": [],
	"description": "",
	"content": " As shown in Exploring the Running Node a node is a Device Manager instance with an associated set of devices and services. A node is completely defined by a Device Configuration Descriptor (DCD) XML file. A Device Manager uses the information in this XML file to deploy, configure, and inter-connect devices and services.\nThe REDHAWK Node Project in the REDHAWK IDE provides a mechanism for generating these DCD files. By invoking the REDHAWK Node Project, a wizard is started where the developer selects different characteristics for the node like the project name. In the wizard, the developer must provide both a project name and a Domain Manager name. The Domain Manager name is the name of the domain that the Device Manager automatically associates with upon startup. At runtime, the Domain Manager name that the Device Manager associates with can be overridden.\nThe node project has multiple tabs: Overview, Devices, Diagram, and the DCD file tab (see Node Editor for additional information). The most intuitive tab is the Diagram tab, which allows a developer to drag devices available in $SDRROOT into the node, as shown below. Once the set of members for a particular node is determined, save the project and drag it to Target SDR to install it.\n Node Design Diagram   To launch this new node:\n Right-click the node descriptor, Target SDR \u0026gt; nodes \u0026gt; sample_node. Select Launch Device Manager. The running node is now visible under the running domain’s Device Managers section.  Device and Service Affinity The REDHAWK RPMs do not include a Device Manager with the affinity option enabled. To enable affinity processing by the Device Manager, build the REDHAWK software with the affinity option enabled (run the configure command with the –enable-affinity=yes). For more information about the affinity directives and how to include them in a DCD file, consult Resource Affinity. The following example sets the processing affinity for the ChannelizerSW device to use the CPUs from the second processor socket.\n\u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;ChannelizerSW_12345\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Channelizer_1\u0026#34; startorder=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Channelizer_1\u0026lt;/usagename\u0026gt; \u0026lt;affinity\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_class\u0026#34; value=\u0026#34;socket\u0026#34; /\u0026gt; \u0026lt;!-- uses numa_parse_nodestring, socket id\u0026#39;s start at 0 --\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_value\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;/affinity\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Channelizer_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/domain-manager/",
	"title": "Domain Manager",
	"tags": [],
	"description": "",
	"content": " The Domain Manager is in charge of the control and configuration of the entire systems domain.\nIts primary responsibilities can be grouped into three main categories:\n Registration Core Framework (CF) administration Human Computer Interfacing  Each domain has a single Domain Manager that keeps track of a File Manager, a set of Device Managers, and a set of Application Factories. The Domain Manager maintains information on all aspects of the waveform’s implementations contained within its system.\nThe Domain Manager is configured from the Domain Manager Configuration Descriptor (DMD) XML file that is located at $SDRROOT/dom/Domain. This file contains the domain’s name, an ID and a description of the domain.\nLaunching a Domain Manager from the command line Enter the following commands to launch a Domain Manager from the command line:\nnodeBooter -D INFO:DomainManager - Starting Domain Manager INFO:DomainManager - Starting ORB! Registration The Domain Manager is able to maintain information about all working parts and interactions in the environment through registration. It can be thought of as the Domain Manager’s responsibility of bookkeeping for the system.\nAny time a Device Manager, device, service, or application is created within the system, it is registered through the Domain Manager. Likewise, when they are destroyed, they are unregistered from the Domain Manager. These tasks are handled through a series of register() and unregister() functions for each of the different modules the Domain Manager is responsible for supporting.\nCore Framework Administration The Domain Manager has CF administrative duties that are required to provide interface access to its registered items. The API of the Device Managers, ApplicationFactories, applications, and the FileManager that are registered in the domain are made available to be accessed from an external piece of software.\nThis is made available so that changes can be made from outside of the running domain. A Python module is distributed with REDHAWK that allows for simple interfacing with a running domain. This allows for runtime inspection and tweaking of the environment.\nHuman Computer Interfacing The Domain Manager is also responsible for providing functionality that allows for simple interaction between the user and the system, granting the user control over the running domain. Functionality exists that provides the ability to configure the domain, get its current device, service and application capabilities and launch maintenance functions.\nCapabilities are managed through a series of data structure sequences. Lists are maintained for all services, Device Managers and devices that have been registered with the domain. Each entry in the list contains name and identification information as well as a reference to the object that has been registered. For any application that has been installed, a reference to its Application Factory is stored in a list along with its name and identification information. Once the application has started, its reference, along with all relevant identification, component, connection and ordering information is stored for later retrieval.\nLogging By default the Domain Manager will output messages to the console. You can provide a custom logging configuration file and logging level using the following options:\nnodeBooter -D -endlogcfgfile \u0026lt;config file\u0026gt; -enddebug \u0026lt;5=TRACE,4=DEBUG,3=INFO,2=WARN,1=ERROR,0=FATAL\u0026gt; This file location will be used as the default value when resolving the LOGGING_CONFIG_URI as well as the DEBUG_LEVEL during deployments. For further details about logging configuration files and LOGGING_CONFIG_URI resolution, consult Logging.\nTo override the default resolution of the LOGGING_CONFIG_URI during deployments, the Domain Manager can be launched with an option to use a plugin library (libossielogcfg.so) for this resolution. To activate this feature launch the Domain Manager as follows:\nnodeBooter -D --useloglib Persistence Store A unique feature of the Domain Manager is the ability to recover from catastrophic failures through domain persistence. In order to make use of persistence, the CF must be compiled with support enabled. As of REDHAWK 2.2.1, this is the default build setting. To disable this support when building the CF, refer to Installing the Framework from Source.\nWith this feature enabled, all bookkeeping data structures that are used to maintain information about services, devices, Device Managers, applications, and Application Factories are written to a database whenever any change is made to them. This database file needs to be specified upon launch of the Domain Manager with the --dburl \u0026lt;file path\u0026gt; argument:\nnodeBooter -D --dburl $SDRROOT/dom/persistence.sqlite The --dburl argument only applies to the Domain Manager. It is an error to provide --dburl when only launching a Device Manager.\n During normal operation, all IDs and references to objects within the Domain are stored. If the Domain Manager fails, objects such as components, devices, services, and Device Managers continue to run because they are processes separate from the Domain Manager process. This separation allows the Domain Manager to be relaunched. Once relaunched, the Domain Manager is returned to its last known good state by reloading the database file passed as the dburl argument to nodeBooter. All connections to Device Managers, devices, services, and components are restored; Applications residing in the Domain Manager process space are also restored.\nSystem-Wide Reset When persistence is enabled and the Domain Manager suffers a catastrophic failure, the data storage functions may lose synchronization. (For example, the Naming Service may be out of sync with the object database.) If this occurs, it is necessary to erase the database, clean out the event service, and clean out the Naming Service. In such instances, the Device Managers that are operating in the system, which may span multiple computers, also need to be reset to an idle state.\nTo deal with such instances, each Device Manager contains a separate thread that checks to see if the Domain Manager contains a reference to this Device Manager. If the reference is missing, the Device Manager assumes that the Domain Manager has been restarted to a blank state, and the Device Manager resets itself (as well as all devices and services that it controls). After resetting itself, the Device Manager re-associates with the Domain Manager. The frequency with which the Device Manager checks with the Domain Manager is controlled by the Device Manager property, DOMAIN_REFRESH. This property’s default value is 10 seconds but can be set to any system-appropriate setting.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/dependencies/",
	"title": "External Dependencies",
	"tags": [],
	"description": "",
	"content": " The following sections explain how to install the dependencies from the Fedora Extra Packages for Enterpise Linux (EPEL) and Red Hat/CentOS repositories. Dependencies not available from either of those sources are included with REDHAWK.\nInstalling the EPEL Repository This section explains how to install the EPEL repository.\nFor more information on the Fedora EPEL project, refer to http://fedoraproject.org/wiki/EPEL.\n From the Fedora Downloads Site Install the EPEL repository on your system from the Fedora downloads site.\nFor RHEL/CentOS 7:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm For RHEL/CentOS 6:\nsudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm Standalone EPEL from REDHAWK REDHAWK provides a condensed version of the EPEL yum repository that can be used to satisfy the required external dependencies from the EPEL repository. The repository is available from the REDHAWK release page on github (https://github.com/RedhawkSDR/redhawk/releases/\u0026lt;version\u0026gt;). (Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE. For example, for REDHAWK version 2.0.3, https://github.com/RedhawkSDR/redhawk/releases/2.0.3).\nTo install the Standalone EPEL yum repository from REDHAWK, use the following commands:\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz tar xf redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt;.tar.gz cd redhawk-yum-\u0026lt;version\u0026gt;-\u0026lt;dist\u0026gt;-\u0026lt;arch\u0026gt; sudo yum install --nogpgcheck *.rpm Where \u0026lt;version\u0026gt;, \u0026lt;dist\u0026gt;, and \u0026lt;arch\u0026gt; correspond to the associated REDHAWK version, Linux distribution, and architecture respectively. For example, for REDHAWK version 2.0.3, 64-bit CentOS 6, redhawk-yum-2.0.3-el6-x86_64.tar.gz.\nRuntime-only Dependencies The following dependencies are required for REDHAWK runtime installations.\nDependencies for RHEL/CentOS 6 The following runtime-only dependencies are required for RHEL/CentOS 6 systems.\n python-matplotlib util-linux numpy omniORB omniORB-devel omniORB-doc omniORB-servers omniORB-utils python-jinja2-26 binutils numactl sqlite bash-completion  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install python-matplotlib \\  util-linux \\  numpy \\  omniORB \\  omniORB-devel \\  omniORB-doc \\  omniORB-servers \\  omniORB-utils \\  python-jinja2-26 \\  binutils \\  numactl \\  sqlite \\  bash-completion Dependencies for RHEL/CentOS 7 The following runtime-only dependencies are required for RHEL/CentOS 7 systems.\n gstreamer-python python-matplotlib-qt4 log4cxx util-linux numpy python-jinja2 binutils numactl numactl-libs sqlite bash-completion  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install gstreamer-python \\  python-matplotlib-qt4 \\  log4cxx \\  util-linux \\  numpy \\  python-jinja2 \\  binutils \\  numactl \\  numactl-libs \\  sqlite \\  bash-completion Dependencies for Development and Building from Source The following dependencies are required for development with the REDHAWK Framework and building REDHAWK from source.\nDependencies for RHEL/CentOS 6 The following dependencies are required for development on RHEL/CentOS 6 with the REDHAWK Framework and building REDHAWK from source.\n libuuid-devel boost-devel autoconf automake libtool cppunit-devel expat-devel gcc-c++ java-1.8.0-openjdk-devel junit4 python-devel python-setuptools PyQt4 python-jinja2-26 xsd numactl-devel sqlite-devel  To install the dependencies for RHEL/CentOS 6, enter the following commands:\nsudo yum install libuuid-devel \\  boost-devel \\  autoconf automake libtool \\  cppunit-devel \\  expat-devel \\  gcc-c++ \\  java-1.8.0-openjdk-devel \\  junit4 \\  python-devel \\  python-setuptools \\  PyQt4 \\  python-jinja2-26 \\  xsd \\  numactl-devel \\  sqlite-devel Dependencies for RHEL/CentOS 7 The following dependencies are required for development on RHEL/CentOS 7 with the REDHAWK Framework and building REDHAWK from source.\n gstreamer-python libuuid-devel boost-devel cppunit-devel autoconf automake libtool expat-devel gcc-c++ java-1.8.0-openjdk-devel junit4 log4cxx-devel python-devel python-setuptools PyQt4 python-jinja2 xsd uhd uhd-devel uhd-doc uhd-firmware numactl-devel sqlite-devel  To install the dependencies for RHEL/CentOS 7, enter the following commands:\nsudo yum install gstreamer-python \\  libuuid-devel \\  boost-devel \\  cppunit-devel \\  autoconf automake libtool \\  expat-devel \\  gcc-c++ \\  java-1.8.0-openjdk-devel \\  junit4 \\  log4cxx-devel \\  python-devel \\  python-setuptools \\  PyQt4 \\  python-jinja2 \\  xsd \\  uhd \\  uhd-devel \\  uhd-doc \\  uhd-firmware \\  numactl-devel \\  sqlite-devel Optional Dependencies for Development The following dependencies are required for Octave component development.\n octave-devel  To install the dependencies, enter the following command:\nsudo yum install octave-devel"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/file-system/",
	"title": "File System",
	"tags": [],
	"description": "",
	"content": " The File System interface defines CORBA operations that exists to provide a runtime abstraction of an OS\u0026rsquo; real file system. It gives REDHAWK the ability to have a single interface for reading and writing individual files within a file system regardless of the underlying implementation in the OS.\nFiles that are stored on the File System may be either plain files or directories.\nCharacters and symbols that are valid in directories and file names consist of:\n Upper and lowercase letters Numbers “_” (underscore) “-” (hyphen) “.” (period)  The file names “.” and “..” are invalid in the context of a File System.   Path names are structured according to the POSIX specification where the “/” (forward slash) is a valid character that acts as the separator between directories.\nAdditionally, the File System interface provides implementation of many standard functions such as:\n remove() copy() exists() list() create() open() mkdir() rmdir() query()  File System attached to the Domain Manager mounts with $SDRROOT/dom as the root. Each Device Manager mounts a File System with $SDRROOT/dev as the root.\nFile Manager The File Manager exists to manage multiple distributed file systems. This interface allows these file systems to act as a single entity, though they may span multiple physical file systems on different pieces of hardware. This provides for a distributed file system that functions as a single file system across multiple Device Managers and the Domain Manager.\nThe file manager inherits the Interface Description Language (IDL) interface of a file system. It then delegates tasks from the Core Framework (CF) based off of the path names to the correct mounted file system, depending on where that file system is mounted. It is also responsible for copying the appropriate component files into the specific Device Manager’s file system as applications are installed and launched.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/getting-started/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Installation Installation of the REDHAWK Core Framework and IDE is handled through a set of RPMs. The use of RPMs allows for automated installation of dependencies required for REDHAWK to run as well as automated installation of the Core Framework and IDE. Greater detail on REDHAWK installation can be found in the REDHAWK manual.\nBasic Example The fastest and easiest way to get a REDHAWK application started is through the REDHAWK sandbox, a self contained Python module that is able to run REDHAWK components outside the runtime environment, which limits the components to a single host computer.\nIn order to do this, first bring up a command line terminal. Begin a Python session and import the sandbox module by typing:\nfrom ossie.utils import sb The Sandbox has commands to list components available for use and to create an instance of a component by passing its name as an argument:\nsb.catalog()  Output:\n[\u0026#39;rh.HardLimit\u0026#39;, \u0026#39;rh.SigGen\u0026#39;]  sigGen = sb.launch(\u0026#34;rh.SigGen\u0026#34;) hardLimit = sb.launch(\u0026#34;rh.HardLimit\u0026#34;) The REDHAWK IDE plotting tool can be used in the Sandbox to display data graphically. The path to the Eclipse directory of the installed IDE must be specified in the sandbox (this can also be done by setting the RH_IDE environment variable to the REDHAWK path prior to starting the python session):\nsb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) plot = sb.Plot() The two components need to be connected, and HardLimit must be connected to the plotter to display the results.\nsigGen.connect(hardLimit) hardLimit.connect(plot) Once the HardLimit component is connected to the plotter, a window appears that plots any data coming from the output port. Once the sandbox is started, the plot begins to display data:\nsb.start() Component properties can be modified as attributes of the component. The HardLimit property upper_limit can be changed to set an upper limit on the data that is displayed:\nhardLimit.upper_limit = .8 For further reading on application development, the component and sandbox chapters of the REDHAWK manual provide a more thorough description of the makeup of components and how to test them in the REDHAWK environment.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/ide/",
	"title": "IDE Sandbox",
	"tags": [],
	"description": "",
	"content": " The IDE-based Sandbox provides a graphical environment for launching, inspecting, and debugging components, devices, services, and waveforms. The IDE-based Sandbox can host an instance of a Python-based Sandbox, with both interlinked, allowing artifacts from the Python environment to interact with those on the graphical UI.\nLaunching Components in the IDE Sandbox The following procedures explain how to launch a component in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a component with default property values, from the REDHAWK Explorer view, right-click the component, select Launch in Sandbox, and select an implementation of the component to start within the Sandbox’s Chalkboard.\nThe component is launched in the Sandbox. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue.\n  Customized Property Values  To launch an implementation of a component with customized property values, from the REDHAWK Explorer view, right-click the component, select Launch in Sandbox, and select Advanced.\nIf the component has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\n Select Implementation Dialog   The Assign Initial Properties dialog of the Launch wizard is displayed.\n Assign Initial Properties Dialog    Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Launch Configuration Options Dialog    Specify the launch options and click Finish.\nThe component is launched in the IDE Sandbox. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue.\n  Launching Devices in the IDE Sandbox The following procedures explain how to launch a device in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a device with default property values, from the REDHAWK Explorer view, right-click the device, select Launch in Sandbox, and select an implementation of the device to start within the Sandbox’s Chalkboard.\nThe device is launched in the Sandbox.\n  Customized Property Values  To launch an implementation of a device with customized property values, from the REDHAWK Explorer view, right-click the device, select Launch in Sandbox, and select Advanced.\nIf the device has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\nThe Assign Initial Properties dialog of the Launch wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Specify the launch options and click Finish.\nThe device is launched in the IDE Sandbox.\n  Launching Services in the IDE Sandbox The following procedures explain how to launch a service in the IDE Sandbox.\nDefault Property Values  To launch an implementation of a service with default property values, from the REDHAWK Explorer view, right-click the service, select Launch in Sandbox, and select an implementation of the service to start within the Sandbox’s Chalkboard.\nThe service is launched in the Sandbox.\n  Customized Property Values  To launch an implementation of a service with customized property values, right-click the service, select Launch in Sandbox, and select Advanced.\nIf the service has multiple implementations, the Select Implementation dialog of the Launch wizard is displayed. Select the implementation and click Next.\nThe Assign Initial Properties dialog of the Launch wizard is displayed.\n Enter the Properties information and click Next.\nThe Launch Configuration Options dialog is displayed.\n Specify the launch options and click Finish.\nThe service is launched in the IDE Sandbox.\n  Launching Waveforms in the IDE Sandbox The following procedures explain how to launch a waveform in the IDE Sandbox.\nDefault Property Values  To launch a waveform with default property values, right-click the waveform, select Launch in Sandbox, and select Default.\nThe waveform is launched in the Sandbox.\n  Customized Property Values  To launch a waveform with customized property values, right-click the waveform, select Launch in Sandbox, and select Advanced.\nThe Assign Initial Properties dialog of the Launch waveform wizard is displayed.\n Assign Initial Properties Dialog    Enter the Properties information and click Next.\nThe Launch Configuration Options dialog of the Launch waveform wizard is displayed.\n Launch Configuration Options Dialog    Specify the launch options and click Finish.\nThe waveform is launched in the IDE Sandbox.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/interacting-with-hardware/interacting-fei-device-python-package/",
	"title": "Interacting with an FEI Device with the Python Package",
	"tags": [],
	"description": "",
	"content": " The Python package contains helpers that simplify the allocation/deallocation of FrontEnd Interfaces (FEI) tuners. For example, to allocate a tuner to receive, centered at 1 MHz with a bandwidth of 1kHz, a 10% tolerance in the requested values, and a sample rate of 2 kHz, the following functionality can be used:\n\u0026gt;\u0026gt;\u0026gt; import frontend \u0026gt;\u0026gt;\u0026gt; allocation = frontend.createTunerAllocation(tuner_type=\u0026#34;RX\u0026#34;, allocation_id=\u0026#34;someid\u0026#34;,center_frequency=1e6, bandwidth=1e3,bandwidth_tolerance=0.1, sample_rate=2e3,sample_rate_tolerance=0.1) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(allocation) where dev is a reference to the device object and retval is True if the allocation succeeded.\nTo connect to an allocated tuner, use the Allocation ID as the Connection ID:\n\u0026gt;\u0026gt;\u0026gt; dev.connect(comp, connectionId=\u0026#34;someid\u0026#34;) where comp is a reference to the component being connected to an allocated tuner. If the Connection ID corresponding to an allocation is not provided and the possible sources of data are not ambiguous, the Python package will create a connection that delivers the allocated stream.\nWhen a device contains a single allocated tuner and there is a single output Bulk Input/Output (BulkIO) port, it is possible to unambiguously determine what tuner to connect to and over which port to connect. In such instances, the Python package creates a listener allocation against the allocated tuner and establishes a connection between the FEI device and the destination using the listener Allocation ID as the Connection ID. The created listener enables the owner of the allocation to establish a connection to the data source with the given Allocation ID. When the connection is removed, the Python package automatically deallocates the listener allocation. In such instances, the following call can be used to connect:\n\u0026gt;\u0026gt;\u0026gt; dev.connect(comp) To deallocate the tuner, use the following call:\n\u0026gt;\u0026gt;\u0026gt; dev.deallocateCapacity(allocation) To allocate a listener to a specific allocated tuner, use the following call:\n\u0026gt;\u0026gt;\u0026gt; listen_alloc = frontend.createTunerListenerAllocation(allocation_id, \u0026#34;some ID listener\u0026#34;) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(listen_alloc) To allocate a listener to any tuner with a particular set of values, use the following call:\n\u0026gt;\u0026gt;\u0026gt; allocation=frontend.createTunerGenericListenerAllocation(tuner_type=\u0026#34;RX\u0026#34;, allocation_id=\u0026#34;someidanotherlistener\u0026#34;,center_frequency=1e6, bandwidth=1e3,bandwidth_tolerance=0.1,sample_rate=2e3, sample_rate_tolerance=0.1) \u0026gt;\u0026gt;\u0026gt; retval = dev.allocateCapacity(allocation) Deallocation of listeners follows the same pattern as the deallocation of tuners.\nScanning Tuners Tuners that have a built-in scanning capability can also be accessed through Python helpers. Assuming that the above device is also scanning-capable, to create a scanning allocation that spans between 1 MHz and 1.1 MHz and the retuning rate will be no less than 100 ms, use the following command:\n\u0026gt;\u0026gt;\u0026gt; scan_alloc = frontend.createScannerAllocation(min_freq=1e6, max_freq=1.1e6, mode=\u0026#39;SPAN_SCAN\u0026#39;, control_mode=\u0026#39;TIME_BASED\u0026#39;, control_limit=0.1) \u0026gt;\u0026gt;\u0026gt; dev.allocateCapacity([allocation, scan_alloc]) The allocation does not setup the scan plan, it just requests a device that will support the type of scan that is required. To create the plan, the strategy for the scanner needs to be created. In this case, the strategy will be a single span that will be scanned between 1.0 MHz and 1.1 MHz in 10 kHz increments, with a retune every 150 ms. To setup the strategy and start the scan, use the following commands:\n\u0026gt;\u0026gt;\u0026gt; from redhawk.frontendInterfaces import FRONTEND \u0026gt;\u0026gt;\u0026gt; from ossie.utils import bulkio \u0026gt;\u0026gt;\u0026gt; scan_spans = [FRONTEND.ScanningTuner.ScanSpanRange(1e6, 1.1e6, 1e4)] \u0026gt;\u0026gt;\u0026gt; scan_strategy=FRONTEND.ScanningTuner.ScanStrategy(FRONTEND.ScanningTuner.SPAN_SCAN, FRONTEND.ScanningTuner.ScanModeDefinition(freq_scan_list=scan_spans), FRONTEND.ScanningTuner.TIME_BASED, 0.15) \u0026gt;\u0026gt;\u0026gt; port = dev.getPort(\u0026#34;DigitalScanningTuner_in\u0026#34;) \u0026gt;\u0026gt;\u0026gt; port.setScanStrategy(\u0026#34;someid\u0026#34;, scan_strategy) \u0026gt;\u0026gt;\u0026gt; port.setScanStartTime(\u0026#34;someid\u0026#34;, bulkio.createCPUTimestamp()) Note that the set of frequencies that will be spanned can extend over multiple non-contiguous spans. To setup these non-contiguous spans, use multiple instances of ScanSpanRange in the scan_spans list.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/messaging/message-consumer/",
	"title": "Message Consumer",
	"tags": [],
	"description": "",
	"content": " A message consumer may be created when creating a new component or editing an existing component. After creating a message consumer, you must register your code to receive a message from the port. The following procedures explain how to create a message consumer and register code to process messages.\nCreating a Message Consumer Use the following procedure to add a message consumer port to a component or device using the REDHAWK IDE.\n From the Project Explorer View, double-click the component\u0026rsquo;s Software Package Descriptor (SPD) file.\nThe Component Editor is displayed.\n From the Component Editor, select the Properties tab.\nThe Component Editor Properties tab is displayed.  Component Editor Properties Tab    To add a struct property, click Add Struct.\nThe Struct Property section of the Properties tab is displayed.  Struct Property Section of Properties Tab    In the Struct Property section, enter the name of the message you want the component to consume. The ID defaults to the name you enter.\n From the Kind drop-down, select message.\n In the All Properties section, select the struct property you added. By default, a simple member already exists. You can modify it and create additional members for the struct property. For more information about property structures, kinds, and types, refer to Managing and Defining Properties. After you modify and/or create them, the members of the structure and corresponding property information is displayed.  Struct Property and Members    Select the Ports tab, click Add, and in the Name field, enter a name.\n In the Port Details section, in the Direction drop-down, select bi-dir \u0026lt;uses/provides\u0026gt;.\n Next to the Interface field, click Browse.\nThe Select an Interface dialog is displayed.\n From the list of interfaces displayed, select ExtendedEvent\u0026gt; MessageEvent and click OK.\nThe message consumer port information is displayed.  Message Consumer Port    Regenerate the component.\n  A bidirectional port is required to support connections to an event channel and a message supplier\u0026rsquo;s output (uses) port. In point-to-point connections, the port behaves like a provides port. In connections with an event channel, the consumer behaves like a uses port.\nAfter creating a message consumer, you must register your code to receive a message from the message consumer port.\nRegistering for Messages The following examples explain how to register code in C++, Java, and Python to process an incoming message.\nFor the purposes of the following examples, assume that the structure is as follows:\n id: foo Contains two members:  name: some_string, type: string name: some_float, type: float  The component’s uses/provides port is called message_in The component’s callback function for this message is messageReceived() The component’s name is message_consumer  If a connection exists between this component and either a message producer or an event channel, the following code examples process an incoming message.\nAny message that comes in with the property ID foo will trigger the callback function messageReceived().\n C++ Given the asynchronous nature of events, a callback pattern was selected for the consumer.\nIn the component header file, declare the following callback function:\nvoid messageReceived(const std::string \u0026amp;id, const foo_struct \u0026amp;msg); In the component source file, implement the callback function:\nvoid message_consumer_i::messageReceived(const std::string \u0026amp;id, const foo_struct \u0026amp;msg) { LOG_INFO(message_consume_i, id\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;msg.some_float\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;msg.some_string); } In the constructor() method, register the callback function:\nmessage_in-\u0026gt;registerMessage(\u0026#34;foo\u0026#34;, this, \u0026amp;message_consumer_i::messageReceived); Java Java callbacks use the org.ossie.events.MessageListener interface, which has a single messageReceived() method. The recommended style for Java messaging is to define the callback as a private method on the component class, and use an anonymous subclass of MessageListener to dispatch the message to your callback.\nAdd to the list of imports:\nimport org.ossie.events.MessageListener; Implement the callback as a method on the component class:\nprivate void messageReceived(String id, foo_struct msg) { logger.info(id + \u0026#34; \u0026#34; + msg.some_float.getValue() + \u0026#34; \u0026#34; + msg.some_string.getValue()); } In the constructor() method, register a MessageListener for the message to dispatch the message to your callback:\nthis.port_message_in.registerMessage(\u0026#34;foo\u0026#34;, foo_struct.class, new MessageListener\u0026lt;foo_struct\u0026gt;() { public void messageReceived(String messageId, foo_struct messageData) { message_consumer.this.messageReceived(messageId, messageData); } }); Python In the constructor() method, register the expected message with a callback method:\nself.port_message_in.registerMessage(\u0026#34;foo\u0026#34;, message_consumer_base.Foo, self.messageReceived) In the class, define the callback method. In this example, the method is called messageReceived():\ndef messageReceived(self, msgId, msgData): self._log.info(\u0026#34;messageReceived *************************\u0026#34;) self._log.info(\u0026#34;messageReceived msgId \u0026#34; + str(msgId)) self._log.info(\u0026#34;messageReceived msgData \u0026#34; + str(msgData))"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/pydev-overview/",
	"title": "PyDev Overview",
	"tags": [],
	"description": "",
	"content": "PyDev is an external product that comes bundled with the REDHAWK IDE and provides a Python IDE for Eclipse, which may be used in Python, Jython, and IronPython development.\nPyDev’s many features include:\n Code completion Code completion with auto import Type hinting Code analysis Go to definition Refactoring Debugger Interactive console Unittest integration  PyDev has its own set of documentation and getting started details. First time users are strongly advised to read the Getting Started Guide, which explains how to properly configure PyDev. The PyDev documentation can be found in the following locations:\n PyDev Getting Started, http://pydev.org/manual_101_root.html PyDev Configuring Interpreter, http://pydev.org/manual_101_interpreter.html PyDev Manual, http://pydev.org/manual.html  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/redhawkcoreservices/",
	"title": "REDHAWK Core Services",
	"tags": [],
	"description": "",
	"content": "The following sections explain how to configure and manage the life cycle of the REDHAWK core services using the rhadmin tool. Running the rhadmin tool does not require system privileges, but installation of service INI files into the appropriate directory requires privileges for the users in the redhawk group.\n Domain Manager Service\n Device Manager Service\n Waveform Service\n Managing Entire Domains \n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/redhawkcoreservices/devicemanager/",
	"title": "REDHAWK Device Manager Service",
	"tags": [],
	"description": "",
	"content": " This section explains how to manage a single REDHAWK REDHAWK Device Manager service. For additional information on managing service configurations and life cycle management, refer to Domain Manager Service, Waveform Service, and Managing Entire Domains.\nCreating a Device Service Configuration Using the rhadmin Script To create a node service configuration, enter the following command:\nrhadmin config node \u0026gt; \u0026lt;output file\u0026gt;.ini A sample configuration is created, which requires the DOMAIN_NAME and NODE_NAME configuration properties and the section\u0026rsquo;s name to be specified. The section name may be used with rhadmin commands. For additional configuration property settings, refer to the Device Manager Configuration File. For the file to be recognized by the AdminService, the file must have an .ini extension and be installed into the proper service directory: /etc/redhawk/nodes.d.\nCreating a Device Service Configuration Using the REDHAWK IDE  In the REDHAWK IDE, to create a configuration file, click the Generate Node button in the Device Configuration Descriptor (DCD) editor.  Generate Node Button    In the Regenerate Files dialog, check the checkbox next to the .ini file to generate it. If the .spec file is also checked, the generated .spec file will include the installation of the .ini file.  Generate Node File Selection     Displaying a Configuration To display the current configuration for a service, enter the following command:\nrhadmin getconfig \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Starting a Service To start a single Device Manager service, enter the following command:\nrhadmin start \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Stopping a Service To stop a single Device Manager service, enter the following command:\nrhadmin stop \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Requesting Status of a Service To status a single Device Manager service, enter the following command:\nrhadmin status \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Restarting a Service To restart a single Device Manager service, enter the following command:\nrhadmin restart \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Example Session The following example creates, activates, starts, and statuses a Device Manager service for the domain, REDHAWK_PROD, which is identified by the section name prodsvr1_gpp.\n# generate a node configuration file rhadmin config node \u0026gt; redhawk_prod_svr1_gpp.ini # edit the ini file and change node1 to prodsvr1_gpp in [node:node1], # and set the following properties: DOMAIN_NAME=REDHAWK_PROD, NODE_NAME=ProdSvr1_GPP vi redhawk_prod_svr1_gpp.ini cp redhawk_prod_svr1_gpp.ini /etc/redhawk/nodes.d rhadmin update REDHAWK_PROD rhadmin start REDHAWK_PROD:prodsvr1_gpp rhadmin status REDHAWK_PROD:prodsvr1_gpp # produces the following output REDHAWK_PROD:prodsvr1_gpp RUNNING pid 2345, uptime 0:00:10"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/sri/",
	"title": "Signal Related Information (SRI)",
	"tags": [],
	"description": "",
	"content": " SRI is delivered with the data (when in-band) that describes the data payload. SRI Keywords provides guidance on how to manipulate keywords in SRI. The following table describes the SRI data structure fields.\nSRI Data Structure Fields    Name Type Description     hversion long Version of the Stream SRI header. Set to 1.   xstart double Specifies the start of the primary axis. (Refer to SRI Fields for Contiguous Data or SRI Fields for Framed Data)   xdelta double Specifies the interval along the primary axis. (Refer to SRI Fields for Contiguous Data or SRI Fields for Framed Data   xunits short Specifies the units associated with the xstart and xdelta values. Refer to the REDHAWK Interface Control Document (ICD) for definitions.   subsize long For contiguous data, 0. For framed data, specifies the number of data elements in each frame (i.e., the row length).   ystart double Specifies the start of the secondary axis. (Refer to SRI Fields for Framed Data)   ydelta double Specifies the interval along the secondary axis. Refer to (SRI Fields for Framed Data)   yunits short Specifies the units associated with the ystart and ydelta values. Refer to the REDHAWK ICD for definitions.   mode short 0-Scalar, 1-Complex. Complex data is passed as interleaved I/Q values in the sequence. The type for the sequence remains the same for both real and complex data.   streamID string Stream ID. Unique streams can be delivered over the same port, where each stream is identified by a unique string (generated or passed along by the provides side). The generation of this Stream ID is Application-specific and not controlled by the REDHAWK Core Framework (CF).   blocking boolean Flag to determine whether the receiving port exhibits back pressure. If this is false and the provides-side queue is full, the data is dumped. If this is true and the provides-side queue is full, the pushPacket() call blocks.   keywords sequence \u0026lt;CF::DataType\u0026gt; User defined keywords. This is a sequence of structures that contain an ID of type string and a value of type CORBA Any. The content of the CORBA Any can be any type.    There are two modes of operation for Bulk Input/Output (BulkIO), contiguous or framed data, with subsize equal to zero or frame size, respectively.\nContiguous Data The most common use of BulkIO is to transfer contiguous data, typically digitized samples. The SRI subsize field must be set to 0. The primary axis is typically in units of time. The secondary axis is unused. The following table describes the SRI fields for contiguous data.\nSRI Fields for Contiguous Data    Name Description     xstart Specifies, in units identifed by xunits, the start time of the first sample, relative to the Unix epoch (January 1, 1970).   xdelta Specifies the interval between consecutive samples.   xunits Specifies the units associated with the xstart and xdelta values.   subsize Set to 0.   ystart Not used.   ydelta Not used.   yunits Not used.    Framed Data BulkIO supports framed data, such as the output of an Fast Fourier Transform (FFT), in which one dimension has a fixed size. The SRI subsize field is set to the frame length. The following table describes the SRI fields for framed data.\nSRI Fields for Framed Data    Name Description     xstart Specifies an abscissa-style value (i.e., relative to xunits) associated with the first element in each frame. For example, in streams containing a series of one-dimensional FFT results, each frame represents a frequency interval with xstart specifying the frequency associated with the lower end of the interval. For real-valued samples, xstart is typically zero, while for complex-valued samples, xstart is typically bw/2.   xdelta Specifies the interval between consecutive samples in a frame.   xunits Specifies the units associated with the xstart and xdelta values.   subsize Specifies the number of data elements in each frame (i.e., the row length).   ystart Interpreted the same way as the xstart field in contiguous data (Refer to SRI Fields for Contiguous Data), except that it refers to the start time of the first frame.   ydelta Specifies the interval between consecutive frames.   yunits Specifies the units associated with the ystart and ydelta values.    SRI Transfer SRI is transferred over a connection by the uses-side invoking the provides-side function pushSRI(). The pushSRI() function contains a single argument, an instance of an SRI object.\nEach provides-side port that implements a BulkIO interface expects that SRI regarding data being received become available before any data is transferred. When using the code generators and base classes in the REDHAWK development tools, this behavior is hard-coded into the uses-side BulkIO ports. If the user code on the uses-side of a BulkIO connection does not explicitly invoke a pushSRI() call before any data is sent out, the auto-generated code creates a trivial SRI message with normalized values.\nPart of the hard-coded behavior on the uses-side BulkIO port is to issue a pushSRI() when a new connection is made to the newly-connected object. For example, a system is created in which data is flowing between components A and B. As data is flowing between these components, a new connection is established between components A and C. When this connection is established, a pushSRI() method call is automatically made from component A to component C.\nSRI Keywords SRI is metadata to describe the payload being pushed (for example, sampling period). While it is possible to describe some generic parameters, signal specific parameters are be stored in a generalized structure called SRI Keywords. SRI keywords are passed as a sequence of key/value pairs (CF::DataType) of type CF::Properties. In properties, the keys are strings, and the values are a CORBA type called CORBA::Any. CORBA::Any is a structure that can be used to marshal a wide variety of types. REDHAWK has developed helper APIs to interact with the keyword sequence.\nAdding SRI Keywords in C++, Python, and Java Given a component with simple properties chan_rf and col_rf that are of type double and have an initial value of -1, and a BulkIO StreamSRI instance named sri, the following implementations in C++, Python and Java, push out those property values as the keywords COL_RF and CHAN_RF.\nC++ Implementation The redhawk::PropertyMap property map enables you to manipulate the sequence of keywords.\ninclude \u0026lt;ossie/PropertyMap.h\u0026gt; redhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(sri.keywords); tmp[\u0026#34;CHAN_RF\u0026#34;] = chan_rf; tmp[\u0026#34;COL_RF\u0026#34;] = col_rf; Python Implementation omniORB helpers any.to_any are used to convert a Python type to a CORBA::Any.\nfrom omniORB import any self.sri.keywords.append(CF.DataType(\u0026#34;CHAN_RF\u0026#34;, any.to_any(self.chan_rf))) self.sri.keywords.append(CF.DataType(\u0026#34;COL_RF\u0026#34;, any.to_any(self.col_rf))) Java Implementation The AnyUtils package is used to convert a Java type to a CORBA::Any.\nimport org.ossie.properties.AnyUtils; double chan_rf = this.chan_rf.getValue(); double col_rf = this.col_rf.getValue(); sri.keywords = new DataType[2]; sri.keywords[0] = new DataType(\u0026#34;CHAN_RF\u0026#34;, AnyUtils.toAny(chan_rf, TCKind.tk_double)); sri.keywords[1] = new DataType(\u0026#34;COL_RF\u0026#34;, AnyUtils.toAny(col_rf, TCKind.tk_double)); Verifying SRI Keywords It is possible to verify the keywords and values being pushed out by connecting a DataSink() component in the Python Sandbox. This assumes there is at least one BulkIO output port for the test component, and a pushSRI() call is made on that port. The following code demonstrates this verification:\nfrom ossie.utils import sb comp = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;) sink = sb.DataSink() comp.connect(sink) sb.start() print sink.sri().keywords Retrieving SRI Keywords in C++ Because redhawk::PropertyMap contains CORBA::Any values, retrieving the contents requires the use of getters to convert to a native type. Assuming that the content of a particular keyword is a double:\nredhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(sri.keywords); chan_rf = tmp[\u0026#34;CHAN_RF\u0026#34;].toDouble();"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/shared-libraries/using-a-shared-library-project/",
	"title": "Using a REDHAWK Shared Library Project",
	"tags": [],
	"description": "",
	"content": "To add a shared library dependency to a component or device:\nThe shared library must be installed to SDRROOT before you can add it to a component or device.\n  Open the Software Package Descriptor (SPD) file for the component or device.  Component SPD File    Select the Implementations tab.  Component Implementations Tab    On the left side of the editor, select the appropriate implementation.\n On the right side of the editor, under Dependencies, next to the Dependency box, click Add\u0026hellip;\nThe Edit Dependency dialog is displayed.  Edit Dependency Dialog    In the dialog, change the Kind to Shared Library (SoftPkg) Reference.\n In the Type box, select other.\n Select a shared library from the list of shared libraries installed in the SDRROOT.  Shared Library Dependency Dialog    Click Finish.\nThe shared library dependency is displayed under the All Implementations section of the Implementations tab.  Shared Library Project Dependency    To update your code to use the dependency, click the Generate All Implementations icon.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/viewing-domain-contents/",
	"title": "Viewing the Contents of the Domain in the REDHAWK Explorer View",
	"tags": [],
	"description": "",
	"content": "After the domain connection is established, the file system visible to the Domain Manager and its attached Device Managers is displayed in the REDHAWK Explorer view. Detailed information about each item is available in the Properties view.\nThe Domain Manager’s root contains the following folders:\n Device Managers: Displays the currently connected Device Managers. More than one Device Manager may be connected to the domain. Each Device Manager entry consists of a single node, and each node may contain multiple devices. Right-click devices to monitor port information, plot port output, and play audio.\n Device Managers Folder    Event Channels: Displays the event channels in the domain. Right-click a channel to display the Refresh and Listen to Event Channel options. Select Listen to Event Channel to open the Event Viewer view.\n Event Channels Folder    File Manager: Displays the file systems in the domain. It contains references to all components, devices, waveforms, and the device and Domain Managers\u0026rsquo; configuration and executable files.\n Example Domain File System    Waveforms: Displays the applications in the domain. When applications launch, they are displayed and can be expanded to show each of the running components within the application. These components can be expanded to show the device on which they are executing and port information.\n Example Waveforms Folder     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/waveform-editor/",
	"title": "Waveform Editor",
	"tags": [],
	"description": "",
	"content": " The Waveform Editor presents all the content that can be found within the sad.xml file in an editing environment designed for ease of use.\n Waveform Editor   To open the Waveform Editor, double-click a Software Assembly Descriptor (SAD) file from the Project Explorer view. The Waveform Editor contains an Overview, Properties, Diagram, and a raw XML tab, which contains the SAD file content.\nOverview Tab The Overview tab provides general information about the waveform and hyperlinks to additional waveform-related sections within the IDE.\n Waveform Editor Overview Tab   The Overview tab contains the following sections:\n The General Information section provides controls to set the ID, Name, Version, Controller and Description for the waveform.\n The External Ports section provides the ability to promote a component\u0026rsquo;s port so it is accessible from the waveform object. By default, an external port name is equal to the name of that port within the component, but the external port can be renamed.\nTo change the external port name:\n In the External Ports section, locate the port and click the cell in the External Name column in the port’s row.\n Enter a new value for the name.  Renaming External Ports    Press Enter.\n  The Testing section allows for the launching of local waveforms. A local waveform does not require a running Domain or Device Manager and executes within the Sandbox. A local waveform is similar to launching an individual component in the Chalkboard and constructs the waveform within a new Chalkboard instance. You may launch additional components into the waveform running in the Chalkboard using the palette. These newly launched components have standard runtime actions (Plot, Start, Stop, Terminate, and Connect) available. When the local running waveform is released these newly launched components are not saved in the waveform.\n The Exporting section provides a hyperlink to the Export Wizard, which steps through the process of deploying the waveform into the SDRROOT.\n  Properties Tab The Properties tab provides access to the component’s properties within the waveform.\n Waveform Editor Properties Tab   Within the Properties tab, you can:\n Assign an external property ID Set the overridden value within the SAD file Filter and search for properties Compare the overridden value to the original Properties File (PRF) value  The properties of the component designated as the Assembly Controller are always accessible externally and are grayed out in the Properties tab. Additional properties may be assigned an external ID, which allows for a particular component’s property to be designated as accessible to external waveform objects. See External Properties for additional information.\nTo make a property external:\n Select the properties tab of the application’s SAD file.\n Edit the External ID field by entering the desired ID.\n  The external IDs must be unique. They can not duplicate another external property\u0026rsquo;s ID, or the ID of a property belonging to the assembly controller.\n  Waveform External Properties   Diagram Tab The Diagram tab is used to place components into a waveform, connect components together, set waveform-specific properties for components, make a port external, and add a usesdevice relationship to a FrontEnd Tuner device.\n Waveform Editor Diagram Tab   To zoom in and out on the diagram, press and hold Ctrl then scroll up or down. Alternatively, press and hold Ctrl then press + or -.\n To add a component to the waveform and configure its properties:\n Drag the component from the Palette onto the diagram. Right-click the component. Select Show Properties From the Properties view, change the desired properties. Press Ctrl+S to save the changes.  If you want to quickly locate a component in the Palette, you can replace the text type filter text in the text field at the top of the Palette with a keyword to filter the component list.\n Any property modified here is specific to this waveform and does not impact the component’s execution in other environments.\n To make a port external:\n Left-click the port you want to make external, to gain focus on the port.\n Right-click the port to open the port context menu.\n Select Mark External Port.  Mark External Ports     From the Diagram tab, a user may also use the Find By feature. The Find By feature enables a user to find a resource by name, a service by name or type, or an event channel by name.\nConnections may be made from input to output ports by clicking and dragging from one port to the other. Multiple connections can be drawn to or from ports. Any unsupported or erroneous connection that the IDE can detect is marked with an appropriate indicator. Hovering over the indicator provides information concerning the error.\nTo add a dependency on a FrontEnd Tuner device that the waveform needs to use at runtime (a usesdevice in the XML):\n From the Palette, in the Advanced folder, select Use FrontEnd Tuner Device and drag it onto the diagram. The Allocate Tuner dialog is displayed.  Select Target Device    Select the FrontEnd Tuner device you want to use. This will complete some of the information in the subsequent wizard pages. Alternatively, select Generic FrontEnd Device for defaults. Click Next.  Allocate Tuner    Enter the Uses Device ID and optionally, enter the Device Model, and then click Next.\n Enter the appropriate information and click Next. For more information, refer to Allocating a FrontEnd Tuner.  Identify Ports    Enter the names of any uses and provides ports that you want to use from the target device and click Finish. The Use FrontEnd Tuner Device is displayed in the diagram. When you launch the waveform, the FrontEnd Tuner device must be available in order for the waveform to run.\nThe sad.xml tab displays the raw XML data, which describes this waveform fully. Although not recommended, manually editing the XML file is supported.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/why-ports/",
	"title": "Why Ports?",
	"tags": [],
	"description": "",
	"content": "It seems burdensome to connect components through port objects; this is an additional level of indirection that adds another layer of complexity. This approach is taken largely because it allows modularization of interfaces when components have more than one input or output port.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/working_with_components/",
	"title": "Working with Components, Devices, and Services",
	"tags": [],
	"description": "",
	"content": " The Sandbox contains the following commands for working with components, devices, and services:\n The show() Command The catalog() Command The api() Method The launch() Command  The show() command displays running components, connections between components, and the SDRROOT:\n\u0026gt;\u0026gt;\u0026gt; sb.show() The catalog() command displays which components, devices, and services are available in SDRROOT. To determine what types are displayed, use the objType argument (by default objType=\u0026quot;components\u0026quot;) as shown below:\n\u0026gt;\u0026gt;\u0026gt; sb.catalog() \u0026gt;\u0026gt;\u0026gt; sb.catalog(objType=\u0026#34;devices\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sb.catalog(objType=\u0026#34;services\u0026#34;) An alternative to catalog() is browse(). The function browse() provides formatted human-readable text that describes the items that are installed on the system rather than the computer-friendly list that catalog() provides.\nThe api() method displays the ports and properties for a running component:\n\u0026gt;\u0026gt;\u0026gt; comp.api() Component [FloatToShort]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- float_in IDL:BULKIO/dataFloat:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- short_out IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- max_value (float/SF/32f) 1.0 1.0 min_value (float/SF/32f) -1.0 -1.0 The launch() command launches components, devices, and services. The first argument identifies the object to launch. It may be either a path to an Software Package Descriptor (SPD) file or, for objects installed to the current SDRROOT, the name of the object as given in the SPD. The path can be absolute or relative and does not need to reside in SDRROOT.\nThe following example demonstrates how to launch a device from the current working directory using the path:\n\u0026gt;\u0026gt;\u0026gt; my_dev = sb.launch(\u0026#34;./MyDevice.spd.xml\u0026#34;) The following example demonstrates how to launch a device named SigGen from the current working directory using the name:\n\u0026gt;\u0026gt;\u0026gt; my_dev = sb.launch(\u0026#34;rh.SigGen\u0026#34;) A component\u0026rsquo;s properties, either normal or with the commandline attribute, may be overridden at launch time by passing a dictionary of property IDs and values to the keyword argument properties. These values override the default values listed in the Properties File (PRF) file.\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;MyComponent\u0026#34;, properties={\u0026#34;EXECPARAM_1\u0026#34;: \u0026#34;value\u0026#34;, \u0026#34;normalparam\u0026#34;: \u0026#34;somevalue\u0026#34;}) The execparams named parameter is deprecated but may be in use by legacy systems. Refer to the documentation for pre-REDHAWK 2.0 releases for details about its use.\n In the case of components and devices, after the process is launched and the component is initialized, the component’s properties are set to their default values as listed in the PRF file. The default values for this initial call to initializeProperties() may be overridden by passing a Python dictionary of property names and values to the keyword argument properties:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;MyComponent\u0026#34;, properties={\u0026#34;normalparam\u0026#34;: \u0026#34;somevalue\u0026#34;, ... \u0026#34;frequency\u0026#34;:22e3, ... \u0026#34;sample_rate\u0026#34;: 1000000}) The initial configure() call has been superseded by the use of the initializeProperties() call.\n By default, the Sandbox launches the first component implementation with an entry point that exists on the file system. A particular implementation may be specified by passing the implementation ID to the impl argument:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;MyComponent\u0026#34;, impl=\u0026#34;cpp\u0026#34;) The Sandbox includes limited support for attaching a debugger to a component process. The debugger console opens in a new XTerm window to allow continued interaction on the Sandbox console.\nIn the case of C++, to launch a component and attach gdb to the process, enter the following command:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;./MyComponent.spd.xml\u0026#34;, debugger=\u0026#34;gdb\u0026#34;) The component and gdb are run in separate processes. Exiting gdb closes the window, but the component continues to function.\nThe debugger argument also supports jdb (Java), pdb (Python), and valgrind (Valgrind, a tool used for diagnostics such as memory leak detection).\nTo provide arguments to the supported debuggers, the debugger needs to be instantiated outside the scope of the launch function. For example, to perform a full leak check using Valgrind, use the following argument:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils.sandbox.debugger import GDB, JDB, PDB, Valgrind \u0026gt;\u0026gt;\u0026gt; vg_option = {\u0026#39;--leak-check\u0026#39;:\u0026#39;full\u0026#39;} \u0026gt;\u0026gt;\u0026gt; vg = Valgrind(**vg_option) \u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;./MyComponent.spd.xml\u0026#34;, debugger=vg) If incorrect arguments are passed, the component fails to deploy. Note that the Python debugger does not take arguments.\nProperties In addition to the standard REDHAWK query() and configure() functions, the Sandbox presents a simplified interface to properties for components and devices. Properties can be accessed as attributes on the component object:\n\u0026gt;\u0026gt;\u0026gt; my_comp.string_prop = \u0026#34;Hello World!\u0026#34; \u0026gt;\u0026gt;\u0026gt; my_comp.long_prop 1 Property names are taken from the component PRF file, with any characters that are invalid for Python identifiers replaced by an underscore.\nThe current value of properties with a mode of “readonly” or “readwrite” may be inspected. Properties with a mode of “readwrite” or “writeonly” can be assigned a new value.\nTo view the properties that are available for a given component, along with their types and current and default values, use the api() function.\nSimple properties with numeric types can be assigned from any Python numeric type:\n\u0026gt;\u0026gt;\u0026gt; my_comp.float_prop = 3 \u0026gt;\u0026gt;\u0026gt; my_comp.long_prop = 1.0e3 The value is range checked and coerced into the desired type before being configured on the component:\n\u0026gt;\u0026gt;\u0026gt; my_comp.ushort_prop = -1 ossie.utils.type_helpers.OutOfRangeException: ... Floating point values are truncated, not rounded, during conversion to integer types:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_value = 1.5 \u0026gt;\u0026gt;\u0026gt; my_comp.long_value 1 A simple property with a complex value type can be assigned from a Python complex or two-item sequence. The numeric conversion of the real and imaginary components is identical to that of single numeric values.\n\u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = 1.0+2.5j \u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = (1, 2) Complex properties support assignment from single numeric values; the imaginary component is assumed to be 0.\n\u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop = 1 \u0026gt;\u0026gt;\u0026gt; my_comp.complex_prop 1+0j Properties that have enumerated values in the component’s PRF support assignment using the enumerated name as a Python string:\n\u0026gt;\u0026gt;\u0026gt; siggen.shape = \u0026#34;triangle\u0026#34; Struct properties can be set with a Python dictionary:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop = {\u0026#34;item_string\u0026#34;: \u0026#34;value\u0026#34;, ... \u0026#34;item_long\u0026#34;: 100} The dictionary keys are the IDs of the simple properties that make up the struct. Each value is converted to the appropriate type following the same rules as simple properties. Any struct members that are not in the dictionary retain their current values.\nIndividual struct members may be set directly, using the simple property name:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop.item_string = \u0026#34;new value\u0026#34; Properties have a mode (readwrite, readonly, writeonly), and for compatibility reasons, the mode is a member of the Python Struct property container and cannot change. If the Struct property has a member called “mode”, requesting the member “mode” from the property will return its access mode rather than the content of the property member. Access the value of any element of a property with a reserved word as its name as follows:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_prop[\u0026#34;mode\u0026#34;] = \u0026#34;Hello World!\u0026#34; Setting a struct member as an attribute uses the simple property’s name, while setting the member via a dictionary uses the simple property’s ID.\n Both simple and struct sequence properties may be manipulated as lists. Sequence properties support the common Python list operations, such as slicing and in-place modifiers:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_seq = [1, 2, 3, 4] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq[2:] [3, 4] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq.append(5) \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 3, 4, 5] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq[2:4] = [6] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 6, 5] The items of simple sequences follow the same conversion rules as the corresponding simple property:\n\u0026gt;\u0026gt;\u0026gt; my_comp.long_seq = [1.5, 2.5, 3.5] \u0026gt;\u0026gt;\u0026gt; my_comp.long_seq [1, 2, 3] Each item in a struct sequence works identically to a single struct property:\n\u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq [{\u0026#39;a\u0026#39;:\u0026#39;first\u0026#39;, \u0026#39;b\u0026#39;:1}, {\u0026#39;a\u0026#39;:\u0026#39;second\u0026#39;, \u0026#39;b\u0026#39;:2}] \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq[0].a = \u0026#34;new value\u0026#34; \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq[1] = {\u0026#34;a\u0026#34;:\u0026#34;third\u0026#34;, \u0026#34;b\u0026#34;:3} \u0026gt;\u0026gt;\u0026gt; my_comp.struct_seq [{\u0026#39;a\u0026#39;:\u0026#39;new value\u0026#39;, \u0026#39;b\u0026#39;:1}, {\u0026#39;a\u0026#39;:\u0026#39;third\u0026#39;, \u0026#39;b\u0026#39;:3}] The Sandbox generates a low-level CORBA configure() call each time a property value is set. However, Sandbox components also support setting multiple property values at once using a Python dictionary:\n\u0026gt;\u0026gt;\u0026gt; my_comp.configure({\u0026#34;long_prop\u0026#34;:1, \u0026#34;string_prop\u0026#34;:\u0026#34;new value\u0026#34;}) The keys may be either the property names or IDs. The values are converted in the same manner as setting the individual property directly.\nProperty Listener It is possible to asynchronously listen to changes in properties such that it is not necessary to poll the component to see the state of a particular property. This is done through property change listeners. To implement this listener, create a property change listener and register it with the component. Note that the listener can be a local object or an event channel.\n\u0026gt;\u0026gt;\u0026gt; def property_change_callback(self, event_id, registration_id, resource_id, properties, timestamp): print event_id, registration_id, resource_id, properties, timestamp \u0026gt;\u0026gt;\u0026gt; listener = sb.PropertyChangeListener(changeCallbacks={\u0026#39;prop_1\u0026#39;:callback_fn}) \u0026gt;\u0026gt;\u0026gt; comp.registerPropertyListener(listener, [\u0026#39;prop_1\u0026#39;], 0.5) # check the property every 0.5 seconds"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/helpers/",
	"title": "Helpers",
	"tags": [],
	"description": "",
	"content": "The Python sandbox provides a variety of helpers to both simplify the interaction with REDHAWK subsystems as well as increase the reliability of interactions with these subsystems.\nA common problem is type matching in properties. While Python is very flexible with types, other languages, like C++ and Java, are not. When properties are set on components, the type for the value has to match the type that is expected by the component. Python, given its dynamic type system, will pack the value in what it deems appropriate, which may or may not match the expected type. While the property mapping performs this matching automatically, it is sometimes desirable to create a set of properties for other systemic uses. For example, it may be desirable to use the Allocation Manager, making it impossible for the Python script to know which device will satisfy the allocateCapacity call. To support this need, the createProps function was created. createProps is given a dictionary of the required properties, and it also takes an optional Properties File (PRF). Using the PRF, the property dictionary is converted to the appropriate format, where the filename is the location on the local filesystem.\nThe following example demonstrates how to use the createProps function with an existing PRF to generate a set of properties.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import allocations \u0026gt;\u0026gt;\u0026gt; prop = allocations.createProps({\u0026#39;some_prop\u0026#39;:[1.0,2.0]}, prf=\u0026#39;/var/tmp/sdr/dev/devices/my_dev/my_dev.prf.xml\u0026#39;)"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/base-component-members/",
	"title": "Base Component Members",
	"tags": [],
	"description": "",
	"content": " This section provides an overview of members available to the component class. There are four kinds of members: ports, properties, domain awareness, and network interface.\nPorts Data flow into and out of components is accomplished through the use of ports. Ports are described as being either a provides (input) or uses (output) port. This naming convention is often viewed as counter-intuitive, so an explanation is in order. Ports are RPC interfaces to a component. An input port, therefore, provides functionality that can be used by an output port.\nREDHAWK contains a variety of standardized interfaces that facilitate interoperability. These interfaces are implemented by ports. When a port is selected in the component generation wizard in the REDHAWK IDE, code to implement these interfaces is automatically generated.\nIrrespective of direction, a port is accessed as a member of the component’s base class. Assuming that a port called myport of any interface exists in the component, it is accessed in the following ways in C++, Python, and Java, respectively:\nthis-\u0026gt;myportself.port_myportthis.port_myport See Standardized Data Interfaces for details on how to use ports for sending or receiving data.\nProperties Much like ports, properties are available to the component through generated members to for the component’s base class. The property is found through the property’s name (if it has one) or its ID. For example, if a property is defined with an ID of foo and a name of abc, it would be accessed in the following ways in C++, Python, and Java, respectively:\nthis-\u0026gt;abcself.abcthis.abc If the property does not have a name defined, then it would be accessed in the following way in C++, Python, and Java, respectively:\nthis-\u0026gt;fooself.foothis.foo Note that no automated check is performed on the code generation to avoid a name collision between properties or ports.\nEnumerations simple properties can have enumerated values, which associate symbolic names with values. Code generation creates constants for these values, allowing the component developer to use the symbolic name instead of the literal value. For simple properties in struct or struct sequence properties, the generated constants are nested under the name of the struct.\nC++ In C++, the generated constants for enumerations are static variables in nested namespaces, under the top-level namespace enums:\nenums::simple::LABEL enums::structprop::field::LABEL enums::structseq_struct::field::LABEL Enumerated values for simple properties are in the component base class header, while those in struct or struct sequence properties are in struct_props.h along with the struct definitions.\nJava In Java, the generated constants for enumerations are public static variables in nested static classes, under a top-level class named enums:\nenums.simple.LABEL enums.structprop.field.LABEL enums.structseq_struct.field.LABEL The enums class is a static nested class in the component base class.\nPython In Python, the generated constants for enumerations are class attributes in nested classes, under a top-level class named enums:\nenums.simple.LABEL enums.structprop.field.LABEL enums.structseq_struct.field.LABEL The enums class is imported from the component base class module.\nDomain Awareness Each component has two members that provide a reference to the domain and application in which the component is operating. To retrieve the Domain Manager and Application, access the member functions getDomainManager() and getApplication(), which return a DomainManagerContainer and ApplicationContainer, respectively. DomainManagerContainer has the member getRef(), which returns the CORBA pointer to the Domain Manager object. ApplicationContainer has the member getRef(), which returns the CORBA pointer to the Application object.\nIn the case of devices, instead of getApplication(), the base class contains getDeviceManager(), which returns a DeviceManagerContainer. The DeviceManagerContainer has the member getRef(), which returns the CORBA pointer to the DeviceManager object.\nNetwork Interface If a component contains a dependency against any member of GPP\u0026rsquo;s nic_allocation allocation property, then the framework will, upon deployment, make sure that those network resources are made available to the component. Whichever NIC statisfies the allocation requirement is fed to the component, and it is made available to the developer through the getNetwork() member, which returns a NetworkContainer. NetworkContainer has the member function getNic(), which is the string name of the NIC that satisfied the requirement (i.e.: eth0).\nNote that if the network dependency is declared for any one component, that component’s deployment is made to the core(s) that are closest to the NIC on the processor. This happens automatically with no need for additional input from the deployer.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/",
	"title": "Components",
	"tags": [],
	"description": "",
	"content": "A component is a modular building block that can be inserted into any number of signal processing applications to perform a specific and reusable function. A component is fully defined by its interfaces, properties, and functionality. Examples include a component that tunes, filters, and decimates a wideband signal and one that performs a FM demodulation. Some components inevitably need to be custom implementations, but a majority of signal processing functions can be reused and shared.\nREDHAWK allows for developers to create components in either C++, Python, or Java. C++ is recommended for most computationally-intensive tasks, whereas Python or Java work well for handling metadata manipulation or command and control tasks.\nComponents can be interconnected together within a waveform to create a complete signal processing application or can be run independently in the REDHAWK Sandbox to perform trivial tasks on a local host. The figure below depicts the composition of components into a waveform.\n REDHAWK Workflow   By using the REDHAWK Framework, basic processing elements may be encapsulated as components and reused by other REDHAWK compliant systems. Using the REDHAWK IDE and the included code generators, much of the code for control and input/output can be auto-generated. The figure below depicts the encapsulation of an arbitrary processing algorithm into an auto-generated REDHAWK component wrapper.\n Components    REDHAWK Core Assets     Creating a Component Project     Creating Octave Components     Running a Component     Sandbox     Creating and Running a Hello World Component     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/configuration/",
	"title": "Configuration Files",
	"tags": [],
	"description": "",
	"content": "The parameters defined in the service configuration files control the REDHAWK core services. For more information about the configuration files used to control the REDHAWK core services, refer to the following sections:\n Domain Manager Configuration File\n Device Manager Configuration File\n Waveform Configuration File\n  The parameters defined in the AdminService configuration file control both the AdminService and the rhadmin client script. For more information about the AdminService configuration file, refer to AdminService Configuration.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/octave-components/",
	"title": "Creating Octave Components",
	"tags": [],
	"description": "",
	"content": " REDHAWK provides the ability to auto-generate a REDHAWK component given an Octave M function. Assuming M functions are set up to input/output data vectors rather than relying on file or terminal-based input/output, these components are seamlessly deployable on runtime systems.\nOctave version 3.4 or greater, with development support, must be installed on the development and deployment systems. This requirement can be met by either installing Octave from source or installing the octave-devel RPM.\nThe generated REDHAWK C++ code utilizes the Octave C++ programming interface to:\n Translate incoming REDHAWK data to the available Octave data formats. Call the M function using Octave’s feval() C++ function. Translate the resulting Octave data to REDHAWK data formats.  In many cases, the Octave component can be created without any C++ programming by the developer and without an in-depth understanding of REDHAWK. Developers with a more in-depth understanding of C++ programming and REDHAWK have the option of leveraging more advanced REDHAWK features by modifying the generated C++ code. Furthermore, Octave components can be composed into waveforms with components written in other languages (Java, C++, and Python).\nThe createOctaveComponent Script Octave components can be generated using a command line tool (createOctaveComponent) or using the REDHAWK IDE. The help string for the command line tool can be accessed by entering the following command:\ncreateOctaveComponent --help In the most simple case, the command line tool is passed a list of M files with no additional flags. Function arguments that have a default value are treated as properties and function arguments without default values are treated as ports.\nBelow is an example of a basic M function defined in a file named addConst.m:\nfunction myOutput = addConst(myInput, myConst=0) myOutput = myInput + myConst To generate the component code, use the following command:\ncreateOctaveComponent addConst.m Refer to the createOctaveComponent help string for flags to:\n Automatically compile and install the component. Automatically create an RPM for the component. Enable buffering, which causes the component to wait for an End of Stream (EOS) before processing data. Enable the Octave diary, which writes Octave’s standard out and standard error to a file. Point to shared .m and .oct files. Specify an output directory.  Design Considerations There are a few design considerations to keep in mind when creating an M file to be used in REDHAWK:\n Data must be passed as row vectors or n-by-m matrices. All values must be doubles. Configuration (property) values may be doubles, double vectors, or strings. All numerical properties are treated as complex. The serviceFunction of the component is auto-generated and should not be hand-modified. To manipulate data before or after the feval() call to Octave, modify the inputPackets and outputPackets maps in the preProcess and postProcess methods.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/devices/",
	"title": "Devices",
	"tags": [],
	"description": "",
	"content": " Devices in the Sandbox support all of the features of components, plus additional features specific to devices. A Sandbox device instance always supports the base CF::Device allocation and deallocation interfaces. If the device supports the CF::LoadableDevice, CF::ExecutableDevice or CF::AggregateDevice interfaces, the methods for those interfaces are also available.\nCapacity Allocation The Sandbox provides a simplified interface for capacity allocation and deallocation. The allocateCapacity() and deallocateCapacity() methods can take a Python dictionary of allocation property names and values. The values are automatically converted to the correct data type in the same manner as configure properties.\nThe following code demonstrates allocation and deallocation of multiple properties, including a struct property:\n\u0026gt;\u0026gt;\u0026gt; caps = {\u0026#34;long_cap\u0026#34;: 1000, ... \u0026#34;float_cap\u0026#34;: 1.0, ... \u0026#34;struct_cap\u0026#34;: {\u0026#34;ushort_item\u0026#34;: 0, ... \u0026#34;bool_item\u0026#34;: False}} \u0026gt;\u0026gt;\u0026gt; my_dev.allocateCapacity(caps) True \u0026gt;\u0026gt;\u0026gt; my_dev.deallocateCapacity(caps) If an allocation is successful, allocateCapacity() returns True; if the device does not have sufficient capacity, it returns False.\nAllocation Properties The api() method for devices shows the allocation properties in addition to the ports and configure properties. The names, types and actions of the allocation properties are given:\n\u0026gt;\u0026gt;\u0026gt; my_dev.api() Component [MyDevice]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- None Uses (Output) Ports ============== Port Name Port Interface --------- -------------- None Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- config_prop (float/SF/32f) 1.0 1.0 DeviceKind (string) MyDevice MyDevice long_cap (long) None 1000 float_cap (float) None 100.0 Allocation Properties ====== Property Name (Data Type) Action ------------- ----------- ------ DeviceKind (string) eq long_cap (long) external float_cap (float) external struct_cap (struct) external ushort_item (ushort) bool_item (boolean) Only properties with an action of “external” may be used for the allocateCapacity() and deallocateCapacity() methods.\nFrontEnd Interfaces REDHAWK has defined a standard API for interacting with RF hardware called FrontEnd Interfaces (FEI). The Python sandbox contains multiple helpers to make interaction between the Python environment and FEI devices easier.\nIn FEI, when Bulk Input/Output (BulkIO) data is generated by the FEI device, a set of Signal Related Information (SRI) keywords is mandated. The helper create in the frontend.sri module can translate between the FEI tuner_status structure and the required SRI.\n\u0026gt;\u0026gt;\u0026gt; from frontend import sri \u0026gt;\u0026gt;\u0026gt; my_SRI = sri.create(\u0026#34;my stream id\u0026#34;, self.frontend_tuner_status[tuner_idx])"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/nodes/distributed-computing-and-rf-devices/",
	"title": "Distributed Computing and RF Devices",
	"tags": [],
	"description": "",
	"content": " Dependencies A component can be described as consuming an arbitrary amount of capacity from a device; this relationship is called a dependency. Dependencies are generalized, so it is possible to create a dependency based on attributes (property of kind allocation) of devices irrespective of the specific nature of a device.\nA dependency is defined by how much of a particular device resource is required. For example, a component dependency could be a requirement of 1.7 units of device property some_id. Testing this description requires the runtime environment to only determine whether a device contains an allocation property with the ID some_id; this concept can be generalized to any physical constraint that a device might have, requiring only a convention between the component developer and the device developer regarding a device’s property ID and units, both of which are publicized in a device’s Properties File (PRF) file (prf.xml).\nAllocation Properties Allocation properties are device properties that are associated with an action and are used by the runtime environment to determine whether or not a device can support a particular component dependency. This action can either be external or some logical operation (e.g., eq (equals) or lt (less than)).\nNon-External Properties Non-external properties are evaluated by the runtime environment without querying the device. For example, a component dependency on an allocation property with operation eq might be blue. The runtime environment then checks the device’s PRF file (prf.xml) and the Device Manager’s configuration file for the deployment of that device (dcd.xml) to determine whether that property’s value is equal to blue.\nExternal Properties External properties, on the other hand, are handled by the device. For example, a component dependency on an allocation property with operation external might be yellow. The runtime environment then makes a function call on that device with two arguments: the allocation property ID and the value yellow. The device then, at its own discretion, determines whether to provide a positive response or a negative one. The algorithm used by the device to determine whether or not it has sufficient capacity to allocate against a value of yellow is left up to the device developer.\nAllocation Usage Capacity allocation can be defined at either the component level or the application level. When defining the capacity allocation at a component level, that means that every time this component is deployed, that capacity must be available. When defining the capacity allocation at a application level, that means that every time that this application is deployed, that capacity must be available, irrespective of which components make up the application.\nEven though capacity allocation can be used to describe any dependency that a component may have, in reality there are two kinds of capacities that concern REDHAWK: RF and computing.\nRF Allocation Although RF capacity dependencies can be declared at either the component level or the application level, it is recommended that the allocation be defined at the application level because the application understands the context for the deployment. REDHAWK defines RF allocations using the FrontendInterfaces specification. For more information, refer to Frontend Interfaces (FEI).\nComputing Allocation Determining capacity for computation is different from determining RF needs. RF needs are fairly straightforward (i.e.: I need to tune to 100 MHz with a 200 kHz bandwidth). Computing resources, on the other hand, can vary substantially. A program (i.e.: a component) consumes different amount of computing resources depending on the nature of the computing platform. Things like L2 cache size and the layout of the processor (from a NUMA perspective) can have a dramatic impact on the computational load a program has on the processor.\nDue to the variability intrinsic to computing resources, REDHAWK does not rely on hardcoded estimates for the selection of a computing platform. Instead, the GPP implements a reservation mechanism. When a component is loaded onto the GPP, the GPP reserves an arbitrary, and tunable, amount of resources. GPP tracks the state of the component, and when the component changes state from stopped to started, the reservation is tabled, and GPP inspects the actual usage by the component. When the state of the component changes from started to stopped, the tabled reservation is applied again.\nUsing this reservation/observation behavior, components can be automatically distributed over an arbitrary number of computers with no planning needed on the part of the user.\nThe user can force components to deploy to specific GPPs. To force a specific placement, use the device assignment fields when creating the application.\nThe Deployment Process The runtime environment scans all non-busy executable devices registered in the domain to determine which GPP matches the processor/operating system dependency. A device is busy when its state is returned as BUSY, otherwise it is either IDLE or ACTIVE. When a device is found that satisfies all component dependencies, it marks that device as assigned to the deployment of that component and moves on to whatever other components make up the waveform. Once all components have been found an assigned GPP, the components are deployed to all those GPPs.\nBinding a Component’s Deployments to Executable Devices When deploying components, you may want to bind a component’s deployment to a specific executable device without going through the allocation process. The node\u0026rsquo;s definition file, the Device Configuration Descriptor (DCD), provides the necessary deployerrequires id/value pairs to be associated with an executable device. These id/value pairs are alphanumeric strings that are matched during a component’s deployments. If a component defines a set of devicerrequires, then the domain is searched for an ExecutableDevice that has a matching set. For components that do not have an id/value set, but request to deploy on an ExecutableDevice with an id/value set, that request for deployment fails.\nThe following example describes the new xml elements deployerrequires that can be assigned to a GPP device (ExecutableDevice):\n\u0026lt;!-- example of ID/value pairs for a GPP in a DCD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;GPP1_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;RED_NODE:GPP_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;RED_NODE:GPP_1\u0026lt;/usagename\u0026gt; \u0026lt;deployerrequires\u0026gt; \u0026lt;requires id=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;requires id=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/deployerrequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; Distribution of Files All component binaries and descriptor files reside in $SDRROOT/dom on whatever host is running the Domain Manager. In every host that is running a Device Manager, a cache directory is created in $SDRROOT/dev/.\u0026lt;Device Manager name\u0026gt;, with a directory entry for each device that the Device Manager manages. When a component runs on any given device, the binary (or module or JAR file) is copied from $SDRROOT/dom to the device’s cache directory. Using this mechanism, the device can start the component process on a remote host.\nDependency Management A difficulty in deploying a component is that, as a program, it might have dependencies like C/C++ libraries, Python modules, or Java JARs. REDHAWK allows for the creation of soft package dependencies, where a library, module, or JAR can be associated with its own profile. Components that have a runtime dependency with this library, module, or JAR, can declare this library profile as a dependency. When the component is loaded over the network, this dependency is also loaded, and before the component is forked, the component’s local running environment is changed to include the library in $LD_LIBRARY_PATH, module in $PYTHONPATH, or JAR in $CLASSPATH. The allocation/dependency requirements associated with the component are also applied to the library; for example, if a component is designed to run on an x86_64 platform, the runtime environment checks that dependency runs on an x86_64 platform.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/configuration/domainmanager/",
	"title": "Domain Manager Service Configuration File",
	"tags": [],
	"description": "",
	"content": " Each REDHAWK Domain Manager service is controlled by a file in the /etc/redhawk/domains.d directory. The AdminService provides the initial values for the configuration parameters of a service. Any values in the /etc/redhawk/init.d/domain.defaults file override the initial configuration. Finally, the values in the INI file override any configuration (defined internally or specified in the /etc/redhawk/init.d/domain.defaults file).\nrhadmin can generate an example Domain Manager configuration file with the complete set of parameters that can be used to the control the setup and execution of a REDHAWK Domain Manager service. To generate a generic Domain Manager configuration, enter the following command.\ncd /etc/redhawk/domains.d rhadmin config domain \u0026gt; domain.ini To generate a domain configuration from an existing Domain Manager project, enter the following command.\ncd /etc/redhawk/domains.d rhadmin config domain \u0026lt;path/to/domain\u0026gt;/DomainManager.dmd.xml \u0026lt;optional DomainName\u0026gt; \u0026gt; domain.ini Domain Manager Service Configuration Parameters This section describes all available configuration parameters for the Domain Manager service.\nParameter names are case sensitive.\nThe following are the valid values for boolean configuration parameters. If no value is present, the feature is disabled.\nTrue: 1, true, True\nFalse: 0, false, False\n parameter: DOMAIN_NAME\nrequired: Yes\ndefault value: None\nformat: Name with no spaces or periods (for example, REDHAWK_DEV)\ndescription: The domain name to be assigned to the Domain Manager process.\nparameter: FORCE_REBIND\nrequired: No\ndefault value: False (no rebind)\nformat: False : no rebind, True : rebind\ndescription: If the naming context already exists for the DOMAIN_NAME, rebinds the Domain Manager to an existing naming context in the CORBA Naming Service\nparameter: PERSISTENCE\nrequired: No\ndefault value: False (no persistence)\nformat: True : domain persistence enabled, False : disabled\ndescription: Enables persistence for the domain. Requires REDHAWK to be compiled with persistence.\nparameter: DB_FILE\nrequired: No\ndefault value: None\ndescription: The absolute path to the file to use for domain persistence (for example, /data/mysqlite.db). Requires REDHAWK to be compiled with persistence enabled.\nparameter: BINDAPPS\nrequired: No\ndefault value: blank\nformat: True : enables option, blank: disables option\ndescription: Specifies that all running applications and components bind to the Domain Manager process instead of the Naming Service. This assists with high frequency deployments of waveforms and components.\nparameter: USELOGCFG\nrequired: No\ndefault value: None\nformat: True : enables option, blank : disables option\ndescription: Enables the use of $OSSIEHOME/lib/libsossielogcfg.so to resolve the LOGGING_CONFIG_URI command line argument.\nparameter: LOGGING_CONFIG_URI\nrequired: No\ndefault value: defaults.logging.properties\nformat: Absolute path to a file, file://\u0026lt;path\u0026gt; URI or sca://\u0026lt;path\u0026gt; URI\ndescription: The logging configuration file to be used by the Domain Manager. Simple file names will be resolved to files in /etc/redhawk/logging directory. All others will be resolved as an absolute path or URI to a logging properties file.\nparameter: DEBUG_LEVEL\nrequired: No\ndefault value: INFO\nvalues: FATAL, ERROR, WARN, INFO, DEBUG, TRACE\ndescription: The Domain Manager’s logging level at startup.\nparameter: SDRROOT\nrequired: No\ndefault value: $SDRROOT\nformat: Standard shell path environment variable description: The absolute path to use as the SDRROOT for this Domain Manager.\nparameter: OSSIEHOME\nrequired: No\ndefault: $OSSIEHOME\nformat: Standard shell path environment variable\ndescription: The absolute path to use as the OSSIEHOME for this Domain Manager.\nparameter: LD_LIBRARY_PATH\nrequired: No\ndefault value: $LD_LIBRARY_PATH\nformat: Standard shell path environment variable\ndescription: The path for link loader to resolve shared object files; overrides the LD_LIBRARY_PATH environment variable.\nparameter: PYTHONPATH\nrequired: No\ndefault value: $PYTHONPATH\nformat: Standard shell path environment variable\ndescription: The path used by Python interpreter to load modules; overrides the PYTHONPATH environment variable.\nparameter: ORB_CFG\nrequired: No\ndefault value: None\nformat: Standard shell environment variable\ndescription: Sets the OMNIORB_CONFIG variable before running the process. For more information, refer to the omniORB documentation.\nparameter: ORB_INITREF\nrequired: No\ndefault value: None\ndescription: Used as omniORB ORBInitRef command line argument when starting the process. For more information, refer to the omniORB documentation.\nparameter: ORB_ENDPOINT\nrequired: No\ndefault value: None\ndescription: Used as omniORB ORBendPoint command line argument when starting the process. For more information, refer to the omniORB documentation.\nparameter: enable\nrequired: No\ndefault value: True\nformat: True, False, or a string to be matched against conditional_config\ndescription: Specifies if the process may be started. True or False will enable or disable the process. Refer to conditional_config for information about how a string value gets evaluated.\nparameter: conditional_config\nrequired: No\ndefault value: /etc/redhawk/rh.cond.cfg\ndescription: Allows conditional startup of processes based on the enable parameter and the contents of this conditional config. If the value enable is a string, the process will start only if there is a line in the conditional_config file that has that exact content; otherwise, the process is skipped. For example, enable=\u0026quot;type=primary\u0026quot; causes the conditional_config file to be examined for a line equal to type=primary when starting a process on the host. If there is no type=primary line in the file, the process is skipped.\nparameter: priority\nrequired: No\ndefault value: 100\ndescription: The priority of this domain relative to other configured domains. Controls which domain gets started first on the system. Lower values will be started earlier. For example, priority 10 will be started before priority 100.\nparameter: autostart\nrequired: No\ndefault value: True\ndescription: Specifies whether to automatically start this process when the AdminService starts, if enable is True.\nparameter: started_status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to determine if the Domain Manager started properly. A script exit value of 0 indicates the Domain Manager started successfully.\nparameter: status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script to check the status for the Domain Manager. A script exit value of 0 indicates the Domain Manager is alive.\nparameter: query_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to get a detailed status output for the Domain Manager.\nparameter: environment\nrequired: No\ndefault value: None\nformat: A list of key/value pairs in the form key=\u0026quot;value\u0026quot;,key2=\u0026quot;value2\u0026quot;\ndescription: Specifies whether to override existing environment variables or set new ones to be used when starting the Domain Manager.\nparameter: user\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with User ID.\nparameter: group\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with Group ID.\nparameter: umask\nrequired: No\ndefault value: None\ndescription: The umask for the process.\nparameter: nicelevel\nrequired: No\ndefault value: None\ndescription: Specifies to run the process using nice with this niceness level.\nparameter: affinity\nrequired: No\ndefault value: None\ndescription: Enables numactl processing. Any valid NUMA control directives will be passed on command line when starting the process. For more information, refer to the numactl documentation.\nparameter: corefiles\nrequired: No\ndefault value: None\ndescription: The maximum size of core files created. This value is passed to the ulimit command using the -c flag when starting the process.\nparameter: ulimit\nrequired: No\ndefault value: User’s environment\ndescription: This value is passed directly to the ulimit command when starting the process. For more information, refer to the ulimit documentation.\nparameter: directory\nrequired: No\ndefault value: $SDRROOT\ndescription: Specifies to change the directory to directory before running the process.\nparameter: run_detached\nrequired: No\ndefault value: True\ndescription: Specifies to run the Domain Manager as a daemon, not a child of the AdminService process.\nparameter: logfile_directory\nrequired: No\ndefault value: /var/log/redhawk/domain-mgr\ndescription: The absolute path to the logging directory.\nparameter: stdout_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.stdout.log\ndescription: The name of a file that captures the stdout from the process. If not specified, the default value list above is used.\nparameter: stderr_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.stderr.log\ndescription: If redirect_stderr is False, the name of a file that captures the stderr from the process. If not specified, the default value list above is used.\nparameter: redirect_stderr\nrequired: No\ndefault value: True\ndescription: Specifies to write stdout and stderr to the same file.\nparameter: start_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the process is started.\nparameter: start_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the process is started.\nparameter: stop_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the process is stopped.\nparameter: stop_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the process is stopped.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/getting-started/ide-quickstart/",
	"title": "IDE Quickstart",
	"tags": [],
	"description": "",
	"content": " This section provides a simple example of the REDHAWK signal processing development environment, though it is far from a comprehensive guide to all of the features available in the REDHAWK IDE. While this guide assumes the user has no prior knowledge of the REDHAWK Core Framework, certain concepts and skills are required to fully understand the material.\nThe minimum technical requirements include:\n Object-oriented programming experience Linux/Unix experience Engineering/Computer Science background Understanding of basic communication theory  In addition to the minimum set of technical requirements, the following prerequisites must be met before beginning the following procedure:\n REDHAWK Core Framework and IDE installed Example components installed:  SigGen HardLimit   Basic IDE Use The following sections discuss how to launch the REDHAWK IDE, how to open the Chalkboard, how to create a signal generator, and how to test the input/output response of a component.\nLaunching the REDHAWK IDE  Start the REDHAWK IDE with the following command:\nrhide If prompted to specify a workspace location, select an appropriate location and select OK.\n  Opening the Chalkboard From the REDHAWK Explorer view expand Sandbox, and double-click Chalkboard.  Chalkboard   Creating a Signal Generator  From the Chalkboard Palette, drag the SigGen (python) component into the Chalkboard canvas.\n In the Palette, if the SigGen component is not displayed, under Components, left-click the rh folder to display the list of available components. If the Python implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name. After the list is displayed, left-click the desired implementation. When the component is finished loading, its background color is blue.  Right-click the SigGen component, and click Start.\n Right-click the SigGen component, and click Show Properties.\n From the Properties view, change the frequency to 20Hz.\n From the Properties view, change the magnitude to 1.\n Right-click SigGen’s dataFloat_out port, and click Plot Port Data.\n Right-click the SigGen component, and click Stop.\n  Testing the Input/Output Response of a Component  From the Chalkboard Palette, drag the HardLimit (python) component into the Chalkboard canvas.\n In the Palette, if the HardLimit component is not displayed, under Components, left-click the rh folder to display the list of available components. If the Python implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name. After the list is displayed, left-click the desired implementation. When the component is finished loading, its background color is blue.  Click-and-drag from SigGen’s dataFloat_out port to the HardLimit dataFloat_in port.\n Right-click the SigGen component, and click Start.\n Right-click the HardLimit component, and click Start.\n Right-click the HardLimit’s dataFloat_out port, and click Plot Port Data. Two Plot Port views are now open, one for each of the plotted ports.\n  Right-click the SigGen component, and click Show Properties.\n From the Properties view, change the magnitude to 5.\nThe Plot Port view for the HardLimit dataFloat_out port is now limiting the output to 1.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/standalone-ide/",
	"title": "Installing a Stand-alone IDE",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE leverages Java technologies and requires Java 8. The IDE also includes native libraries that allow the IDE to have a look and feel appropriate for the OS. A minimum of 2 GB of RAM is required, but 4 GB+ is recommended.\nThe following procedure explains how to install a stand-alone IDE.\n Ensure your system has the appropriate dependencies installed.\nOn RHEL/CentOS 7:\nsudo yum install java-1.8.0-openjdk-devel PackageKit-gtk3-module libcanberra-gtk3 libwebkit2gtk On RHEL/CentOS 6:\nsudo yum install java-1.8.0-openjdk-devel PackageKit-gtk-module libcanberra-gtk2 webkitgtk Locate the appropriate archive from the REDHAWK release page on GitHub (https://github.com/RedhawkSDR/redhawk/releases/\u0026lt;version\u0026gt;). (Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE. For example, https://github.com/RedhawkSDR/redhawk/releases/2.0.3).\n Run the following command:\ntar zxf redhawk-ide-\u0026lt;version\u0026gt;-linux.gtk.\u0026lt;arch\u0026gt;.tar.gz Where \u0026lt;version\u0026gt; corresponds to the version of the REDHAWK IDE and \u0026lt;arch\u0026gt; is x86_64 for 64-bit systems.\n Start the IDE by running the eclipse executable in the eclipse directory.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/multiout-ports/",
	"title": "Multi-out Ports",
	"tags": [],
	"description": "",
	"content": "Each output Burst Input/Output (BurstIO) port type provides the ability to filter burst data from the resource based on Stream ID and Connection ID. To use the multi-out capability of the ports, a resource must include code similar to the following:\n\u0026lt;structsequence id=\u0026#34;connectionTable\u0026#34;\u0026gt; \u0026lt;struct id=\u0026#34;connectionTable::connection_descriptor\u0026#34; name=\u0026#34;connection_descriptor\u0026#34;\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::connection_id\u0026#34; name=\u0026#34;connection_id\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::stream_id\u0026#34; name=\u0026#34;stream_id\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::port_name\u0026#34; name=\u0026#34;port_name\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt; \u0026lt;kind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/simple\u0026gt; \u0026lt;/struct\u0026gt; \u0026lt;configurationkind kindtype=\u0026#34;configure\u0026#34;/\u0026gt; \u0026lt;/structsequence\u0026gt; To steer a particular stream of data to a particular connection, pass the connectionTable object to the port’s updateConnectionFilter method. With the routing mode set to ROUTE_CONNECTION_STREAMS, the port will then apply the filter state to any burst traffic as it is passed out the resource’s BurstIO port. For the burst to be passed to an existing connection, there must exist a match in the port’s filters table for the burst’s Stream ID and Connection ID of the resource downstream.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/node-editor/",
	"title": "Node Editor",
	"tags": [],
	"description": "",
	"content": " The Node Editor presents all the content that can be found within the dcd.xml file in an editing environment designed for ease of use.\n Node Editor   To open the Node Editor, double-click a Device Configuration Descriptor (DCD) file from the Project Explorer view. The Node Editor contains an Overview, Devices, Diagram, and a raw XML tab, which contains the DCD file content.\nOverview Tab The Overview tab provides general information about the node with hyperlinks to additional node-related sections within the IDE.\n Node Editor Overview Tab   In the top-right corner, the Generate Node button is used to generate supporting files for the node. To produce an RPM spec file for the node, click the button.\n The General Information section provides controls to set the ID, Name, and Description of the node. The Project Documentation section displays a Header hyperlink, which if clicked, provides the option to create and edit the file \u0026ldquo;HEADER\u0026rdquo; in the project. When code generation is performed, the header is applied to your project files. The Testing section is currently under development and is presently not supported. The Exporting section provides a hyperlink to the Export Wizard, which steps through the process of deploying the node into the SDRROOT.  Devices/Services Tab The Devices/Services tab enables a user to add devices and services from the SDRROOT into the node and to configure the properties for the devices and services. When a property is set or changed here, it is specific to this node and does not impact other nodes or instances of this device or service.\n Node Editor Devices/Services Tab   The following steps explain how to add a device to the node:\n Click Add….\n Select the device or service to add.\n Click Finish.\n  Use the table in the Details section to configure the properties of the device or service.\nDiagram Tab The Diagram tab enables a user to add devices and services from the SDRROOT into the node, configure the properties for the devices and services, and make connections.\n Node Editor Diagram Tab   To zoom in and out on the diagram, press and hold Ctrl then scroll up or down. Alternatively, press and hold Ctrl then press + or -.\n Adding a Device and Editing Device Properties in a Node The following steps explain how to add a device to the node and configure its properties:\n Drag the device from the Palette onto the diagram.\n Select the device.\n Open the Properties view and verify the Properties tab is selected.  Properties View    From the Properties view, change the desired properties.\n Press Ctrl+S to save the changes.\n  If you want to quickly find a device in the Palette, you can replace the text type filter text in the text field at the top of the Palette with a keyword to filter the device list.\n Like the Devices/Services tab, any property modified from the Diagram section is specific to this node and does not impact the device’s execution in other environments.\nEditing the deployerrequires Set in a Node The deployerrequires set for a Node is managed through the Requirements tab of the Properties view. When these Requirements are set, they become specific to the node and are written to the *.dcd.xml file.\nThe following steps explain how to edit the deployerrequires set.\n On the Diagram tab of the Node, select the Device In the Properties view, verify the Requirements tab is selected.  Properties View Requirements    To add an ID and value, click + and add the ID and value. The ID and value can be any alphanumeric string value. This assigns a devicerequires key/value pair to the Node. To remove an ID and value, select the ID and click X.  Using the Find By Feature From the Diagram tab, a user may also use the Find By feature. The Find By feature enables a user to find a resource by name, a service by name or type, or an event channel by name.\nMaking Connections Connections may be made from input to output ports by clicking and dragging from one port to the other. Ports may have more than one connection drawn to or from them. Any unsupported or erroneous connection detected by the IDE is marked with an appropriate indicator. Hovering over the indicator provides information concerning the error.\nStart Order The Diagram tab also displays the start order of devices and services in the waveform. Start order represents the order in which its start() method is called by the Device Manager on startup, and the order in which its stop() method is called by the Device Manager on shutdown.\n Devices/Services Start Order   Each of the devices/services within the node contains a number with a circle around it, which represents that device’s/service’s start order. The start order 0 is called first. Start order is optional and may be changed by right-clicking a device/service and selecting Move Start Order Earlier or Move Start Order Later from the context menu. Devices/services without a start order will not be started or stopped automatically.\nThe dcd.xml Tab The dcd.xml tab displays the raw XML data, which describes the node fully. Although not recommended, manually editing the XML file is supported.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/shared-libraries/packaging-shared-libraries/",
	"title": "Packaging Shared Libraries",
	"tags": [],
	"description": "",
	"content": " The REDHAWK code generators for components support locating and building against REDHAWK shared libraries in C++, Python, and Java. This section covers the conventions for packaging shared libraries to allow the REDHAWK build system to find, build, and run with shared libraries. The REDHAWK IDE provides a C++ shared library project type that automatically manages the build and installation of C++ libraries; however, in some cases, it may be necessary to create a REDHAWK shared library manually.\nGeneral A shared library has a Software Package Descriptor (SPD) but does not include a Properties File (PRF) or Software Component Descriptor (SCD).\nThe implementation has a localfile element but no entrypoint. The localfile points to the directory or file that contains the library.\nShared libraries are installed in $SDRROOT/dom/deps/\u0026lt;library name\u0026gt;/. Libraries may be namespaced; for example, a library named rh.example would be installed to $SDRROOT/dom/deps/rh/example/.\nC++ Libraries The implementation of a C++ shared library is a .so file, or a directory containing multiple .so files. For building and linking components, C++ shared libraries also contain header files and a .pc file.\nHeader files are installed in include/ under the top-level soft package directory. Libraries are installed in the implementation directory, typically cpp/lib/. The shared library must include a .pc file that is installed in pkgconfig/ under the library directory (for example, cpp/lib/pkgconfig/mylib.pc).\nThe following example shows a file list for a C++ library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/include/mylib.h $SDRROOT/dom/deps/mylib/cpp/lib/libmylib.so $SDRROOT/dom/deps/mylib/cpp/lib/pkgconfig/mylib.pc  At runtime, the implementation directory is added to LD_LIBRARY_PATH.\nPython Libraries The implementation of a Python shared library is one or more .py modules. The modules may be standalone, or organized into packages.\nPython code is installed in the implementation directory, python. The library must be importable from that location.\nThe following example shows a file list for a Python library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/python/mylib/__init__.py $SDRROOT/dom/deps/mylib/python/mylib/utils.py  At runtime, the implementation directory is added to PYTHONPATH.\nJava Libraries The implementation of a Java shared library is a single .jar file.\nThe .jar file is installed in the implementation directory, java/.\nThe following example shows a file list for a Java library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/java/mylib.jar  At runtime, the .jar file is added to CLASSPATH.\nOctave Libraries The implementation of an Octave shared library is a directory of .m files.\nOctave code is installed in the implementation directory (typically noarch).\nThe following example shows a file list for an Octave library named mylib:\n $SDRROOT/dom/deps/mylib/mylib.spd.xml $SDRROOT/dom/deps/mylib/noarch/func1.m $SDRROOT/dom/deps/mylib/noarch/func2.m  At runtime, the implementation directory is added to OCTAVE_PATH.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/port-access/",
	"title": "Port Access",
	"tags": [],
	"description": "",
	"content": "A port belongs to a component or device (devices are specialized components - see Working With Devices for additional information). To retrieve a port, an external entity needs to call getPort() on the component that owns that port. The argument to the getPort() function is the string name for the port, and the return value is a CORBA pointer to that port object. Both uses and provides ports are retrieved from components through this function call. Base supported interfaces are not retrieved through the getPort(), because they are not ports. Instead, these references are retrieved directly from an entity like the Domain Manager or the Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/redhawkcoreservices/waveform/",
	"title": "REDHAWK Waveform Service",
	"tags": [],
	"description": "",
	"content": " This section explains how to manage a single REDHAWK waveform service. For additional information on managing service configurations and life cycle management, refer to Domain Manager Service, Device Manager Service, and Managing Entire Domains .\nCreating a Waveform Service Configuration Using the rhadmin Script To create a waveform service configuration, enter the following command:\nrhadmin config waveform \u0026gt; \u0026lt;output file\u0026gt;.ini A sample configuration is created, which requires the DOMAIN_NAME and WAVEFORM configuration properties and the section’s name to be specified. The section name may be used with rhadmin commands. For additional configuration property settings, refer to the Waveform Configuration File . For the file to be recognized by the AdminService, the file must have an .ini extension and be installed into the proper service directory: /etc/redhawk/waveforms.d.\nCreating a Waveform Service Configuration Using the REDHAWK IDE  In the REDHAWK IDE, to create a configuration file, click the Generate Waveform button in the Software Assembly Descriptor (SAD) editor.  Generate Waveform Button    In the Regenerate Files dialog, check the checkbox next to the .ini file to generate it. If the .spec file is also checked, the generated .spec file will include the installation of the .ini file.  Generate Waveform File Selection     Displaying a Configuration To display the current configuration for a service, enter the following command:\nrhadmin getconfig \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Starting a Service Starting a waveform service will install the Application Factory in the Domain Manager and then start the waveform. To start a single waveform service, enter the following command:\nrhadmin start \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Stopping a Service To stop a single waveform service, enter the following command:\nrhadmin stop \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Requesting Status of a Service To status a single waveform service, enter the following command:\nrhadmin status \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Restarting a Service To restart a single waveform service, enter the following command:\nrhadmin restart \u0026lt;Domain Name\u0026gt;:\u0026lt;section name\u0026gt; Example Session The following example creates, activates, starts, and status a waveform service for the domain, REDHAWK_PROD, which is identified by the section name controller.\n# generate a waveform configuration file rhadmin config waveform \u0026gt; redhawk_prod_controller.ini # edit the ini file and change waveform1 to controller in [waveform:waveform1], # and set the following properties: DOMAIN_NAME=REDHAWK_PROD, WAVEFORM=controller vi redhawk_prod_controller.ini cp redhawk_prod_controller.ini /etc/redhawk/waveforms.d rhadmin update REDHAWK_PROD rhadmin start REDHAWK_PROD:controller rhadmin status REDHAWK_PROD:controller # produces the following output REDHAWK_PROD:controller RUNNING pid 3456, uptime 0:00:10"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/stream-api/",
	"title": "Stream API",
	"tags": [],
	"description": "",
	"content": " The Bulk Input/Output (BulkIO) stream API provides a high-level interface to sending and receiving data via BulkIO ports. Each stream is tied to a port, and encapsulates both the Signal Related Information (SRI) and the data associated with it.\nStreams are automatically managed by the port that creates them. User code does not own the stream itself; instead, user instances are opaque stream handles. This allows them to be passed around by value or safely stored in other data structures.\nAll BulkIO port types, except for SDDS and VITA49, support the stream API.\nMost stream methods are not thread-safe; it is assumed that each stream will be written to or read from by a single thread. However, it is safe to use multiple streams simultaneously.\nThe BulkIO stream API is not supported in Java as of REDHAWK 2.2.0.\n Data Types The following table describes the data types of a typical read or write operation.\nData Types for Read or Write Operations    Stream Type C++ Python     char redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   octet redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   short redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   ushort redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   long redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   ulong redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   longlong redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   ulonglong redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   float redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   double redhawk::shared_buffer\u0026lt;T\u0026gt; list(T)   bit redhawk::shared_bitbuffer bitbuffer   XML std::string str   file std::string str    The following table describes the element types for the variable \u0026ldquo;T\u0026rdquo;.\nElement Types    Stream Type Complex C++ Python     char no int8_t int   char yes std::complex\u0026lt;int8_t\u0026gt; complex   octet no CORBA::Octet int   octet yes std::complex\u0026lt;CORBA::Octet\u0026gt; complex   short no CORBA::Short int   short yes std::complex\u0026lt;CORBA::Short\u0026gt; complex   ushort no CORBA::UShort int   ushort yes std::complex\u0026lt;CORBA::UShort\u0026gt; complex   long no CORBA::Long int/long   long yes std::complex\u0026lt;CORBA::Long\u0026gt; complex   ulong no CORBA::ULong int/long   ulong yes std::complex\u0026lt;CORBA::ULong\u0026gt; complex   longlong no CORBA::LongLong long   longlong yes std::complex\u0026lt;CORBA::LongLong\u0026gt; complex   ulonglong no CORBA::ULongLong long   ulonglong yes std::complex\u0026lt;CORBA::ULongLong\u0026gt; complex   float no float float   float yes std::complex\u0026lt;float\u0026gt; complex   double no double float   double yes std::complex\u0026lt;double\u0026gt; complex    Python automatically promotes an int to a long if its value exceeds the maximum int value for the platform.\nOutput Streams Output streams ensure that data is always associated with an active SRI and simplify management of stream lifetime.\nOutput Stream Types (C++) Each numeric output port type has a corresponding stream type (e.g., bulkio::OutFloatStream for bulkio::OutFloatPort) that provides the interface for sending stream data.\nCreating An output stream is created via the port\u0026rsquo;s createStream() method. The following examples create a new stream with ID \u0026ldquo;my_stream_id\u0026rdquo; and default SRI.\nC++:\nbulkio::OutFloatStream stream = dataFloat_out-\u0026gt;createStream(\u0026#34;my_stream_id\u0026#34;); Python:\nstream = self.port_dataFloat_out.createStream(\u0026#39;my_stream_id\u0026#39;) The createStream() method also accepts an SRI.\nThe output port keeps track of the streams that have been created, up until they are closed. The getStream() method provides a way to look up a stream by ID, eliminating the need to keep local references to output streams.\nModifying Stream Metadata Output streams provide convenience methods (C++) or attributes (Python) for modifying common SRI fields. The following examples configure an output stream for complex data at a sample rate of 250Ksps, centered at 91.1MHz.\nC++:\nstream.complex(true); stream.xdelta(1.0 / 250000.0); stream.setKeyword(\u0026#34;CHAN_RF\u0026#34;, 91.1e6); Python:\nstream.complex = True stream.xdelta = 1.0 / 250000.0 stream.setKeyword(\u0026#39;CHAN_RF\u0026#39;, 91.1e6) The SRI can be updated in its entirety with the sri() method in C++:\nstream.sri(newSri); In Python, assign a new SRI to the sri attribute:\nstream.sri = newSri All SRI fields are updated from the new SRI, with the exception of the Stream ID. The Stream ID is immutable and cannot be changed after creation.\nUpdates to the SRI are stored and pushed before the next packet goes out.\nIt is not necessary to manually call pushSRI() when using streams.\n Writing Data is sent with the write() method. With the exception of XML streams, which do not support time stamps, write() must be given a PrecisionUTCTime representing the date of birth of the first element in the data being written.\nC++:\nredhawk::buffer\u0026lt;float\u0026gt; data(1024); // ...fill data... stream.write(data, bulkio::time::utils::now()); Python:\ndata = range(1024) stream.write(data, bulkio.timestamp.now()) Writing Complex Data In C++, if the stream is configured for complex data, give write() a complex data type:\nredhawk::buffer\u0026lt; std::complex\u0026lt;float\u0026gt; \u0026gt; data(1024); // ...fill data... stream.write(buffer, size, bulkio::time::utils::now()); When writing scalar data to a complex stream, make sure that the size is a multiple of 2.\nIn Python, data written to a complex stream is assumed to be a list of complex values. If an element in the list is not a Python complex, its imaginary component is treated as 0.\nWrite Buffering Most BulkIO output stream types, with the exception of XML and File, support a buffered write mode. When buffering is enabled, the stream can queue up small writes into a single push.\nBy default, write buffering is disabled. To enable buffering, set the desired size with the setBufferSize() method. On writes, the stream will copy data into its internal buffer until the desired size is reached, then push out the buffered data as a single push.\nBuffered data will be pushed to the port immediately if the SRI changes or on close. A push may also be triggered explicitly by calling the flush() method.\nTo disable buffering once it has been enabled, set the buffer size to 0.\nWrite buffering does not preserve every time stamp. If precise time information is required, disable write buffering.\n Closing When an output stream is complete, close the stream. The close() method sends an End of Stream (EOS) packet and dissociates the stream from the output port.\nInput Streams An input stream encapsulates SRI and all received packets associated with that Stream ID. Buffering and overlap are built in, removing the need for client code to implement these features.\nInput streams are created automatically by the input port when an SRI is received with a new Stream ID. Only one stream per port can exist with a given Stream ID; in the event that an input stream has an unacknowledged EOS waiting, a new SRI with the same Stream ID will be queued until the EOS has been reached.\nMethods that accept or return a number of samples take the input stream’s complex mode into account. For example, requesting 1024 samples from a complex stream returns 1024 complex pairs, which is equivalent to 2048 scalar values.\nThere are two ways of retrieving an input stream: Stream Polling or Stream Callback.\nInput Stream Types (C++) Each input port type has a corresponding stream type (e.g., bulkio::InFloatStream for bulkio::InFloatPort).\nStream Polling For the basic case, the getCurrentStream() method returns the next input stream that is ready for reading. Similar to getPacket(), the next packet in the queue is consulted; however, if any stream has buffered data from a prior read (such as when using fixed-sized reads), it is given priority. Developers accustomed to using getPacket() will find that getCurrentStream() provides a familiar flow, while extending the available functionality.\nThe optional timeout argument is identical to the timeout argument for getPacket. If the timeout is omitted, getCurrentStream() defaults to blocking mode. The following examples wait indefinitely for a stream to become ready.\nC++:\nbulkio::InFloatStream stream = dataFloat_in-\u0026gt;getCurrentStream(); if (!stream) { return NOOP; } Python:\nstream = self.port_dataFloat_in.getCurrentStream() if not stream: return NOOP If there are no streams ready, such as when the timeout expires or the component receives a stop() call, the returned stream will be invalid. Streams should be checked for validity before performing any operations. In C++, the boolean not (!) operator returns true if the stream is invalid. In Python, getCurrentStream() returns None.\nAdvanced Polling (C++ Only) For more advanced use, the input port’s pollStreams() family of methods allow you to wait for one or more streams to be ready to read. Like getCurrentStream(), pollStreams takes a timeout argument to set the maximum wait time.\nThe ready streams are returned as a list:\n// Wait up to 1/8th second for a stream to be ready bulkio::InFloatPort::StreamList streams = dataFloat_in-\u0026gt;pollStreams(0.125); if (streams.empty()) { return NOOP; } for (bulkio::InFloatPort::StreamList::iterator stream = streams.begin(); stream != streams.end(); ++stream) { // Handle each stream; note that stream is an iterator  LOG_TRACE(Component_i, \u0026#34;Reading stream \u0026#34; \u0026lt;\u0026lt; stream-\u0026gt;streamID()); } If no streams are ready, the returned list is empty. pollStreams() returns as soon as one stream is ready.\nIf a minimum number of samples is required, it may be provided in the pollStreams() call:\nbulkio::InFloatPort::StreamList streams = dataFloat_in-\u0026gt;pollStreams(1024, bulkio::Const::BLOCKING); Stream Callback As opposed to polling, callback functions may be registered with the input port to be notified when a new stream has been created. Using a callback supports more sophisticated patterns, such as handling each stream in a separate thread or disabling unwanted streams.\nThe callback has no return value and takes a single argument, the input stream.\nC++:\nvoid MyComponent_i::newStreamCreated(bulkio::InFloatStream newStream) { // Store the stream in the component, set up supporting data structures, etc. } Python:\ndef newStreamCreated(self, newStream): # Store the stream in the component, set up supporting data structures, etc. The callback should be registered with the port in the REDHAWK constructor.\nC++:\nvoid MyComponent_i::constructor() { // Other setup code...  dataFloat_in-\u0026gt;addStreamListener(this, \u0026amp;MyComponent_i::newStreamCreated); } Python:\ndef constructor(self): # Other setup code... self.port_dataFloat_in.addStreamListener(self.newStreamCreated) Data Blocks In BulkIO input stream-based code, data is retrieved from data streams as blocks. Data blocks can be retrieved on a per-packet basis, or they can be retrieved as a definite-sized buffer, with or without overlap.\nData Block Types (C++) Each input stream data type has a corresponding data block type, such as bulkio::FloatDataBlock.\nReading Data Blocks The read() family of methods synchronously fetch data from a stream. The basic read() returns the next packet worth of data for the stream, blocking if necessary.\nFor common use cases, reading a packet at a time is the most efficent approach because it avoids the need to copy data.\n C++:\nbulkio::FloatDataBlock block = stream.read(); Python:\nblock = stream.read() Sized Reads You may request a set amount of data by supplying the number of samples. The following examples read 1K samples.\nC++:\nbulkio::FloatDataBlock block = stream.read(1024); Python:\nblock = stream.read(1024) The read() call blocks until at least the requested number of samples is available. Packets are combined or split as necessary to return the correct amount of data. The returned block may contain less than the requested number of samples if the stream has ended or the component is stopped.\nXML and File streams do not support sized reads.\n Overlapping Reads For algorithms that require data to overlap between iterations, you may also pass the number of samples to consume. The following examples read 1K samples with 50% overlap.\nC++:\nbulkio::FloatDataBlock block = dataFloat_in-\u0026gt;read(1024, 512); Python:\nblock = self.port_dataFloat_in.read(1024, 512) The input stream’s read pointer is advanced up to the consume length. The next call to read() will return data starting at that point.\nXML and File streams do not support overlapping reads.\n Read Failures If the EOS flag is received, or the component is interrupted, read() may return early. In the overlap case, if EOS is reached before receiving the requested number of samples, all remaining data is consumed and no further reads are possible.\nWhen a read() returns an invalid block, it is important to check for an EOS.\nC++:\nif (!block) { if (stream.eos()) { // Stream has ended, no more data will be received  } } Python:\nif not block: if stream.eos(): # Stream has ended, no more data will be received Skipping Data can be dropped with the skip() method. In the following examples, 256 samples are dropped.\nC++:\nsize_t skipped = stream.skip(256); Python:\nskipped = stream.skip(256) The returned value is the number of samples that were dropped. If the streams ends or the component is stopped, this may be less than the requested value.\nNon-Blocking Read The read() family of methods is always blocking. For non-blocking reads, use tryread().\nC++:\nbulkio::FloatDataBlock block = stream.tryread(2048); Python:\nblock = stream.tryread(2048) tryread() will only return a valid block of data if the entire request can be satisfied or if no more data will be received. In the case that the stream has ended or that component has been stopped, all remaining queued data in the stream will be returned.\nInteracting with Data Blocks Data blocks contain the input data, as well as the SRI that describes the data. A variety of functions are contained in data blocks that help the developer manage and interact with the data block’s contents.\nMemory Management (C++) The memory is managed automatically inside the object to minimize copies, so there is no need to explicitly delete data blocks.\nValidity Checking If a read fails, such as when the component receives a stop() call, it will return an invalid block. The block should be checked for validity using a boolean test before attempting to access the block\u0026rsquo;s data or metadata.\nIn C++, data block objects support boolean tests. Commonly, a block is tested for validity with the boolean not operator (!):\nbulkio::FloatDataBlock block = stream.read(); // Check if a valid block was returned if (!block) { return NOOP; } // Operate on the block In Python, failed read operations return None. A valid data block will always evaluate to True in a boolean context:\nblock = stream.read() # Check if a valid block was returned if not block: return NOOP # Operate on the block Metadata Data blocks provide methods (C++) or attributes (Python) to access common metadata:\n sri returns the SRI at the time the data was received xdelta returns the SRI xdelta  Occasionally, the input stream’s state may change between data blocks. To handle this situation, the data block provides methods (C++) or attributes (Python) to check these conditions:\n inputQueueFlushed sriChanged sriChangeFlags returns the changed SRI fields as a bit field  C++ example:\nif (block.inputQueueFlushed()) { // Handle data discontinuity... } if (block.sriChangeFlags() \u0026amp; bulkio::XDELTA) { // Update processing... } Python example:\nif block.inputQueueFlushed: # Handle data discontinuity... if block.sriChangeFlags \u0026amp; bulkio.sri.XDELTA: # Update processing Data The buffer method (C++) or attribute (Python) provides access the data stored in a data block with minimal overhead. For sample-based data block types (such as float), refer to Real Data or Complex Data.\nReal Data For sample-based data block types, buffer accesses the data as real samples.\nIn C++:\nfloat blocksum = 0.0; const redhawk::shared_buffer\u0026lt;float\u0026gt;\u0026amp; data = block.buffer(); for (size_t index = 0; index \u0026lt; block.size(); ++index) { blocksum += data[index]; } In Python, buffer is a list of numeric values:\nblocksum = 0.0 for val in block.buffer: blocksum += val Complex Data If the input stream is complex, the returned data buffer should be treated as complex data. Data block objects provide convenience methods (C++) or attributes (Python) to make it easy to work with complex data:\n complex returns true if the data is complex (i.e., SRI mode is 1) cxbuffer returns the sample data reinterpreted as complex numbers  C++:\nif (block.complex()) { std::complex\u0026lt;float\u0026gt; blocksum = 0.0; redhawk::shared_buffer\u0026lt;std::complex\u0026lt;float\u0026gt; \u0026gt; data = block.cxbuffer(); for (size_t index = 0; index \u0026lt; data.size(); ++index) { blocksum += data[index]; } } Python:\nif block.complex: blocksum = 0j for val in block.cxbuffer: blocksum += val Time Stamps Because a single data block may span multiple input packets, it can contain more than one time stamp. Data blocks returned from an input stream, with the exception of XML streams, are guaranteed to have at least one time stamp.\nThe first time stamp may be accessed with the getStartTime() method. This returns the PrecisionUTCTime of the first sample.\nIf the data block contains more than one time stamp, the full list of time stamps may be accessed with the getTimestamps() method.\nC++:\nstd::list\u0026lt;bulkio::SampleTimestamp\u0026gt; timestamps = block.getTimestamps(); Python:\ntimestamps = block.getTimestamps() The SampleTimestamp class contains three fields:\n time - a PrecisionUTCTime time stamp offset - the sample number at which this time stamp applies synthetic - is true if the time stamp was calculated based on a prior data block  When the start of a data block does not match up exactly with a packet, the input stream will use the last known time stamp, the SRI xdelta and the number of samples to calculate a time stamp. Only the first time stamp in a data block can be synthetic.\nIgnoring Streams Some components may prefer to only handle one stream at a time. Unwanted input streams can be disabled by calling the disable() method.\nAll data for the stream will be discarded until EOS is reached, preventing queue backups due to unhandled data.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/workbench/",
	"title": "The Workbench",
	"tags": [],
	"description": "",
	"content": " The Eclipse introductory screen displays a Workbench button that takes the user to the IDE’s development environment: the workbench. The workbench is made up of multiple, smaller windows, which are referred to as views in the Eclipse context.\nAt the center of the IDE workbench is the editor window, which is empty at initial startup. The editor is the primary window used when developing code within the REDHAWK IDE. An Eclipse editor is a context-sensitive window within the workbench; the language of opened files dictates the type of editor that is opened, impacting editing features such as syntax highlighting.\nFor a more detailed understanding of the Eclipse environment and nomenclature, consult the online Eclipse documentation at http://help.eclipse.org/ or the embedded documentation within the REDHAWK IDE by selecting Help \u0026gt; Search.\nPerspectives The views that makeup the workbench, along with the particular layout of those views, are referred to as a perspective. By changing perspectives throughout the development process, a developer may optimize his/her work environment based on the requirements of the particular task at hand. The default perspective in the REDHAWK IDE is the REDHAWK perspective, which is discussed in the following section. A user may switch from the REDHAWK perspective to any other perspective whenever needed.\nThere are two primary methods for changing perspectives:\n Click Open Perspective from the top right of the workbench.  Open Perspective    Select Window \u0026gt; Open Perspective \u0026gt; Other.  A view may be resized, moved, and closed within a given perspective to allow for personal customization.\nTo reset the current perspective to its default state:\n Click Window \u0026gt; Reset Perspective…  The REDHAWK Perspective The REDHAWK perspective is comprised of seven views and the editor window. Five of these views are provided by Eclipse IDE, while the remaining two views are REDHAWK-specific.\nThe following five Eclipse-provided views are in the REDHAWK perspective:\n Project Explorer view: Provides a hierarchical view of the resources in the Workbench. Outline view: Displays an outline of a structured file that is currently open in the editor area. Properties view: Displays property names and basic properties of a selected resource. Problems view: Automatically logs problems, errors, or warnings when working with various resources in the workbench. Console view: Displays a variety of console types depending on the type of development and the current set of user settings.  The following two REDHAWK-specific views are in the REDHAWK perspective:\n REDHAWK Explorer view: Allows a user to navigate the contents of a REDHAWK domain. It provides capabilities for viewing the contents of the domain, configuring instantiated resources, and launching applications in a Target SDR environment. It also provides access to the Sandbox, which is an environment for running components and applications without a Domain Manager or a Device Manager.  REDHAWK Explorer View    CORBA Name Browser view: Maps names to specific CORBA Servants. The CORBA Name Browser view is used to examine the current contents of the Naming Service as well as perform basic manipulation of that context. The view displays all currently bound name contexts (folders) and objects.  CORBA Name Browser View     Programming Language Specific Perspectives While the REDHAWK perspective combines views that are commonly used while viewing domain objects, creating REDHAWK resources, and launching applications, many other perspectives are available that are optimized for code development. Because the REDHAWK IDE is built on top of the Eclipse platform, it takes advantage of standard Eclipse, as well as third party, IDE perspectives for the purpose of supporting language-specific development. Specifically, the IDE contains perspectives that support C/C++, Java, and Python development.\nFor example, the Java perspective combines views that are commonly used while editing Java source files, while the Debug perspective contains the views that are used while debugging Java programs.\nFor more information on perspectives, particularly the Eclipse default and the programming language-specific perspectives packaged with the REDHAWK IDE, refer to http://help.eclipse.org/.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/running-components/",
	"title": "Using Devices to Run Components",
	"tags": [],
	"description": "",
	"content": " The Sandbox runs components without needing a device proxy; it forks the component process and manages its lifecycle. When running in a domain, however, the deployment of components in an application requires the domain to search for available host computers that can run the components in the application. The search requires each host computer to have a program that can publicize the host computer’s capabilities (for example, operating system, processor type, or available memory). This proxy is referred to as an executable device. REDHAWK includes a default executable device, the GPP, which is automatically configured by the create_node.py script whenever a new node is installed on the host computer. The GPP is written in C++ and can serve any node that supports x86 64-bit architecture. In cases where a more specialized proxy is required, REDHAWK includes base classes that can be extended in Python or C++. However, a detailed discussion of this process is beyond the scope of this document.\nControlling the Cache and Working Directory When a component is deployed by the GPP, it operates as a separate entity, either as a forked process or an operating thread (in the case of C++). Each component has a corresponding cached file or set of cached files and a working directory from which the program executes. The GPP manages the cached files and working directory settings through the cacheDirectory and workingDirectory properties, respectively. These properties can be reconfigured using the node’s configuration file (DCD).\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/interacting-with-hardware/using-fei-device-ide/",
	"title": "Using an FEI Device in the IDE",
	"tags": [],
	"description": "",
	"content": " After you have created the FrontEnd Interfaces (FEI) device, you can launch the device in the sandbox or launch it in a domain as part of a node. For more information, refer to Launching Components in the IDE Sandbox or Creating a New Node and Launching a Domain. After launching the device, the FrontEnd Tuners folder is displayed under the device in the REDHAWK Explorer view and the available tuners are displayed under it with a tuning fork icon:\n Available FEI Tuners   Allocating a FrontEnd Tuner The usage status of a FrontEnd Tuner device is IDLE until a successful allocation has been made. Allocation is the process where a specific tuner is requested for use, and initial setup of the tuner is performed. When at least one channel has been allocated, but there is one channel not allocated, the device is ACTIVE. If all channels have been allocated, the device is BUSY.\nThe following procedure explains how to allocate a FrontEnd tuner using the Allocate Tuner wizard.\n Right-click the FrontEnd Tuners folder and select Allocate:  Allocating an FEI Tuner   The Allocate Tuner wizard is displayed. In this wizard, you specify the desired tuner properties such as frequency, bandwidth, and so forth.\n   Allocate Tuner Wizard    In the Allocation drop-down box, verify Control New Tuner is selected.\n Optionally, in the New Allocation ID field, modify the text if needed.\n In Tuner Type, select the appropriate tuner type. You have the following options:\n RX_DIGITIZER CHANNELIZER DDC RX RX_DIGITIZER_CHANNELIZER TX RX_SCANNER_DIGITIZER  For more information about tuner types, refer to Types of Tuners.\n In Center Frequency (MHz), specify the center frequency. Bandwidth and sample rate must be specified during allocation. For an allocation to be successful, the tuner must be able to provide a value that is greater than or equal to the requested value without exceeding the appropriate tolerance value specified. Requesting a bandwidth or sample rate of zero (0.0) indicates to the tuner that any value is acceptable and that the tolerance values can be ignored. Requesting 0 typically results in the lowest value the tuner is capable of providing while still satisfying the remainder of the allocation request. If the Any Value checkbox is selected, a value of 0 is requested.\n  In Bandwidth (MHz), specify the bandwidth, or if a specific bandwidth is not required, select the Any Value checkbox.\n In Sample Rate (Msps), specify the sample rate, or if a specific sample rate is not required, select the Any Value checkbox.\n Optionally, adjust the Bandwidth Tolerance (%) or Sample Rate Tolerance (%) (Refer to Optional Status Elements).\n Optionally, specify the ID of the analog feed in RF Flow ID or the device\u0026rsquo;s Group ID.\n If allocating a scanner, click Next. For any other allocation, click Finish.\nFor a scanner allocation, the Scanner Allocation page is displayed:\n Scanner Allocation   You must complete the following for the scanner:\n In Minimum Frequency (MHz) and Maximum Frequency (MHz), specify the lower and upper bounds of the frequencies that will be scanned.\n In Mode, select SPAN_SCAN to request scanning ranges of frequencies, or DISCRETE_SCAN to enumerate individual frequencies.\n In Control Mode, select TIME_BASED to specify the minimum dwell time of the scanner in seconds, or SAMPLE_BASED to specify the minimum dwell time in samples.\n In Control Limit, specify a lower bound on the dwell time.\n Click Finish.\n  The tuner is allocated and is displayed under the FrontEnd Tuners folder with the truncated Allocation ID and an active tuning fork icon. If you left-click or hover over the allocated tuner, the full Allocation ID is displayed. A successful allocation tunes the hardware to the requested frequency and establishes a Bulk Input/Output (BulkIO) data stream containing the content. In the case of a multi-out BulkIO port, the data stream will only be pushed over a connection with a Connection ID that is identical to the Allocation ID associated with the data stream. In cases where the BulkIO port is not a multi-out port, all data streams are pushed over all connections, regardless of Connection ID.\n   Allocated Tuner   Deallocating a Tuner If a tuner was previously allocated, it can be deallocated. To deallocate a tuner, right-click the allocated FrontEnd tuner and select Deallocate. The tuner is deallocated and displays an inactive tuning fork icon along with a status of Unallocated.\nAttaching a Listener to a Tuned Receiver Sometimes, it is necessary for multiple different applications to share a single FEI source. To support this concept, FEI includes both allocation owners and listeners. The allocations that have been discussed so far are owners; they maintain complete control over the allocated hardware. Listeners, on the other hand, allow for an arbitrary number of applications to receive the same data that the allocation owner receives. However, listeners have no control over the source. Listener allocations can be made against a particular allocation (through the Allocation ID) or by parameters (i.e.: center frequency).\nTo allocate a listener, right-click the allocated FrontEnd tuner and select Add Listener. The Listener Allocation dialog is displayed:  Listener Allocation Dialog   It is possible to specify an Allocation ID for the listener, but that is strictly optional (note that the listener Allocation ID is needed as the Connection ID when consuming the listener data). Click Finish to exit the wizard and allocate the listener. When the process is complete, the listener is associate with the receiver, and is displayed under the appropriate FrontEnd tuner.\nMetadata from the Tuner Device An FEI device provides metadata along with its data stream. This metadata is attached to the Signal Related Information\u0026rsquo;s (SRI) keywords passed along BulkIO. A total of 5 SRI elements have been defined, and they are described below:\nFEI Data Passed as SRI    Identifier Value Type     COL_RF The center frequency (in Hz) for the receiver that was used to receive the data. double   CHAN_RF The center frequency (in Hz) for the tuned receiver. double   FRONTEND::RF_FLOW_ID The identifier for the stream (usually the antenna), if available. string   FRONTEND::BANDWIDTH The bandwidth (in Hz) for the tuned signal. double   FRONTEND::DEVICE_ID The identifier for the device acquiring the data. string    Deallocating a Listener If a listener was previously allocated, you can deallocate it. To deallocate a listener, right-click the allocated listener and select Deallocate.\nPerforming a Scan After a tuner has been allocated in a scanning mode (RX_SCANNER_DIGITIZER), it can be given a scanning plan to execute.\n Right-click the allocated FrontEnd tuner and select Scan. The Tuner Scan wizard is displayed:\n Tuner Scan    In Mode, select the type of scan to be performed. Use MANUAL_SCAN to specify a single frequency, DISCRETE_SCAN to provide a list of frequencies, or SPAN_SCAN to provide ranges of frequencies to step through.\n In Control Mode, select TIME_BASED to specify the minimum dwell time of the scanner in seconds, or SAMPLE_BASED to specify the minimum dwell time in samples.\n In Control Value, specify the dwell time.\n In Delay (s), provide the number of seconds until the scan should start.\n Click Next.\nIf MANUAL_SCAN was selected, the Manual Scan page is displayed and the single dwell frequency can be provided:\n Manual Scan   If DISCRETE_SCAN was selected, the Discrete Scan page is displayed and a list of frequencies can be provided:\n Discrete Scan   If SPAN_SCAN was selected, the Span Scan page is displayed and ranges of frequencies can be provided. Each range has a low (start) frequency, a high (ending) frequency, and the step width the scanner should use while scanning the range:\n Span Scan    After entering the scan plan, click Finish. The scanning starts after the delay specified on the first page.\n  To save the data entered in the wizard to an XML file that can later be loaded, click the save button at the bottom of the wizard. To load a previously saved XML file, click the load button at the bottom of the wizard.\nControlling a Tuned Receiver FEI devices can be controlled using a FrontEnd Tuner port. The port provides an interface to modify parameters such as center frequency, bandwidth, gain, and sample rate.\nThis tuner interface provides the ability to set parameters like center frequency and bandwith for the receiver. Any FEI compliant device may not output any data until the transients from any receiver setting change have settled to steady state. In short, all data output from an FEI compliant device must correspond to unambiguous receiver settings.\nThere is a custom view under each tuned receiver that sends commands over the control port. This custom view is mapped to the Properties view. Note that this is not a device property, but instead it is the use of the property view as the artifact for interacting with the port.\nThe following procedure explains how to control an allocated tuner.\n Select the allocated tuner.\n Select the properties tab if available. Otherwise, from the top IDE menu, select Window \u0026gt; Show View \u0026gt; Properties.  Properties View of an Allocated Tuner    Select the entry, or entries, to change from this view.\n Press Enter to have the change take affect or Esc to cancel.\n  Even though it is the property view, the Tuner port is exercised to effect the requested changes. If successful, the view updates and displays the new value.\nPlotting a Tuned Receiver The process described in Plotting BulkIO Ports only applies to a single-channel system. In multi-channel devices, a single port is used to send out all the data, so additional structures are used to identify which channel to plot.\n To plot an FEI device, right-click the allocated FrontEnd tuner and select Plot Port Data, or any other Plot Port option:  Plotting an Allocated Tuner    If the FrontEnd tuner has multiple BulkIO ports, the Ambiguous Data Port dialog is displayed. Select the port to plot.\nFor more information about interacting with the plots, refer to REDHAWK Plot View.\n  Plotting a Tuned Receiver with Multiple Channels In multi-channel devices, all data is pushed out of a single port. To disambiguate the traffic, additional structures are used. When a device or component contains both a BulkIO output port and the well-defined property connectionTable, different data streams can be directed out of different connections on the port. When the multi-out selection is checked on the output selection of the FEI wizard, the connectionTable property is automatically added to the FEI device.\nDeclare the association between a Connection ID, a Stream ID, and a port name:\n// create an association between an allocation, a Stream ID, and a port // the request data structure contains the Allocation ID // \u0026#34;my_data\u0026#34; is some arbitrary Stream ID // my_port is whatever output port the data is pushed out of std::string stream_id = \u0026#34;my_data\u0026#34;; this-\u0026gt;matchAllocationIdToStreamId(request.allocation_id, stream_id, this-\u0026gt;my_port-\u0026gt;getName()); // at this point, also push SRI that contains information relevant to this connection (i.e.: bandwidth) BULKIO::StreamSRI SRI = bulkio::SRI::create(stream_id); redhawk::PropertyMap\u0026amp; keywords = redhawk::PropertyMap::cast(SRI.keywords); keywords[\u0026#34;FRONTEND::BANDWIDTH\u0026#34;] = request.bandwidth; keywords[\u0026#34;FRONTEND::DEVICE_ID\u0026#34;] = this-\u0026gt;_identifier; this-\u0026gt;my_port-\u0026gt;pushSRI(SRI); Send data with the Stream ID associated with a particular allocation:\n// push the data out using the arbitrary Stream ID defined in the Allocation ID/Stream ID/port association this-\u0026gt;my_port-\u0026gt;pushPacket(data, bulkio::time::utils::now(), false, \u0026#34;my_data\u0026#34;); While this example is in C++, this functionality is also supported in Python and Java. Unfortunately, the allocation_csv element of the frontend_tuner_status structure pre-dates the availability of sequences as elements in structures (added in REDHAWK 2.0), so it is a comma-separated value whose first value is the owner allocation.\nconnectionTable is a readonly property, so software running outside the scope of the device can inspect but not change these associations.\n The state of the connectionTable is managed by the FEI base classes. The device developer must set up the state of connectionTable when a new tuner is added. However, when a listener is added to a tuner that is already on the connectionTable, the listener entry is managed automatically.\nWhen plotting an allocated tuner on a multi-channel device, the IDE automatically creates a listener allocation so that the correct stream is routed to the plot.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/messaging/viewing-messages/",
	"title": "Viewing Messages",
	"tags": [],
	"description": "",
	"content": "Messages are events with their payload definition tied to structures in component properties. Viewing messages can be done with the same techniques that are used to view events.\nTo view events and messages sent to an event channel in a terminal window:\neventviewer \u0026lt;domain name\u0026gt; \u0026lt;event channel\u0026gt; Help for the utility:\neventviewer --help Example output:\neventviewer REDHAWK_DEV testchan Receiving events. Press \u0026#39;enter\u0026#39; key to exit [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}] [{\u0026#39;id\u0026#39;: \u0026#39;foo\u0026#39;, \u0026#39;value\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;some_string\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;some string\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;some_float\u0026#39;, \u0026#39;value\u0026#39;: 1.0}]}]"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/waveforms/deployment-resources/",
	"title": "Waveform Deployment and Computing Resources",
	"tags": [],
	"description": "",
	"content": " Components are processes that run on a computer. As such, each component takes up some arbitrary, often time-varying amount of spare capacity (for example, CPU computing load, memory, network I/O). REDHAWK manages computing resources on every computer under its domain to minimize the likelihood that computing resources are over-subscribed. Each computer under REDHAWK’s domain is managed through the GPP process.\nGPP Device The GPP device is a specialized REDHAWK device that manages the deployment of components onto the computer and can be inspected like any other REDHAWK device.\nGPP can be in three possible usage states: IDLE, ACTIVE, or BUSY.\n IDLE indicates the GPP is not running any REDHAWK components. ACTIVE indicates the GPP is running at least one component, but has spare capacity to run additional components. BUSY indicates the GPP does not have any spare capacity to run additional components.  The usage state of any device can be accessed through its usageState member. To inspect the usage state:\n In the IDE, select the “Advanced” tab of the “Properties” tab for the deployed device. In a Python session, run the following script (assuming a domain is running):\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; dom=redhawk.attach() \u0026gt;\u0026gt;\u0026gt; dev = dom.devMgrs[0].devs[0] \u0026gt;\u0026gt;\u0026gt; print dev._get_usageState()  The GPP contains several properties that are critical for the deployment of components to a device. When a waveform is deployed, the framework scans through all IDLE and ACTIVE GPP devices. The component’s os and/or processor elements from its Software Package Descriptor (SPD) file are compared against the GPP’s os_name and/or processor_name properties, respectively. If there is a match, the component is assigned to that GPP. This search/assignment is performed for all components in the waveform. Once all components have been assigned to specific GPPs, the deployment process begins.\nDeployment Process The deployment of a component to a GPP begins by copying all relevant files from $SDRROOT/dom/components/\u0026lt;component\u0026gt;/ to the GPP’s cache. The GPP cache is a temporary directory on the computer used to run each component (recall that REDHAWK is designed to support distributed processing). The cache is located in the local computer’s $SDRROOT/dev/.\u0026lt;Device Manager name\u0026gt;/\u0026lt;Device Name\u0026gt;. Note that the component’s working directory is the GPP’s cache directory.\nAfter all files are copied, the component is started in its own process space using the fork system call. At program startup, the component registers with the Domain Manager and the initial property state is applied to the component’s property values. Next, connections are created as defined in the waveform file. The waveform is successfully deployed when all waveform components are registered with the Domain Manager and all component initialization is complete.\nShared Address Space Components Shared address space components (C++ only) are deployed differently than executable components. The component files are still copied, but an additional specialized component called ComponentHost is deployed to the GPP to manage the components. The GPP only executes the ComponentHost via fork and exec. Once the ComponentHost registers with the Domain Manager, all of the shared address space components assigned to the GPP are executed in the ComponentHost. The remainder of the deployment process is the same as for executable components.\nUsing Valgrind to Debug Components The GPP supports launching components using Valgrind, an open source tool that helps detect memory errors and leaks.\nThe VALGRIND environment variable controls this behavior:\n If VALGRIND is not set, components launch as usual. If VALGRIND is set but has no value, the GPP searches the path for valgrind. If VALGRIND has a value, it is assumed to be the full path to the valgrind executable.  Valgrind log files are written to the same directory as the component entry point within the GPP’s cache. For example, if the component, MyComponent, has an entry point of cpp/MyComponent, the logs are written to MyComponent/cpp. The log file name follows the pattern valgrind.\u0026lt;PID\u0026gt;.log, where PID is the process ID of the component.\nMonitoring Computing Resources per Application Each application object has a metrics function that provides access to application-level metrics. The available metrics include:\n cores: number of cores used memory: amount of memory occupied processes: how many processes make up the component files: how many file handles the component has open threads: how many threads the component has open shared: whether or not it is a shared address space component (C++ only) componenthost: The ID for the component’s host  Component ID for C++ components generated in RH 2.0 or earlier, and Python and Java components ComponentHost_GPP_1 for shared address space C++ components   The metrics are available on a per-component basis or aggregated for the whole application.\nThe metrics function takes two arguments, the list of components to report and the metrics to report, where the ID \u0026ldquo;application utilization\u0026rdquo; is used to retrieve the application’s aggregated metrics. Both arguments to the metrics function are lists of strings. To retrieve all metrics for all components as well as the aggregated application, use empty lists for both arguments.\nTo display metrics in the IDE, select a running waveform, and in the Properties view, select the Metrics tab.\n Waveform Metrics   Monitoring Computing Resources per GPP The GPP monitors the following resources:\n System: CPU utilization, memory usage, nic usage, total number of threads, and number of open files For each component: CPU usage, memory usage, and process state  When a component fails (for example, segfault), the GPP issues a AbnormalComponentTerminationEventType message on the IDM_Channel. The message contains the component ID of the component that failed, the application ID for the component’s waveform, and the device ID for the GPP that is running the component.\nThe GPP contains a thresholds structure with five elements. If at any point any of these thresholds is exceeded (because of any process’s usage, not just those forked by the GPP), the GPP usage state changes to BUSY.\nThe following table describes the elements of the thresholds structured property:\nThresholds Structured Property    Element Description     mem_free Amount of free memory available that triggers a threshold condition (default units in MB).   nic_usage Amount of network capacity used by the NIC interface that triggers a threshold condition.   threads Percentage of threads available to the GPP that triggers a threshold condition.   files_available Percentage of file handles remaining to the GPP that triggers a threshold condition.   cpu_idle Amount of CPU idle percentage that triggers a threshold condition.   ignore Ignore all thresholds and never enter into a BUSY state.    To disable the GPP’s response to any threshold, set thresholds.ignore to True. If thresholds.ignore is True, the GPP will either be in an IDLE state if no components are deployed, or an ACTIVE state if one or more component is deployed, but never BUSY, irresepecitve of the overall computer usage.\nSetting any element of the thresholds structure to -1 disables the GPP’s response to that particular element.\nFor example, to ignore the processor’s usage, set thresholds.cpu_idle to -1. The GPP state will be IDLE if no components are deployed, and ACTIVE if one or more component is deployed, irrespective of the cpu idle percentage.\nSetting any element of the thresholds structure to 0 changes the GPP usage state to BUSY, and thus, the GPP cannot launch any addtional components.\nThe GPP contains a utilization structured property that shows the overall system utilization at any time. The following table describes the elements of the utilization structured property.\nUtilization Structured Property    Element Description     description Human-readable description of the content. In the case of CPU usage, this element’s content is “CPU cores”. The numbers in this structure reflect the effective number of cores that are being utilized.   component_load Overall load by all the components that were forked by the GPP.   system_load Total load from every process, irrespective of whether or not it was forked by this GPP.   subscribed Sum of the total system load and however much is reserved. (Refer to Capacity Reservation).   maximum Maximum load that the GPP will accept before switching to a BUSY state.    ComponentHost ComponentHost is a specialized REDHAWK component that launches and manages shared address space components in a waveform. It is installed in $SDRROOT on the DomainManager and deployed to the GPP as required. There is no need to explicitly include ComponentHost in a Software Assembly Descriptor (SAD) file, as the Application Factory automatically creates one (or more) as part of the waveform deployment.\nOne ComponentHost instance is created per GPP, per waveform; all shared address space components assigned to the same GPP in a waveform reside within the same ComponentHost. Within ComponentHost, each started component runs as a separate thread, named according to the component’s label. The individual component’s main threads may be viewed in common Linux utilities such as top by enabling the display of threads. Other threads, such as those used for I/O by the middleware layer, are typically named according to the ComponentHost instance.\nBinding Components to Executable Devices For standard application/component deployment, the Application Factory searches the domain to find a matching executable device using the OS and architecture implementation properties and optional implementation dependencies. The first available executable device matching those properties is selected as the deployment device for the component. The SAD and Device Configuration Definition (DCD) files now allow system integrators to define additional id/value pairs to match against when deploying a component to an executable device. The following example describes the new xml elements (devicerequires and deployerrequires), that allow Component_1 to be deployed only on RED_NODE:GPP_1.\n\u0026lt;!-- example of ID/value pairs for a component in a SAD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;Component_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Component_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Component_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;devicerequires\u0026gt; \u0026lt;simpleref refid=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;simpleref refid=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/devicerequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;\u0026lt;!-- example of ID/value pairs for a GPP in a DCD file \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;GPP1_SPD_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;RED_NODE:GPP_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;RED_NODE:GPP_1\u0026lt;/usagename\u0026gt; \u0026lt;deployerrequires\u0026gt; \u0026lt;requires id=\u0026#34;color\u0026#34; value=\u0026#34;RED\u0026#34;/\u0026gt; \u0026lt;requires id=\u0026#34;rank\u0026#34; value=\u0026#34;15\u0026#34;/\u0026gt; \u0026lt;/deployerrequires\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; During the deployment process, when a component has a devicerequires id/value set defined in a SAD file, the list of available executable devices in the domain is filtered based on the entire id/value set. The Application Factory performs a match against the devicerequires id/value pairs and the executable devices’s devicerequires id/value pairs. If there is an exact match between both sets, that executable device is selected as the deployment device. If no matching executable devices are found, then the waveform fails to deploy and an exception is raised.\nIn addition to allowing components to select deployment devices, an executable device with a devicerequires id/value set restricts deployment to only components with a matching id/value set. All other requests for deployment to that executable device fail.\nFor host collocation and regular deployment requests, the following table explains the deployment behavior for devicerequires and deployerrequires id/value sets:\nDeployment Matching    device requires deployer requires Host Collocation Match Deployment     Yes Yes No Yes Yes, deploy on matching device.   Yes Yes No No No, matching failed.   Yes No No No No, device not used for deployment.   No Yes No No No, skip this device.   Yes (single set) Yes Yes Yes Yes, entire host collocation on this device.   Yes (mixed sets) Yes Yes Yes No, different devicerequire sets will fail.   Yes (same sets) Yes Yes Yes Yes, entire host collocation on this device.   No Yes Yes Yes No, skip this device.    Capacity Reservation A non-reservation strategy assumes that each process is running at full capacity at the time of execution. This is clearly not the case when the waveform is initially deployed because all of the waveform’s components are in a stopped state, thus taking little to no system resources. Only after the waveform is switched to a started state do the components begin to consume system resources. Those system resources that are monitored for threshold changes by the GPP will directly affect the Device’s usageState: IDLE, ACTIVE, or BUSY.\nA non-reservation strategy with a deployment pattern where multiple waveforms are launched and not initially started but are delayed due to system events or predefined behavior, can create an over-utilized system. For example, a system may initially create twenty instances of a waveform and later, start them as a result of an aperiodic event. All twenty waveforms are created, but starting the 15th instance causes the CPU utilization for the entire system to reach 100%. When the next five waveforms are started, the system will be over utilized, and all running components will be affected leading to degraded system performance, such as data loss or lack of timely response to message events.\nTo mitigate this issue, the GPP maintains a reservation-based strategy to properly forecast the CPU load for each component it manages. During initial waveform deployment, the forecasted load for each component of the waveform is reserved against the current system’s available CPU capacity. As components are moved to the start state, the forecasted load is tabled, and the actual load or a minimum utilitization load (whichever is greater), is used for determining the system load, and thus, the available CPU capacity. The available CPU capacity is one of the system resources that will directly determine the system’s usageState, (i.e., IDLE, ACTIVE, or BUSY ). The GPP’s utilization.subscribed property maintains the runtime value of the total reservation for the system.\n Example Reservation Schema   In the figure above, an example of the reservation schema is shown where actual usage is shown in green, reserved capacity is shown in blue, and the maximum for the host is shown in orange. In the figure shown, the GPP’s capacity calculation is affected by the components deployed and whether or not its host application is started.\nThe property, reserved_capacity_per_component, is the default forecasted load for every component deployed by the GPP.\nSpecialized Reservation The generalized reservation schema based on a common value set for all components is functional but often too generic. Furthermore, as the load imposed by a component changes (for example, as the noise environment changes), a floor for the component’s load is needed. For such a case, a per-component load floor can be set. This floor is maintained when the component’s load is lower than the specified value. However, the component’s load is computed as the actual load when it exceeds the floor value set. In other words, the component’s effective load is the higher of the floor or actual load. Currently, this floor is only available through the REDHAWK Python package when the waveform is created. The following example describes how to set the reserved forecasted load for a component. In this example, the component, my_comp_1, on the waveform, my_wave, has a reservation floor of 4 cpu cores.\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;my_comp_1\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect In other cases, an aggregate load for a whole waveform is needed rather than loads for individual components. To support this need, it is possible to provide a reservation floor on a per-host collocation basis rather than on a per-component basis. The reservation floor can be set through the SAD file or as a waveform creation parameter.\nWhen the reservation is based on the SAD file, it is added through an additional child element to the hostcollocation element. The additional child element is reservation, with two attributes: kind (“cpucores\u0026rdquo; for processing) and value (in this case, the number of cores that should be reserved). For example, if a host collocation were to include a reservation for a hostcollocation with component “some_comp\u0026rdquo; and an aggregate reservation of 3 cores, it would follow a pattern similar to this:\n\u0026lt;hostcollocation id=\u0026#34;ID_TEST_SET1\u0026#34; name=\u0026#34;COLLOC_SET1\u0026#34;\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;some_comp_ref\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;SigGen_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;SigGen_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;SigGen_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;reservation kind=\u0026#34;cpucores\u0026#34; value=\u0026#34;3\u0026#34;/\u0026gt; \u0026lt;/hostcollocation\u0026gt; Alternatively, the reservation can be made in the IDE by selecting a host collocation in the SAD editor diagram and editing the reservation in the Properties view. The following procedure explains how to set the reservation using the IDE.\n Create a new Waveform project. In the SAD diagram, add a host collocation. Edit the host collocation’s name to match the XML (COLLOC_SET1). Add rh.SigGen to the host collocation. Select the host collocation. Open the Properties view, select the Reservations tab.  Properties View Reservations Tab    Click the + button. Set the Kind and Value to match the XML (cpucores and 3, respectively).  When a waveform contains a single host collocation, it is possible to provide an override value for that host collocation by providing an empty ID to the SPECIALIZED_CPU_RESERVATION.\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize for the host collocation _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect If the waveform contains more than one host collocation, it can be overloaded through the host collocation’s id. For example, if the SAD example above were to be overloaded with 4 cores rather than 3, the code would look as follows:\nfrom ossie.utils import redhawk from ossie.cf import CF from omniORB import any, CORBA dom=redhawk.attach() dev = dom.devMgrs[0].devs[0] extra_reservation = 4 # number of cores to reserve/utilize for the host collocation _value=any.to_any(extra_reservation) _value._t=CORBA.TC_double # make sure that the number is packed as a double app_1=dom.createApplication(\u0026#39;/waveforms/my_wave/my_wave.sad.xml\u0026#39;,\u0026#39;my_wave\u0026#39;,[CF.DataType(id=\u0026#39;SPECIALIZED_CPU_RESERVATION\u0026#39;,value=any.to_any([CF.DataType(id=\u0026#39;ID_TEST_SET1\u0026#39;,value=_value)]))]) print dev._get_usageState() # view the reservation effect Resource Affinity Modern Linux kernels support the ability to define memory and processor affinity using the NUMA library. REDHAWK has added support to define processor affinity during the component deployment process as specified in a waveform’s SAD file. The affinity element can be added to the componentplacement/componentinstantiation element for the resource. During deployment, the REDHAWK GPP recognizes these options and performs the appropriate affinity requests when the resource is executed. An affinity request is defined by the following two intrinsic Property identifiers added to the affinity element.\n affinity::exec_directive_class - The context classification of affinity directive to perform. affinity::exec_directive_value - Value to use when processing the affinity directive.  Affinity Class Directives    Directive Class Description Values     socket Processor affinity using a processor socket identifier set. Supported values are defined by the NUMA library’s numa_parse_nodestring method; consult the NUMA man page for further clarification.   cpu CPU affinity using a cpu identifier set. Supported values are defined by NUMA library’s numa_parse_cpustring method; consult the NUMA man page for further clarification.   nic Determine which CPU manages the nic’s interrupts then assign processor affiliation to that CPU. Name of a host’s network interface. Processor identification is resolved by processing/proc/interrupts for the requested interface name.    The current REDHAWK development tool set does not support the inclusion of the affinity element into a SAD file. Adding this element requires manual editing of the file with a text editor. The following example restricts the processor affinity for component C2_1 to CPU number 5.\n\u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;C2_5fb7296e-b543-43fc-bc14-88a9299b458b\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;C2_1\u0026#34; startorder=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;C2_1\u0026lt;/usagename\u0026gt; \u0026lt;affinity\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_class\u0026#34; value=\u0026#34;cpu\u0026#34; /\u0026gt; \u0026lt;simpleref refid=\u0026#34;affinity::exec_directive_value\u0026#34; value=\u0026#34;5\u0026#34;/\u0026gt; \u0026lt;/affinity\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;C2_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt;"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/working-with-complex-data/",
	"title": "Working with Complex Data",
	"tags": [],
	"description": "",
	"content": " Each BurstPacket of the incoming data provides the getComplex() method to denote if the vector contains complex samples (It is comprised of real and imaginary parts.) Complex data is sent as alternating real and imaginary values. A developer can work with this data in any fashion; however, this section describes the common methods for converting the data into a more workable form.\nConverting Complex Data in C++ In C++, the incoming Burst Input/Output (BurstIO) data vector may be typecast into a std::vector of complex values. For example:\nBurstShortIn::BurstPacket *pkt = myShortPort-\u0026gt;getPacket(bulkio::Const::BLOCKING); if ( pkt-\u0026gt;isComplex() ) { BurstShortIn::ComplexType cplx_data = pkt-\u0026gt;getComplexData(); // ... do some processing with cplx_data } Converting Complex Data in Python The helper functions bulkioComplexToPythonComplexList and pythonComplexListToBulkioComplex, defined in the module ossie.utils.bulkio.bulkio_helpers, provide an efficient translation to and from lists of Python complex numbers.\nConverting Complex Data in Java Unlike with C++ and Python, Java does not have an ubiquitous means for representing complex numbers; therefore, when using Java, users are free to map the incoming BurstIO getData() method to the complex data representation of their choosing.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/working-with-waveforms/",
	"title": "Working with Waveforms on a Running Domain",
	"tags": [],
	"description": "",
	"content": " If you have a running Domain Manager and Device Manager, you may create and work with waveforms. You can launch the waveform on the domain, launch additional components into the running waveform, stop the running waveform, and release the waveform from the domain.\nLaunching a Waveform To launch a waveform:\n Right-click the domain and from the domain context menu, select Launch Waveform…:  Domain Context Menu   The Launch Waveform wizard is displayed:  Launch Waveform Wizard    On the Select a Waveform page of the Launch Waveform wizard, perform the following procedure:\n Select the waveform to launch.\n Select the Start the waveform after launching checkbox to start the waveform and all of its contained components immediately after launch.\n Click Next.\n  The Assign Initial Properties page is displayed.  Assign Initial Properties Page    On the Assign Initial Properties page, set the properties of the components within the waveform. Any property modified here is specific to this waveform and does not impact the component‘s execution in other environments. As the properties are changed from their default values, the now non-default values appear in bold as shown below:  Assign Initial Properties Page: Non-Default   When you are finished assigning properties, click Next. The Assign Components to Devices page is displayed:  Assign Components to Devices Page    The Assign Components to Devices page enables you to specify what executable device on which each of the components launches. If the device setting is Auto, REDHAWK determines the executable device based on any allocation properties and dependencies set on the components and devices.\n To launch the waveform, click Finish.\nIn the REDHAWK Explorer view, the Domain Manager now displays the launched waveform within the Waveforms folder.\n If you did not select the Start the waveform after launching checkbox, the waveform has not been started. To start the waveform, in the REDHAWK Explorer view, right-click the waveform from the domain’s waveforms folder and select Start.\n Once the waveform is started, the REDHAWK Explorer view indicates that the waveform and components within the waveform are in the started state by displaying STARTED next to the waveform’s instance and the instance of each component:  Started Waveform     Launching Additional Components into a Running Waveform Once a waveform has been started, additional components may be launched into the running waveform. These additional components run on the local machine and not on the domain.\n In the REDHAWK Explorer view, right-click the waveform and select Open With \u0026gt; Chalkboard:  Opening a Running Waveform in the Chalkboard   This displays the running waveform in the Chalkboard:  Running Waveform in the Chalkboard    From the Palette, add additional components to the waveform.\nStandard runtime actions (Plot, Start, Stop, Terminate, and Connect) are available on the newly added components. These components are added only to the currently running instance of the waveform and are launched on the local machine, NOT in the domain.\n   Stopping a Waveform To stop a running waveform but keep it on the domain, in the REDHAWK Explorer view, right-click the running waveform and select Stop from the context menu:  Stopping a Waveform   Releasing a Waveform To stop a running waveform and release it from the domain, in the REDHAWK Explorer view, right-click the running waveform and select Release from the context menu:  Releasing a Waveform   It is not necessary to select Stop prior to releasing the waveform. The IDE stops the waveform before releasing it.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/troubleshooting/omni/",
	"title": "omniNames and omniEvents Issues",
	"tags": [],
	"description": "",
	"content": " This section explains how to troubleshoot and resolve omniNames and omniEvents issues.\nPerforming a Hard Reset Using the cleanomni Script The cleanomni script is used to perform a hard reset of omniNames and omniEvents and delete their associated log files. To run this script, enter the following command:\nsudo $OSSIEHOME/bin/cleanomni The cleanomni script performs the following:\n Stops the omniNames service Stops the omniEvents service Removes all the old log files from omniNames and omniEvents Starts omniNames Starts omniEvents  Performing a Soft Reset of omniNames and omniEvents If the runtime-error indicates a Naming Service failure, enter the following command to attempt a soft reset on omniNames:\n# CentOS 7 command sudo systemctl restart omniNames # CentOS 6 command sudo /sbin/service omniNames restart This process first performs a stop and then performs a start. If the stop process fails, omniNames was never started, stopped due to an error condition, or is in a non-recoverable state. If the start process fails, omniNames is either misconfigured or already running (i.e., omniNames was not stopped).\nomniNames can potentially report a successful start and then fail soon after. If the omniNames service appears to fail after reporting a successful start, a reconfiguration and hard reset of omniNames may be necessary. For more information, refer to Common Failures and Using cleanomni.\n A restart of omniEvents may be necessary when restarting omniNames. To perform a soft reset of omniEvents, enter the following commands:\n# CentOS 7 command sudo systemctl restart omniEvents # CentOS 6 command sudo /sbin/service omniEvents restart Setting Omni Log Levels When diagnosing omniNames/omniEvents problems, it is often useful to set the omni logging levels. Use the following procedure to set the omni logging levels (requires root permissions):\n Open the /etc/omniORB.cfg file. Set a traceLevel value. For example: bash traceLevel = 10   Details on the available trace levels can be found in Chapter 4 of the omniORB User’s Guide (http://omniorb.sourceforge.net/omni41/omniORB/omniORB004.html) (CentOS 6) and (http://omniorb.sourceforge.net/omni42/omniORB/omniORB004.html) (CentOS 7) or on your local system at file:///usr/share/doc/omniORB-devel-4.1.6/doc/omniORB/omniORB004.html (CentOS 6) and at file:///usr/share/doc/omniORB-devel-4.2.0/doc/omniORB/omniORB004.html (CentOS 7).\nFor the changes to take effect, restart omniNames/omniEvents.\nLog messages are displayed in the terminal and in the files contained in /var/log/omniORB and /var/lib/omniEvents.\nCommon Causes for omniNames Failure This section identifies the most common causes for omniNames failures.\nIP Version 6 Conflicts Certain combinations of IP Version 6 (IPv6) configurations and /etc/omniORB.cfg configurations can cause omniNames failures.\nSpecifically, if the InitRef section of /etc/omniORB.cfg is set to point to localhost rather than pointing explicitly to 127.0.0.1, the operating system may resolve localhost to ::1 (the IPv6 localhost) and not to 127.0.0.1 (the IPv4 localhost). If this occurs, omniNames fails. There are three options for preventing this failure condition:\n Explicitly set 127.0.0.1 in the InitRef section instead of using localhost. Disable IPv6 in the operating system (refer to operating system documentation). Modify the /etc/hosts file to prevent localhost from being resolved as ::1.  Preventing IPv6 localhost Resolution Below is an example /etc/hosts file from an older CentOS distribution:\n127.0.0.1 localhost.localdomain localhost ::1 localhost6.localdomain6 localhost6 Below is an example /etc/hosts file from a newer CentOS distribution:\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 In the older /etc/hosts file, localhost resolves unambiguously to 127.0.0.1. In the newer /etc/hosts file, localhost can resolve to either 127.0.0.1 or ::1 (where resolving to ::1 causes an omniNames failure).\nThe newer /etc/hosts file can be modified to read:\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost6 localhost6.localdomain6 Alternatively, localhost4 can be used in the InitRef section of /etc/omniORB.cfg.\nThe line pertaining to IPv6 can also be completely removed from the file; however, some operating systems, depending on IPv6 configurations, may automatically repopulate IPv6 localhost settings on reboot.\nInvalid IP Addresses in /etc/hosts Invalid entries in the /etc/hosts file may induce an omniNames failure. Invalid entries may be in the form of an IP address that cannot be reached or in the form of an entry that is not valid according to the /etc/hosts grammar. Firewall IP and port settings on both the server and client side may cause the target omniNames service to be unreachable.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/bit-data/",
	"title": "Bit Data",
	"tags": [],
	"description": "",
	"content": " In REDHAWK 2.2.0 and above, Bulk Input/Output (BulkIO) includes a packed bit data format, BULKIO::dataBit. The transfer of packed bit data between processing stages is standardized, including the ability to transfer a non-byte aligned number of bits.\nGeneral REDHAWK manages bits as arrays of bytes, with each byte containing up to 8 consecutive bits. Bit indices start with the most significant bit: bit index 0 is the most significant bit of the first byte, bit index 1 is the second most significant bit, and so on.\nC++ In C++, there are two classes, redhawk::shared_bitbuffer and redhawk::bitbuffer that provide high-level access to bit data. These are analagous to redhawk::shared_buffer\u0026lt;T\u0026gt; and redhawk::buffer\u0026lt;T\u0026gt;, respectively, but for bit data.\nBulkIO packed bit streams are designed to work with redhawk::shared_bitbuffer.\nRead-Only The redhawk::shared_bitbuffer class provides read-only access to packed bit data stored in a backing byte array.\nIndividual bits may be accessed via indexing:\nint bit = buf[0]; A bit is returned as an integer value that is always 0 or 1.\nIntegers up to 64 bits in size may be extracted from a given bit offset with the getint() method. The following example extracts a 24-bit integer value at bit 36:\nint value = buf.getint(36, 24); The returned value is an unsigned 64-bit integer with the extracted value in the least significant bits.\nRead/Write The redhawk::bitbuffer class adds methods that provide write access to the redhawk::shared_bitbuffer class.\nIndividual bits may be set via indexing:\nbuf[0] = 1; Any non-zero value sets the bit, while a zero clears the bit.\nIn C++, there is no primitive type that represents a single bit; index assignment is implemented with a private proxy class. Taking the address of an indexed value is a compiler error.\n Integer values up to 64 bits may be set at a given bit offset with the setint() method. The following example sets a 24-bit integer value at bit 36:\nbuf.setint(36, 0xABCDEF, 24); The least significant 24 bits of the value are stored.\nCreating To allocate a new bitbuffer with enough space to hold 256 bits:\nredhawk::bitbuffer data(256); The bit values in the new bitbuffer are not initialized.\nTo create a writable copy of an existing shared_bitbuffer:\nredhawk::bitbuffer data = shared.copy(); To parse a string literal, use the static class method from_string():\nredhawk::bitbuffer data = redhawk::bitbuffer::from_string(\u0026#34;0101101010101\u0026#34;); The from_string() method parses the input string and returns a new bitbuffer that owns the memory.\nTo create a bitbuffer from a integer literal of up to 64 bits, use the static class method from_int(). The following example creates a 36-bit bitbuffer from a hexadecimal literal:\nredhawk::bitbuffer data = redhawk::bitbuffer::from_int(0x123456789, 36); Only the least significant 36 bits are taken from the literal; any bits above the least significant 36 bits are discarded.\nSharing Algorithms that create new bit data or transform existing bit data should allocate a new bitbuffer for each iteration. Once a bitbuffer has been written to an output stream, it must not be modified. Modifications to the contents of a bitbuffer are visible to all instances that share the same data. However, algorithms that require history can preserve an inexpensive read-only reference to the outgoing data:\nredhawk::shared_bitbuffer history = data; Bit Operations The shared_bitbuffer class includes several features useful for bit-level processing:\n distance(other) returns the Hamming distance between two bitbuffers. find(pattern, maxDistance) searches for a bit pattern within a maximum Hamming distance. popcount() returns the population count (number of 1 bits). takeskip(M,N) performs a take/skip, iteratively copying M bits and skipping N bits until the end of the data.  Python In Python, the bitbuffer class provides high-level access to bit data. BulkIO packed bit streams are designed to work with bitbuffer.\nTo use bitbuffer in your Python code, import it from the redhawk.bitbuffer package:\nfrom redhawk.bitbuffer import bitbuffer bitbuffer behaves as a standard Python container. It supports indexing, slicing and concatenation.\nheader[0] = 1 header[15] = header[14] result = header[:16] + data[16:256] To construct an uninitialized bitbuffer of a desired size:\ndata = bitbuffer(bits=255) The contents of the new bitbuffer are undefined.\nTo parse a string literal as a bitbuffer:\ndata = bitbuffer(\u0026#39;1011010110100101001\u0026#39;) Any other non-string sequence or iterable may be used to create a bitbuffer, as long as each item can be converted to an int:\n# Packs a list of integer values into a bitbuffer data = bitbuffer([1, 0, 1, 1, 0, 1, 1, 1]) # Creates a 96-bit bitbuffer with alterating 0s and 1s data2 = bitbuffer(x \u0026amp; 1 for x in xrange(96)) Bit Operations The bitbuffer class includes several features useful for bit-level processing:\n distance(other) returns the Hamming distance between two bitbuffers. find(pattern, maxDistance) searches for a bit pattern within a maximum Hamming distance. popcount() returns the population count (number of 1 bits). takeskip(M,N) performs a take/skip, iteratively copying M bits and skipping N bits until the end of the data.  Java Java does not include a high level bit API. Input and output ports use the raw CORBA BULKIO.BitSequence class for bit data.\nSandbox The REDHAWK sandbox has built-in support for working with packed bit data. General sandbox features are discussed in more depth in Sandbox.\nSending Bit Data In the Python sandbox, StreamSource supports writing packed bit data. Data may be written using a bitbuffer instance, or by using string literals:\nsource = sb.StreamSource() comp = sb.launch(\u0026#39;my_bit_component\u0026#39;) sb.start() source.write(\u0026#39;10110101110\u0026#39;) The legacy DataSource helper does not support packed bit data.\n Receiving Bit Data In the Python sandbox, StreamSink supports reading packed bit data:\ncomp = sb.launch(\u0026#39;my_bit_generator\u0026#39;) sink = sb.StreamSink() comp.connect(sink) data = sink.read() If the read is successful, data.data will be a bitbuffer instance containing all of the data available for a particular stream.\nThe legacy DataSink helper does not support packed bit data.\n Plotting Bit Data Within REDHAWK IDE, packed bit ports can be monitored and plotted just like any other BulkIO type. By default, plotting a packed bit port automatically brings up a raster plot.\n Packed Bit Raster   General IDE plot use is described in REDHAWK Plot View.\nThe Python sandbox plots also support displaying packed bit data. In particular, RasterPlot has several attributes that can be modified in real time to make it easy to visualize bit data:\n frameSize changes the number of bits displayed per line frameOffset adjusts the start of the line  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/adjusting-logging-at-runtime/",
	"title": "Adjusting Logging at Runtime",
	"tags": [],
	"description": "",
	"content": "The logging level for the root logger of a component/device can be adjusted at runtime in the IDE. The following procedure explains how to adjust the logging level.\n Right-click the running component or device and select Logging \u0026gt; Log Level.\nThe Set Debug Level dialog displays the current logging level:  Set Debug Level    Select the new logging level you want to use and click OK.\nThe new log level is used.\n  After a component or device has been launched, its logging configuration can also be dynamically modified.\n Right-click the running component or device and select Logging \u0026gt; Edit Log Config. If this is the first time you have used the editor, a warning is displayed.\n If a warning is displayed, click Yes. The Edit Log Config editor is displayed.\n Edit Log Config Editor   The editor shows the resource’s logging configuration. Saving changes to the editor performs a live update of the resource’s logging configuration.\n  The logging API provides fine-grained access to the various loggers. The logging API can be used to retrieve a list of the resource\u0026rsquo;s loggers, change the logging level or configuration for any one specific logger, or determine the state of any one logger.\nThis API is available directly to the resources; one way of accessing this API is through the Python package.\nAssuming that there is a reference to an instance of a component called comp_1 associated with variable c, the following Python examples can be exercised:\n Use getNamedLoggers to get a list of the named loggers in a system.\n\u0026gt;\u0026gt;\u0026gt; c.getNamedLoggers() [\u0026#39;comp_1\u0026#39;, \u0026#39;comp_1.system.PortSupplier\u0026#39;, \u0026#39;comp_1.system.PropertySet\u0026#39;, \u0026#39;comp_1.system.Resource\u0026#39;] Use setLogLevel to change a named logger\u0026rsquo;s level.\n\u0026gt;\u0026gt;\u0026gt; c.setLogLevel(\u0026#39;comp_1\u0026#39;, \u0026#39;trace\u0026#39;) Use getLogLevel to get a named logger\u0026rsquo;s level.\n\u0026gt;\u0026gt;\u0026gt; c.getLogLevel(\u0026#39;comp_1\u0026#39;) 5000 Use setLogConfig/getLogConfig to set or get a named logger\u0026rsquo;s configuration.\n\u0026gt;\u0026gt;\u0026gt; c.getLogConfig(\u0026#39;comp_1\u0026#39;) \u0026#39;log4j.rootLogger=INFO,STDOUT\\n# Direct log messages to STDOUT\\nlog4j.appender.STDOUT=org.apache.log4j.ConsoleAppender\\nlog4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.STDOUT.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\u0026#39; Use resetLog to reset a resource\u0026rsquo;s loggers to whatever configuration each had on startup.\n\u0026gt;\u0026gt;\u0026gt; c.resetLog() Use log_level with no arguments to get the log level for the base logger.\n\u0026gt;\u0026gt;\u0026gt; c.log_level() 5000 Use log_level with an argument to set the log level for the base logger.\n\u0026gt;\u0026gt;\u0026gt; c.log_level(10000)  These commands are also available for the Domain Manager, Device Manager, and application objects. In the case of the Domain Manager and Device Manager, they affect the specific object. In the case of an application, the logging API aggregates all components\u0026rsquo; loggers through a single interface. For example, calling getNamedLoggers on an application object returns a list of all the named loggers in all components in the application.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/applications/",
	"title": "Applications",
	"tags": [],
	"description": "",
	"content": " Applications are software objects representing waveforms. They are used to organize a group of components that are linked together to accomplish a useful computational task. Applications provide a convenient way to move data around in order to achieve these different tasks by allowing for components to easily be interchanged.\nApplication Class Each application contains a unique application name and profile, which describes the application’s configuration. This profile is a Software Assembly Descriptor (SAD) file that is referenced by a File Manager.\nAn Application object is responsible for providing control, configuration, and status of any application that is instantiated in the domain. In order to accomplish this, each Application object maintains various data structures to monitor all aspects of its execution.\nA list of Software Package Descriptor (SPD) implementation IDs and a list of pids are kept for each component that makes up the application in order to manage their life cycles. Since every component has to be associated with at least one device, each component is also stored in a list with the device that it uses, is loaded on or is executed on.\nUpon completion, the Application’s releaseObject() function is responsible for various clean up tasks. Any task or process allocated on Executable devices are stopped using the terminate() function. All memory allocated by component instances on Loadable devices is freed using the unload() function. Finally, any additional capacities or resources that were allocated during creation are released using the device’s deallocateCapacity() method. These changes return the devices to the state they were in before the application was launched (the state of the devices may not have changed during application execution).\nAll object references to components that make up the application are released and all connected ports are disconnected. Any consumers or producers that were connected to a CORBA event channel are removed. Finally, all component’s naming contexts are unbound from the Naming Service.\nSAD File The SAD File is where information about a waveform’s composition and configuration is stored. It is an XML file that contains tags for all of the elements required for the application to be built and is located in: $SDRROOT/dom/waveforms/WAVE_NAME. This file is parsed by the runtime environment and used by an ApplicationFactory to construct the desired waveform.\nIndividual elements of the file include:\n References to all required component’s SPD and their locations Required connections between the component’s ports and interfaces External ports Required connections to devices Name given in Naming Service Co-Location (deployment) dependencies Assembly Controller Start order of the components  Within the SAD file, each component instantiation has a unique ID, which allows support for multiple instantiations of the same component. In this situation, each component would have the same file reference, a unique ID, as well as a unique name in the Naming Service that is based off of the component’s usage name. For multiple instantiations of the same component, the trailing digit on the usage name is simply incremented.\nAssembly Controller and Start Order Each waveform has only one Assembly Controller that serves as the starting point for the application. The component that is marked as the Assembly Controller is responsible for delegating implementations of the inherited CF::Resource functions that include:\n start() stop() configure() query()  By default, the first component added to a waveform is the Assembly Controller. However, the Assembly Controller can be changed to any component in the waveform by right-clicking on the component in the waveform diagram and selecting Set As Assembly Controller from the context menu.  Assembly Controller Assignment   In the waveform diagram, the circled number in the component indicates the component’s designated start order. This is the order that the start() function is called on the components within the waveform.\nThe Assembly Controller is always started first.\n To modify the start order:\n In the waveform diagram, right-click the component for which you want to change the start order. Select Move Start Order Earlier to start the component earlier. Select Move Start Order Later to start the component later.  Start Order Assignment     Host Collocation To address varying performance considerations, some application designs may require multiple components be deployed on the same piece of hardware. To meet this type of requirement, in the sad.xml file, you can specify that a set of components be collocated on a single host at runtime.\nTo collocate components in the IDE:\n Open the Advanced section of the Palette. Select Host Collocation.  Select Host Collocation     Drag Host Collocation onto the Diagram. The collocation area is displayed.  Collocation    Add desired components to the collocated area.  Add Components to Host Collocation    Finalize other component connections.  Finalize Other Component Connections     External Ports Within the REDHAWK Framework, a particular component’s port can be designated as an external port so that it is accessible to external waveform objects. Using external ports, a complex waveform may be subdivided into smaller more manageable waveforms. Marking a port as external adds an external ports tag in the SAD XML file containing the component instance that owns the port in question. Additionally, the color of the port’s block in the diagram changes color to mark it as externally accessible. For information about marking a Port as external, refer to Waveform Editor Diagram Tab.\nExternal ports can be renamed in the Overview tab of the application’s SAD file. Renaming a port enables other applications to access the port with a different name instance than the one specified in the components Software Component Descriptor (SCD) file, thus preventing naming collision. For information about renaming an external port, refer to Waveform Editor Overview Tab.\nExternal Properties Individual component properties can be promoted as external in the properties tab of the application’s SAD file, which enables other applications to access these internal property values through configure() and query(). To prevent naming collision, the property ID can also be assigned an external ID. If no external ID is specified, the internal property ID from the components Properties File (PRF) file is used as its external ID. For information about making a property external, refer to Waveform Editor Properties Tab.\nUsing the Find By Feature A Find By represents an object within a REDHAWK domain that will be available at runtime (when the waveform is launched in a domain). Find Bys contain details that describe the object. For example, the details may specify that it is a Domain Manager or it is a service with a specific name. When a waveform is launched in a domain, the Find By details help to locate the appropriate object, and then any connections the user specified in the waveform are established. Those connections are sometimes directly to the object itself, or sometimes to ports on the object, depending on the context. You can search for a resource by name, a service by name or type, or an event channel by name.\nFind By Name To find a resource in the domain by name:\n From the Palette, in the Find By folder, select Find By Name and drag it onto the diagram. The Find By Name dialog is displayed.  Find By Name    Enter the name of the component you want to find. Optionally, enter the component’s ports names that you want to use. For Provides ports, enter the name and click + next to Provides Port. For Uses ports, enter the name and click + next to Uses Port. Click Finish.\nThe Find By Name is displayed in the diagram.\n  Find By Service To find a service in the domain:\n From the Palette, in the Find By folder, select Service and drag it onto the diagram. The Find By Service dialog is displayed.  Find By Service    If you want to search for a service Name, select the Service Name radio button and enter the service Name you want to find. If you want to search for a service Type, select the Service Type radio button and enter the service Type you want to find. The service Type indicates the interface provided by the service. Click Browse to select an interface type the IDE recognizes. Optionally, enter the component’s ports names that you want to use. For Provides ports, enter the name and click Add Provides Port. For Uses ports, enter the name and click Add Uses Port. Click Finish.\nThe Service Name or Service Type is displayed in the diagram.\n  Find By Event Channel To find an event channel in the domain:\n From the Palette, in the Find By folder, select Event Channel and drag it onto the diagram.\nThe Event Channel dialog is displayed.  Event Channel    Enter the name of the event channel you want to find and click OK.\nThe Event Channel is displayed in the diagram.\n  usesdevice Relationship An application may require that specific devices are running in order for the application to be deployed. The usesdevice relationship is a mechanism for expressing such a requirement. The usesdevice relationship also enables the application to connect ports of components within the SAD file to ports of devices running in a node. These specifications are handled through tags in the application’s SAD XML, which can contain any number of usesdevice relationships. Each usesdevice relationship has a unique ID with a set of allocation property dependencies required for the relationship to be satisfied..\nThe following example XML expresses the usesdevice relationship and must reside within the softwareassembly element of the SAD XML file. The usesdevicedependencies element must be the last element within the softwareassembly element.\n\u0026lt;usesdevicedependencies\u0026gt; \u0026lt;usesdevice id=\u0026#34;uses_device_1\u0026#34;\u0026gt; \u0026lt;propertyref refid=\u0026#34;os\u0026#34; value=\u0026#34;linux\u0026#34;/\u0026gt; \u0026lt;/usesdevice\u0026gt; \u0026lt;usesdevice id=\u0026#34;uses_device_2\u0026#34;\u0026gt; \u0026lt;structref refid=\u0026#34;struct_alloc_prop\u0026#34;\u0026gt; \u0026lt;simpleref refid=\u0026#34;long_capacity\u0026#34; value=\u0026#34;10\u0026#34;/\u0026gt; \u0026lt;simpleref refid=\u0026#34;float_capacity\u0026#34; value=\u0026#34;0.1\u0026#34;/\u0026gt; \u0026lt;/structref\u0026gt; \u0026lt;/usesdevice\u0026gt; \u0026lt;/usesdevicedependencies\u0026gt; In the above example, there are two usesdevice dependencies with IDs of uses_device_1 and uses_device_2. The first requires a property with an ID of os that matches the value of linux. The second requires a struct with an ID of struct_alloc_prop with members long_capacity and float_capacity that have the necessary available capacity specified in the value tag.\nOnce these dependencies have been declared, port connections can be made in the connections section of the SAD XML file. The following example makes two connections. The first connection is from the port: output_port of Component_1 to the port: input_port of the device that satisfies the uses_device_1 relationship. The second is from the port: output_port of the device that satisfies the uses_device_2 relationship to the port: input_port of Component_2.\n\u0026lt;connections\u0026gt; \u0026lt;connectinterface id=\u0026#34;connection_1\u0026#34;\u0026gt; \u0026lt;usesport\u0026gt; \u0026lt;usesidentifier\u0026gt;output_port\u0026lt;/usesidentifier\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/usesport\u0026gt; \u0026lt;providesport\u0026gt; \u0026lt;providesidentifier\u0026gt;input_port\u0026lt;/providesidentifier\u0026gt; \u0026lt;deviceusedbyapplication usesrefid=\u0026#34;uses_device_1\u0026#34;/\u0026gt; \u0026lt;/providesport\u0026gt; \u0026lt;/connectinterface\u0026gt; \u0026lt;connectinterface id=\u0026#34;connection_2\u0026#34;\u0026gt; \u0026lt;usesport\u0026gt; \u0026lt;usesidentifier\u0026gt;output_port\u0026lt;/usesidentifier\u0026gt; \u0026lt;deviceusedbyapplication usesrefid=\u0026#34;uses_device_2\u0026#34;/\u0026gt; \u0026lt;/usesport\u0026gt; \u0026lt;providesport\u0026gt; \u0026lt;providesidentifier\u0026gt;input_port\u0026lt;/providesidentifier\u0026gt; \u0026lt;componentinstantiationref refid=\u0026#34;Component_2\u0026#34;/\u0026gt; \u0026lt;/providesport\u0026gt; \u0026lt;/connectinterface\u0026gt; \u0026lt;/connections\u0026gt; HostCollocation and usesdevice Relationship To further refine the deployment of an Application, the SAD file allows for the specification of a usesdeviceref within the context of a HostCollocation. If a HostCollocation is defined with a set of Components and a usesdeviceref, all the Components can be deployed on the ExecutableDevice that resides on the same host as the Device that was satisfied by the usesdevicedependency section.\n\u0026lt;hostcollocation name=\u0026#34;collocation_1\u0026#34;\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;Component_1\u0026#34; startorder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;Component_1\u0026lt;/usagename\u0026gt; \u0026lt;findcomponent\u0026gt; \u0026lt;namingservice name=\u0026#34;Component_1\u0026#34;/\u0026gt; \u0026lt;/findcomponent\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;usesdeviceref refid=\u0026#34;uses_device_2\u0026#34;/\u0026gt; \u0026lt;/hostcollocation\u0026gt; To add a usesdevice to or remove a usesdevice from a host collocation:\n Double-click the the host collocation area.\nThe Edit Host Collocation dialog is displayed.\n Edit Host Collocation    To add a Device, under Available uses devices, select the Device, click Add, and click Finish. The Device is added to the host collocation.\n Host Collocation Including a usesdevice    To remove a Device, under Collocated uses devices, select the Device, click Remove, and click Finish. The Device is removed.  Host Collocation without a usesdevice     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/source-installation/",
	"title": "Building and Installing REDHAWK from Source",
	"tags": [],
	"description": "",
	"content": " Building the Framework This section describes how to build and install REDHAWK from source and use the environment variables to run REDHAWK.\nInstalling Build Dependencies Building REDHAWK from source requires a few additional dependencies beyond those required to run REDHAWK. The following procedure explains how to install the additional build dependencies.\n First, ensure your system has the necessary dependency software provided by RHEL / CentOS and Fedora EPEL. Ensure the REDHAWK Yum repository is set up using the process described in Setting Up the REDHAWK Repostiory. Install the dependencies distributed with the REDHAWK tarball.  Installing the Framework from Source To install the Core Framework (CF) from source, the redhawk-src-\u0026lt;version\u0026gt;.tar.gz must be downloaded.\nwget https://github.com/RedhawkSDR/redhawk/releases/download/\u0026lt;version\u0026gt;/redhawk-src-\u0026lt;version\u0026gt;.tar.gz You must set the OSSIEHOME and SDRROOT environment variables (recommended defaults shown below) before running the installation script. You must have write permission for the locations of OSSIEHOME and SDRROOT or the installation will not work.\nRecent Linux distributions include newer versions of GCC that default to the C++11 standard or newer. REDHAWK is developed and tested using the C++98 standard and may not compile in C++11 mode.\nTo configure GCC to use the C++98 standard, set the CXXFLAGS environment variable before building REDHAWK from source:\nexport CXXFLAGS=\u0026#34;--std=gnu++98\u0026#34; To compile the source, execute the following commands:\nexport OSSIEHOME=/usr/local/redhawk/core export SDRROOT=/var/redhawk/sdr tar zxvf redhawk-src-\u0026lt;version\u0026gt;.tar.gz cd redhawk-src-\u0026lt;version\u0026gt;/ ./redhawk-install.sh . $OSSIEHOME/environment-setup If you wish to preserve the environment used to compile the source, add the following lines to .bashrc:\nexport OSSIEHOME=/usr/local/redhawk/core export SDRROOT=/var/redhawk/sdr . $OSSIEHOME/environment-setup To build the source code with or without optional features, provide the appropriate build option to the configure setup. The following table describes some common options.\nCommon Build Options for the Configure Command    Option Description     --enable-affinity Enable NUMA affinity processing.   --enable-persistence=\u0026lt;type\u0026gt; Enable persistence support (default sqlite). Supported types: bdb, gdbm, sqlite.   --disable-persistence Disable persistence support. This may be desired for specialized builds to eliminate the additional database dependency.   --disable-log4cxx Disable log4cxx support.    As of REDHAWK 2.2.1, the default setting is to enable persistence using sqlite. It is only necessary to specify --enable-persistence to use a different backend database. The default setting from prior versions is selectable with --disable-persistence.\n To view a complete list of configurations, enter the following commands:\ncd \u0026lt;redhawk src directory\u0026gt; cd redhawk/src ./reconf ./configure --help To provide any of the build options, edit the redhawk-install.sh script and change the following line to include the appropriate option:\n./configure Setting Environment Variables REDHAWK expects several environment variables to be set to run. REDHAWK installs a set of scripts that appropriately set these variables in the etc/profile.d directory in your installation. Source the appropriate files for your shell before running. For example, if you installed to the default OSSIEHOME location (/usr/local/redhawk/core) and are using bash/dash:\n. /usr/local/redhawk/core/etc/profile.d/redhawk.sh . /usr/local/redhawk/core/etc/profile.d/redhawk-sdrroot.sh or copy them to your system’s /etc/profile.d directory to make them global for all users:\nsudo cp /usr/local/redhawk/core/etc/profile.d/* /etc/profile.d Remember to restart your terminal if you modify the system’s /etc/profile.d directory for changes to take effect.\n Configuring omniORB Refer to Configuring omniORB for information on how to edit the omniORB configuration file (/etc/omniORB.cfg) to provide information about how to reach the CORBA event service.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/component-implementations/",
	"title": "Component Implementations",
	"tags": [],
	"description": "",
	"content": "Components may specify particular dependencies such as OS, processor architecture, or required device properties (e.g., processor speed or memory capacity). Setting these dependencies ensures that a component is deployed to an appropriate device at runtime.\nWhile REDHAWK supports multiple implementations for a single component, it can be confusing, especially when debugging a system. Except for some limited scenarios, it is recommended that developers associate a single implementation with each component.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/",
	"title": "Component Structure",
	"tags": [],
	"description": "",
	"content": "This chapter discusses more advanced topics related to component development. Prior to reading this content, familiarize yourself with the information in Components.\n Auto-Generated Component Files     Auto-Generated Component Methods     Base Component Members     Component Implementations     Java Version     Managing and Defining Properties     Working with Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/messaging/connecting-producers-consumers/",
	"title": "Connecting Producers and Consumers",
	"tags": [],
	"description": "",
	"content": "Producers and consumers can be connected either point-to-point or through an event channel in the IDE. Connecting a producer directly to a consumer does not require an application and can be done in the Sandbox:\nfrom ossie.utils import sb sb.catalog() #[\u0026#39;structs_test\u0026#39;, \u0026#39;m_in\u0026#39;, \u0026#39;prop_changes\u0026#39;, \u0026#39;m_out\u0026#39;,\u0026#39;pass\u0026#39;] prod=sb.launch(\u0026#34;m_out\u0026#34;) cons=sb.launch(\u0026#34;m_in\u0026#34;) prod.connect(cons) #True sb.start() Output:\nfoo 1 hello foo 1 hello foo 1 hello foo 1 hello foo 1 hello foo 1 hello foo 1 hello Connecting producers to consumers through an event channel requires an application. An application can also support point-to-point connections.\nBelow is a description of how to connect producers through point-to-point and through an event channel:\n Add producer and consumer components. For point-to-point messaging, connect the output MessageEvent port, message_out in this example, to the input MessageEvent port of the receive component. For messaging via an event channel, add an event channel to the waveform and connect to it.\n In the waveform Diagram, under Palette \u0026gt; Find By:  Select EventChannel and drag it onto the diagram. The New Event Channel dialog is displayed.  New Event Channel    Enter the event channel you want to find and click OK. The EventChannel is displayed in the diagram.  Connect the Uses (Output) MessageEvent port of the sending component, message_out in this example, to the event channel. Connect the Uses (Output) MessageEvent port of the receiving component, message_in, to the event channel. This is the black output port that must be connected to the event channel.   In this example, connections are made point-to-point and through the event channel. Therefore, for every message sent, two messages are received.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/configuration/devicemanager/",
	"title": "Device Manager Service Configuration File",
	"tags": [],
	"description": "",
	"content": " Each REDHAWK Device Manager service is controlled by a file in the /etc/redhawk/nodes.d directory. The AdminService provides the initial values for the configuration parameters of a service. Any values in the /etc/redhawk/init.d/node.defaults file override the initial configuration. Finally, the values in the INI file override any configuration (defined internally or specified in the /etc/redhawk/init.d/node.defaults file).\nAlthough there are no rules on partitioning nodes for a REDHAWK system, it is recommended that you do not define more than one GPP per computing host. To define multiple nodes for a computing host, create a new configuration file for each node.\nThe Device Manager can be configured to start after the Domain Manager has started up, or it can start up at the same time as the Domain Manager, and it will wait for the domain to be available and register its Devices and Services. If many devices or services need to start, it is recommended that you add a custom script to verify that the Device Manager has started all devices and services and registered them with the Domain Manager (refer to the start_post_script parameter).\nrhadmin can generate an example Device Manager configuration file with the complete set of parameters that can be used to the control the setup and execution of a REDHAWK Device Manager service. To generate a generic Device Manager configuration, enter the following command.\ncd /etc/redhawk/nodes.d rhadmin config node \u0026gt; node.ini To generate a node configuration from an existing Device Manager project, enter the following command.\ncd /etc/redhawk/nodes.d rhadmin config node \u0026lt;path/to/node\u0026gt;/DeviceManager.dcd.xml \u0026lt;optional DomainName\u0026gt; \u0026gt; node.ini Device Manager Configuration Parameters This section describes all available configuration parameters for the Device Manager service.\nParameter names are case sensitive.\nThe following are the valid values for boolean configuration parameters. If no value is present, the feature is disabled.\nTrue: 1, true, True\nFalse: 0, false, False\n parameter: DOMAIN_NAME\nrequired: Yes\ndefault value: None\nformat: Name with no spaces or periods (for example, REDHAWK_DEV)\ndescription: The domain name to associate with this Device Manager.\nparameter: NODE_NAME\nrequired: Yes\ndefault value: None\nformat: Name with no spaces or periods\ndescription: The name of the node to launch with this Device Manager. Must be a valid directory name in $SDRROOT/dev/nodes.\nparameter: DCD_FILE\nrequired: No\ndefault: /nodes/$NODE_NAME/DeviceManager.dcd.xml\nformat: $SDRROOT/dev relative path to a Device Configuration Descriptor (DCD) file\ndescription: The path to the DCD file (DeviceManager.dcd.xml file) describing the Device Manager.\nparameter: SDRCACHE\nrequired: No\ndefault value: None\ndescription: The absolute path to use as cache directory for Device Manager and its devices. If no value is specified, the system defaults to creating a directory in $SDRROOT/dev.\nparameter: CLIENT_WAIT_TIME\nrequired: No\ndefault value: 10000 (milliseconds)\nformat: number in milliseconds\ndescription: The wait time, in milliseconds, before the Device Manager times out waiting for a response when making remote calls.\nparameter: USELOGCFG\nrequired: No\ndefault value: None\nformat: True : enables option, blank : disables option\ndescription: Enables the use of $OSSIEHOME/lib/libsossielogcfg.so to resolve the LOGGING_CONFIG_URI command line argument.\nparameter: LOGGING_CONFIG_URI\nrequired: No\ndefault value: defaults.logging.properties\nformat: Absolute path to a file, file://\u0026lt;path\u0026gt; URI or sca://\u0026lt;path\u0026gt; URI\ndescription: The logging configuration file to be used by the Device Manager. Simple file names will be resolved to files in /etc/redhawk/logging directory. All others will be resolved as an absolute path or URI to a logging properties file.\nparameter: DEBUG_LEVEL\nrequired: No\ndefault value: INFO\nvalues: FATAL, ERROR, WARN, INFO, DEBUG, TRACE\ndescription: The Device Manager’s logging level at startup.\nparameter: SDRROOT\nrequired: No\ndefault value: $SDRROOT\nformat: Standard shell path environment variable\ndescription: The path to use as the SDRROOT for this Device Manager.\nparameter: OSSIEHOME\nrequired: No\ndefault: $OSSIEHOME\nformat: Standard shell path environment variable\ndescription: The absolute path to use as the OSSIEHOME for this Device Manager.\nparameter: LD_LIBRARY_PATH\nrequired: No\ndefault value: $LD_LIBRARY_PATH\nformat: Standard shell path environment variable\ndescription: The path for link loader to resolve shared object files; overrides the LD_LIBRARY_PATH environment variable.\nparameter: PYTHONPATH\nrequired: No\ndefault value: $PYTHONPATH\nformat: Standard shell path environment variable.\ndescription: The path used by Python interpreter to load modules; overrides the PYTHONPATH environment variable.\nparameter: JAVA_HOME\nrequired: No\ndefault value: $JAVA_HOME\nformat: Standard shell path environment variable\ndescription: The home directory used by the Java installation when launching devices and services.\nparameter: PATH\nrequired: No\ndefault value: $PATH\nformat: Standard shell path environment variable\ndescription: The search path to use when launching devices and services.\nparameter: ORB_CFG\nrequired: No\ndefault value: None\nformat: Standard shell environment variable.\ndescription: Sets the OMNIORB_CONFIG variable before running the process. For more information, refer to the omniORB documentation.\nparameter: ORB_INITREF\nrequired: No\ndefault value: None\ndescription: Used as omniORB ORBInitRef command line argument when starting process. For more information, refer to the omniORB documentation.\nparameter: ORB_ENDPOINT\nrequired: No\ndefault value: None\ndescription: Used as omniORB ORBendPoint command line argument when starting process. For more information, refer to the omniORB documentation.\nparameter: enable\nrequired: No\ndefault value: True\nformat: True, False, or a string to be matched against conditional_config\ndescription: Specifies if the process may be started. True or False will enable or disable the process. Refer to conditional_config for information about how a string value gets evaluated.\nparameter: conditional_config\nrequired: No\ndefault value: /etc/redhawk/rh.cond.cfg\ndescription: Allows conditional startup of processes based on the enable parameter and the contents of this conditional config. If the value enable is a string, the process will start only if there is a line in the conditional_config file that has that exact content; otherwise, the process is skipped. For example, enable=\u0026quot;type=primary\u0026quot; causes the conditional_config file to be examined for a line equal to type=primary when starting a process on the host. If there is no type=primary line in the file, the process is skipped.\nparameter: priority\nrequired: No\ndefault value: 400\ndescription: The relative priority of the Device Manager in the group of processes to start for this domain. Lower values will be started earlier. For example, priority 100 will be started before priority 400.\nparameter: autostart\nrequired: No\ndefault value: True\ndescription: Specifies whether to automatically start this process when the AdminService starts, if enable is True.\nparameter: waitforprevious\nrequired: No\ndefault value: 45\ndescription: The number of seconds to wait for the previous higher priority process to start before trying to start this process.\nparameter: failafterwait\nrequired: No\ndefault value: True\ndescription: Specifies whether to abort starting this domain if waitforprevious has expired and the previous process has not been declared started yet. This is useful to make sure the Domain Manager is started before launching the Device Manager.\nparameter: started_status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to determine if the Device Manager started properly. A script exit value of 0 indicates the Device Manager started successfully.\nparameter: status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script to check the status for the Device Manager. A script exit value of 0 indicates the Device Manager is alive.\nparameter: query_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to get a detailed status output for the Device Manager. This is useful to return the status of each device or service for this Device Manager.\nparameter: environment\nrequired: No\ndefault value: None\nformat: A list of key/value pairs in the form key=\u0026quot;value\u0026quot;,key2=\u0026quot;value2\u0026quot;\ndescription: Specifies whether to override existing environment variables or set new ones to be used when starting the Device Manager.\nparameter: user\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with User ID.\nparameter: group\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with Group ID.\nparameter: umask\nrequired: No\ndefault value: None\ndescription: The umask for the process.\nparameter: nicelevel\nrequired: No\ndefault value: None\ndescription: Specifies to run the process using nice with this niceness level.\nparameter: affinity\nrequired: No\ndefault value: None\ndescription: Enables numactl processing. Any valid NUMA control directives will be passed on command line when starting the process. For more information, refer to the numactl documentation.\nparameter: corefiles\nrequired: No\ndefault value: None\ndescription: The maximum size of core files created. This value is passed to the ulimit command using the -c flag when starting the process.\nparameter: ulimit\nrequired: No\ndefault value: user’s environment\ndescription: This value is passed directly to the ulimit command when starting the process. For more information, refer to the ulimit documentation.\nparameter: directory\nrequired: No\ndefault value: $SDRROOT\ndescription: Specifies to change the directory to directory before running the process.\nparameter: run_detached\nrequired: No\ndefault value: True\ndescription: Specifies to run the Device Manager as a daemon, not a child of the AdminService process.\nparameter: logfile_directory\nrequired: No\ndefault value: /var/log/redhawk/device-mgr\ndescription: The absolute path to the logging directory.\nparameter: stdout_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.\u0026lt;node name\u0026gt;.stdout.log\ndescription: The name of a file that captures the stdout from the process. If not specified, the default value list above is used.\nparameter: stderr_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.\u0026lt;node name\u0026gt;.stderr.log\ndescription: If redirect_stderr is False, the name of a file that captures the stderr from the process. If not specified, the default value list above is used.\nparameter: redirect_stderr\nrequired: No\ndefault value: True\ndescription: Specifies to write stdout and stderr to the same file.\nparameter: start_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the process is started.\nparameter: start_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the process is started.\nparameter: stop_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the process is stopped.\nparameter: stop_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the process is stopped.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/dynamic-connections/",
	"title": "Dynamic Connections",
	"tags": [],
	"description": "",
	"content": "Unless a component is in the process of being terminated, it is valid to retrieve a port reference at any other point in the component’s life cycle. Anyone may call getPort() on the component at any time. In the case of a uses port, anyone may call connectPort() or disconnectPort() at any time. In the case of a provides port, anyone may cast to that port reference and start making calls on it. It is the task of the component developer to make sure that the component handles changes like this smoothly. The base classes and code generators provided with REDHAWK handle the vast majority of the issues arising from this change, especially when the provides port implements one of the REDHAWK standard interfaces.\nThis dynamic connection behavior provides huge benefits to an application developer. For example, if one wanted to inspect the data being passed from one component to the next, a temporary provides-side implementation can be created and a new connection established. The standard behavior of a uses port is to send the same data to all its existing connections. This means of dynamic connecting is essential for REDHAWK’s plotting mechanism.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/",
	"title": "Editors and Views",
	"tags": [],
	"description": "",
	"content": "This section discusses the most commonly used Editors and views provided with the REDHAWK IDE.\n SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/example-interaction/",
	"title": "Example Sandbox Interaction",
	"tags": [],
	"description": "",
	"content": " The code below provides an example of component interaction in the Sandbox:\n\u0026gt;\u0026gt;\u0026gt; my_comp = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_comp \u0026lt;local component \u0026#39;\u0026lt;component name\u0026gt;_1\u0026#39; at 0x\u0026lt;hex address\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; my_comp.api() Component [example]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- input_s IDL:BULKIO/dataShort:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- output_s IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- my_float (float/SF/32f) [None] None my_string (string) [None] None some_shorts (ShortSeq) [None] None \u0026gt;\u0026gt;\u0026gt; my_comp.my_float \u0026gt;\u0026gt;\u0026gt; my_comp.my_float = 5.0 \u0026gt;\u0026gt;\u0026gt; my_comp.my_float 5.0 \u0026gt;\u0026gt;\u0026gt; my_comp.api() Component [example]: Provides (Input) Ports ============== Port Name Port Interface --------- -------------- input_s IDL:BULKIO/dataShort:1.0 Uses (Output) Ports ============== Port Name Port Interface --------- -------------- output_s IDL:BULKIO/dataShort:1.0 Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- my_float (float/SF/32f) [None] 5.0 my_string (string) [None] None some_shorts (ShortSeq) [None] None Connecting Components Connecting components is done by invoking a connect() function on the uses-side (output-side) component with the provides-side (input-side) component as the argument of the call.\n\u0026gt;\u0026gt;\u0026gt; another_comp = sb.launch(\u0026#34;repeater\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_comp.connect(another_comp) True To assign a connection identifier when connecting two resources, you must provide the connectionId argument.\n\u0026gt;\u0026gt;\u0026gt; import frontend \u0026gt;\u0026gt;\u0026gt; dev = sb.launch(\u0026#34;rh.RTL2832U\u0026#34;) \u0026gt;\u0026gt;\u0026gt; alloc=frontend.createTunerAllocation(\u0026#34;RX_DIGITIZER\u0026#34;,center_frequency=100e6,allocation_id=\u0026#34;alloc1\u0026#34;) \u0026gt;\u0026gt;\u0026gt; dev.allocateCapacity(alloc) \u0026gt;\u0026gt;\u0026gt; data_conv = sb.launch(\u0026#34;rh.DataConverter\u0026#34;) \u0026gt;\u0026gt;\u0026gt; dev.connect( data_conv, usesPortName=\u0026#34;dataOctet_out\u0026#34;, connectionId=\u0026#34;alloc1\u0026#34;) If the connections are ambiguous (multiple uses ports or multiple provides ports have matching types), an error occurs. To resolve the ambiguity, usesPortName and/or providesPortName must be specified as arguments to the function. For example, the following call specifies providesPortName as an argument.\n\u0026gt;\u0026gt;\u0026gt; my_comp.connect(another_comp, providesPortName=\u0026#34;float_in_1\u0026#34;) Connection Manager A REDHAWK Domain Manager contains a Connection Manager that provides systemic benefits for the management of connections between endpoints that can come and go. The underlying endpoints are specialized data strutures and CORBA references required to complete the connection, which complicates the creation of endpoints. The Python Sandbox already contains Pythonic representations of these domain objects, which reduce the need to retrieve the CORBA references. The Python Sandbox contains helpers that use these representations for the creation of endpoints.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import rhconnection \u0026gt;\u0026gt;\u0026gt; dom = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; app = dom.createApplication(\u0026#39;/waveforms/my_app/my_app.sad.xml\u0026#39;) \u0026gt;\u0026gt;\u0026gt; dev = dom.devices[0] \u0026gt;\u0026gt;\u0026gt; uses = rhconnection.makeEndPoint(app, \u0026#39;out_portname\u0026#39;) \u0026gt;\u0026gt;\u0026gt; prov = rhconnection.makeEndPoint(dev, \u0026#39;in_portname\u0026#39;) \u0026gt;\u0026gt;\u0026gt; dom.getConnectionMgr().connect(uses,prov,\u0026#39;user_id\u0026#39;,\u0026#39;connection_id\u0026#39;) Sending and Receiving Data Multiple helpers are available in the Sandbox that can be connected to running components and devices.\nSetting Component Log Levels The log level of the component may be set using the execparams argument in the component constructor.\n\u0026gt;\u0026gt; myComponent = sb.launch(\u0026#34;\u0026lt;component name\u0026gt;\u0026#34;, execparams={\u0026#34;DEBUG_LEVEL\u0026#34;:1})"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/getting-started/further-reading/",
	"title": "Further Reading",
	"tags": [],
	"description": "",
	"content": " The REDHAWK manual explains the use of REDHAWK to build, deploy, and manage data streaming applications. The principal REDHAWK features are outlined in the following sections, and a reference to the corresponding REDHAWK documentation is provided for further reading.\nReferences for Application Developers The following chapters are particularly useful for application developers:\n Component development is introduced in Components. Greater detail related to component development is discussed in the following chapters:\n Component Structure\n Connections\n Logging\n  Waveforms, including a demonstration of creating a REDHAWK waveform and launching it as an application using the IDE, are discussed in-depth in Waveforms\n The Sandbox, which is used to run components on a local host without any additional runtime infrastructure such as the Domain Manager, is described in-depth in Sandbox\n  References for System Developers The following chapters are useful to system developers:\n Managing and interacting with hardware through Devices\n Devices and Device Managers make up individual nodes, which are used to deploy and manage devices in a REDHAWK system. Devices are used to determine whether or not a host can deploy any given component. Devices and Device Managers are discussed in-depth in Devices, Nodes, and The Runtime Environment.\n The Domain Manager and Device Manager are the foundation for The Runtime Environment for the deployment of distributed applications. Runtime Environment Inspection describes additional tooling.\n Services, are programs that provide some system-specific always-on software support to components. An example of a service is a web server.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/logging-within-a-resource/",
	"title": "Logging Within A Resource",
	"tags": [],
	"description": "",
	"content": " Every resource capable of hosting custom logging (component, device, service) includes the class member _baseLog. The _baseLog member is a logger instance that has the same logging name as the resource instance. For example, the first instance of comp in a waveform is comp_1. For logging within a REDHAWK resource, _baseLog is the resource\u0026rsquo;s \u0026ldquo;root\u0026rdquo; logger. The log4j root logger still exists and is the parent for the resource\u0026rsquo;s \u0026ldquo;root\u0026rdquo; logger. The log4j root logger is referred to as the empty string.\nEach logger object has a member function, getChildLogger(), that takes 1 required argument and a second optional argument. The first argument is the name for the child logger and the second argument is an optional namespace for this logger. If _baseLog belongs to component comp_1, calling getChildLogger() with the first argument set to mylog and no second argument, the logger name comp_1.user.mylog is created. Calling getChildLogger() with the first argument set to mylog and the second argument set to some.namespace creates the logger name comp_1.some.namespace.mylog.\nC++ Use All the following logging statements work with _baseLog. However, to declare a new logger, use the following code in the header:\nrh_logger::LoggerPtr my_logger; To instantiate the new logger, use the following code:\nmy_logger = this-\u0026gt;_baseLog-\u0026gt;getChildLogger(\u0026#34;my_logger\u0026#34;); The logger name and the logger variable name do not need to match.\n To add logging messages within your resource’s code, the following macros are available. These macros use the predefined class logger as the input parameter.\n RH_FATAL(\u0026lt;logger\u0026gt;, message text ) RH_ERROR(\u0026lt;logger\u0026gt;, message text ) RH_WARN(\u0026lt;logger\u0026gt;, message text ) RH_INFO(\u0026lt;logger\u0026gt;, message text ) RH_DEBUG(\u0026lt;logger\u0026gt;, message text ) RH_TRACE(\u0026lt;logger\u0026gt;, message text )  where \u0026lt;logger\u0026gt; is the logger instance that should publish the message.\nThe following example adds DEBUG-level logging messages to the logger my_logger.\nRH_DEBUG(this-\u0026gt;my_logger, \u0026#34;example log message\u0026#34;); The message text can be combined with stream operations, so the variable my_variable can be added to the logging message:\nRH_DEBUG(this-\u0026gt;my_logger, \u0026#34;The variable my_variable has the value: \u0026#34;\u0026lt;\u0026lt;my_variable); Java Use All of the following logging statements work with _baseLog. However, to declare a new logger, use the following code:\nprivate RHLogger my_logger; To instantiate the new logger, use the following code:\nmy_logger = this._baseLog.getChildLogger(\u0026#34;my_logger\u0026#34;); The logger name and the logger variable name do not need to match.\n The following example adds DEBUG-level logging messages to the logger my_logger.\nvoid someMethod() { this.my_logger.debug(\u0026#34;example log message\u0026#34;); } Log4j supports the following severity levels for logging.\n_baseLog.fatal(...) _baseLog.warn(...) _baseLog.error(...) _baseLog.info(...) _baseLog.debug(...) _baseLog.trace(...) It also supports programmatically changing the severity level of the logger object.\n_baseLog.setLevel(Level.WARN) Python Use All the following logging statements work with _baseLog. However, to create a new logger, use the following code:\nself.my_logger = self._baseLog.getChildLogger(\u0026#34;my_logger\u0026#34;) The following example adds DEBUG-level logging messages to the logger my_logger.\nself.my_logger.debug(\u0026#34;example log message\u0026#34;) REDHAWK has extended the Python logging support to include the trace method functionality.\nself._baseLog.fatal(...) self._baseLog.warn(...) self._baseLog.error(...) self._baseLog.info(...) self._baseLog.debug(...) self._baseLog.trace(...) As with the other logging capabilities, you can programatically change the logging level.\nself._baseLog.setLevel(logging.WARN)"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/redhawkcoreservices/domains/",
	"title": "Managing Services By Domains and Types",
	"tags": [],
	"description": "",
	"content": " This section explains how to manage REDHAWK core services either by domain or by type (domain, nodes, or waveforms). For additional information on managing service configurations and life cycle management, refer to Domain Manager Service, Device Manager Service, and Waveform Service.\nManaging Services for a Domain Services for a domain can be managed using the following commands.\n Reloading and restarting all services for a domain from current configuration files:  rhadmin update \u0026lt;Domain Name\u0026gt;  Starting all services in a domain:  rhadmin start \u0026lt;Domain Name\u0026gt;  Stopping all the services in a domain:  rhadmin stop \u0026lt;Domain Name\u0026gt;  Inspecting the status of all the services in a domain:  rhadmin status \u0026lt;Domain Name\u0026gt;  Running a custom status script for all the services in a domain and displaying the script output:  rhadmin query \u0026lt;Domain Name\u0026gt;  Restarting all the services for a domain:  rhadmin restart \u0026lt;Domain Name\u0026gt; Managing Services by Type Each life cycle management command (start, stop, status, query, and restart) has an optional type parameter (domain, nodes, and waveforms), which restricts the command to execute against the specific type of service for a domain. In addition, the value all can be substituted for the \u0026lt;Domain Name\u0026gt; argument, which executes the command for a specific service type, regardless of the service type\u0026rsquo;s domain. The same command syntax is supported for all life cycle commands (start, stop, status, query, restart):\nrhadmin command type \u0026lt;Domain Name\u0026gt;|all The following commands demonstrate how to execute the start command using the type option.\n Starting a specific Domain Manager service:  rhadmin start domain \u0026lt;Domain Name\u0026gt;  Starting all defined Domain Manager services:  rhadmin start domain all  Starting all Device Manager services for a specific domain:  rhadmin start nodes \u0026lt;Domain Name\u0026gt;  Starting all Device Manager services:  rhadmin start nodes all  Starting all waveform services for a specific domain:  rhadmin start waveforms \u0026lt;Domain Name\u0026gt;  Starting all waveform services:  rhadmin start waveforms all"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/shared-libraries/manually-including-external-libraries/",
	"title": "Manually Including External Libraries",
	"tags": [],
	"description": "",
	"content": " Occasionally, a C++ component may require building and linking with a library that is not packaged as a REDHAWK shared library. This section details how to manually configure the compiler and linker flags. Two examples are given:\n using a pkg-config (.pc) file to find and link against a library - enables your project to check for the presence of the library and issue an error while running configure if the library is not found, and enables you to avoid hard-coded options. directly linking against a library - enables you to directly supply the compiler/linker flags and can be used if a pkg-config file is not available.  Adding a Library by Referencing a pkg-config File To add a library by referencing a pkg-config (.pc) file, edit the configure.ac file in your component’s implementation directory.\n Open the configure.ac file in your component’s implementation directory.\n Locate the following line referencing PROJECTDEPS in the code:\n  PKG_CHECK_MODULES([PROJECTDEPS], [ossie \u0026gt;= 2.0 omniORB4 \u0026gt;= 4.1.0])  Add your library to the list of requirements. For example, if you need version 1.2.3 or greater of the foo library:  PKG_CHECK_MODULES([PROJECTDEPS], [ ossie \u0026gt;= 2.0 omniORB4 \u0026gt;= 4.1.0 foo \u0026gt;= 1.2.3 ])  If your pkg-config file is not on the pkg-config path, you can augment the pkg-config search path by adding a line just before the call to PKG_CHECK_MODULES:  export PKG_CONFIG_PATH=/custom/path:$PKG_CONFIG_PATH Adding a Library Directly To add a library, edit the Makefile.am file in your component’s implementation directory.\n Open the Makefile.am file in your component’s implementation directory.\n Append compiler and linker flags to the end of the CXXFLAGS and LDADD lines, respectively. For example:\nMyComponent_CXXFLAGS += -I/usr/local/include/foo MyComponent_LDADD += -L/usr/local/lib64 -lfoo   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/multiout-ports/",
	"title": "Multi-out Ports",
	"tags": [],
	"description": "",
	"content": " A multi-out port allows a component to select specific streams to be sent over specific connections out of arbitrarily-selected ports. To use multi-out ports, a component must include the following property:\n\u0026lt;structsequence id=\u0026#34;connectionTable\u0026#34;\u0026gt; \u0026lt;struct id=\u0026#34;connectionTable::connection_descriptor\u0026#34; name=\u0026#34;connection_descriptor\u0026#34;\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::connection_id\u0026#34; name=\u0026#34;connection_id\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::stream_id\u0026#34; name=\u0026#34;stream_id\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;simple id=\u0026#34;connectionTable::port_name\u0026#34; name=\u0026#34;port_name\u0026#34; type=\u0026#34;string\u0026#34;/\u0026gt; \u0026lt;/struct\u0026gt; \u0026lt;configurationkind kindtype=\u0026#34;property\u0026#34;/\u0026gt; \u0026lt;/structsequence\u0026gt; To steer a particular stream out of a particular connection through a particular port, an element must be added to the connection table structure that identifies the Stream ID/Connection ID/port name set. After this element is added to the structure, any data pushed to a particular port is filtered by that port in the appropriate fashion.\nA port does not filter its output until an element in the connection table sequence mentions the port name. If a port is listed on the connection table, then data is pushed out only if both the Stream ID and Connection ID match.\nThe multi-out capability is supported only for Bulk Input/Output (BulkIO) and Burst Input/Output (BurstIO) output (uses) ports.\n Multi-out Port Support in the IDE When interacting with FrontEnd devices, it is easiest to perform an operation (for example, Plot Port Data) directly on the desired tuner. For more information, refer to Plotting a Tuned Receiver.\nOtherwise, the REDHAWK IDE provides support for the following operations using multi-out ports:\n Creating connections to downstream devices or components Plotting Tracking SRI data Data List feature Snapshot feature Play port feature  When performing an operation on a multi-out port, if there is only one connection ID, it is used by the IDE. If there are multiple connection IDs in the connection table, the IDE displays the Multi-out Port Connection Wizard dialog with the option to either select a Connection ID from the entries in the connection table or input one manually.\n Mult-out Port Connection Wizard   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/nextmidas-plot-editor/",
	"title": "NeXtMidas Plot Editor",
	"tags": [],
	"description": "",
	"content": "The NeXtMidas Plot Editor displays Midas BLUE files. In the workspace, if a file with the extensions .prm or .tmp is opened, the NeXtMidas Plot Editor is displayed.\n NeXtMidas Plot Editor   The NeXtMidas Framework has an in plot menu system and mouse zoom functionality that may be used within the plot window. The full use and features of the plotting menus are beyond the scope of this guide and are explained within the official NeXtMidas documentation.\nInteract with the plot in the following ways:\n Zoom In: Left-click and drag to form a box to zoom in on a portion of the plot. Zoom Out: Right-click to zoom out a single level. Open Menu: Center-click to bring up the NeXtMidas plot menu. Close Menu: Right-click an open menu to close the pop-up menu.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/plotting-bulkio-ports/",
	"title": "Plotting BulkIO Ports",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE contains the ability to plot using the NeXtMidas plotting framework. If the output port uses the Bulk Input/Output (BulkIO) interface, it can take advantage of this feature and plot a line graph or a falling raster.\nTo bring up a plot within the IDE:\n Make sure that the component is currently in the started state.\n Right-click the desired port to plot.\n Select either Plot Port Data or Plot Port FFT.\nA new view is created, and it contains the plot of the port’s output data.\n  The new view has the same name as the source port. To view additional source information, hover the mouse over the title.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/running-a-component/",
	"title": "Running a Component",
	"tags": [],
	"description": "",
	"content": "To run a component, use one of the following mechanisms: the REDHAWK Sandbox or the REDHAWK domain. When using the Sandbox, a component is run from within a Python shell or a graphical environment, all operating on a single computer. When using the domain, a component is run in the context of an application that can be deployed over an arbitrarily large number of computers. The Sandbox is useful for tasks such as signal processing development and analysis, component debugging, and data inspection.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/time-stamps/",
	"title": "Time Stamps",
	"tags": [],
	"description": "",
	"content": "The following code segment provides an example of how to construct a BULKIO::PrecisionUTCTime time stamp to be sent in the burst Signal Related Information (SRI).\n/** * To create a time stamp from the current time of day */ BULKIO::PrecisionUTCTime tstamp = burstio::utils::now();"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/interface-with-fpgas/",
	"title": "Using Devices to Interface with FPGAs",
	"tags": [],
	"description": "",
	"content": "Many Software-Defined Radio (SDR) systems depend on custom hardware solutions implemented on FPGAs and GPUs. REDHAWK has developed a design pattern to interface with these custom hardware solutions that enables users and the REDHAWK Framework alike to change the behavior of an FPGA at run-time to meet the needs of the application. Refer to REDHAWK Persona Device Pattern for more information.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/working-with-complex-data/",
	"title": "Working with Complex Data",
	"tags": [],
	"description": "",
	"content": " If the StreamSRI mode field of the incoming data is set to 1, the associated input data is complex (i.e., it is composed of real and imaginary parts). Complex data is sent as alternating real and imaginary values. A developer can work with this data in any fashion; however, this section provides common methods for converting the data into a more workable form.\nConverting Complex Data in C++ In C++, the incoming Bulk Input/Output (BulkIO) data block provides a complex() method to check whether the data is complex, and a cxbuffer() method to reinterpret the sample data as a redhawk::shared_buffer of std::complex values. For example:\nbulkio::ShortDataBlock block = stream.read(); if (block.complex()) { redhawk::shared_buffer\u0026lt;std::complex\u0026lt;short\u0026gt; \u0026gt; data = block.cxbuffer(); const size_t size = data.size(); } Converting Complex Data in Python In Python, the incoming BulkIO data block provides a complex attribute to check whether the data is complex, and a cxbuffer attribute that gives the sample data as a list of Python complex values. For example:\nblock = stream.read() if block.complex: data = block.cxbuffer size = len(data) Converting Complex Data in Java Unlike with C++ and Python, Java does not have a ubiquitous means for representing complex numbers; therefore, when using Java, users are free to map the incoming BulkIO data to the complex data representation of their choosing.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/rhadmin/",
	"title": "rhadmin",
	"tags": [],
	"description": "",
	"content": " This section explains the rhadmin commands used to control the AdminService, and how to execute commands from the interactive console mode or from the command line, and how to specify an optional type.\nCommands The following table describes the rhadmin commands.\nCommand Descriptions    Command Argument Description     getconfig \u0026lt;service name\u0026gt; Displays the current configuration values for the listed service. Multiple arguments can be specified.   list  Shows the current list of configured services.   query all, \u0026lt;domain name\u0026gt;, \u0026lt;service name\u0026gt; Query a service for extended status. all queries all services, \u0026lt;domain name\u0026gt; queries all services in the specified domain, \u0026lt;service name\u0026gt; queries a specific service. Can specify multiple \u0026lt;domain name\u0026gt; or \u0026lt;service name\u0026gt; arguments.   query \u0026lt;type\u0026gt; all, \u0026lt;domain name\u0026gt; Query a \u0026lt;type\u0026gt; of service (domain, nodes, or waveforms). all queries all domains, \u0026lt;domain name\u0026gt; queries the specified domain.   reload  AdminService will restart itself and reread all configuration files. Running services are not affected.   restart all, \u0026lt;domain name\u0026gt;, \u0026lt;service name\u0026gt; Restarts a service. all stops all running services and then starts all enabled services, \u0026lt;domain name\u0026gt; stops all running services in the specified domain and then starts all enabled services in the specified domain, \u0026lt;service name\u0026gt; restarts a specific service. Can specify multiple \u0026lt;domain name\u0026gt; or \u0026lt;service name\u0026gt; arguments.   restart \u0026lt;type\u0026gt; all, \u0026lt;domain name\u0026gt; Restarts a \u0026lt;type\u0026gt; of service (domain, nodes, or waveforms). all stops and then starts all domains, \u0026lt;domain name\u0026gt; stops and then starts the specified domain.   shutdown  Stops the AdminService.   start all, \u0026lt;domain name\u0026gt;, \u0026lt;service name\u0026gt; Start a service. all starts all enabled services, \u0026lt;domain name\u0026gt; starts all enabled services in the specified domain, \u0026lt;service name\u0026gt; starts a specific service. Can specify multiple \u0026lt;domain name\u0026gt; or \u0026lt;service name\u0026gt; arguments.   start \u0026lt;type\u0026gt; all, \u0026lt;domain name\u0026gt; Starts a \u0026lt;type\u0026gt; of service (domain, nodes, or waveforms). all starts all domains, \u0026lt;domain name\u0026gt; starts the specified domain.   status none,\u0026lt;domain name\u0026gt;, \u0026lt;service name\u0026gt; Shows the status of a service. No argument will status all services, \u0026lt;domain name\u0026gt; status all services in the specified domain, \u0026lt;service name\u0026gt; status a specific service.   status \u0026lt;type\u0026gt; none, \u0026lt;domain name\u0026gt; Status a \u0026lt;type\u0026gt; of service (domain, nodes, or waveforms). No argument will status in all domains, \u0026lt;domain name\u0026gt; status the specified domain.   stop all, \u0026lt;domain name\u0026gt;, \u0026lt;service name\u0026gt; Stop a service. all stops all running services, \u0026lt;domain name\u0026gt; stops all running services in the specified domain, \u0026lt;service name\u0026gt; stops a specific service, Can specify multiple \u0026lt;domain name\u0026gt; or \u0026lt;service name\u0026gt; arguments.   stop \u0026lt;type\u0026gt; all, \u0026lt;domain name\u0026gt; Stop a \u0026lt;type\u0026gt; of service (domain, nodes, or waveforms). all stops all domains, \u0026lt;domain name\u0026gt; stops the specified domain.   update none, \u0026lt;domain name\u0026gt; Reloads the configuration and optionally starts/stops any domain groupings that have changed. Can specify multiple \u0026lt;domain name\u0026gt; arguments.    \u0026lt;type\u0026gt; refers to a service type: \u0026lsquo;domain\u0026rsquo;, \u0026lsquo;nodes\u0026rsquo;, or \u0026lsquo;waveforms\u0026rsquo;.\n\u0026lt;domain name\u0026gt; refers to the value of the DOMAIN_NAME INI configuration property. For example, the domain name is REDHAWK_PROD for the configuration property DOMAIN_NAME=REDHAWK_PROD.\n\u0026lt;service name\u0026gt; is derived from the section header [\u0026lt;type\u0026gt;:\u0026lt;name\u0026gt;] and DOMAIN_NAME property in a service INI file. For example, service name is REDHAWK_DEV:GppNode from a node INI file that contains the section [node:GppNode] and configuration property DOMAIN_NAME=REDHAWK_DEV\n Running Commands All commands can be run in either an interactive console mode or from the command line. To run the list command using the rhadmin client script in interactive mode, enter the following:\nrhadmin -i and when the rh_admin\u0026gt; prompt is displayed, enter:\nlist To run the same command from the command line, enter the following:\nrhadmin list Specifying an Optional Type Commands that support the optional \u0026lt;type\u0026gt; argument (domain, nodes, or waveforms), will execute the specified command against a specific type of service. For example, the following command only starts all Device Managers for the REDHAWK_DEV domain;\nrhadmin start nodes REDHAWK_DEV To restart all configured Device Managers in all domains, use the following command:\nrhadmin start nodes all"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/sources-and-sinks/",
	"title": "Built-in Sources and Sinks",
	"tags": [],
	"description": "",
	"content": " REDHAWK includes a variety of helpers that allow a developer to inject data into or extract data from components deployed through the Sandbox. The following sections describe each of these helpers and how they are used.\nData Sources The DataSource module provides a mechanism for producing Bulk Input/Output (BulkIO) data to be sent to a provides (input) port. Once instantiated, a Python vector of data can be pushed by the DataSource.\nAn example instantiation and use of the Data Source module can be seen below:\n\u0026gt;\u0026gt;\u0026gt; input_source = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; input_source.connect(my_comp) \u0026gt;\u0026gt;\u0026gt; my_data = range(10000) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_source.push(my_data) When the DataSource sends data, it attempts to match the data type to the type of the associated provides (input) port. Alternatively, the data type may be set explicitly in the DataSource constructor. Note that the default type for the DataSource is short, which implies that values over 32768 may induce an exception.\nThe default setting for number of bytes per pushPacket() is 512000 bytes. Data is broken up into chunks of this size before being sent via the port’s pushPacket() method. To change this default size, set the bytesPerPush argument in the DataSource constructor.\nTo generate continuous data, add loop=True to the push call.\n\u0026gt;\u0026gt;\u0026gt; input_source.push(my_data,loop=True) To stop looping data, enter the following command:\n\u0026gt;\u0026gt;\u0026gt; input_source.stop() A specific module is provided for reading data from a file. This module, FileSource, is used and instantiated much like the DataSource module. The most significant difference between the two modules is the presence of a file name in the FileSource constructor.\n\u0026gt;\u0026gt;\u0026gt; input_file = sb.FileSource(\u0026#34;~/short_file.tmp\u0026#34;, dataFormat=\u0026#34;short\u0026#34;) Signal Related Information (SRI) keywords may be generated and sent with data from the DataSource module.\nAn example generate/send can be seen below:\n\u0026gt;\u0026gt;\u0026gt; kw = sb.SRIKeyword(\u0026#34;SOME_RF\u0026#34;,155000000.0,\u0026#34;double\u0026#34;) \u0026gt;\u0026gt;\u0026gt; kw2 = sb.SRIKeyword(\u0026#34;EFFECTIVE_BITS_PER_SAMPLE\u0026#34;,16,\u0026#34;long\u0026#34;) \u0026gt;\u0026gt;\u0026gt; keywords = [kw, kw2] \u0026gt;\u0026gt;\u0026gt; input_data = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; data = range(1000) \u0026gt;\u0026gt;\u0026gt; input_data.connect(my_comp) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_data.push(data,SRIKeywords=keywords) The SRIKeyword() constructor takes in the following arguments:\n name - A string representing the name of the keyword being set. value - The value to be set. format - A string indicating the data type of the value. Valid data types are short, ushort, float, double, long, ulong, longlong, ulonglong, char, octet, string, boolean.  Messages can be sent to components using the MessageSource module. Messages sent using the sendMessage() method can be one of four types: struct, dictionary, CORBA Any, and data types that can be mapped to a CORBA Any.\nThe default message ID is sb_struct:\n\u0026gt;\u0026gt;\u0026gt; mySource = sb.MessageSource() \u0026gt;\u0026gt;\u0026gt; myComponent = sb.launch(\u0026#34;test_message_rx_cpp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; mySource.connect(myComponent) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; msg = {\u0026#34;val1\u0026#34;:\u0026#34;test string\u0026#34;, \u0026#34;val2\u0026#34;:123} \u0026gt;\u0026gt;\u0026gt; mySource.sendMessage(msg) Data Sinks The Sandbox provides a variety of data sinks including DataSink, FileSink, MessageSink, and the ability to plot data using one of the following plot types: LinePlot, LinePSD, RasterPSD, and XYPlot. For more information about the plot types, refer to Plotting Data.\nDataSink Example The Sandbox provides a DataSink module, which simply reads data from a uses (output) port. Below is an example instantiation and use of the DataSink module. In this example, data sent from myComponent’s uses (output) port is written to the received_data variable.\nSRI associated with the packet can be viewed using the SRI() method:\n\u0026gt;\u0026gt;\u0026gt; output_data = sb.DataSink() \u0026gt;\u0026gt;\u0026gt; myComponent.connect(output_data) \u0026gt;\u0026gt;\u0026gt; stream = output_data.getCurrentStream() \u0026gt;\u0026gt;\u0026gt; received_data = stream.read() \u0026gt;\u0026gt;\u0026gt; received_SRI = stream.SRI() To block until a certain amount of data is received, specify the data length as an argument to the read() method:\n\u0026gt;\u0026gt;\u0026gt; received_data = stream.read(100) The eos() method indicates whether or not an End of Stream (EOS) was received:\n\u0026gt;\u0026gt;\u0026gt; stream.eos() False The consume argument may be used to configure the read() method to move the read pointer forward a different length than what was read.\nFileSink Example Similar to the DataSource’s FileSource counterpart, the DataSink has an associated FileSink module for writing data to a file:\n\u0026gt;\u0026gt;\u0026gt; output_file = sb.FileSink(\u0026#34;~/some_file.tmp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; another_comp.connect(output_file) MessageSink Example Messages may be displayed using the MessageSink module. Data sent to a running MessageSink is printed in the Python interpreter.\nBelow is an example of MessageSink usage:\n\u0026gt;\u0026gt;\u0026gt; myComponent = sb.launch(\u0026#34;test_message_send_cpp\u0026#34;) \u0026gt;\u0026gt;\u0026gt; myMessageSink = sb.MessageSink() \u0026gt;\u0026gt;\u0026gt; myComponent.connect(myMessageSink) \u0026gt;\u0026gt;\u0026gt; sb.start() # assume that message_src sends a message In the above example, the received message is printed to the screen. MessageSink can either use a callback or a polling mechanism to retrieve messages.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; message_src = sb.launch(\u0026#39;test_message_send_cpp\u0026#39;) \u0026gt;\u0026gt;\u0026gt; def msgCallback(msg_id, msg): ... print msg_id, msg \u0026gt;\u0026gt;\u0026gt; callback_msg = sb.MessageSink(messageCallback=msgCallback) \u0026gt;\u0026gt;\u0026gt; retrieve_msg = sb.MessageSink(messageCallback=None, storeMessages=True) \u0026gt;\u0026gt;\u0026gt; message_src.connect(callback_msg) \u0026gt;\u0026gt;\u0026gt; message_src.connect(retrieve_msg) \u0026gt;\u0026gt;\u0026gt; sb.start() # assume that message_src sends a message \u0026gt;\u0026gt;\u0026gt; rcv_message = retrieve_msg.getMessages() In the above example, a message source component (created at some previous time), is connected to two instances of MessageSink, one instance implements a callback function and the other instance does not. When the message sink implementing the callback function receives a message, it triggers the callback function. The message sink that does not have a callback implementation stores the messages until they are retrieved through the getMessages() function.\nPassing a Struct to sendMessage Example The following example demonstrates how to generate and send messages in the Sandbox.\nfrom ossie.utils import sb from ossie.properties import simple_property class MessageProp(object): val1 = simple_property(id_=\u0026#34;val1\u0026#34;, type_=\u0026#34;string\u0026#34;, defvalue=\u0026#34;trm\u0026#34;) val2 = simple_property(id_=\u0026#34;val2\u0026#34;, type_=\u0026#34;double\u0026#34;, defvalue=1211) def __init__(self): \u0026#34;\u0026#34;\u0026#34;Construct an initialized instance of this struct definition\u0026#34;\u0026#34;\u0026#34; for attrname, classattr in type(self).__dict__.items(): if type(classattr) == simple_property: classattr.initialize(self) def __str__(self): \u0026#34;\u0026#34;\u0026#34;Return a string representation of this structure\u0026#34;\u0026#34;\u0026#34; d = {} d[\u0026#34;val1\u0026#34;] = self.val1 d[\u0026#34;val2\u0026#34;] = self.val2 return str(d) def getId(self): return \u0026#34;message_prop\u0026#34; def isStruct(self): return True def getMembers(self): return [(\u0026#34;val1\u0026#34;,self.val1),(\u0026#34;val2\u0026#34;,self.val2)] testmessage = MessageProp() testmessage.val1 = \u0026#34;test string\u0026#34; testmessage.val2 = 123 a = sb.MessageSource() b = sb.launch(\u0026#34;test_message_rx_cpp\u0026#34;) a.connect(b) sb.start() a.sendMessage(testmessage) Plotting Data Example The following example demonstrates how to use the sb.Plot() feature as a DataSink. Note that for plotting data, the REDHAWK IDE must be installed and the path to the eclipse directory of the installed IDE must be specified to the Sandbox.\nThis can be done through the IDELocation() function:\n\u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) This can also be done by setting the RH_IDE environment variable prior to starting the Python session.\n\u0026gt;\u0026gt;\u0026gt; input_source = sb.DataSource() \u0026gt;\u0026gt;\u0026gt; my_data = range(10000) \u0026gt;\u0026gt;\u0026gt; my_plot = sb.Plot() \u0026gt;\u0026gt;\u0026gt; input_source.connect(my_plot) \u0026gt;\u0026gt;\u0026gt; sb.start() \u0026gt;\u0026gt;\u0026gt; input_source.push(my_data) File Data Plotting Example The following example demonstrates how to plot the contents of a data file in the Sandbox. First, create a FileSource object. Then, connect it to a plot and start playing the data.\n\u0026gt;\u0026gt;\u0026gt; input_file = sb.FileSource(\u0026#34;~/short_file.tmp\u0026#34;, dataFormat=\u0026#34;short\u0026#34;) \u0026gt;\u0026gt;\u0026gt; my_plot = sb.Plot() \u0026gt;\u0026gt;\u0026gt; input_file.connect(my_plot) \u0026gt;\u0026gt;\u0026gt; input_file.start() Custom Sinks If there is a need to create a custom sink with specialized behavior, the DataSink object can be modified with a customized sink service function that allows tailoring the DataSink instance to special circumstances. The sink service function must inherit from bulkio_data_helpers.ArraySink and can overload any existing functions that need to be tailored.\nThe following example is a sink specialization in which the effective xdelta for the received data needs to change by a factor of two.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils.bulkio import bulkio_data_helpers \u0026gt;\u0026gt;\u0026gt; class customSink(bulkio_data_helpers.ArraySink): ... def __init__(self, porttype): ... bulkio_data_helpers.ArraySink.__init__(self, porttype) ... def pushSRI(self, H): ... _H = H ... _H.xdelta = H.xdelta * 2 ... self.SRI = _H ... self.SRIs.append([len(self.data), _H]) \u0026gt;\u0026gt;\u0026gt; src=sb.DataSource(dataFormat=\u0026#39;float\u0026#39;) \u0026gt;\u0026gt;\u0026gt; snk = sb.DataSink(sinkClass=customSink) \u0026gt;\u0026gt;\u0026gt; src.connect(snk)"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/creating-redhawk-projects/",
	"title": "Creating REDHAWK Projects",
	"tags": [],
	"description": "",
	"content": " This section describes the different types of REDHAWK projects and how to create them using the provided Wizards. Before creating a new project, it is recommended that the IDE be in the REDHAWK perspective so that the proper menus are available.\nTo create a new REDHAWK project, click File \u0026gt; New \u0026gt; Project, and then select the project type.\nThe IDE displays the Select a wizard window, which prompts the user to select from multiple project types. Each project type has a custom Wizard to guide users through the initial creation process.\nCommon Fields Some basic fields within the new project Wizard are common to all project types and include:\n Project Name: A project name that is unique to the current workspace. Projects can be namespaced by adding dots in the name. Project names may not begin with a number and may not contain special characters other than dots for the namespace. Namespacing projects provides the ability to uniquely identify projects that share the same base name but have different implementations and also provides a logical grouping of resources. For example, the REDHAWK basic assets are namspaced as rh.xxxx. The Wizard dialog detects errors and informs the user if there is an invalid entry.\n  Location: By default the location of the project is set to the current workspace. This may be changed by deselecting the Use default location check box and providing a custom location.\n Working sets: A working set is an Eclipse concept and provides an additional layer of organization to the project workspace. A user may put common projects into a single “working set” to visually organize the Project Explorer. Additional options become available when projects are placed in working sets allowing the user to build, refresh, and search based on a specific working set. While it may resemble a folder, a working set does not create a new directory on the file system and the same project may belong to multiple working sets.\n  REDHAWK Component Project The New Component Project Wizard is a three page wizard that walks the user through creating a new REDHAWK component, selecting a programming language, and selecting a code generator. Many of the fields found within the component project wizard are also found within the device project wizard. Fields common to all new project wizards are defined in Common Fields.\nPage one of the component wizard contains:\n Contents: A REDHAWK component is defined by an Software Package Descriptor (SPD) file. By default, when creating a new component, the SPD file created is an empty skeleton. A new component may be based off of a previous component’s SPD file by selecting it from the file system. Component ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the component’s implementation, the programming language used and the code generation template.\nThe content found on this page includes:\n Prog. Lang: A component’s implementation may be written in either C++, Java, or Python. Code Generator: The REDHAWK IDE provides a single code generator for each of the programming languages. It is possible to augment the IDE with additional code generators. A user may choose to forgo automatic code generation and instead choose to create their implementation manually.\n ID: Each language implementation has a project unique ID. By default the language chosen is used as the ID.\n Description: A component’s implementation may contain a description. The description is written into the component’s SPD file.\n  Page three of the wizard allows the user to customize the properties of the code generator and template.\nWizard page three contains fields for:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties that may be set from the properties section. Output Directory: The folder created to house the generated code. Package: Available only for Java implementations. The Java package to place auto-generated code within. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Click Finish to complete the new project creation wizard.\nREDHAWK Control Panel Project The New Control Panel Project Wizard is a two to three page wizard that walks the user through creating a new Plug-in project and optionally, generating a fully functioning project based off of supplied template projects. The New Control Panel Project Wizard is taken directly from the Eclipse New Plug-in Project Wizard and contains identical fields. Refer to the Eclipse documentation for more information.\nREDHAWK Device Project The New Device Project Wizard is a three page wizard that walks the user through creating a new REDHAWK device, selecting a programming language, and selecting a code generator. Many of the fields found within the device project wizard are also found within the component project wizard. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Device: The user may select whether this is a standard device, Loadable device, or an Executable device. The checkbox below indicates if this is an Aggregate device. Contents: A REDHAWK device is defined by an SPD file. By default, when creating a new device, the SPD file created is an empty skeleton. The new device may be based off of a previous device’s SPD file by selecting it from the file system. Device ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the device’s implementation, the programming language used and the code generation template.\nWizard page two contains:\n Prog. Lang: A device’s implementation may be written in either C++, Java, or Python. Code Generator: The REDHAWK IDE provides a single code generator for each of the programming languages. It is possible to augment the IDE with additional code generators. A user may choose to forgo automatic code generation and instead choose to create their implementation manually. ID: Each language implementation has a project unique ID, by default the language chosen is used as the ID. Description: A description for this implementation may be provided. The description is written into the device’s SPD file.  Page three of the wizard allows the user to customize the properties of the code generator and template.\nWizard page three contains:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties which may be set in the properties section. Output Directory: The folder created to house the generated code. Package: Available only for Java implementations. The Java package to place auto-generated code within. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Click Finish to complete the new project creation wizard.\nREDHAWK FrontEnd Device Project The FEI Wizard enables users to quickly create an FrontEnd Interfaces (FEI) compliant RX or TX tuner device. In the wizard, the user specifies the physical properties of the device, including whether the device ingests or outputs GPS and if the device has digital or analog input and output ports. Additionally, the user can choose to augment the required tuner status properties with additional optional properties.\nREDHAWK Interface Description Language (IDL) Project The IDL Project Wizard is a one page wizard that walks the user through creating a new REDHAWK IDL project. Fields common to all new project wizards are defined in Common Fields.\nWhen creating a new IDL project, avoid using reserved names as specified in the Object Management Group Language Mapping Specifications (IDL to Java Language Mapping, Python, and C++).\n Page one of the wizard contains:\n Module Name: The module to place this IDL into. Version: IDL Version Import existing IDL Files: Specifies IDL files on disk which are included in this new IDL.  Click Finish to complete the new project creation wizard.\nIf you upgrade to REDHAWK version 2.0, and your custom IDL project references the Core Framework (CF) IDLs, compiler errors may be displayed. To resolve the errors, create a new IDL project and import your IDL files into the new project. The new project contains an updated Makefile.am that accounts for changes in the REDHAWK 2.0 IDL files.\n REDHAWK Node Project The New Node Project Wizard is a one to two page wizard that walks the user through creating a new REDHAWK node and optionally, placing devices into the new node. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Domain Manager: Select the Domain Manager this node is assigned.\n Contents: A REDHAWK node is defined by a Device Configuration Descriptor (DCD) file. By default, when creating a new node, the DCD file created is an empty skeleton. The new node may be based off of a previous node’s DCD file by selecting it from the file system.\n Node ID: Every DCD contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.\n  The wizard may be completed at this point by clicking Finish or the user may continue to the optional second page.\nOn page two the user chooses what devices/services make up this node. This may be changed after the node’s creation from the Node Editor.\nSelect Finish to complete the new project creation wizard.\nREDHAWK Octave Project The Octave Wizard enables users to import existing Octave M-files for easy conversion into REDHAWK C++ components. The user imports an existing M-file, as well as any required dependent M-files, and then maps the M-file’s inputs and outputs to REDHAWK ports and properties.\nREDHAWK Service Project The New Service Project Wizard is a three page wizard that walks the user through creating a new REDHAWK service selecting a programming language, and selecting a code generator. Many of the fields found within the service project wizard are also found within the component and device project wizard. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Service Interface: Select from the list of installed IDLs the interface which this service uses. Contents: A REDHAWK service is defined by an SPD file. By default, when creating a new service, the SPD file created is an empty skeleton. The new service may be based off of a previous service’s SPD file by selecting it from the file system. Service ID: Every SoftPkg element contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  Page two of the wizard defines the service’s implementation, the programming language used and the code generation template.\nWizard page two contains:\n Prog. Lang: The service’s implementation may be written in either C++, Java, or Python. Code Generator: A Python code generator is available for REDHAWK service code generation. It is possible to augment the IDE with additional code generators. ID: Each language implementation has a project unique ID, by default the language chosen is used as the ID. Description: A description may be provided for this implementation. The description is written into the service’s SPD file.  Page three of the wizard provides customization to the configuration values of this implementation’s code generation properties and template.\nWizard page three contains:\n Generator: A read only label displaying the code generator being configured. This is the code generator that was chosen on the previous wizard page. Template: The code generator may provide multiple templates to choose from. Each template may contain unique properties which may be set in the properties section. Output Directory: The folder created to house the generated code. Properties: Different code generation templates may provide configuration properties. Mouse hovering over the individual property provides information about the property.  Select Finish to complete the new project creation wizard.\nREDHAWK Shared Library Project The REDHAWK Shared Library Project Wizard enables users to quickly create a C++ shared library for use in REDHAWK. In the wizard, the user specifies the project name and can then generate a simple set of code files to begin adding in library functions.\nREDHAWK Waveform Project The New Waveform Project Wizard is a one to two page wizard that walks the user through creating a new REDHAWK waveform and optionally, assigning an Assembly Controller. Fields common to all new project wizards are defined in Common Fields.\nPage one of the wizard contains:\n Contents: An waveform is defined by an Software Assembly Descriptor (SAD) file. By default, when creating a new waveform, the SAD file created is an empty skeleton. The new waveform may be based off of a previous waveform’s SAD file by selecting it from the file system. REDHAWK Waveform ID: Every SAD file contains an ID which is used for universally unique identification. The IDE generates a DCE compliant UUID by default.  The user may choose to complete the wizard at this point or continue on to the optional second page. Page two allows the user to set an Assembly Controller for the new waveform. The Assembly Controller may be set, or changed after the waveforms creation from within the Assembly Controller editor.\nClick Finish to complete the new project creation wizard.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/fei-data-structures/",
	"title": "Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators",
	"tags": [],
	"description": "",
	"content": " The following table describes the functions and data structures that are provided by the FrontEnd Interfaces (FEI) library and code generators, which are useful when customizing FEI devices.\nFEI Functions and Data Structures    Function/Data Structure Description     setNumChannels Used to size various FrontendTunerDevice class data structures.   frontend_tuner_status This is the FrontEnd tuner status property, which is a vector of structs. The indices match the tuner_id or index of the tuner used by the FrontEnd Tuner device. The developer is responsible for maintaining all fields with the sole exception of the allocation_id_csv, which is managed internally by the FrontendTunerDevice class.   getControlAllocationId Returns the control Allocation ID for the tuner specified, or an empty string if not allocated.   getTunerMapping Returns the tuner ID or tuner index of the tuner associated with the Allocation ID, or -1 if the Allocation ID is not associated with any tuner.   create Returns a StreamSRI object constructed using the frontend_tuner_status for a tuner, including the required Signal Related Information (SRI) keywords. Only required FrontEnd tuner status fields are used in constructing the StreamSRI, and any additional information that affects StreamSRI must be manually modified. In the case of Digital Down Converter (DDC) tuners, there is an optional parameter accepted by create for specifying the collector frequency since this information cannot be gathered from the frontend_tuner_status struct.   printSRI Used for debug purposes to print the values of a StreamSRI object to stdout.   addModifyKeyword Used to add a keyword to a StreamSRI object, or modify an existing keyword.   uuidGenerator Used to generate a new UUID string.   floatingPointCompare Used to handle potential errors introduced by floating-point math. Default precision is to the tenths place, and there is an optional parameter that can be used to specify a different precision.   matchAllocationIdToStreamId Only available when multi-out ports are specified. Multi-out capability of a Bulk Input/Output (BulkIO) port only pushes stream data with a particular Stream ID to connections that have a Connection ID that matches the Allocation ID. It is recommended that this function be called in deviceSetTuning.   validateRequest Used to verify that a value falls within the specified range. This function is overloaded to accept a range as well, to verify that it falls within a second range.   validateRequestVsSRI Used to check that the input data stream can support the allocation request. The output mode (True if complex output) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown. If the CHAN_RF and FRONTEND::BANDWIDTH keywords are not found in the SRI, FRONTEND::BadParameterException is thrown.   validateRequestVsRFInfo Used to check that the analog capabilities can support the allocation request. The mode (True if complex) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown.   validateRequestVsDevice Used to check that the input data stream and the device can support an allocation request. The mode (True if complex output) is used when determining the necessary sample rate required to satisfy the request. The entire frequency band of the request must be available for True to be returned, not just the center frequency. True is returned upon success, otherwise FRONTEND::BadParameterException is thrown. This function is overloaded to accept RFInfoPkt for an analog input data stream, and StreamSRI for a digital input data stream. For StreamSRI, if the CHAN_RF and FRONTEND::BANDWIDTH keywords are not found in the SRI, FRONTEND::BadParameterException is thrown.    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/increasing-bulkio-connection-bandwidth/",
	"title": "Increasing the Bandwidth of BulkIO Connections",
	"tags": [],
	"description": "",
	"content": "In the presence of high data rates, plots of Bulk Input/Output (BulkIO) ports may not be able to keep up with the data stream. To increase the bandwidth of BulkIO CORBA connections, it is possible to connect using native omniORB libraries. This ability is currently disabled by default. The following procedure explains how to enable this ability from within the IDE:\n Select Window \u0026gt; Preferences.\nThe Preferences dialog is displayed:\n Preferences Dialog    Expand REDHAWK.\n Select BulkIO.\n Set Port Factory to omnijni.\n Click OK.\n  This option should only be enabled if the domain matches the version of the IDE, and your application requires the increased performance of omnijni.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/java-version/",
	"title": "Java Version",
	"tags": [],
	"description": "",
	"content": "The default supported version for the Java language for Java components is 1.8. The Java version for any specific component can be changed by changing the argument to the RH_PROG_JAVAC macro in the component’s configure.ac file.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/optimization/",
	"title": "Optimization",
	"tags": [],
	"description": "",
	"content": " As a system framework, REDHAWK is affected by system settings beyond the scope of REDHAWK. System optimization is sensitive to the set of applications that the system is intended to support. However, there are some simple settings that can apply to a wide set of applications. This chapter describes some of the effects of these generalized settings.\nConfiguring omniORB By default, omniORB configuration relies on the loopback interface of the operating system. While easy to use and manage, the loopback interface is not the fastest default transport that omniORB supports. omniORB also supports Unix domain sockets. Unix domain sockets are configured through the omniORB configuration file (/etc/omniORB.cfg).\nThe following steps explain how to configure Unix domain sockets.\nRoot permissions are required to perform the following steps.\n  In the omiORB configuration file (/etc/omniORB.cfg), set the endpoints where the server is listening by adding the following lines to the endPoint section of the file:\nendPoint = giop:tcp:127.0.0.1: = giop:tcp:\u0026lt;computer IP address\u0026gt;: = giop:unix: GIOP (General Inter-ORB Protocol) is the scheme used by the endpoint. TCP is the protocol followed by an IP address or host name. The port is specified after the last colon. Since no port is specified here, the operating system chooses the port. The Unix transport name uses a filename as the name of the socket in the filesystem. Since a name is not specified here, a name based on the process ID and timestamp is used.\n  Set the endpoints that are published in an object’s Interoperable Object Reference (IOR) by adding the following lines to the endPointPublish section of the file:\nendPointPublish = all(addr) After changing these settings, the naming and event services must be reset, and their associated log files must be deleted. If the log files are not deleted, they preserve IORs that are no longer valid.\n Use the following command to reset the name and event services and delete the associated log files:\nsudo $OSSIEHOME/bin/cleanomni Run this script with the -v or --verbose option to print the cleanup process.\n To verify that Unix domain sockets are being used, go to /tmp, and verify that the omni-omni and omni-root directories exist. These two directories contain the files for the Unix domain sockets. Given that communications are now over file descriptors, verify that read permissions are open when communicating between objects owned by different users. This change in the omniORB configuration greatly improves data transport rates.\n  Packet Transfer Size REDHAWK transfers data using Bulk Input/Output (BulkIO), which is an RPC mechanism. The size of the data sequence that is passed on each of these calls has an effect on the data rate. The size of the transfer is not controlled by the REDHAWK runtime environment; instead, data producers can pass any arbitrary length less than giopMaxMsgSize.\nTo demonstrate how throughput is affected by the configuration of omniORB and data transfer size, tests were performed on a system with the specifications shown below.\nComputer Hosting Experiments    Parameter Value     Number of cores 8   CPU clock speed 3.40 GHz   Cache size 8192 kB    The figure below shows the supported data rate in Giga-bytes per second at different transfer sizes when using the loopback interface (the default setting for omniORB). Data rates on the experiment platform plateau when transfer size approaches approximately 500 kB. Using higher transfer sizes, data rate does not improve, while latency increases. The value at which data rates plateau is system-specific.  Throughput for BulkIO When Using the Loopback Interface   Another result derived from this experiment is that there is a substantial impact when the number of component pairs transferring data increases.\nBy following the steps in Configuring omniORB, it is possible to achieve higher data rates. The following figure shows the same experiment as the one shown above, but with omniORB configured for Unix domain sockets. The sustained data rates on the computer used in this experiment are roughly four times higher when using Unix domain sockets compared to using the loopback interface. Even when heavily loaded, the Unix domain socket configuration is as fast or faster than the lightly-loaded loopback configuration.  Throughput for BulkIO When Using Unix Domain Sockets   Messaging Latency Much like BulkIO, messaging is subject to performance issues as the transfer size changes. Testing was performed to determine the impact of message size on the latency per message. The size of the message was modified and the latency per message was measured. The average latency was measured for sets of 1000 messages. The two figures below show the latency results when using the loopback interface and when using Unix domain sockets. Latency is a function of the size of the message, where the measured latency ranges between 40-150 microseconds and 50-160 microseconds for Unix domain sockets and loopback interface, respectively.  Message Latency When Using the Loopback Interface    Message Latency When Using Unix Domain Sockets   Note that in both figures latency is linear as a function of the message size. Furthermore, the number of concurrent messaging components has no discernible impact on the message latency. Finally, the difference shown between Unix domain socket performance and loopback interface performance is, while measurable, relatively small.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/port-statistics/",
	"title": "Port Statistics",
	"tags": [],
	"description": "",
	"content": " All Burst Input/Output (BurstIO) ports support the Bulk Input/Output (BulkIO) statistics interface with additional keywords to track burst-specific metrics. Statistics are tracked over a window of 10 pushBurst calls. An input port contains a single PortStatistics structure, whereas, an output port contains a sequence of PortStatistics structures; one structure per connection. For more information on BULKIO::PortStatistics, see Port Statistics. The additional BurstIO metrics for both input and output ports are described in the following tables:\nC++ The following example illustrates a component that performs a transform on the incoming burst data and pushes the results downstream.\nburstio::BurstShortIn::PacketType *pkt; pkt = inShortPort-\u0026gt;getPacket(bulkio::Const::NON_BLOCKING); // check if a valid packet was returned if ( pkt == NULL ) { return NOOP; } // check for EOS if ( pkt-\u0026gt;getEOS() ) { outShortPort-\u0026gt;pushBurst(pkt-\u0026gt;getSequence(), pkt-\u0026gt;getSRI(), pkt-\u0026gt;getEOS()); } // do some processing.....to the burst contents BurstShortOut::SequenceType data = do_some_magic(pkt-\u0026gt;getSequence()); // we changed the data so calc new time stamp.... BULKIO::PrecisionUTCTime newTS = calc_timestamp(pkt-\u0026gt;getTime()); outShortPort-\u0026gt;pushBurst(data, pkt-\u0026gt;getSRI(), newTS, pkt-\u0026gt;getEOS()); Java The following example illustrates a component that generates 10 bursts objects containing 100 samples of data and sends the array downstream.\n/** This example demonstrates a Component that uses the pushBursts method to generate data */ int nbursts=10; String sid = new String(\u0026#34;stream-1-1\u0026#34;); BURSTIO.LongBurst [] bursts = new BURSTIO.LongBurst[nbursts]; // allocate space for 10 bursts to push downstream  // generate bursts with 100 samples of data for downstream for ( int j=0; j \u0026lt; nbursts; j++ ) { BURSTIO.LongBurst burst = new BURSTIO.LongBurst(); burst.SRI = make_SRI( sid ); // generate a Burst SRI object for use...  burst.EOS = false; burst.T = burstio.Utils.now(); burst.data = generate_samples( 100 ); bursts[j] = burst; } longOutPort.pushBursts( bursts ); Python The following example illustrates a component that generates burst samples that will be filtered out by the port’s routing table when at least 10 bursts are queued for delivery.\nfrom redhawk.burstioInterfaces import BURSTIO from redhawk.burstio import * def initialize(self): # # Send bursts to downstream resource using connection filtering # **you will need to set the routing table in a property change event # callback for the resource\u0026#39;s connection table object** # self.outShortPort.setRoutingMode( ROUTE_CONNECTION_STREAMS ) self.outShortPort.setMaxBursts(10); def generate_burst_samples(self, nsamps=10 ): # # generate number of sample data.. return range(nsamps) def process(self): # data = self.generate_burst_samples(100) SRI = burstio.utils.createSRI(\u0026#34;test_stream_id\u0026#34;) SRI.xdelta = 1.0/1000.0 SRI.mode = 0 self.outShortPort.pushBurst( data, SRI, burstio.utils.now() ) return NORMAL"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/redhawk-explorer-view/",
	"title": "REDHAWK Explorer View",
	"tags": [],
	"description": "",
	"content": "The REDHAWK Explorer view enables users to navigate the contents of a REDHAWK domain.\n REDHAWK Explorer View   It provides capabilities for viewing the contents of the domain, configuring instantiated resources, and launching applications in a Target SDR. It also provides access to the IDE Sandbox, which is an environment for running components and applications without launching a Domain Manager or Device Manager.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": " This section briefly describes how to use the sandbox either from a Python shell or via the REDHAWK IDE; a more detailed description is available in the Sandbox chapter.\nPython Sandbox The sandbox can be accessed directly from the command line and is used to manipulate new components and waveforms. This provides a very powerful means of testing and scripting tests for REDHAWK systems.\n Open a Python session and import the sandbox:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb Running a component\n To get a list of available components, type:\n\u0026gt;\u0026gt;\u0026gt; sb.catalog() [\u0026#39;rh.HardLimit\u0026#39;, \u0026#39;rh.SigGen\u0026#39;, ...] The displayed list is derived by scanning $SDRROOT. HardLimit and SigGen are examples of existing components.\n  Create the component object by typing:\n\u0026gt;\u0026gt;\u0026gt; hardLimit = sb.launch(\u0026#34;rh.HardLimit\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sigGen = sb.launch(\u0026#34;rh.SigGen\u0026#34;) After the constructor is finished, the components run as their own processes. If an absolute file path for a component’s Software Package Descriptor (SPD) file (\u0026lt;component.spd.xml) is given as a constructor argument for the component instance, then that component is started irrespective of whether or not it is present in $SDRROOT.\n   Support widgets are available in the sandbox to help the developer interact with running components. There are a variety of widgets, including data sources and sinks, a speaker interface, and plotters. In this example, the plot widget is used.\n To use plotting, the path to the eclipse directory of the installed IDE must be specified in the sandbox (this can also be done by setting the RH_IDE environment variable to the absolute path of the Eclipse directory prior to starting the Python session):\n\u0026gt;\u0026gt;\u0026gt; sb.IDELocation(\u0026#34;/path/to/ide/eclipse\u0026#34;) \u0026gt;\u0026gt;\u0026gt; plot = sb.Plot() Create two plot objects by instantiating the Plot class twice and assigning the objects to local variables:\n\u0026gt;\u0026gt;\u0026gt; plot1 = sb.Plot() \u0026gt;\u0026gt;\u0026gt; plot2 = sb.Plot()  Connect the components together and connect the plots. The connect() method tries to match the port; ambiguities can be resolved with the parameters usesPortName and providesPortName. Connecting the plots to the components displays the Plot Application window.\n\u0026gt;\u0026gt;\u0026gt; sigGen.connect(hardLimit) \u0026gt;\u0026gt;\u0026gt; sigGen.connect(plot1) \u0026gt;\u0026gt;\u0026gt; hardLimit.connect(plot2) In this tutorial, the SigGen component is configured before it is started to get a better visual. Set the frequency of the SigGen Component equal to 5006:\n\u0026gt;\u0026gt;\u0026gt; sigGen.frequency = 5006 Start everything in the sandbox:\n\u0026gt;\u0026gt;\u0026gt; sb.start() The property values can now be set on the HardLimit component. The plot reflects the property change:\n\u0026gt;\u0026gt;\u0026gt; hardLimit.upper_limit = .8 To inspect the properties and input/output ports of a component, invoke the component’s api() method:\n\u0026gt;\u0026gt;\u0026gt; sigGen.api() To clean up, type Ctrl+D to end the Python session. The Python sandbox releases all components and cleans up whatever plots or additional widgets were created during the session.\n  The IDE Sandbox This section provides an overview of how to use the sandbox in the REDHAWK IDE. The IDE sandbox provides a graphical environment for launching, inspecting, and debugging components, devices, nodes, services, and waveforms. In addition, via the REDHAWK Console, you can use the Python-based sandbox API to interact with objects that are running within the IDE sandbox.\nThe following procedure provides an example of launching and interacting with a component in the sandbox in the REDHAWK IDE.\n In the REDHAWK Explorer view:\n Expand the Sandbox to expose the Chalkboard.\n Double-click the Chalkboard.  Open Chalkboard     From the Chalkboard:\n Select the palette on the right; drag the SigGen (cpp) component onto the Chalkboard. The component will initially be gray in color until launching is complete. When the component is finished loading, its background color is blue. SigGen will be used to help test the new HardLimit component.\n If the SigGen component is not displayed, left-click the rh folder to display the list of available components.\n If the cpp implementation is not displayed, expand the list of implementations by left-clicking the arrow to the left of the component name and select the cpp implementation. To zoom in and out on the diagram, press and hold Ctrl; then scroll up or down. Alternatively, press and hold Ctrl; then press + or -.\n  Right-click the SigGen component, and select Start.  Start Component    Left-click the dataFloat_out port to select it, then right-click the port to open the port context menu, and select Plot Port Data.  Plot Port Data    Open the Properties view and change the following signal properties:\n frequency: 100 magnitude: 10  Change Property Value     Select the palette on the right, drag the HardLimit component onto the Chalkboard.\n Right-click the HardLimit component, click Start.\n Connect the dataFloat_out port on the SigGen component to the dataFloat_in port on the HardLimit component by clicking and dragging from the solid black output port to the input port.  Connect Ports    Right-click the dataFloat_out port on the HardLimit component, click Plot Port Data\n Notice that the output has been hard limited by the HardLimit component\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/adminservice/serviceconfigurations/",
	"title": "Service Configurations",
	"tags": [],
	"description": "",
	"content": " The INI service configuration files define the execution environment for each REDHAWK core service. The AdminService reads all the service configuration files at startup and executes any enabled configuration. This section provides an overview of the service configuration files and how to manage configurations using rhadmin.\nConfiguration Contents The INI files contain configuration properties in the form Name=Value and are grouped by section headers with the syntax [\u0026lt;type\u0026gt;:\u0026lt;section name\u0026gt;]; where \u0026lt;type\u0026gt; is either domain, node, or waveform. All service configuration files contain a required property DOMAIN_NAME, which is used by the AdminService to group services by domain, and used to define the service\u0026rsquo;s name. The complete definition for each type of service configuration file is explained in the following sections.\n Domain Manager Configuration File\n Device Manager Configuration File\n Waveform Configuration File\n  Configuration Concepts This section provides general concepts about the implementation of the AdminService.\nService Name The service\u0026rsquo;s name takes the form of \u0026lt;domain name\u0026gt;:\u0026lt;section name\u0026gt;, and is derived from the section header, [\u0026lt;type\u0026gt;:\u0026lt;section name\u0026gt;], in the INI file and the value of the DOMAIN_NAME property. The service\u0026rsquo;s name may be used as the target for rhadmin commands that accept this argument. The following example describes a Device Manager service with service name REDHAWK_DEV:MyNode:\n[node:MyNode] DOMAIN_NAME=REDHAWK_DEV NODE_NAME=NODE  Domain Name All REDHAWK core services are required to have a DOMAIN_NAME configuration property. This property defines the REDHAWK domain context and allows the AdminService to group services into a domain group. This domain group is used to determine the execution priority and arguments for rhadmin commands.\nPriority The priority setting is the main contributing factor in how the AdminService starts and stops the REDHAWK core services. Every core service has a default priority that the AdminService uses to organize the startup of domain groups, and then services within a domain group. The default priority for each service type within a domain group is (Domain Manager, Device Managers, and then waveforms). If there are multiple domains defined, all services in the domain with the lowest numerical priority Domain Manager are started first. The priority setting can be used to customize the startup of domains and service types within the domain.\nWhen shutting down a domain or during system shutdown, the AdminService stops the domain with the highest numerical priority first.\nDaemon Process By default, the run_detached property for all services is set to true. This property controls if the service is started as a daemon and detached from the AdminService. If set to true, the service\u0026rsquo;s process running state is not affected by restarts of the AdminService. In essence, the service\u0026rsquo;s process life cycle is independent of the AdminService\u0026rsquo;s process life cycle. If run_detached is set to false, then the service\u0026rsquo;s life cycle follows the AdminService\u0026rsquo;s life cycle.\nEnvironment Variables Environment variables may also be referenced and defined in the service configuration files. To reference an environment variable, use the following expression syntax: %(ENV_X)s, where X is the name of the environment variable. All AdminService\u0026rsquo;s environment variables are available for use when the service configuration is processed. In the following example, the environment variable LOGLEVEL is used to the set the configuration property loglevel.\nloglevel=%(ENV_LOGLEVEL)s  Environment variables may be overridden by using the environment configuration property. However, only uppercase configuration parameter names can use the values of these overridden environment variables. In the following example of a node configuration, the PYTHONPATH configuration parameter uses the overridden environment variable.\nenvironment=PYTHONPATH=/usr/local/redhawk/core/lib/python:/usr/local/mylibrary/lib/python PYTHONPATH=%(ENV_PYTHONPATH)s  Default Configurations Each service type (domain, node, waveform) has an associated defaults file in the directory /etc/redhawk/init.d/. Each file provides the default settings for all optional configuration properties in a service configuration file. For example, a Domain Manager service configuration file only requires setting the DOMAIN_NAME property; all other default property settings are resolved from the file /etc/redhawk/init.d/domain.defaults.\nService File Locations The AdminService reads service configuration files from several directories on startup. The following table lists the locations and the files read:\nService File Locations and File Types    Service Configuration Directory File     Defaults /etc/redhawk/init.d *.defaults   Domain Manager /etc/redhawk/domains.d *.ini   Device Manager /etc/redhawk/nodes.d *.ini   Waveform /etc/redhawk/waveforms.d *.ini    Creating Configuration Files To create a new configuration file, enter the following command, replacing \u0026lt;type\u0026gt; with domain, node, or waveform as appropriate.\n# This will generate a generic configuration file rhadmin config \u0026lt;type\u0026gt; \u0026gt; \u0026lt;file name\u0026gt;.ini For the file to be recognized by the AdminService, the file is required to have an .ini file extension and be installed into the proper service directory under /etc/redhawk. The following example describes how to create, install, and activate a Domain Manager service configuration.\n# This will generate a generic configuration file rhadmin config domain \u0026gt; rhdom.ini # edit file and change DOMAIN_NAME=REDHAWK_DEV vi rhdom.ini cp rhdom.ini /etc/redhawk/domains.d rhadmin reload The configuration files are located in system privileged directories. Ensure that you have proper privileges to create and edit files in those directories.\n For Device Manager and waveform manager services, the REDHAWK IDE can also be used to generate an example configuration file and an RPM .spec file to install it. For more information, refer to Device Manager Service and Waveform Service.\nViewing Configured Services in the AdminService To view what services are currently configured in the AdminService, enter the following command:\nrhadmin list The configured Domain Manager, Device Manager, and waveform services are displayed.\nName In Use Autostart Enabled Priority REDHAWK_DEV:GppNode in use auto Enabled 100:400 REDHAWK_DEV:REDHAWK_DEV_mgr in use auto Enabled 100:100 REDHAWK_DEV:Wave in use auto Enabled 100:900  The following columns are displayed in the configured services output:\n Name - The service name that may be used for other commands. The format is \u0026lt;domain name\u0026gt;:\u0026lt;section name\u0026gt;. In Use - The status of the service configuration, which indicates whether the configuration has been activated and is operable. Autostart - Specifies whether the service will automatically start when the AdminService starts. Enabled - Specifies whether the service configuration can be started. This setting may be overridden on the start command with the -f flag. Priority - The priority of the service\u0026rsquo;s configuration. The format is \u0026lt;domain priority\u0026gt;:\u0026lt;service priority\u0026gt;. In a multiple domain scenario, the lowest value for the domain priority is started first. When starting services in a domain, the lowest value for service priority is started first.  To view the contents of a service\u0026rsquo;s configuration file use the getconfig command.\nrhadmin getconfig \u0026lt;service name\u0026gt; Managing Configurations There is no direct command to add or remove service configurations from the AdminService. This is accomplished by adding or deleting files from the appropriate service directory under /etc/redhawk and then running the rhadmin update command. This command rereads the configuration files, starts any new services that were defined, and stops any currently running services that are not enabled or defined (for example, a deleted INI file). Service\u0026rsquo;s with their configuration property run_detached=True will have their configuration processed but the underlying service process will not be restarted.\nThe following example adds a new waveform service, REDHAWK_DEV:Wave2, to the AdminService.\nrhadmin config waveform \u0026gt; wave2.ini # change DOMAIN_NAME=REDHAWK_DEV and WAVEFORM=wave2 properties, set the section header to [waveform:Wave2] vi wave2.ini cp wave2.ini /etc/redhawk/waveforms.d rhadmin update REDHAWK_DEV The following output is displayed:\nREDHAWK_DEV: updated process group  To verify the REDHAWK_DEV:Wave2 configuration was added and started, enter the following command:\nrhadmin status The following output is displayed:\nREDHAWK_DEV:GppNode RUNNING pid 31316, uptime 0:00:46 REDHAWK_DEV:REDHAWK_DEV_mgr RUNNING pid 31185, uptime 0:00:52 REDHAWK_DEV:Wave RUNNING pid 31745, uptime 0:00:30 REDHAWK_DEV:Wave2 RUNNING pid 31408, uptime 0:00:41  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/shared-libraries/",
	"title": "Shared Libraries",
	"tags": [],
	"description": "",
	"content": "Shared libraries are a way to share common code between multiple REDHAWK projects, both at development and run time. When developing components or devices, REDHAWK shared libraries are automatically integrated into the build system. At run time, a component’s dependencies are copied to the GPP as required, eliminating the need to install dependencies on each system in a domain.\nUsing shared libraries reduces the development, maintenance, and deployment costs of REDHAWK systems.\n Creating a REDHAWK Shared Library Project     Using a REDHAWK Shared Library Project     Packaging Shared Libraries     Manually Including External Libraries     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/standardized-data-interfaces/",
	"title": "Standardized Data Interfaces",
	"tags": [],
	"description": "",
	"content": "Data flow between REDHAWK resources (components and devices) is managed through two sets of interfaces: Bulk Input/Output (BulkIO) and Burst Input/Output (BurstIO). The BulkIO module is designed for streaming data and maximizes the efficiency for bulk data transfers between resources, whereas, BurstIO is designed for applications that require small and possibly non-contiguous chunks of data transfers. Both interfaces also allow for the association of metadata, Signal Related Information (SRI), and a Precision Time Stamp, which describe the content being transferred in support of content processing. The following 3 sections detail the capabilities for both BulkIO and BurstIO implementations and the interfaces they provide.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/application-factory/",
	"title": "The Application Factory",
	"tags": [],
	"description": "",
	"content": "The Application Factory is responsible for the creation of applications within a domain. Whenever an application is installed by the Domain Manager, an Application Factory is created from tags in the application’s Software Assembly Descriptor (SAD) file, in order to deploy components of the application to devices based on their implementation dependencies.\nWhen the create() function is called, the Application Factory uses the Software Package Descriptor (SPD) implementation element to locate devices that are capable of loading and executing the given component. The Application Factory does this by first assembling a list of all of the allocation properties required by the components that make up its application. It then searches through each of the candidate devices for properties whose kindtype is allocation and action is not external. It attempts to use that devices allocateCapacity() function in order to compare the requested capacities with the devices available resources.\nThe creation of the application fails if the Application Factory is unable to deploy all of the components in compliance with the components’ dependencies and host-collocation requirements given the available devices.\nOnce the resource marshaling has been successfully completed, the filemanager copies the appropriate component files into the specific Device Manager\u0026rsquo;s File System and the Application Factory performs the load() and execute() operations in order to launch the component on its assigned device. It then continues to initialize, connect and configure the components. Properties can also be overridden from the componentproperties tags in the waveform\u0026rsquo;s SAD file.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/time-stamps/",
	"title": "Time Stamps",
	"tags": [],
	"description": "",
	"content": " Bulk Input/Output (BulkIO) uses BULKIO::PrecisionUTCTime time stamps that denote the time since 12:00 AM January 1, 1970 (Unix epoch) in UTC. The time stamp contains several elements. In BulkIO, a time stamp corresponds to the date of birth of the first element in the data being pushed. The following table describes the different elements making up the BULKIO::PrecisionUTCTime structure.\nElements in BULKIO::PrecisionUTCTime    Identifier Value Type     tcmode timecode mode short   tcstatus timecode status short   toff Fractional sample offset double   twsec Number of seconds since 12:00 AM January 1, 1970 (Unix epoch) double   tfsec Number of fractional seconds (0.0 to 1.0) to be added to twsec double    Two of the elements described in the table above correspond to predefined values. tcstatus can only take two values, TCS_INVALID (0), and TCS_VALID (1), showing whether the time stamp is valid or not. Invalid time stamps do not contain valid time data and should be ignored. tcmode is the method by which the timestamp was obtained, but this use has since been deprecated, and this value is ignored. The default value for tcmode is 1.\nThe following code snippets provide examples of how to construct a time stamp to be sent in the pushPacket() call. The now() method returns the current time of day.\nC++:\nBULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); Python:\ntstamp = bulkio.timestamp.now() Java:\nBULKIO.PrecisionUTCTime tstamp = bulkio.time.utils.now(); Timestamp Operators (C++) In C++, BULKIO::PrecisionUTCTime supports common arithmetic, comparison and stream operators.\nAdding an offset to a time stamp:\n/** * Add 1/8th of a second to the current time */ BULKIO::PrecisionUTCTime time1 = bulkio::time::utils::now(); time1 += 0.125; Subtracting two time stamps returns the difference in seconds:\n/** * Check if time2 is less than a second after time1 */ if (time2 - time1 \u0026lt; 1.0) { ... } Comparing two time stamps:\n/** * Check if the second time stamp occurs before the first */ if (time2 \u0026lt; time1) { ... } Stream formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n/** * Write the current time out to the console */ std::cout \u0026lt;\u0026lt; bulkio::time::utils::now() \u0026lt;\u0026lt; std::endl; Timestamp Operators (Python) In Python, BULKIO.PrecisionUTCTime supports common arithmetic, comparison and string conversion operators.\nAdding an offset to a time stamp:\n# Add 1/8th of a second to the current time tstamp = bulkio.timestamp.now() tstamp += 0.125 Subtracting two time stamps returns the difference in seconds:\n# Check if time2 is less than a second after time1 if (time2 - time1) \u0026lt; 1.0: ... Comparing two time stamps:\n# Check if the second time stamp occurs before the first if time2 \u0026lt; time1: ... String formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n# Write the current time out to the console print str(bulkio.timestamp.now()) Timestamp Helpers (Java) In Java, the bulkio.time.utils class provides static helper methods for common arithmetic, comparison and string conversion operations.\nAdding an offset to a time stamp with increment() modifies the original time stamp:\n// Add 1/8th of a second to the current time BULKIO.PrecisionUTCTime tstamp = bulkio.time.utils.now(); bulkio.time.utils.increment(tstamp, 0.125); Adding an offset to a time stamp with add() returns a new time stamp with the result, leaving the original time stamp unmodified:\n// Add a second to the current time BULKIO.PrecisionUTCTime time1 = bulkio.time.utils.now(); BULKIO.PrecisionUTCTime time2 = bulkio.time.utils.add(time1, 1.0); Calculating the difference in seconds between two time stamps:\n// Check if time2 is less than a second after time1 if (bulkio.time.utils.difference(time2, time1) \u0026lt; 1.0) { ... } Comparing two time stamps:\n// Check if the second time stamp occurs before the first if (bulkio.time.utils.compare(time2, time1) \u0026lt; 0) { ... } The compare() method follows the same rules as java.util.Comparator.\nString formatting (output format is “YYYY:MM:DD::HH::MM::SS.SSSSSS”):\n// Write the current time out to the console System.out.println(bulkio.time.utils.now());"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/configuration/waveform/",
	"title": "Waveform Configuration File",
	"tags": [],
	"description": "",
	"content": " REDHAWK waveforms are controlled by files in the /etc/redhawk/waveforms.d directory. The AdminService provides the initial values for the configuration parameters of a service. Any values in the /etc/redhawk/init.d/waveform.defaults file override the initial configuration. Finally, the values in the INI file override any configuration (defined internally or specified in the /etc/redhawk/init.d/waveform.defaults file). To define multiple waveform instances in one file, add multiple sections.\nThe waveform can be configured to start after the Device Manager has started up; it can also optionally wait a configurable amount of time for the domain to be available before attempting to start an instance of the waveform. If the waveform depends on devices or services, it is recommended that you add a custom script to verify that those devices and services have started and registered with the Domain Manager (refer to the start_pre_script parameter).\nrhadmin can generate an example waveform configuration file with the complete set of parameters that can be used to the control the setup and execution of a REDHAWK waveform. To generate a generic waveform configuration, enter the following command.\ncd /etc/redhawk/waveforms.d rhadmin config waveform \u0026gt; waveform.ini To generate a waveform configuration from an existing waveform project, enter the following command.\ncd /etc/redhawk/waveforms.d rhadmin config waveform \u0026lt;path/to/waveform\u0026gt;/\u0026lt;file\u0026gt;.sad.xml \u0026lt;DomainName\u0026gt; \u0026gt; waveform.ini Waveform Service Configuration Parameters This section describes all available configuration parameters for the Waveform service.\nParameter names are case sensitive.\nThe following are the valid values for boolean configuration parameters. If no value is present, the feature is disabled.\nTrue: 1, true, True\nFalse: 0, false, False\n parameter: DOMAIN_NAME\nrequired: Yes\ndefault value: None\nformat: A name with no spaces or periods (for example, REDHAWK_DEV)\ndescription: The domain name to associate with this waveform.\nparameter: WAVEFORM\nrequired: Yes\ndefault value: None\nformat: Valid directory under $SDRROOT/dom/waveforms, or a namespaced waveform identifier (for example, rh.MyWaveform)\ndescription: The name of the waveform to launch.\nparameter: INSTANCE_NAME\nrequired: No\nformat: A name with no spaces or periods (for example, THE_WAVEFORM)\ndescription: Specifies an instance-specific name for the waveform.\nparameter: OSSIEHOME\nrequired: No\ndefault: $OSSIEHOME\nformat: Standard shell path environment variable\ndescription: The absolute path to use as the OSSIEHOME for this waveform.\nparameter: PYTHONPATH\nrequired: No\ndefault value: $PYTHONPATH\nformat: Standard shell path environment variable\ndescription: The path used by Python interpreter to load modules; overridesthe PYTHONPATH environment variable.\nparameter: start_delay\nrequired: No\ndefault value: 30\ndescription: The amount of time for the waveform control script to wait for the Domain Manager to be available before failing startup.\nparameter: enable\nrequired: No\ndefault value: True\nformat: True, False, or a string to be matched against conditional_config\ndescription: Specifies if waveform may be started. True or False will enable or disable the waveform. Refer to conditional_config for information about how a string value gets evaluated.\nparameter: conditional_config\nrequired: No\ndefault value: /etc/redhawk/rh.cond.cfg\ndescription: Allows conditional startup of processes based on the enable parameter and the contents of this conditional config. If the value enable is a string, the process will start only if there is a line in the conditional_config file that has that exact content; otherwise, the process is skipped. For example, enable=\u0026quot;type=primary\u0026quot; causes the conditional_config file to be examined for a line equal to type=primary when starting a process on the host. If there is no type=primary line in the file, the process is skipped.\nparameter: priority\nrequired: No\ndefault value: 900\ndescription: The priority of this waveform relative to the group of processes to start for this domain. Lower values will be started earlier. For example, priority 800 will be started before priority 900.\nparameter: autostart\nrequired: No\ndefault value: True\ndescription: Specifies whether to automatically start this process when the AdminService starts, if enable is True.\nparameter: waitforprevious\nrequired: No\ndefault value: 45\ndescription: The number of seconds to wait for the previous higher priority process to start before trying to start this process.\nparameter: failafterwait\nrequired: No\ndefault value: False\ndescription: Specifies whether to abort starting this domain if waitforprevious has expired and the previous process has not been declared started yet. This is useful to make sure the DeviceManager is started and all devices are ready before launching the waveform.\nparameter: started_status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to determine if the waveform started properly. A script exit value of 0 indicates the waveform started successfully.\nparameter: status_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script to check the status for the waveform. A script exit value of 0 indicates the waveform is alive.\nparameter: query_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file\ndescription: Specifies an optional bash script used to get a detailed status output for the waveform. This is useful to return a custom status string for the components in the waveform.\nparameter: environment\nrequired: No\ndefault value: None\nformat: A list of key/value pairs in the form key=\u0026quot;value\u0026quot;,key2=\u0026quot;value2\u0026quot;\ndescription: Specifies whether to override existing environment variables or set new ones to be used when starting the waveform. This value does not get passed to the components running inside the waveform.\nparameter: user\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with User ID.\nparameter: group\nrequired: No\ndefault value: redhawk\ndescription: Executes the process with Group ID.\nparameter: umask\nrequired: No\ndefault value: None\ndescription: The umask for the process.\nparameter: directory\nrequired: No\ndefault value:$SDRROOT\ndescription: Specifies to change the directory to directory before running this waveform.\nparameter: run_detached\nrequired: No\ndefault value: True\ndescription: Specifies to run the the waveform as a daemon, not a child of the AdminService process.\nparameter: logfile_directory\nrequired: No\ndefault value: /var/log/redhawk/waveforms\ndescription: The absolute path to the logging directory.\nparameter: stdout_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.\u0026lt;waveform name\u0026gt;.stdout.log\ndescription: The name of a file that captures the stdout from the process. If not specified, the default value list above is used.\nparameter: stderr_logfile\nrequired: No\ndefault value: \u0026lt;domain name\u0026gt;.\u0026lt;waveform name\u0026gt;.stderr.log\ndescription: If redirect_stderr is False, the name of a file that captures the stderr from the process. If not specified, the default value list above is used.\nparameter: redirect_stderr\nrequired: No\ndefault value: True\ndescription: Specifies to write stdout and stderr to the same file.\nparameter: start_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the waveform is started.\nparameter: start_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the waveform is started.\nparameter: stop_pre_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run before the waveform is stopped.\nparameter: stop_post_script\nrequired: No\ndefault value: None\nformat: Absolute path of a file or absolute path of a directory of files\ndescription: The bash script or directory of bash scripts to run after the waveform is stopped.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/",
	"title": "REDHAWK System Services",
	"tags": [],
	"description": "",
	"content": "REDHAWK provides an optional RPM, redhawk-adminservice, to manage the REDHAWK core services (Domain Manager, Device Manager, and waveforms). These core services are managed as Linux system services using INI configuration files. The RPM is part of the REDHAWK yum repository; however, it is not installed by default. Additional support files are included in the RPM to assist with tuning common operating system parameters and configuring the REDHAWK logging subsystem.\nFor more information about the AdminService and Linux support files, refer to the following:\n AdminService\n Linux Support Files  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/sdds-data/",
	"title": "Working with SDDS Data",
	"tags": [],
	"description": "",
	"content": " This section describes how to work with SDDS data in the Sandbox, including how to write, ingest, manipulate, and introspect the data.\nSDDS Data via REDHAWK Components The sandbox along with the SourceSDDS and SinkSDDS REDHAWK components allow a user to ingest and emit SDDS data during a user’s session. These two components provide a fully-compliant capability when processing SDDS network traffic. Consult the appropriate documentation for the SDDS specification and each of the components.\n SourceSDDS - Ingests SDDS packets from the network and repackages the data for Bulk Input/Output (BulkIO) port transmission. The component creates the proper BulkIO Signal Related Information (SRI), time stamps, and data vectors from the SDDS packet headers and payloads.\n SinkSDDS - Emits SDDS packets from a connected BulkIO port to the network. The component uses the BulkIO SRI, time stamps, and data vectors to produce valid SDDS packets.\n  Each of these components requires a network address specification to access the appropriate host interface. The following table describes the two different network addresses supported by these components.\nSDDS Address Specification    Protocol Address Port VLAN     UDP IPv4 address 1024 - 65535 number (optional)   MULTICAST 224.0.0.0 - 239.255.25.255 1024 - 65535 number (optional)    Writing SDDS Data to a Network Interface To generate SDDS packet data, the rh.SinkSDDS component is used to send BulkIO data over the network interface as SDDS packets. This component accepts three different BulkIO data types (octet, short and float) and then formats the data, SRI, and time stamp information into valid SDDS packets.\nThe following example uses the Sandbox’s DataSource and the rh.SinkSDDS component to generate SDDS packets to be sent over interface eth0, the IP address 127.0.0.1, and port 29000.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; sig=sb.DataSource() \u0026gt;\u0026gt;\u0026gt; sdds_out = sb.launch(\u0026#34;rh.SinkSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.interface=\u0026#34;eth0\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.ip_address=\u0026#34;127.0.0.1\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_out.network_settings.port=29000 \u0026gt;\u0026gt;\u0026gt; sig.connect(sdds_out, usesPortName=\u0026#34;shortOut\u0026#34;) \u0026gt;\u0026gt;\u0026gt; data=range(1024) \u0026gt;\u0026gt;\u0026gt; SRI=sig.SRI() \u0026gt;\u0026gt;\u0026gt; SRI.xdelta = 1/1000.0 \u0026gt;\u0026gt;\u0026gt; sig.push(data, SRI=SRI, EOS=False, loop=False) Reading SDDS Data from a Network Interface To read SDDS packet data, the rh.SourceSDDS component is used to receive SDDS data from a network interface. This component transforms the SDDS packet data into BulkIO data, SRI, and time stamps for downstream connections.\nThe following example configures a rh.SourceSDDS component to read data from interface eth0, send it to IP address 127.0.0.1 and port 29495, and forward the data to a Sandbox DataSink over a short typed port.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; dsink=sb.DataSink() \u0026gt;\u0026gt;\u0026gt; sdds_in = sb.launch(\u0026#34;rh.SourceSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.ip_address=\u0026#34;127.0.0.1\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.port=29495 \u0026gt;\u0026gt;\u0026gt; sdds_in.attachment_override.enable=True \u0026gt;\u0026gt;\u0026gt; sdds_in.interface=\u0026#34;eth0\u0026#34; \u0026gt;\u0026gt;\u0026gt; sdds_in.connect(dsink,usesPortName=\u0026#34;dataShortOut\u0026#34;) In lieu of the attachment_override property, both components support the BulkIO dataSDDS interface and BULKIO::SDDSStreamDefinition structure. This interface defines an attach method, which is implemented by each component, and performs the necessary actions to connect to the SDDS source defined in the BULKIO::SDDSStreamDefinition structure.\nThe following table describes the members of the BULKIO::SDDSStreamDefinition structure.\nBULKIO::SDDSStreamDefinition    Name Type Description     id string Stream ID to identify the data or Allocation ID for attachment   dataFormat SDDSDataDigraph Payload type of SDDS packet   multicastAddress string Multicast address   vlan long Virtual LAN number   port long Port number   sampleRate long Sampling frequence of SDDS payload data (egress only)   timeTagValid boolean Marks packets with valid time stamp field (egress only)   privateInfo string User-generated text    The following example configures the rh.SourceSDDS component to read data using the address specification defined by the BULKIO::SDDSStreamDefinition structure, and forward the data to a Sandbox DataSink over it’s short typed port.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; from bulkio.bulkioInterfaces import BULKIO \u0026gt;\u0026gt;\u0026gt; dsink=sb.DataSink() \u0026gt;\u0026gt;\u0026gt; sdds_in = sb.launch(\u0026#34;rh.SourceSDDS\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_in.connect(dsink,usesPortName=\u0026#34;dataShortOut\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sdds_port=sdds_in.getPort(\u0026#34;dataSddsIn\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sd = BULKIO.SDDSStreamDefinition(\u0026#34;my_stream\u0026#34;, BULKIO.SDDS_SI, \u0026#34;127.0.0.1\u0026#34;, 0, 29495, 8000, True, \u0026#34;testing\u0026#34;) \u0026gt;\u0026gt;\u0026gt; attach_id = sdds_port.attach(sd, \u0026#34;username\u0026#34;) Capturing SDDS Data and the Sandbox’s DataSourceSDDS This section describes how to capture SDDS Data packets, introspect their contents, and manipulate the data using the Sandbox.\nSDDS Data and the Sandbox’s DataSourceSDDS Independent of the components, the Sandbox also provides a snapshot and introspection capability through the DataSourceSDDS class. The following commands create the DataSourceSDDS object.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; ds=sb.DataSourceSDDS() Using this object, the user can capture an arbitrary number of packets and then introspect their contents. The content analysis and packet decomposition is provided through the SDDSAnalyzer class. To initiate a data capture, call the DataSourceSDDS’s getData or getStreamDef. By default, these methods return a SDDSAnalyzer object that contains all the raw packet data.\ngetData( mgroup, hostip, port=29495, pkts=1000, pktlen=1080, block=True, returnSddsAnalyzer=True) Parameters: mgroup = multicast address or IP address hostip = address of host interface to use port = port number to listen on pkts = number of packets to capture pktlen = length in bytes of a single packet block = will block until all packets are read returnSddsAnalyzer = returns SDDS analyzer object instead of raw data Returns: SDDSAnalyzer: provides SDDS packet introspection and tracking or tuple: data - converted raw data to a list of numbers rawdata - actual data read from socket pktlen - packet length provided during capture pkts - number of packets read totalRead - total number of bytes read Using the SDDSAnalyzer Using the SDDSAnalyzer, you can perform the following actions:\n dumpPackets - Displays packet data as readable SDDS packets with header breakout.\ndumpPackets(pkt_start=0, pkt_end=None, payload_start=0, payload_end=40, raw_payload=False, header_only=False, use_pager=True) Displays SDDS packet header and payload in human readable format. Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) payload_start = starting payload sample to display payload_end = ending payload sample to display raw_payload = dump payload data as raw bytes header_only = only display header information for each packet use_pager = display data using pager to limit number of packets that are displayed dumpRawPackets - Displays packet data as bytes.\ndumpRawPackets(pkt_start=0, pkt_end=None, row_width=80, bytes_per_group=2, pkt_len=None, use_pager=True) Displays SDDS packet data in hexidecimal format Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) row_width = 80 the number of bytes to display per row bytes_per_group = the number of bytes to group when hexify-ing pkt_len = the number of bytes in a packet, None defaults to 1080 or length when getData method was called use_pager = display data using pager to limit number of packets that are displayed getPacketIterator - Returns a Python iterator that can be used in loops.\ngetPacketIterator(pkt_start=0, pkt_end=None) Returns a Python iterator that will traverse the set of packets managed by the SDDSAnalyzer object Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) getPackets - Returns a list of SDDS packet objects.\ngetPackets(pkt_start=0, pkt_end=None) Returns a list of sdds_packet objects Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) trackChanges - Tracks changes in header fields.\ntrackChanges(pkt_start=0, pkt_end=None, repeat_header=20, use_pager=True) Tracks changes to the following SDDS packet fields: sequence numbers, data mode, complex flags, bits per sample, frequency, rate, time tag valid, time slips No changes in the data field are displayed as: - Changes in the data field are displayed as: *** Valid TimeStamps are denoted as: + Parameters: pkt_start = first packet to dump pkt_end = last packet to dump (None == end of list) repeat_header = displays column header every Nth packet displayed use_pager = display data using pager to limit number of packets that are displayed  SDDS Packets The resulting SDDS packet objects, provided by the SDDSAnalyzer, allow for inspection and manipulation of each packet’s underlying data. The python help utility for ossie.utils.sdds.sdds_packet module describes these methods in more detail. The following sample code creates a SDDS packet object and sets the sample rate and payload contents of the packet.\nfrom ossie.utils.sdds import * pkt=sdds_packet() pkt.header.set_rate(10e6) pkt.header.get_rate() # OUT: 10000000.0 pkt.payload.sb.set_data(1024*[100]) # diplay the payload contents as list of numbers pkt.payload.sb.get_data() # OUT: [100, 100, 100, 100, 100, .... 100, 100, 100, 100, 100 ] # print out the entire contents of the sdds packet as array of octets pkt.asBuffer() DataSinkSDDS in the Sandbox The rh.SinkSDDS component provides a fully compliant capability for ingesting BulkIO’s data streams and publishing SDDS packets to a network. To support use cases that do not require this level of compliance, the Sandbox provides the DataSinkSDDS object that can capture the stream definitions and SRI data from a BulkIO SDDS interface that publishes this information. Below is a sample code session showing how to connect to a DataSinkSDDS object and capture the stream definition.\nfrom ossie.utils import sb from bulkio import BULKIO def inStreamDef(sd,userid): print \u0026#34;stream def: \u0026#34;, sd print \u0026#34;user: \u0026#34;, userid sink=sb.DataSinkSDDS() src=sb.DataSourceSDDS() src.connect(sink) sd=BULKIO.SDDSStreamDefinition(\u0026#34;data1\u0026#34;, BULKIO.SDDS_SB,\u0026#34;239.1.1.0\u0026#34;,0,29495,1000000,False,\u0026#34;\u0026#34;) # # triggers default process to print out stream definition and user id src.attach(sd,\u0026#34;stream1\u0026#34;) # # setup callback for attachment sink.registerAttachCallback(inStreamDef) src.attach(sd,\u0026#34;stream2\u0026#34;)"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/namespaces/",
	"title": "Adding/Changing/Removing REDHAWK Project Namespaces",
	"tags": [],
	"description": "",
	"content": "Existing REDHAWK projects can be renamed to include a namespace. Projects can be namespaced by adding dots in the name. Project names may not begin with a number and may not contain special characters other than dots for the namespace. Namespacing projects provides the ability to uniquely identify projects that share the same base name but have different implementations and also provides a logical grouping of resources. For example, the REDHAWK basic assets are namspaced as rh.xxxx.\nThe following procedure explains how to rename a project to include a namespace.\nThe IDE only supports automatic refactoring of project namespaces, not project base-names. If you want to change the base-name of a project, create a new project with the new base-name, and then manually move code into the new project.\n  In Project Explorer, right-click the project, select Rename.\nThe Rename Resource dialog is displayed:  Rename Resource Dialog    Enter the new project namespace and click Preview.\nThe Rename Resource window is displayed:  Rename Resource Window    Click OK.\nThe IDE updates all relevant references, directories, and file names to match the new namespace.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/",
	"title": "BulkIO",
	"tags": [],
	"description": "",
	"content": "Bulk Input/Output (BulkIO) is designed to provide a standardized methodology and to maximize efficiency for bulk data transfers between REDHAWK resources (components and devices). This interface supports the transfer of data vectors (float, double, char (int8), octet (uint8), short (int16), ushort (uint16), long (int32), ulong (uint32), longlong (int64), ulonglong(uint64)), character strings (char *), and out-of-band connection descriptors for SDDS data streams.\nThese interfaces also allow for metadata, Signal Related Information (SRI), and a precision time stamp (described in detail in the following subsections), which describe the content being transferred and support content processing. Part of the required methodology for passing data between REDHAWK components is that all data transfers via pushPacket() are preceded by at least one call to pushSRI() with an appropriate SRI object. SRI data is passed out-of-band from the content data to reduce the overhead for transferring data between components. The precision time stamp represents the birth date for data and is part of the pushPacket() method call for those components that require this information.\nThe data flow implementation for a component’s BulkIO port interface is provided by a shared bulkio base class library. The resulting component code instantiates a bulkio base class object and makes use of the shared library during deployment and execution.\n Data Transfers     Signal Related Information (SRI)     Stream API     Bit Data     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/",
	"title": "Connections",
	"tags": [],
	"description": "",
	"content": "When discussing connections, there are several terms that are thrown around in REDHAWK: uses, provides, port, interfaces, Interface Description Language (IDL), among others. This section demystifies connections and presents the key concepts that enable a REDHAWK-based system to easily interact with other REDHAWK systems and external tools developed outside the scope of REDHAWK.\n The Connection Process     Why Ports?     Port Access     Dynamic Connections     Standardized Data Interfaces     BulkIO    Data Transfers     Signal Related Information (SRI)     Stream API     Bit Data     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     Examples      BurstIO    Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics      Messaging    Message Producer     Message Consumer     Viewing Messages     Connecting Producers and Consumers      Connection Callbacks     Custom IDL Interfaces     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/components/hello-world-component/",
	"title": "Creating and Running a Hello World Component",
	"tags": [],
	"description": "",
	"content": "Use the following procedure to create a simple component that prints hello world to the terminal upon startup.\n Create a new REDHAWK component Project:\n File \u0026gt; New \u0026gt; REDHAWK Component Project  Name the project: HelloWorld\n Click Next.\n Select:\n Prog. Lang: C++  Click Next.\n Click Finish.\n If a dialog asks to switch to CPP perspective, click No.  Generate Code:\n In the editor tool bar, click Generate All Component Implementations  In the HelloWorld.cpp file, add the following include to the beginning of the file:\n#include \u0026lt;iostream\u0026gt; In the HelloWorld.cpp file, add the following code to the serviceFunction() method:\nstd::cout\u0026lt;\u0026lt;\u0026#34;Hello world\u0026#34;\u0026lt;\u0026lt;std::endl; Compile the project:\n Project \u0026gt; Build Project  Drag the project to the Target SDR section of the REDHAWK Explorer.\n On a terminal, start a Python session.\n Run the following commands:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; hello_world = sb.launch(\u0026#34;HelloWorld\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sb.start()  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/fei/",
	"title": "FrontEnd Interfaces",
	"tags": [],
	"description": "",
	"content": " FrontEnd Interfaces (FEI) is a module containing interfaces designed to standardize the interaction between applications and radio hardware. This appendix specifies the requirements of an FEI 2.0 compatible device, explains best-practices, provides advice for development, and describes related data structures. This appendix is not intended to be an API reference for FEI or an exhaustive description of the Interface Description Language (IDL). This appendix is intended to provide an additional resource for developers.\nTheory of Operations FEI were developed to standardize the allocation, operation, and development of tuner devices within the REDHAWK Core Framework (CF). Tuner devices in this context may consist of Radio Frequency (RF), Intermediate Frequency (IF), or purely digital tuning equipment or software. Explicit types for tuners have been defined, so that devices can be easily categorized by the capabilities they provide.\nTuner devices can provide individual tuners to other REDHAWK entities through tuner allocation. To allocate an individual tuner, the allocateCapacity() function of a device is called with an appropriate allocation structure as the only argument. Devices then allocate physical resources and, once a valid connection has been made, begin flowing data out of the device.\nCommon FEI Terminology The following table describes the FEI terminology used for tuner devices.\nFEI Terminology    Terminology Description     device A REDHAWK device.   FEI device Devices that have a device_kind of FRONTEND and implement one of the FEI IDLs. Typically, GPS and navigation devices fall into this category.   tuner A specific tuner capability in an FEI device.   FEI tuner device Devices that have a device_kind of FRONTEND::TUNER. These devices must implement the TunerControl IDL and contain tuners for allocation.    Required Properties for an FEI Tuner The following table describes the required properties for an FEI tuner device.\nRequired Properties for an FEI Tuner    Name / ID Description     device_kind / DCE:cdc5ee18-7ceb-4ae6-bf4c-31f983179b4d Must be set to FRONTEND or FRONTEND::TUNER.   device_model / DCE:0f99b2e4-9903-4631-9846-ff349d18ecfb Used to specify the model of the hardware device.   frontend_tuner_status / FRONTEND::tuner_status A struct sequence where each struct in the sequence represents a single tuner. The structure is defined further in Status Elements.    Types of Tuners Tuner types are defined so that device developers and users can categorize the basic behavior of disparate hardware. Behavior of each of these types is described below and must be adhered to during development to allow for interoperability between different hardware baselines.\nPhysical devices often need to be split into multiple logical REDHAWK tuners to fully describe their functionality. Splitting physical devices often involves multiple tuners of the same, or mixed, types. Common pairings are described in each of the type descriptions.\nRX Tuner A simple receiver, or RX tuner, is an RF to IF conversion only. This conversion implies an analog to analog translation, typically down-converting an RF signal to a new IF. Devices often have multiple RX devices corresponding to each of the independent analog channels provided. Single channels that have selectable RF input ports should be represented as a single RX tuner and utilize an RF Flow ID to select between the input options.\nRX devices have an analog output port. RX devices that output digital-IF (SDDS, VITA-49, etc.) are considered RX_DIGITIZERS, which are a distinct tuner type and should be classified as such.\nRX_DIGITIZER Tuner An RX_DIGITIZER tuner is an RX device that also samples the analog data and provides it as a digitized stream. The stream can be either real samples (typically referred to as digital-IF) or complex baseband data. Multiple RX_DIGITIZER channels in a singular physical device should be treated like RX devices, including using the RF Flow ID to differentiate between which external RF source to use.\nRX_DIGITIZER tuners can also optionally provide access to the analog-IF output. If the device in question provides access to the analog-IF output, an additional analog output port should be added to the device. Users can optionally connect to and use that port, although the existence of the port is not guaranteed for all RX_DIGITIZER tuners.\nCHANNELIZER Tuner A CHANNELIZER tuner takes a digital wideband input and provides tuned, filtered, and decimated narrowband output. A CHANNELIZER device acts as a token to allocate and control the wideband input, which then can have individual narrowband channels allocated as well. Each of these narrowband tuners is its own tuner of type Digital Down Converter (DDC).\nAllocating a CHANNELIZER establishes control over the input to a CHANNELIZER and allows users to understand that they have the ability to attach a new stream to the wideband input. Typical operation is to allocate a CHANNELIZER to gain control over the input prior to connecting a data stream to the input, though the order is not mandatory.\nAllocating a DDC provides the tuned, filtered, and decimated narrowband output. A DDC is allocated by calling allocateCapacity() with the tuner type set to DDC and also specifying the frequency, bandwidth, sample rate, and any other desired aspects of the resulting DDC. Optionally, the RF Flow ID is used during allocation to specify the wideband input connection and CHANNELIZER desired. Allocation of a DDC succeeds only if the information specified during allocation can be supported by an allocated CHANNELIZER with a successful matching input connection. Changing the CHANNELIZER input can cause attached DDC tuners to be dropped.\nDDC Tuner DDC tuners provide a narrowband output from an existing CHANNELIZER capability. These narrowband channels are typically selectable in terms of the center frequency and bandwidth/sample rate within the constraints of the wideband input to the CHANNELIZER.\nAllocating a DDC tuner against a device with multiple CHANNELIZER (or RX_DIGITIZER_CHANNELIZER) tuners can specify which tuner to use in two different ways. One method is to specify an RF Flow ID of the specific CHANNELIZER to be allocated against. The other method is to allow the device to match by using the requested center frequency and/or bandwidth/sample rate. The device matches the DDC to the first channelizer capability that meets those criteria.\nRX_DIGITIZER_CHANNELIZER Tuner The RX_DIGITIZER_CHANNELIZER tuner is a combination of an RX_DIGITIZER and CHANNELIZER capability into a single tuner type. Input is through an analog-RF input port, and output is through DDC tuners.\nRX_DIGITIZER_CHANNELIZER tuners have the optional ability to output both analog-IF as well as digital-IF data. The analog-IF ports are represented just like the output of an RX or RX_DIGITIZER tuner. The digital-IF data is accessed by allocating a listener to the RX_DIGITIZER_CHANNELIZER, which then starts flowing digital data just like an RX_DIGITIZER.\nThe primary RX_DIGITIZER_CHANNELIZER allocation does not put out wideband digital data by default. These are optional ports, and each may or may not be present on each device.\n RX_SCANNER_DIGITIZER Tuner The RX_SCANNER_DIGITIZER tuner is an RX_DIGITIZER that also has a scanning capability (usually a built-in hardware capability). RX_SCANNER_DIGITIZER tuners can follow a scan plan. This plan may be a list of discrete frequencies to dwell on or a regular pattern that is followed. The transition between frequencies is controlled by time or number of samples generated.\nAn RX_SCANNER_DIGITIZER allocation\u0026rsquo;s allocateCapacity() call does not stand on its own. The call requires both a FRONTEND::scanner_allocation and a FRONTEND::tuner_allocation allocation.\n TX Tuner Although the exact functionality of the TX tuner is not yet defined, it is reserved for transmitter devices.\nTuner Allocation Allocation is the process where specific tuners are requested for use, and initial setup of the tuner is performed. Allocation of FrontEnd devices always occurs by calling allocateCapacity() on the device with the argument of the allocateCapacity() call being a FrontEnd allocation property.\nID A number of different IDs are used in REDHAWK and FEI devices. The most important types of IDs are described in this section.\nAllocation ID The Allocation ID is a string used as an unique ID for each allocated FEI tuner. The Allocation ID is passed in as part of the allocateCapacity() call and is used as identification for all subsequent interaction. Allocation IDs are used to identify tuners in the FEI Status structure and in the TunerControl IDL.\nAllocation IDs can be any unique string, but typically UUID values are used. If human readable Allocation IDs are required, the preferred approach is to append the UUID onto a base human-readable string. With this approach, allocations for non-coordinated devices are not likely to create identical allocations.\nStream ID In all REDHAWK Bulk Input/Output (BulkIO) ports, Stream ID is used to separate unique data streams that are passed in a single BulkIO port. This methodology is also utilized in FEI devices to allow devices to pass the output of multiple tuners through a single BulkIO port. REDHAWK does not mandate any uniqueness requirements on Stream IDs, but it is recommended that developers attempt to make the Stream IDs unique by appending a UUID.\nStream IDs can only be changed after an End of Stream (EOS) is sent, and in FEI devices, an EOS is only sent when deallocating or disabling the tuner.\nAn EOS should only be sent on an externally commanded tuner disable and not one that is handled internally to the device. Therefore, if the device must temporarily disable output to tune, an EOS should not be sent.\n Connection ID In all REDHAWK BulkIO connections, there is a specific string ID for the connection. For FEI devices, the connection to the output port of the device must have a Connection ID, which can be assigned as described in Connect Wizard, that is equal to the Allocation ID of the tuner to be accessed. Because the Connection ID is equal to the Allocation ID, the output port can be constructed as a multi-out port.\nRF Flow ID RF Flow IDs are used to differentiate between RF input streams, similarly to how Stream IDs are used to differentiate between BulkIO streams. For FrontEnd devices, these RF Flow IDs are used to match allocation requests to specific RF sources.\nUnlike Allocation IDs and Stream IDs, RF Flow IDs are often human readable. Typically, they describe specific inputs to a device or feed names. RF Flow IDs for a device can be set as a device property, which is set as part of the node configuration. System developers can create a node that sets the individual FrontEnd device with the RF Flow IDs that are appropriately set to the current state of the physical RF connections.\nDevice Group ID Device Group ID is similar to RF Flow ID in that it is used as an additional ID to allow allocations against a specific pool of devices. In this case, each FEI device can have its Group ID set, and individual allocations can request specific Group IDs. Devices with the same Group ID are considered to be in the same group, and only devices that are part of that group allow those allocations. Group IDs are strings that are often human readable. A device typically has its Group IDs set as a property, so it can be configured as part of a node.\nTuner Allocation Overview FrontEnd tuners are allocated by calling the device’s allocateCapacity() method with a particular FrontEnd Allocation structure. The call acts as a request to the device for allocation of a tuner that meets the specifications in that structure. If the request is able to be met by that device, then the tuner is allocated, and True is returned by the allocateCapacity() call. If the tuner cannot be allocated, then an appropriate exception is thrown. Returns and exceptions are shown in Allocation Return Types.\nTwo different FrontEnd Allocation structures can be used. The FRONTEND::tuner_allocation structure is primarily used for allocating new tuners of an FEI device. The FRONTEND::listener_allocation structure is used for allocating listener tuners that piggyback on existing control tuners. Listener tuners are logical tuners that simply mirror the output of existing control tuners. Therefore, FrontEnd devices can keep track of how many consumers are attached to each of the tuner outputs and handle requests appropriately. The FRONTEND::tuner_allocation structure is described in Tuner Allocation Properties, and the FRONTEND::listener_allocation structure is described in Listener Allocation Properties.\nAllocation Return Types The following table describes the values returned and exceptions thrown by the allocateCapacity() method.\nAllocation Return Types    Return Type Description Notes     True Tuner was successfully allocated. Returned if the tuner was successfully allocated. Indicates that the tuner has been added to the status structure, the underlying hardware/software has been set up, and the tuner is now enabled.   CF::Device::InvalidCapacity Capacity request was malformed. Indicates that there was an error in parsing the capacity (FrontEnd Allocation Structure) that was passed in. The error is typically the result of a missing Allocation ID or other critical field but can also indicate a duplicate Allocation ID request.   CF::Device::InvalidState Device is in an invalid state for allocation. Returned when the device is in an Error or Disabled state.   False Tuner was not successfully allocated. Indicates the device is unable to meet the request in the allocation structure.    Tuner Allocation Properties Each allocateCapacity() call passes in a single FRONTEND::tuner_allocation structure. If multiple tuners are allocated, each tuner needs an independent allocateCapacity() call. Each field in the allocation structure needs to be matched against the available tuners in the device. Each field must correctly match for the allocation to be successful. If any of the properties cannot be met, the allocation throws an exception.\nThe following table describes the tuner elements of the FRONTEND::tuner_allocation structure and how to handle requests.\nTuner Allocation Properties    Name Type Notes Description     tuner_type string Type of tuner requested. The tuner type must match exactly and cannot be a super set of the request (e.g., an RX_DIGITIZER is not a match for an RX request).   allocation_id string Used by the caller to reference the tuner uniquely. Reject any requests with an Allocation ID already in use with the InvalidCapacity exception.   center_frequency double Requested center frequency in Hz. It is up to the device developer to determine the error tolerance of the true tuned center frequency. For CHANNELIZER tuners only, this is the expected input frequency of the stream that is provided.   bandwidth double Requested Bandwidth in Hz. The minimum bandwidth that must be provided to allocate the channel. See tolerance for the upper bound of bandwidth. A value of zero indicates any bandwidth is acceptable.   bandwidth_tolerance double Allowable Percent above requested bandwidth. The acceptable amount of excess bandwidth used to allocate the channel. This amount is defined as a percentage of the requested bandwidth. For example, if a 1kHz bandwidth was required, and the tolerance was set to 50%, then any bandwidth between 1-1.5kHz is acceptable. For the CHANNELIZER only, this should be the expected bandwidth of the provided input stream.   sample_rate double Requested complex sample rate in Hz. The minimum sample rate that must be provided to allocate the channel expressed in terms of complex sample rate. Refer to the tolerance for the upper bound of sample rate. A value of zero indicates any sample rate is acceptable. The sample_rate value can be ignored for such devices as analog tuners, which do not provide digital (sampled) data. For the CHANNELIZER only, this is the expected sample rate of the provided input stream.   sample_rate_tolerance double Allowable percent above requested sample rate. The amount of excess sample rate that is acceptable to allocate the channel as a percentage of the requested sample rate.   device_control boolean Indicates if this tuner has modification control. Describes if the requested tuner has control over the tuner and can make changes to tuner parameters. Setting device_control to false indicates that the device should attempt to find an existing channel and add the allocated tuner as a listener. If no suitable tuners exist, the request fails. For CHANNELIZER tuners, device_control must always be set to true and, if not, an InvalidCapacity exception is thrown.   group_id string Unique ID that specifies a group of devices. Must match group_id on the device; otherwise, allocation fails. The matching must be explicit, but a blank string is typically used to indicate a default group.   rf_flow_id string Specifies a certain RF flow to allocate against. Must match rf_flow_id on the device input used; otherwise, allocation fails. A blank string indicates that no channel is requested.    After successfully matching the allocation properties, the FrontEnd device needs to perform a number of tasks prior to returning from the allocateCapacity() call. First, the actual hardware or software should then be allocated with the values requested. Then, the internal status properties need to be updated to show the new channel. Once the status is set, the allocateCapacity() call can return.\nAfter a successful allocation, the tuner is enabled and data is flowing though the device and out the output port. It is not required that the allocateCapacity() call return prior to the first data packet being pushed through the device.\nIn the event that a device has an RFInfo input port, the center frequency for allocation should be the true RF frequency of the signal even if the RFInfo port indicates that some frequency translation has occurred before input to the device. In this case, the tuner allocation frequency and status frequency will be different than the actual tuned frequency to which the hardware device was tuned. The center frequency and bandwidth of the RFInfo packet should be used to validate the requested center frequency. The requested center frequency should fit within the bandwidth of the incoming analog signal as described by the RFInfo packet. However, the requested bandwidth from the FEI allocation should be interpreted as the requested bandwidth of the receiver or receiver digitizer and can include bandwidth that is outside the bandwidth specified by the RFInfo packet.\nScanner Allocation Properties To allocate the scanning functionality in a tuner that supports automatic scanning, the FRONTEND::scanner_allocation property must be used. This property cannot be used on its own, it needs to be passed in the same allocateCapacity() call with the FRONTEND::tuner_allocation property described above.\nThe following table describes the scanning elements and how to handle requests.\nScanner Allocation Properties    Name Type Notes Description     min_freq double Requested lower edge of the scanning band. The center frequency of the scanning plan cannot go below this frequency.   max_freq double Requested upper edge of the scanning band. The center frequency of the scanning plan cannot go above this frequency.   mode enum string SPAN_SCAN or DISCRETE_SCAN. Use SPAN_SCAN for a regularly-spaced set of frequencies and DISCRETE_SCAN for a discrete list of frequencies   control_mode enum string TIME_BASED or SAMPLE_BASED. Use TIME_BASED when the re-tune decision is based on the dwell time in seconds and SAMPLE_BASED when the re-tuning decision is made based on the number of samples produced.   control_limit double Limits on the control of the scanning device. Use TIME_BASED to establish the fastest hop rate and SAMPLE_BASED for the fewest number of samples that the scanner is expected to output before re-tuning.    In the case of a scanning device, allocation is insufficient for defining the scan. The allocation data structure provides the bounds for the scanning strategy (e.g.: minimum and maximum frequency, fastest re-tuning rate). To define the scanning strategy such that the device will execute it, the strategy needs to be set through the setScanStrategy function in the ScanningTuner control port, as described in Scanning Tuner Control Functions.\nListener Allocation Properties There are two methods used to perform listener allocations. The first method is to use a standard FrontEnd Allocation Structure as shown in Tuner Allocation Properties with the control property set to False. Setting the control property to False causes the device to look for existing tuners that meet the required properties in the rest of the FrontEnd Allocation Structure and assign a new listener tuner to that master tuner. If no tuners already exist, the request fails.\nThe second way of allocating a listener tuner is by using a FrontEnd::listener_allocation structure in the allocateCapacity() call. Passing in this FrontEnd::listener_allocation structure causes the device to create a new listener tuner that is attached to the tuner with the Allocation ID given in the structure. The following table describes the FrontEnd::listener_allocation structure.\nFrontEnd Listener Allocation Structure    Name Type Description Notes     existing_allocation_id string Allocation ID for an existing allocation. The Allocation ID of the tuner to which the new listener should attach. The tuner can be either a control or listener.   listener_allocation_id string New Listener ID The Allocation ID of the new listener tuner. All typical Allocation ID requirements apply.    The requirements for tuner setup of a listener tuner are the same as those for a control tuner. The status structure must be updated, and the output must be enabled. These actions are expected to be performed prior to returning from allocateCapacity().\nTuner Deallocation Tuners are deallocated using the deallocateCapacity() call. There is no return from the deallocateCapacity() function, but exceptions are thrown if deallocation is unsuccessful. The only exceptions that can be thrown are InvalidCapacity, which indicates that the Allocation ID provided is not valid, or InvalidState, indicating the device is in an error state.\nThe deallocateCapacity() call can accept either a FRONTEND::tuner_allocation structure or a FRONTEND::listener_allocation structure as only the Allocation ID field is utilized. All other fields are ignored and have no impact on the deallocation. The concept is that the same allocation structure provided to allocateCapacity() can be sent to deallocateCapacity() to remove the tuner.\nTuners that are deallocated need to have their status entries removed, the underlying hardware/software disabled, and all output stopped. A final BulkIO packet containing an EOS Signal Related Information (SRI) flag is sent prior to the return from the deallocateCapacity() call. More information on the BulkIO SRI information can be found in FrontEnd-specific Keywords. No more data from that tuner flows though the BulkIO port.\nAutomatic Listener Deallocation When a control tuner is deallocated, its attached listeners are expected to also be deallocated. Therefore, both status cleanup and EOS information flows over the BulkIO port.\nCommand and Control Command and Control of existing allocated tuners is performed through the DigitalTuner or AnalogTuner port on the FEI device. These commands allow external users to get and set specific settings for each of the tuners. Each FEI tuner device must have a DigitalTuner port named DigitalTuner_in (or AnalogTuner_in for an AnalogTuner port) that allows for command and control. All of the functions in the tuner control interface need to be implemented even if only to report that the capability is not supported. Each of these tuner control interface functions uses the Allocation ID to uniquely identify the tuners.\nAn output control port used to control an FEI device follows the same connectivity rules explained in Custom IDL Interfaces.\n Tuner Control Interface The tuner control interface describes two interfaces for control. The first is the AnalogTuner, which describes all of the functions common for Digital and Analog tuners. DigitalTuner inherits AnalogTuner and adds setOutputSampleRate() and getOutputSampleRate().\nTuner Control Functions The following table describes the functions that can be accessed via the Tuner Control IDL.\nTuner Control Functions    Function Prototype Description     string getTunerType(in string id) Get the type of tuner (e.g., RX or DDC) associated with this Allocation ID.   boolean getTunerDeviceControl(in string id) Returns whether this Allocation ID has control (modification privileges) over the tuner.   string getTunerGroupId(in string id) Retrieves the Group ID (may be empty) for this Allocation ID.   string getTunerRfFlowId(in string id) Retrieves the RF Flow ID (may be empty) for this Allocation ID.   CF::Properties getTunerStatus(in string id) Key/Value pair of entire tuner status structure. Note: The return is a sequence of simple properties, not a single struct property.   void setTunerCenterFrequency(in string id, in double freq) Set the current center frequency in Hz.   double getTunerCenterFrequency(in string id) Get the current center frequency in Hz.   void setTunerBandwidth(in string id, in double bw) Set the current bandwidth in Hz.   double getTunerBandwidth(in string id) Get the current bandwidth in Hz.   void setTunerAgcEnable(in string id, in boolean enable) Enable or disable the Auto Gain Control (AGC). True indicates that the AGC should be enabled.   boolean getTunerAgcEnable(in string id) Get the current status of AGC. True indicates enabled.   void setTunerGain(in string id, in float gain) Set tuner gain in dB.   float getTunerGain(in string id) Get current tuner gain in dB.   void setTunerReferenceSource(in string id, in long source) Set the tuner reference source. Zero is defined as internal and one is defined as external.   long getTunerReferenceSource(in string id) Get the current tuner reference source.   void setTunerEnable(in string id, in boolean enable) Set the output enable state of the tuner. True indicates output is enabled.   boolean getTunerEnable(in string id) Get the current output enable state of the tuner. True indicates output is enabled.   void setTunerOutputSampleRate(in string id, in double sr) Set the output sample rate in samples/sec.   double getTunerOutputSampleRate(in string id) Get the output sample rate in samples/sec.    Scanner Tuner Control Functions The following table describes additional tuner control functions, which are present when the device is of type RX_SCANNER_DIGITIZER.\nScanner Tuner Control Functions    Function Prototype Description     ScanStatus getScanStatus(in string id) Get the current scanner status. The return structure is of type FRONTEND::ScanningTuner::ScanStatus, which contains information on the scanning strategy, the scheduled start time, the list of center frequencies that the plan will execute, and whether or not the scan has started   void setScanStartTime(in string id, in BULKIO::PrecisionUTCTime start_time) Schedule when a scan plan should start (in epoch time). Setting the time to 0 or a previous time with the tcstatus flag set to true starts a scan immediately. To disable the scan, set the start_time\u0026rsquo;s tcstatus flag to false.   void setScanStrategy(in string id, in ScanStrategy scan_strategy) Provide a plan for what frequencies the scanner will cover and how it will cover them.    Tuner Control Exceptions The following table describes exceptions that may occur during calls to tuner control functions.\nTuner Control Exceptions    Exception Description Notes     BadParameterException Parameter provided is invalid. Indicates the value provided is out of bounds for the capability of the device or that the value was invalid (e.g., a negative frequency).   NotSupportedException Capability is not supported. Indicates the tuner does not support the setting (or getting) of this capability.   FrontendException Generic FrontEnd exception. Indicates there is a FrontEnd issue preventing the command, often because the Allocation ID does not match any currently allocated tuners.    Scanning Interface A scanning tuner requires a definition of how it should scan. This is provided with the ScanStrategy data structure.\nScanStrategy Description The following table describes the members of the ScanStrategy data structure.\nScanStrategy Description    Member Type Description     scan_mode ScanMode ScanMode is an enumerated type that can be set to MANUAL_SCAN, SPAN_SCAN, or DISCRETE_SCAN   scan_definition ScanModeDefinition ScanModeDefinition is a union that provides the mode-specific information: double center_frequency for MANUAL_SCAN, ScanSpanRanges freq_scan_list for SPAN_SCAN, and Frequencies discrete_freq_list for DISCRETE_SCAN   control_mode OutputControlMode OutputControlMode is an enumerated type that can be set to TIME_BASED or SAMPLE_BASED   control_value double This is the value for control_mode. The unit is seconds for TIME_BASED and samples for SAMPLE_BASED    ScanSpanRange Description The data structures Frequencies and ScanSpanRanges provide more detail for their respective modes. Frequencies is a sequence of doubles. ScanSpanRanges is a sequence of ScanSpanRange. The following table describes the members of ScanSpanRange.\nScanSpanRange Description    Member Type Description     begin_frequency double The beginning center frequency for the scan in Hz   end_frequency double The ending center frequency for the scan in Hz   step double The change in center frequency in Hz    GPS Interface The GPS IDL provides an interface to retrieve GPS information from a device that is GPS-enabled. The GPS interface is composed of two attributes and no functions. However, the data structures returned by these attributes contain a large amount of detail.\nThis interface\u0026rsquo;s attributes are read/write, therefore, this interface can be used to read GPS information or to receive GPS information.\n GPS Attributes The GPS attributes are listed in the following table.\nGPS Attributes    Attribute Prototype Description     GPSInfo gps_info Get a detailed description of the GPS information on the device.   GpsTimePos gps_time_pos Return the position generated by GPS as well as the timestamp for that position estimate.    GPSInfo The GPSInfo descriptions are listed in the following table.\nGPSInfo Description    Member Type Description     source_id string Device identifier for the device that generated the GPS location report (this device\u0026rsquo;s ID if accessing the hardware directly)   rf_flow_id string Identifier for the RF source (antenna)   mode string \u0026ldquo;Locked\u0026rdquo; if the GPS Receiver has locked onto the signal, and \u0026ldquo;Unlocked\u0026rdquo; if the GPS Receiver has not locked onto the signal. Use \u0026ldquo;Tracking\u0026rdquo; if the GPS Receiver has found but not locked onto the signal (if available).   fom long Position figure-of-merit (refer to the Figure of Merit table)   tfom long Time figure-of-merit (refer to the Time Figure of Merit table)   datumID long Identifier for the reference ellipsoid (datum). Use 47 for WGS 1984, the GPS datum   time_offset double Receiver oscillator\u0026rsquo;s most recent time offset (seconds). Usually 0   freq_offset double Receiver\u0026rsquo;s center frequency offset (Hz)   time_variance double Receiver oscillator\u0026rsquo;s time offset variance (seconds**2). Usually 0   freq_variance double Receiver\u0026rsquo;s center frequency offset variance (Hz**2)   satellite_count short Number of satellites visible to the receiver   snr float GPS receiver\u0026rsquo;s reported signal to noise ratio. The definition of this value is not standardized and varies by manufacturer.   status_message string Device-specific status message   timestamp BULKIO::PrecisionUTCTime Timestamp for the GPS information   additional_info CF::Properties Device-specific additional information    Figure of Merit The figure of merit (fom) provides the expected position error (EPE). The following table describes the possible values of the fom.\nFigure of Merit    Value Error (meters)     1 less than 25   2 less than 50   3 less than 75   4 less than 100   5 less than 200   6 less than 500   7 less than 1000   8 less than 5000   9 greater than or equal to 5000    Time Figure of Merit The time figure of merit (tfom) provides the expected time error (ETE). The following table describes the possible values of the tfom.\nTime Figure of Merit    Value Error (nanoseconds)     1 less than 1   2 less than 10   3 less than 100   4 less than 1e3   5 less than 1e4   6 less than 1e5   7 less than 1e6   8 less than 1e7   9 greater than or equal to 1e7    GPS Interface Helpers The GPS Interface helpers identify whether the GPS receiver has locked in on a signal or only found the receiver. The helper details are listed in the table below.\nHelper Definitions    Member Value Description     GPS_MODE_LOCKED Locked GPS Receiver has locked onto the signal   GPS_MODE_UNLOCKED Unlocked GPS Receiver has not locked onto the signal   GPS_MODE_TRACKING Tracking GPS Receiver has found, but not locked onto the signal (optional)    GpsTimePos The GPSTimePos reports the location and the timestamp associated with the location report. The GPSTimePos details are listed in the table below.\nGpsTimePos Description    Member Type Description     position PositionInfo Position report   timestamp BULKIO::PrecisionUTCTime Timestamp for the location report    GPS Support Types The following table lists the type used by GpsTimePos for communicating position information.\nPositionInfo    Member Type Description     valid boolean The report is valid   datum string Reference ellipsoid. Set to DATUM_WGS84   lat double Latitude (degrees)   lon double Longitude (degrees)   alt double Altitude (meters)    NavData Interface This interface provides basic navigational information such as position, velocity, and so forth. The NavData interface is composed of one attribute and no functions. While the interface returns a single attribute, that attribute contains multiple positional structures, some of which may not be supported by the navigation data source. Structures contain a \u0026ldquo;valid\u0026rdquo; flag, allowing the hardware to indicate whether or not the source provides that specific data set.\nThis interface\u0026rsquo;s attributes are read/write, therefore, this interface can be used to read navigation information or to receive navigation information.\n NavData Attribute The NavData attribute is used to retrieve additional detailed navigation information from devices.\nNavData Attribute    Attribute Prototype Description     NavigationPacket nav_packet Get detailed navigational information from the device.    NavigationPacket The NavigationPacket provides all of the detail required for communicating navigational information for a device.\nNavigationPacket Description    Member Type Description     source_id string Device identifier for the device that generated the navigation report (this device\u0026rsquo;s ID if accessing the hardware directly)   rf_flow_id string Identifier for the RF source (antenna)   position PositionInfo Location information in lat/long/altitude   cposition CartesianPositionInfo Location information in x/y/z   velocity VelocityInfo Velocity vector   acceleration AccelerationInfo Acceleration vector   attitude AttitudeInfo Attitude info (pitch/yaw/roll)   timestamp BULKIO::PrecisionUTCTime Timestamp for the navigation data information   additional_info CF::Properties Device-specific additional information    NavData Support Types The following tables list the types that are used by the NavigationPacket for communicating position, velocity, acceleration, and attitude information.\nPositionInfo    Member Type Description     valid boolean The report is valid   datum string Reference ellipsoid. Set to DATUM_WGS84   lat double Latitude (degrees)   lon double Longitude (degrees)   alt double Altitude (meters)    CartesianPositionInfo    Member Type Description     valid boolean The report is valid   datum string Reference ellipsoid. Set to DATUM_WGS84   x double X-axis (meters)   y double Y-axis (meters)   z double Z-axis (meters)    VelocityInfo    Member Type Description     valid boolean The report is valid   datum string Reference ellipsoid. Set to DATUM_WGS84   coordinate_system string CS_ECF (Earth-Centered Earth-Fixed), CS_ENU (East, North, Up), CS_NED (North, East, Down)   x double X-axis (meters/second)   y double Y-axis (meters/second)   z double Z-axis (meters/second)    AccelerationInfo    Member Type Description     valid boolean The report is valid   datum string Reference ellipsoid. Set to DATUM_WGS84   coordinate_system string CS_ECF (Earth-Centered Earth-Fixed), CS_ENU (East, North, Up), CS_NED (North, East, Down)   x double X-axis (meters/second^2)   y double Y-axis (meters/second^2)   z double Z-axis (meters/second^2)    AttitudeInfo    Member Type Description     valid boolean The report is valid   pitch double Pitch (degrees)   yaw double Yaw (degrees)   roll double Roll (degrees)    RFInfo Interface The RFInfo interface describes the contents of an RF feed (antenna/feed); the most direct analogy is that RFInfo describes a wire connecting an antenna to a tuner.\nThis interface\u0026rsquo;s attributes are read/write, therefore, this interface can be used to send RF feed information or to describe the RF feed information being received.\n RFInfo Attributes The RFInfo interface implements the attributes listed in the table below.\nRFInfo Attributes    Attribute Prototype Description     string rf_flow_id A string that uniquely describes the feed   RFInfoPkt rfinfo_pkt A description of the RF feed    Support Types The following tables list the types that are used by the RFInfo for communicating RF, sensor, antenna, feed, and frequency, path delay, and frequency range information.\nRFInfoPkt    Member Type Description     rf_flow_id string The string that uniquely describes the feed   rf_center_freq double Center frequency for the RF Feed (the physical antenna)   rf_bandwidth double Bandwidth for the RF Feed (the physical antenna)   if_center_freq double Center frequency for the IF that is output by the feed (if the hardware performs a down-conversion)   spectrum_inverted boolean Set to true if the spectrum for the feed output is inverted   sensor SensorInfo A description of the antenna/feed combination   ext_path_delays sequence PathDelay Frequency-selective path delays   capabilities RFCapabilities Potential operating frequency range for the antenna/feed combination   additional_info CF::Properties Device-specific additional information    SensorInfo    Member Type Description     mission string Name for the mission   collector double Name for the collector   rx double Name for the rx element   antenna AntennaInfo Description of the antenna\u0026rsquo;s RF characteristics   feed FeedInfo Description of the feed\u0026rsquo;s RF characteristics    AntennaInfo    Member Type Description     name string Name for the antenna   type string Type of antenna   size string Size of the antenna   description string Description of the antenna installation    FeedInfo    Member Type Description     name string Name for the feed   polarization string Polarization (for example, \u0026ldquo;vertical\u0026rdquo;, \u0026ldquo;horizontal\u0026rdquo;)   freq_range FreqRange Operating range for the RF feed    FreqRange    Member Type Description     min_val double Minimum frequency   max_val double Maximum frequency   values sequence double List of specific center frequencies that are available (if not continuous)    PathDelay    Member Type Description     freq double Frequency where this delay applies   delay_ns double Delay at the given frequency (nanoseconds)    RFCapabilities    Member Type Description     freq_range FreqRange Minimum to Maximum center frequency   bw_range FreqRange Minimum to Maximum operating bandwidth    RFSource Interface The RFSource interface describes a device that contains multiple RF feeds and any one can be selected at any one time. This is equivalent to an RF switch connected to multiple antenna subsystems.\nThis interface\u0026rsquo;s attributes are read/write, therefore, they are meant to be used to control the RF source (RF switch) to select the appropriate RF stream to feed to the tuner.\n RFSource Attributes The RFSource interface implements the attributes listed in the table below.\nRFSource Attributes    Attribute Prototype Description     RFInfoPktSequence available_rf_inputs The list of RF feeds that can be selected. Each RF feed is described by an RFInfoPkt structure   RFInfoPkt current_rf_input The RF feed that is currently streaming out of the device    Data Flow By default, FEI devices can provide BulkIO data. Data flow into FEI devices is typically constrained to digital-IF data for CHANNELIZER tuners. Digital-IF data is consumed regardless of Stream ID and it is the responsibility of the CHANNELIZER allocator to make the connection from the source into the FrontEnd device.\nOutput data flow is managed by the FEI device and multiple tuners can have output through a single BulkIO port. In general, there should only be one BulkIO port for each data type (int, float, etc.). All streams of any data type must pass through this BulkIO port. The allocator of each tuner is responsible for connecting to the device output port. The Connection ID of the BulkIO connection must match the Allocation ID of the tuner for data to flow through that connection. Thus, the output port must be a multi-out port, one that only passes data packets to specific connections rather than all connections.\nMulti-Output Multi-out ports are a specific implementation of a BulkIO output port. The defining characteristic is that multi-out ports are selective in which connection each piece of data is sent to rather than having each piece of data broadcast to every connection. This behavior is typically implemented by creating a custom BulkIO port implementation that handles data routing for each connection.\nConstructing the custom port is easiest if the internal pushPacket() call does not need to be modified, which is why Stream ID is the easiest field on which to differentiate. As long as the Stream ID is equal to the Allocation ID, the Stream ID can simply be matched to the Connection ID to make a multi-out port. Hence, a REDHAWK best practice is to maintain a one-to-one relationship between Stream and Allocation IDs.\nIf the IDs are the same, there are only two required changes to the standard port implementation. The first change is that as the port iterates over the list of connections, a simple check needs to be performed to only do the remote pushPacket() or pushSRI() call on connections where the Connection ID matches the Allocation ID associated with the current packet. The second change is that the internal storage of previous SRI states needs to become a vector rather than a single element so that a new connection gets the correct previous SRI for its stream rather than just the most recent stream that has had data sent.\nSRI and Keywords FrontEnd devices use both the basic BulkIO SRI fields and the Keywords field for additional items. All standard SRI fields are filled out as appropriate in accordance with the existing BulkIO IDL descriptions. The following table describes the specific keywords for FrontEnd devices.\nFrontEnd-Specific Keywords    Name Type Description Notes     COL_RF double Collector center frequency in Hz. Center frequency of the collector, which is typically thought of as the center frequency of the wideband receiver used to generate the IF data. In the case of a DDC tuner, the value of COL_RF is the center frequency of the input to the CHANNELIZER.   CHAN_RF double Channel center frequency in Hz. The center frequency of the stream. The value of CHAN_RF is equal to the COL_RF for RX and RX_DIGITIZER tuners but should still be included.   FRONTEND::BANDWIDTH double Effective bandwidth in Hz. The effective bandwidth of the stream.   FRONTEND::RF_FLOW_ID string RF Flow ID of data. Always include even if the RF Flow ID is blank.   FRONTEND::DEVICE_ID string The ID of the device. Component ref ID, which allows downstream users to gain a reference to the device that created the data.    Status Recall that frontend_tuner_status is a sequence of structs. Each FEI tuner device reports its status in one of these structs. This includes both allocated and un-allocated tuners so users can see tuners available for allocation.\nStatus Elements Each struct in the frontend_tuner_status sequence contains all of the required elements listed below, and may contain any number of the optional elements. Additional elements are permitted in the structures if a suitable element is not already defined.\nRequired Status Elements The following table describes the required status elements for each tuner of an FEI tuner device. In some cases, null, zero, or blank values may be used to indicate that a value is not set for this device.\nRequired Status Elements of an FEI Tuner Device    Name Type Description Notes     tuner_type string Type description of tuner. Defined in Types of Tuners   allocation_id_csv string Comma separated list of current Allocation IDs. Contains a list of both control and listener Allocation IDs. In effect, the length of the allocation_id_csv list is the number of independent consumers of the tuner output. The control Allocation ID must be the first in the comma separated list.   center_frequency double Current center frequency in Hz. Actual tuned frequency rather than the desired frequency (if those values are not the same).   bandwidth double Current bandwidth in Hz Actual bandwidth rather than the desired bandwidth (if those values are not the same).   sample_rate double Current sample rate in Hz. Actual sample rate rather than the desired sample rate (if those values are not the same). Can be ignored for such devices as analog tuners   group_id string Unique ID that specifies a group of devices. Actual Group ID, regardless whether it was requested in the tuner allocation or not.   rf_flow_id string Specifies a certain RF flow to allocate against. Actual RF Flow ID, regardless whether it was requested in the tuner allocation or not.   enabled boolean Indicates if tuner is enabled. Enabled refers to the output state not any internal hardware/software state.    Additional Required Status Elements of an FEI Scanner Device The following table describes additional fields required in the tuner status structure when a device is of type RX_SCANNER_DIGITIZER.\nAdditional Required Status Elements of an FEI Scanner Device    Name Type Description Notes     scan_mode_enabled boolean Describes whether or not a scan plan is running on this tuner.    supports_scan boolean Describes whether or not this tuner can support a scan plan. Scan plans may not necessarily be available to all tuners in a device.    Optional Status Elements The following table describes the optional status elements for each tuner of an FEI tuner device. In some cases, null, zero, or blank values may be used to indicate that a value is not set for an individual tuner. Note that all tuners of the same device must have the same set of properties in their status structure.\nOptional Status Elements of an FEI Tuner Device    Name Type Description Notes     bandwidth_tolerance double Allowable percentage over requested bandwidth. Tolerance provided by the requester.   sample_rate_tolerance double Allowable percentage over requested sample rate. Tolerance provided by the requester.   complex boolean Indicates if the output data is complex. True for complex; False for real.   gain double Current gain in dB. N/A   agc boolean Indicates if the tuner has AGC enabled. Even if AGC is enabled, the device still reports the current gain in the gain property.   valid boolean Indicates if the tuner is in a valid state. When the tuner is of type DDC, False indicates that the DDC channel is no longer able to tune to the appropriate frequency because the CHANNELIZER it is attached to has been moved.   available_frequency string Valid potential center frequencies for the tuner in Hz. In range(XX-YY) or csv (X,Y,Z) format.   available_bandwidth string Valid potential bandwidth for the tuner in Hz. In range(XX-YY) or csv (X,Y,Z) format.   available_gain string Valid potential gain for the tuner in dB. In range(XX-YY) or csv (X,Y,Z) format.   available_sample_rate string Valid potential sample rates for the tuner. In range(XX-YY) or csv (X,Y,Z) format.   reference_source long Indicates internal vs external reference source. 0 = internal reference; 1 = external reference.   output_format string Indicates current output data format. Uses the SDDS digraph format.   output_multicast string Multicast address for SDDS output. Multicast address in dotted quad notation (e.g., \u0026ldquo;192.168.0.1\u0026rdquo;).   output_vlan long vlan number for SDDS output. If there is no vlan used, indicate that with a zero.   output_port long port number for SDDS output. N/A   decimation long Current decimation of tuner. Decimation values for DDC tuners. Defined as the ratio of input sample rate to output sample rate regardless of data format.   tuner_number short Physical tuner ID. Tuner ID number within device. May represent physical tuner ordering or virtual ordering in software.    RFSource Interface FrontEnd devices that have RFInfo output ports and that flow RF metadata to other FrontEnd devices also have an RFSource interface. Such devices include antennas and RF distribution/switches. The RFSource interface is used to determine the currently selected RF Flow and all possible RF flows that a device can provide. The interface has two attributes:\n RFInfoPktSequence available_rf_inputs - A list of all possible RF inputs to which this source could switch.\n RFInfoPkt current_rf_input - The currently selected source that is being output.\n  Typical consumers of the RFInfo can read these values to know if other RF flows are possible. A device with the RFSource interface may get the information about its RF flows in multiple ways. The device may get the information through a non-REDHAWK interface to the actual switch, it may be stored as a configuration item or a property, or it may be set through the RFSource interface by another entity in the system with knowledge of the current RF configuration. If an external entity has knowledge of the RF configuration and sets the two attributes on a device, the device should push out an updated RFInfoPacket to any connected users.\nRFSource Allocation Property The RFSource rf_flow_id property is used in the allocateCapacity() interface of a device to request a particular RF flow. Allocation is performed by setting the FRONTEND::RFSource::rf_flow_id allocation property equal to the value of the RF flow requested. The following table describes the RFSource allocation property.\nRFSource Allocation Property    Name Type Description Notes     FRONTEND::RFSource::rf_flow_id string Requested rf_flow_id. Will return true if source can satisfy the request.    allocationCount Property If the requested RF flow can be switched to the output, the RFSource device will make the switch and the allocateCapacity() call will return true. If the device cannot provide the RF flow or has already been allocated to another RF flow, the allocateCapacity() call will return false. If the device is already allocated to the requested RF flow, the allocateCapacity() call will return true and increment the count of the total number of allocations received for that rf_flow_id. Once allocated, the device will not switch RF flows until the number of deallocateCapacity() calls received is equal to the total number of allocations for that rf_flow_id. The total number of allocations for the selected RF flow is stored in a readonly property named allocationCount. The following table describes the allocationCount property.\nallocationCount Property    Name Type Description Notes     allocationCount long Total number of successful allocations against the current output. Always \u0026gt;0 if the device is allocated.    Even when the allocationCount is zero and no switch allocations are allocated, the current_rf_input and the RFInfoPacket should reflect the current state of the RF Flow. For example, even without allocation, if real RF data is still being output, the status should reflect that. If no data is being output, then the current_rf_input attribute should be empty. Setting the current_rf_input attribute does not imply allocation or a request to switch an input. It assumes that this would only be set if the input had already switched to that new value from outside of the device. If the device allocationCount is not zero, it is not recommended to change the switch configuration and thus set the current_rf_input.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/managing-defining-properties/",
	"title": "Managing and Defining Properties",
	"tags": [],
	"description": "",
	"content": " Properties are defined by their structure, kind, and type. The four different property structures include:\n simple - single value such as 1.0, or \u0026ldquo;a string\u0026rdquo; simple sequence - list/array of zero or more simples such as [1, 2, 3], or [\u0026ldquo;first\u0026rdquo;, \u0026ldquo;second\u0026rdquo;] struct - groups several simples and simple sequences together struct sequence - list/array of zero or more instances of a struct  Three commonly used kinds of properties in REDHAWK include:\n property - denotes properties that are used for configuration and status allocation - expresses requirements that will be satisfied by a REDHAWK device message - used only with structs and indicates that the struct will be used as an event message within REDHAWK  The property’s type corresponds with basic programming language primitive types such as floats, long integers, booleans, etc. Additionally, numeric types can be complex.\nThrough the use of generated code and the REDHAWK libraries, manipulation of properties uses fundamental types provided by C++, Python, or Java, as seen in Properties. For example, a simple sequence, complex-float property is manipulated via a std::vector\u0026lt; std::complex\u0026lt;float\u0026gt; \u0026gt; variable in C++ and a list of Python complex objects in Python. Generated component code provides a class data field representing each property for that component.\nThe primitive data types supported for simple and simple sequence properties are: boolean, octet, float, double, short, ushort, long, longlong, ulong, ulonglong, string, objref, char, and utctime. The utctime type is used to describe time and can be used to synchronize property change events and queries on the component or device. To set a default value for a time as a property, use a string of the form \u0026ldquo;YYYY:MM:DD::hh:mm:ss.sss\u0026rdquo; where YYYY is the year, MM is the month, DD is the day, hh is the hour (0-23), mm is the minutes, and ss.sss is the fractional seconds.\nIn some cases, it is desirable for the utctime property to be initialized to the current time. To do so, the default value (in either the component’s default property value or as an overload at the waveform level) is set to \u0026ldquo;now\u0026rdquo;, which is the time when the component is deployed. The string \u0026ldquo;now\u0026rdquo; can also be used in the Python Sandbox to set the utctime property’s value to the current time. Inside the component code, helpers are available to set the utctime property value to the current time; for example, in C++, the following code sets the property to now:\nmy_prop = redhawk::time::utils::now(); The following primitive data types can be marked as complex values: boolean, octet, float, double, short, ushort, long, longlong, ulong, and ulonglong.\nEach component implements the CF::PropertySet interface, which provides remote access to the component’s properties through the query() and configure() methods. The query() method provides a means for reading a component’s current property settings and the configure() method provides a means for setting a component’s property values. Properties identified in these methods will use the property identifier value to resolve identifier access.\nProperties can be readonly, writeonly, or readwrite. properties with read privileges can only be accessed using the query() method and properties with write privileges can only be set using the configure() method.\nThe REDHAWK library base classes provide a complete implementation of configure(), with the creation of specific properties handled per component by the generated base classes. Beyond the basic updating of local values, the standard configure() implementation provides:\n Thread-safe updates via mutual exclusion Automatic conversion of numeric types Notification on changes to property values External reporting of changes via events Exception throwing for invalid input  Because of these enhancements, developers are strongly discouraged from overloading either the query() or configure() methods.\nProperty ID Properties are identified by ID and name. The ID must be unique to the scope of the component or device. This uniqueness applies to all properties, including the members of struct and struct sequence properties. Therefore, if two different struct properties in the same component each have a member with the name abc, both members cannot use the ID abc.\nTo eliminate ID conflicts, REDHAWK provides a naming convention that allows for multiple struct properties to use the same member names without creating ID conflicts. For members of a struct, the ID is created by combining the name of the member and the ID of the struct. For example, if struct property foo has a simple member bar, the member would have the name bar and ID foo::bar. The naming convention also applies to struct sequence properties as well.\nProperty Name The property name, if provided, is used for member variables in generated code and for display within the IDE. If not provided, the ID is used instead.\nProperty Access Summary The combination of property types and their related attributes, such as readwrite and command-line, can be confusing. Furthermore, different properties whose values are overloaded are initialized at different points in the component lifecycle. To clarify the behavior of these different properties, the table below is included.\nProperty Summary  Setting Behavior (Yes/No/Undefined)   kind mode command line overload config query initialization         language constructor generated constructor   property readwrite No Yes Yes Yes No Yes   property readonly No Yes No Yes No Yes   property writeonly No Yes Yes No No Yes   property readwrite Yes Yes Yes Yes No Yes   property readonly Yes Yes No Yes No Yes   property writeonly Yes Yes Yes No No Yes   allocation readwrite N/A No No U U U   allocation readonly N/A No No U U U   allocation writeonly N/A No No No U U   message any N/A No No No U U   There are several aspects of the table that are of note. The language-specific constructor (for example, __init__ in Python) never has the correct overloaded default value for a property; that value is only available when the generated constructor function is invoked. The use of the command-line marker for a property does not make it available at the language-specific constructor. The command-line marker is used to pass a property value in the command-line to services.\nA service normally does not support interfaces necessary to initialize properties over CORBA. In order to support properties in services, a property can be defined for a service and set as command-line, allowing the property to be overloaded for the specific service instance. The resulting command line argument will resolve from the service’s Properties File (PRF) file, and optionally be overridden from the Device Configuration Descriptor (DCD) file. Standard property processing will apply to all types with the exception of the boolean type; in which case the exact contents supplied in either the PRF or DCD file will be passed on the command line.\nAllocation properties are not to be used as value containers; they are to be used to describe allocations to the device. While it is technically possible to query allocation properties, and while they may hold a value in the device implementation, that value is undefined, and could be anything. Allocation properties only have meaning in the context of allocateCapacity calls, and by extension have meaning only when servicing an allocation callback function.\nMessage properties have no storage meaning at all. They are prototypes describing structure message formats to be sent over MessageEvent ports. Furthermore, message properties can only be structures; they cannot be simple, simplesequence, or structsequence.\nProperty Change Listeners Often, it is useful to trigger additional actions when the value of a property changes. Components support a type of notification called property change listeners that enable the developer to register callback methods that are executed whenever configure() is called with new values for the particular property.\nProperty change listeners are executed while holding the lock that protects access to all properties for the component. This ensures that no outside changes can occur while responding to property changes. The callback may alter the value of the property or call additional functions; however, avoid computationally expensive or blocking operations.\nC++ C++ components support notification of property value changes using member function callbacks.\nThe following example explains how to add a property change listener for the freqMHz simple property of type float, of a component named MyComponent.\nIn [component].h, add a private method declaration for your callback. The callback receives two arguments, the old and new values:\nvoid freqMHz_changed(float oldValue, float newValue); Implement the function in [component].cpp.\nThen, in the component constructor(), register the change listener:\nthis-\u0026gt;addPropertyListener(freqMHz, this, \u0026amp;MyComponent_i::freqMHz_changed); addPropertyListener takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nWhen defining a property listener for struct or sequence property, the new and old values are passed by const reference:\nvoid taps_changed(const std::vector\u0026lt;float\u0026gt;\u0026amp; oldValue, const std::vector\u0026lt;float\u0026gt;\u0026amp; newValue); Python Like C++, Python components allow registering listeners by property. The callback is typically a member function.\nThe following example explains how to add a property change listener for the freqMHz property.\nDefine the callback as a member function on your component. Excluding the implicit self argument, the callback receives three arguments: the property ID and the old and new values.\ndef freqMHz_changed(self, propid, oldval, newval): # Perform action based on change In your component constructor() method, register the change listener:\nself.addPropertyChangeListener(\u0026#34;freqMHz\u0026#34;, self.freqMHz_changed) Java Java properties support an idiomatic listener interface for responding to changes. As opposed to C++ and Python, listener registration is performed directly on the property object.\nThe following example explains how to add a property change listener for the freqMHz property of a component named MyComponent.\nDefine your callback that will respond to changes for the property as a member function on your component class. For simple numeric properties, the old and new value arguments can be the primitive type (for example, float):\nprivate void freqMHz_changed(float oldValue, float newValue) { // Perform action based on change } In your component’s constructor() method, define an anonymous subclass of org.ossie.properties.PropertyListener that connects the property’s change notification to your callback. For simple numeric properties, the type parameter of the PropertyListener class must be the boxed type (for example, Float).\nthis.freqMHz.addChangeListener(new PropertyListener\u0026lt;Float\u0026gt;() { public void valueChanged(Float oldValue, Float newValue) { MyComponent.this.freqMHz_changed(oldValue, newValue); } }); Customizing Query and Configure This feature is only available in C++.\n The REDHAWK libraries and generated component code automatically handle query() and configure() for all defined properties. However, in some cases, it may be preferable to retrieve the current value of a property in response to a query(), such as when fetching status from an external library. A developer may also want more control over how the property value is set. Components support per-property callbacks to customize query and configure behavior.\nThe query callback is called when the component receives a query() for that property, in lieu of consulting the local state. Likewise, the configure callback is called when the component receives a configure() for that property, instead of updating the component local state.\nUnlike property listeners, the configure callback is always called regardless of whether the new value is equal to the old value.\n Query and configure callbacks are executed while holding the lock that protects access to all properties for the component. This ensures that the callback has exclusive access to the component properties. If possible, avoid computationally expensive or blocking operations to ensure that the component remains responsive.\nC++ In C++, query and configure callbacks are registered on the components. Registering a new callback replaces the old one.\nQuery Callbacks To create a query callback, in [component].h, add a private member function declaration. It takes no arguments and returns the value:\nfloat get_freqMHz(); Implement the function in [component].cpp.\nThen, in the body of constructor(), register the query function:\nthis-\u0026gt;setPropertyQueryImpl(freqMHz, this, \u0026amp;MyComponent_i::get_freqMHz); setPropertyQueryImpl takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nConfigure Callbacks To create a configure callback, in [component].h, add a private member function declaration. It takes one argument, the new value, and returns void:\nvoid set_freqMHz(float value); Implement the function in [component].cpp.\nThen, in the body of constructor(), register the configure function:\nthis-\u0026gt;setPropertyConfigureImpl(freqMHz, this, \u0026amp;MyComponent_i::set_freqMHz); setPropertyConfigureImpl takes three arguments: the property’s member variable, the target object (typically this) and a pointer to a member function.\nWhen a configure callback is set, the member variable is not updated automatically. It is up to the component developer to update the member variable, if desired.\nOverriding the configure() Method For the vast majority of cases, the standard configure() implementation is sufficient. Developers are strongly discouraged from overriding configure(). However, in the event that additional functionality beyond what is provided is required, the overridden method should call the base class configure() method to ensure that the behavior expected by the library and framework is preserved. Whether the base class method is pre- or post-extended is left to the discretion of the component developer.\nSynchronization External listeners to properties can be informed of changes in component properties by using the registerPropertyListener function on the component. The registerPropertyListener function allows an event consumer to register with the component. Upon registration, the component begins a thread that monitors the value of the requested properties. When the value of any of the monitored properties changes, an event is issued notifying the consumer what property changed on what component, when, and to what new value.\nTo maintain synchronization between property change events and query calls to the component, it is possible to add a QUERY_TIMESTAMP property to the query. The QUERY_TIMESTAMP property on the query() is populated with the timestamp for this query. The returned timestamp can be compared to asynchronously received property change events to assess what is the most recent known value for the requested property.\nQuerying and Configuring Components and Devices The previous sections explain the component developer\u0026rsquo;s ability to define properties and respond to external requests to query the property value or change its value through a configure call. This section focuses on the process of invoking a query or configure call from an external source.\nProperties are packed as a sequence of CF::DataType structures, where each CF::DataType structure is composed of the string element id and the CORBA::Any element value, forming an id/value pair for any one property. The CORBA::Any element is a construct that can hold any arbitrary data type (including custom-defined structures and objects); this construct holds both the value itself and information regarding the type for the value. REDHAWK struct properties are packed as nested sequences of CF::DataType. The outer construct is the property, and the value element contains a sequence of CF::DataType elements, one for each member of the structure.\nProperties in REDHAWK are strongly typed, so the data type for the value element must match the type that the component or device expects for that particular property. If the wrong type is packed into the CORBA::Any, the property will fail to configure. For example, if a property is defined as type long and the value packed into the value element is of type short, then the operation will fail.\nAccess from C++ Accessing component or device properties from a C++ program can be awkward because it requires the developer to comply with the CORBA API. To simplify the manipulation of properties, REDHAWK includes redhawk::PropertyMap which overlays the std::map API onto CF::DataType sequences enabling the developer to inspect, add, or remove a property from a property sequence.\nConfigure a value:\ninclude \u0026lt;ossie/PropertyMap.h\u0026gt; CF::Properties my_props; redhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(my_props); short num_value = 2; std::string str_value(\u0026#34;hello\u0026#34;); tmp[\u0026#34;property_id_a\u0026#34;] = num_value; tmp[\u0026#34;property_id_b\u0026#34;] = str_value; comp-\u0026gt;configure(my_props); short retval = tmp[\u0026#34;property_id\u0026#34;].toShort(); Query a value:\ninclude \u0026lt;ossie/PropertyMap.h\u0026gt; CF::Properties my_props; redhawk::PropertyMap \u0026amp;tmp = redhawk::PropertyMap::cast(my_props); tmp[\u0026#34;property_id_a\u0026#34;] = redhawk::Value(); tmp[\u0026#34;property_id_b\u0026#34;] = redhawk::Value(); comp-\u0026gt;query(my_props); short num_value = tmp[\u0026#34;property_id_a\u0026#34;].toShort(); std::string str_value = tmp[\u0026#34;property_id_b\u0026#34;].toString(); Additional convenience functions are declared in the header ossie/CorbaUtils.h. These functions make it easier to interact directly with the CORBA::Any type, but they have been superseded by redhawk::PropertyMap and are included only to maintain API compatibility with older software.\nAccess from Java To make the interaction with the Any type simpler, REDHAWK includes the package org.ossie.properties.AnyUtils. This package includes helper functions converting primitive property types, complex values, and sequences to and from an Any object.\nConfigure a value:\nimport CF.DataType; import org.ossie.properties.AnyUtils; import java.util.ArrayList; short num_value = 2; String str_value = \u0026#34;hello\u0026#34;; ArrayList\u0026lt;DataType\u0026gt; props = new ArrayList\u0026lt;DataType\u0026gt;(); props.add(new DataType(\u0026#34;property_id_a\u0026#34;, AnyUtils.toAny((Object)num_value, \u0026#34;short\u0026#34;))); props.add(new DataType(\u0026#34;property_id_b\u0026#34;, AnyUtils.toAny((Object)str_value, \u0026#34;string\u0026#34;))); try { comp.configure((DataType[])props.toArray()); } catch (CF.PropertySetPackage.PartialConfiguration|CF.PropertySetPackage.InvalidConfiguration e) { } Query a value:\nimport org.omg.CORBA.ORB; import CF.DataType; import CF.UnknownProperties; import org.ossie.properties.AnyUtils; PropertiesHolder props_h = new PropertiesHolder(); props.add(new DataType(\u0026#34;property_id_a\u0026#34;, ORB.init().create_any())); props.add(new DataType(\u0026#34;property_id_b\u0026#34;, ORB.init().create_any())); props_h.value = (DataType[])props.toArray(); try { comp.query(props_h); } catch (CF.UnknownProperties e) { } short num_value = (short) AnyUtils.convertAny(props_h.value[0].value); String str_value = (String) AnyUtils.convertAny(props_h.value[1].value); Access from Python Accessing component or device properties, or any other control functionality in REDHAWK, is simplest from a Python program. The Python sandbox is an environment that presents REDHAWK as Pythonic elements, making it easy to access elements in the framework. The Python sandbox was designed to support the development of command-and-control software that performs functions like querying or configuring properties.\nConfigure a value:\nfrom ossie.utils import sb, redhawk # the sb package is used to launch component instances # the redhawk package is used to connect to a running domain comp.property_id_a = 2 comp.property_id_b = \u0026#34;hello\u0026#34; Query a value:\nfrom ossie.utils import sb, redhawk # the sb package is used to launch component instances # the redhawk package is used to connect to a running domain print comp.property_id_a # prints \u0026#34;2\u0026#34; to standard out 2 print comp.property_id_b # prints \u0026#34;hello\u0026#34; to standard out hello num_value = comp.property_id_a.queryValue() # queryValue is needed to assign the value rather than the container str_value = comp.property_id_b.queryValue() # queryValue is needed to assign the value rather than the container Helper functions designed to support the development of Python software, such as ossie.properties.props_to_dict and ossie.properties.props_from_dict, are still available in compliance with REDHAWK\u0026rsquo;s API support policy; however, REDHAWK does not recommend using these helper functions in any new software. Python is not strongly typed like C++ or Java, making packing values into an Any object error-prone. Functions such as ossie.properties.props_from_dict do not have enough information regarding property data types and often pack the property using the wrong native type (for example, using double instead of float), which leads to difficulty when debugging problems.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/misc/",
	"title": "Miscellaneous FrontEnd Tuner Library Implementation Details",
	"tags": [],
	"description": "",
	"content": " The tolerances specified in an allocation request are checked after deviceSetTuning returns True using the frontend_tuner_status values, and then deallocates if the tolerances are not met. The allocation fails without attempting the allocation on additional tuner channels that may be able to satisfy the request. Optionally, the developer can check the tolerances within the deviceSetTuning function and return False without configuring the tuner to indicate that the tuner could not meet the request. At this point, the allocateCapacity function will continue attempting to allocate using the next tuner channel that is available.\n An allocation request can specify zero (0) for either the bandwidth or sample rate or both if a specific value is not required. (This is the Any Value option.) The result of a successful allocation will be the lowest bandwidth or sample rate that the device can provide while meeting the other requirements in the allocation request.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/plotting-data/",
	"title": "Plotting Data",
	"tags": [],
	"description": "",
	"content": " The sandbox includes tools for plotting Bulk Input/Output (BulkIO) data from components and devices. The built-in matplotlib plots support visualizing BulkIO data in the time and frequency domains, as well as constellations. The plots are fully integrated into the sandbox, support all numeric BulkIO data types, and may be used as the provides side for component connections.\nThe following example plots the data from a component as a line plot:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; my_comp.connect(plot) \u0026gt;\u0026gt;\u0026gt; sb.start() Before displaying data, plots must be started either by calling their start() method or by calling sb.start(). If the Sandbox is already started when the plot is created, then the plot’s initial state is started.\n Example of LinePlot   Frame Size By default, all the plots display 1024 input samples at a time. To override this default setting, set the frame size by using the frameSize argument:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot(frameSize=8192) Larger frame sizes allow the plot to keep up with a higher rate of input data.\n Fast Fourier Transform (FFT) Size Plots that display the Power Spectral Density (PSD) of input data use a default FFT size of 1024 points. To increase the frequency resolution, set the nfft argument to a larger FFT size:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.LinePSD(nfft=8192) The frame size defaults to the FFT size, but can be overridden with frameSize. It may be smaller than the FFT size; however, it cannot exceed the FFT size. If the frame size is smaller than the FFT size, the data is zero-padded.\n Example of LinePSD   Line Plots Line plots display signal or PSD data as a series of colored line segments, similar to an oscilloscope display. Each input signal is represented by a different line color. A new trace is created for each connect() call, and traces may be added and removed dynamically.\nAll input signals must have the same sample rate or the sources may get out of sync.\n The X range is based on the frame size and input Signal Related Information (SRI). By default, the Y range is determined automatically per-frame based on the input data. A fixed minimum and maximum may be set independently with the ymin and ymax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot.ymin, plot.ymax = (-2.5, 2.5) Automatic scaling can be re-enabled by setting ymin or ymax to None.\n\u0026gt;\u0026gt;\u0026gt; plot.ymin = None The LinePlot plot displays one or more input signals. Time and value are displayed on the X and Y axes, respectively.\nThe LinePSD plot displays the PSD of one or more input signals. The frequency is represented by the X axis, while the magnitude is represented by the Y axis using a logarithmic scale.\nRaster Plots Raster plots display signal or PSD data as a two-dimensional image. Each horizontal line represents one frame of data. This plot type is most useful for visualizing an input signal in the frequency domain over time.\nAll raster plots allow configuration of the image size at creation time. The default image size is 1024x1024; height and width can be overridden with the imageHeight and imageWidth arguments:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.RasterPSD(imageHeight=512, imageWidth=768)  Example of RasterPSD   The plot X and Y ranges are fixed based on the FFT or frame size (X) and image height (Y). The Z range (magnitude) can be set at creation time or changed dynamically with the zmin and zmax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.RasterPSD(zmin=1e-12) \u0026gt;\u0026gt;\u0026gt; plot.zmax = 1e4 The RasterPSD plot displays the PSD of an input signal as a falling raster. Time and frequency are displayed on the Y and X axes, respectively. The magnitude of a given frequency bin is represented by a logarithmic colormap. The default Z (magnitude) range is [1e-18, 1].\nThe RasterPlot plot displays a falling raster of an input signal. Inter-frame time is displayed on the Y axis, while intra-frame time is displayed on the X axis. The sample value of a given point is represented by a linear colormap. The default Z (magnitude) range is [-1, 1].\nX/Y Plot The XYPlot plot displays a series of complex samples as points on a two-dimensional plane. The real and imaginary components of a given sample are mapped to the point’s X and Y coordinates. This plot type is designed for viewing signal constellations, though it may be useful for other purposes.\nBy default, the plot is centered at the origin, and both the X and Y ranges are [-1, 1]. The minimum and maximum X and Y values may be set at creation time or changed dynamically with any combination of the xmin, xmax, ymin and ymax attributes:\n\u0026gt;\u0026gt;\u0026gt; plot = sb.XYPlot(xmin=-2.0, xmax=2.0) \u0026gt;\u0026gt;\u0026gt; plot.ymin, plot.ymax = -2.0, 2.0  Example of XYPlot   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/port-statistics/",
	"title": "Port Statistics",
	"tags": [],
	"description": "",
	"content": " All Bulk Input/Output (BulkIO) ports contain a read only attribute called statistics. The statistics attribute is of type BULKIO::PortStatistics, and it contains information regarding the performance of the port. The table below contains a description of a statistics structure:\nFields in Returned Port Statistics    Name Type Description     portName string Name of this port   elementsPerSecond float A moving average describing the rate at which elements are arriving.   bitsPerSecond float This is the same as elementsPerSecond * bits per elements.   callsPerSecond float Number of pushPacket() calls per second.   streamIDs CF::StringSequence List of all Stream IDs where a pushSRI() has occurred but no End of Stream (EOS) has been received.   averageQueueDepth float Moving average calculation of the percentage queue depth.   timeSinceLastCall float The elapsed time, in seconds, since the last packet was transferred via a pushPacket() call   keywords sequence \u0026lt;CF::DataType\u0026gt; Additional statistics information provided by the port.    The provides-side port contains a single PortStatistics structure. The uses-side port contains a sequence of PortStatistics structures; each one associated with a single connection.\nAn interesting exercise is to create components that generate and consume data in the three languages supported by REDHAWK. The data generator and consumer generate/consume data as fast as possible. The statistics data structure can provide metrics regarding data transfer rates, average latency, and other relevant data. Shifting the transfer length (by changing the size of the sequence in the pushPacket() call) and seeing its effects on the performance of the connection is also instructive.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/redhawk-plot-view/",
	"title": "REDHAWK Plot View",
	"tags": [],
	"description": "",
	"content": "The REDHAWK Plot view displays a NeXtMidas Plot when a user plots a port.\n REDHAWK Plot View   Within the REDHAWK Plot view, users can manipulate the plot as follows:\n Zoom In: Left-click and drag to form a box to zoom in on a portion of the plot. Zoom Out: Right-click to zoom out a single level.  The REDHAWK IDE contains the following controls for interacting with the active plot:\n Change Plot Mode: Changes the mode of the current plot. The plot options include:\n Auto Imaginary Magnitude Phase Real Real and Imaginary Real vs Imaginary 10 Log 20 Log  Change FFT Size: Changes the Fast Fourier Transform (FFT) size.\n Change Plot Type: Changes the plot type. The types include:\n Dot Line Point Raster  Change Frame Size: Changes the frame size.\nThe red icon next to the Change Plot type arrow is a toggle button that when clicked, changes the active plot to display either the Line or the Raster plot.\n  The View menu contains the following options:  View Menu    New Plot View: Displays an identical plot view. This option is useful to view both the Line and Raster plots of the same data simultaneously. Plot Type: Changes the plot type. Plot types include: Dot, Line, Point and Raster. Display SRI: Displays the Signal Related Information (SRI) view. Settings\u0026hellip;: Displays the Plot Settings dialog   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/adminservice/servicelifecycle/",
	"title": "Service Life Cycle",
	"tags": [],
	"description": "",
	"content": " When the AdminService is started at system startup, all enabled services are started. This section explains the commands used to manage the life cycle of a REDHAWK core service process after system startup.\nInspecting the Status of a Service To inspect the status of a REDHAWK core service, use the status command.\nrhadmin status service_name or\nrhadmin status domain_name or\nrhadmin status or\nrhadmin status [type] all Where optional [type] is domain, nodes, or waveforms.\nIf service_name is provided, process the command against a specific service. If domain_name is provided, process the command against the specified domain group. If no argument is provided, process the command against all services. If the optional [type] is specified, then restrict the command to a specific core service type.\nrhadmin status The following output is displayed for all activated services:\nREDHAWK_DEV:GppNode STOPPED May 11 11:31 AM REDHAWK_DEV:REDHAWK_DEV_mgr RUNNING pid 19302, uptime 0:00:16 REDHAWK_DEV:Wave STOPPED May 11 11:30 AM  The following columns are displayed in the activated services output:\n Column 1 - The service name that may be used for other commands. The format is \u0026lt;domain name\u0026gt;:\u0026lt;section name\u0026gt;. Column 2 - State of the service process: RUNNING or STOPPED. Column 3 - For RUNNING processes, process ID of the actual service, and the amount of time the service has been running. For STOPPED processes, the date and time the service was stopped.  Starting a Service To start a service, use the following commands:\nrhadmin start service_name or\nrhadmin start domain_name or\nrhadmin start all or\nrhadmin start [type] all Where optional [type] is domain, nodes, or waveforms.\nIf service_name is provided, the command is processed against a specific service. If domain_name is provided, the command is processed against the specified domain group. If \u0026lsquo;all\u0026rsquo; is provided, the command is processed against all services. If the optional [type] is specified, then the command is restricted to a specific core service type.\nThe following example starts the Domain Manager service REDHAWK_DEV:REDHAWK_DEV_mgr:\nrhadmin start REDHAWK_DEV:REDHAWK_DEV_mgr The following output is displayed:\nREDHAWK_DEV:REDHAWK_DEV_mgr: started  Stopping a Service To stop a service, use the following commands:\nrhadmin stop service_name or\nrhadmin stop domain_name or\nrhadmin stop all or\nrhadmin stop [type] all Where optional [type] is domain, nodes, waveforms.\nIf service_name is provided, the command is processed against a specific service. If domain_name is provided, the command is processed against the specified domain group. If \u0026lsquo;all\u0026rsquo; is provided, the command is processed against all services. If the optional [type] is specified, then the command is restricted to a specific core service type.\nThe following example stops the waveform service REDHAWK_DEV:Wave:\nrhadmin stop REDHAWK_DEV:Wave The following output is displayed:\nREDHAWK_DEV:Wave: stopped  The following status is displayed:\nREDHAWK_DEV:GppNode RUNNING pid 17582, uptime 0:58:01 REDHAWK_DEV:REDHAWK_DEV_mgr RUNNING pid 17492, uptime 0:58:07 REDHAWK_DEV:Wave STOPPED May 11 11:30 AM  Restarting a Service To restart a service, use the following commands:\nrhadmin restart service_name or\nrhadmin restart domain_name or\nrhadmin restart all or\nrhadmin restart [type] all Where optional [type] is domain, nodes, waveforms.\nIf service_name is provided, the command is processed against a specific service. If domain_name is provided, the command is processed against the specified domain group. If \u0026lsquo;all\u0026rsquo; is provided, the command is processed against all services. If the optional [type] is specified, then the command is restricted to a specific core service type.\nThe following example restarts all the services for the domain group REDHAWK_DEV:\nrhadmin restart REDHAWK_DEV The following output is displayed:\nREDHAWK_DEV:Wave stopped REDHAWK_DEV:GppNode stopped REDHAWK_DEV:REDHAWK_DEV_mgr stopped REDHAWK_DEV:REDHAWK_DEV_mgr started REDHAWK_DEV:GppNode started REDHAWK_DEV:Wave started  The following status is displayed:\nREDHAWK_DEV:GppNode RUNNING pid 20124, uptime 0:00:20 REDHAWK_DEV:REDHAWK_DEV_mgr RUNNING pid 20123, uptime 0:00:30 REDHAWK_DEV:Wave RUNNING pid 20125, uptime 0:00:10  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/device-manager/",
	"title": "The Device Manager",
	"tags": [],
	"description": "",
	"content": " The Device Manager interface is used to manage a set of logical devices, services and a File System. The Device Manager is responsible for parsing the node\u0026rsquo;s Device Configuration Descriptor (DCD) XML in order to fork processes for all devices and services in the node. Each process gets passed a list of command-line character strings as executable parameters that are node-specific configuration variables read from the dcd.xml file.\nOnce a child process has been forked, its reference is added to a pending list in the Device Manager, while the child process is initialized and configured (possibly with overloaded property values). After that, it registers itself with the Device Manager, moving its reference from the pending list into a registered list. These lists allow the Device Manager to have knowledge of the status of all devices and services contained within its node. Once all children have been launched, instantiated, and configured, the Device Manager connects the devices as described by the dcd.xml file.\nThe Device Manager also responds to signals from any of its child processes. Upon exit of a child, the Device Manager cleans up the bookkeeping by removing any references to the process from the pending or registered lists and unbinding its name from the Naming Service.\nThe Device Manager also has a signal handler for SIGINT, SIGQUIT and SIGTERM that triggers a shutdown of the node. The node shutdown process unregisters and calls releaseObject on all services and devices, kills off all of the child processes, and unbinds any remaining names, including itself, from the Naming Service.\nLaunching a Device Manager from the Command Line To launch a device from the command line, a Domain Manager must be up and running.\nnodeBooter -d /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DeviceManager - Starting Device Manager with /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DeviceManager_impl - Connecting to Domain Manager REDHAWK_DEV/REDHAWK_DEV INFO:DeviceManager - Starting ORB! INFO:DCE:9d9bcc38-d654-43b1-8b74-1dc024318b6f:Registering Device INFO:DeviceManager_impl - Registering device GPP_localhost_localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Initializing device GPP_localhost_localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Registering device GPP_localhost_localdomain on Domain Manager DCD File The DCD file is an XML file that contains the necessary information to configure a node, which is a specific instance of a Device Manager, as well as all devices and services associated with that Device Manager instance. The DCD file contains information about the devices and services associated with a Device Manager, where to look for a Domain Manager, and other configuration information for devices and services. The file is named: DeviceManager.dcd.xml and is located at: $SDRROOT/dev/nodes/NODE_NAME.\nInformation that is covered in this file includes:\n Device Manager name Device Manager ID References to required devices Software Package Descriptor (SPD) files References to required services SPD files The Domain Manager’s Naming Service name Any required device connections Start order of the devices/services  Nodes Nodes are the collection of devices, services, and connections associated with a single Device Manager instance. There is always only one Device Manager per node. Nodes are deployed on a domain to give the applications the ability to communicate with the systems hardware. Upon creation of an application, the Application Factory attempts to place each required component on a device that is deployed in a node.\nDevices In REDHAWK, devices are specialized components that perform command and control of hardware. They are proxies that are able to run in the domain and provide a single point to interact with one or more pieces of physical hardware.\nDevices communicate with various pieces of hardware in order to keep track of their capacities. When waveforms are deployed and the hardware resources are allocated, the devices keep track of the amount of any specific resource that was used, and what is still currently available. This is a important because it keeps components from attempting to over-allocate on any one piece of hardware.\nUsing Valgrind to Debug Devices The Device Manager supports launching devices using Valgrind, an open source tool that helps detect memory errors and leaks.\nThe VALGRIND environment variable controls this behavior:\n If VALGRIND is not set, devices launch as usual. If VALGRIND is set but has no value, the Device Manager searches the path for valgrind. If VALGRIND has a value, it is assumed to be the full path to the valgrind executable.  Valgrind log files are written to the device’s cache directory (e.g., $SDRROOT/dev/.MyNode/MyDevice). The log file name follows the pattern valgrind.\u0026lt;PID\u0026gt;.log, where PID is the process ID of the device.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/viewing-logging-events/",
	"title": "Viewing Logging Events",
	"tags": [],
	"description": "",
	"content": "A live view of events logged by components or devices can be displayed in the IDE. The component or device provides logging events to an event channel, and the IDE displays them as it receives them. To view the log:\n Right-click the running component or device and select Logging \u0026gt; Tail Log. The Specify logging details dialog is displayed:\n Specify Logging Details Dialog    Select the logging level.\n If desired, specify the logger to which the IDE should attach. Leave the field blank to attach to the root logger.\n Click OK.\nA new Console view displays logging events as they are received.\n To no longer view events, click the Stop icon on the Console toolbar.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/waveforms/",
	"title": "Waveforms",
	"tags": [],
	"description": "",
	"content": "This chapter discusses the construction and execution of waveforms within REDHAWK. An application is the software object that represents an instance of a waveform. A waveform is an XML file that describes the deployment, inter-connection, and configuration of components. It is possible to launch waveforms in the Sandbox as well as in the REDHAWK domain. This chapter discusses the mechanisms for launching a waveform as a running application in a domain.\nTo complete the procedures in this chapter, the SigGen and HardLimit components must be installed in $SDRROOT/dom/components.\n  Waveform Editor     Create and Deploy a Sample Waveform     Waveform Deployment and Computing Resources     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/burstio/",
	"title": "BurstIO",
	"tags": [],
	"description": "",
	"content": "For those applications that require small, and possibly non-contiguous, chunks (or bursts) of data with frequently-varying metadata, Burst Input/Output (BurstIO) provides the data transfer containers and interfaces to meet those requirements. This interface only supports the transfer of data vectors: float, double, octet (int8/uint8), short (int16), ushort (uint16), long (int32), ulong (uint32), longlong (int64), and ulonglong(uint64). Similar to Bulk Input/Output (BulkIO), BurstIO provides Burst Signal Related Information (SRI), and a Precision Time stamp but provides this information in-band with each data burst. With the increased overhead requirement for metadata, BurstIO can achieve its highest throughput by grouping multiple bursts into a single transfer, either programmatically or through configurable policy settings, to try and maximize efficiency and limit latency.\n Data Transfers     Burst Signal Related Information (SRI)     Multi-out Ports     Working with Complex Data     Time Stamps     Port Statistics     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/debugging/",
	"title": "Debugging REDHAWK Components and Devices with Eclipse",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE uses the debugging capabilities from the JDT, CDT, PyDev, and REDHAWK Sandbox. The debugger provides tools to detect and diagnose errors in an application during execution. The debugger allows control of execution of the program by setting breakpoints, suspending launched programs, stepping through source code, and examining the contents of variables.\nFor more details on debugging concepts, consult the Eclipse documentation at http://help.eclipse.org/ or view the embedded documentation from within the REDHAWK IDE by selecting Help \u0026gt; Help Contents.\nIn the Eclipse documentation browser refer to the following sections for additional debugging concepts and details:\n Java development user guide \u0026gt; Concepts \u0026gt; Debugger Java development user guide \u0026gt; Concepts \u0026gt; Breakpoints Java development user guide \u0026gt; Tasks \u0026gt; Running and Debugging C/C++ Development User Guide \u0026gt; Concepts \u0026gt; Debug C/C++ Development User Guide \u0026gt; Tasks \u0026gt; Running and debugging projects \u0026gt; Debugging  Running Unit Tests Component and device projects created with the IDE have a tests folder that contains a functional example test case. This test case checks that the resource can be started, stopped, and released without error.\nTo run the unit test case:\n From the Project Explorer view, expand the project folder then the tests folder to display the existing test cases. Right-click the test script, select Run As \u0026gt; Python unit-test. Check the test results from the Console and PyUnit views.  Running a Component or Device from the REDHAWK Sandbox The REDHAWK Sandbox provides an environment to run components and devices without the need for a domain or Device Manager. When running a component or device from the Sandbox, it is started as its own forked process. A new Console view is created for logging and error messages.\nTo launch a REDHAWK component or device in the Sandbox:\n Open the project’s spd.xml file. From the Overview tab, in the Testing section, click Launch a local component. From the REDHAWK Explorer view, expand the Sandbox. To view a running component, expand or double click the Chalkboard. To view a running device, expand the Device Manager. To display the corresponding console, right-click the component or device, select Show Console.  Releasing a Component/Device from the REDHAWK Sandbox Releasing a resource invokes a graceful shutdown, which follows the object lifecycle sequence. Release makes a call to the resource’s releaseObject() method to initiate the sequence. There are two ways to release a component using the IDE and one to release a device:\n Releasing using REDHAWK Explorer view:\n In the REDHAWK Explorer view, expand Sandbox \u0026gt; Chalkboard to display the running component or Sandbox \u0026gt; Device Manager to display a running device. Right-click the component/device, select Release.  Releasing using Chalkboard diagram:\n In the REDHAWK Explorer view, expand the Sandbox, double-click Chalkboard. In the Chalkboard diagram, right-click the REDHAWK component, select Release.   Terminating a Component from the REDHAWK Sandbox Sometimes a REDHAWK component fails to respond to input. In these cases the component may need to be terminated. Terminate kills the processes of the resource.\nTo terminate a component:\n Terminating using REDHAWK Explorer view:\n In the REDHAWK Explorer view, expand the Sandbox \u0026gt; Chalkboard. Right-click the REDHAWK component, select Terminate.  Terminating using the Chalkboard:\n In the REDHAWK Explorer view, expand the Sandbox, double-click Chalkboard. In the Chalkboard diagram, right-click the REDHAWK component, select Terminate.  Terminating using the Console view:\n In the Console view, click the Display Selected Console drop down. Select the launched REDHAWK component from the drop-down list to switch to its console. Click the Terminate icon, indicated by a red square.   Using the Debugger with the Sandbox The REDHAWK IDE provides an infrastructure-free way to use, test, and debug a REDHAWK components. This section describes how to use the debugging features of the IDE.\nSetting Breakpoints in Component source code A breakpoint suspends the execution of a program at the location where the breakpoint is set. Breakpoints can be enabled and disabled via the Breakpoints view or from the source code editor.\nTo set a breakpoint from the source code editor:\n Open the source code file. Choose a line to set the breakpoint. Directly to the left of the line of code, in the vertical marker bar, perform one of the following actions:  Right-click, select Add Breakpoint or Toggle Breakpoint. Double-click in the marker bar.  A small solid blue (for C/C++/Java code) or green (for Python code) circle marks the breakpoint location.  Launching a Component in the REDHAWK Sandbox in Debug Mode To use the REDHAWK IDE’s debugger, a REDHAWK component can be launched in the Sandbox in debug mode.\nA component can be launched in debug mode in several ways:\n From the Software Package Descriptor (SPD) file Editor:\n Open the project’s spd.xml file. From the Overview tab of the SoftPkg Editor, in the Testing section, click Debug a component in the Sandbox. The REDHAWK component is now launched in the Sandbox in debug mode.  From the Project Explorer:\n In the Project Explorer view, expand the project. Right-click project’s spd.xml file and select Debug As \u0026gt; 1 Launch component in Sandbox. The REDHAWK component is now launched in the Sandbox in debug mode.   There are two ways to confirm that the REDHAWK component has been launched in debug mode:\n From the Chalkboard diagram, there is a small bug icon at the top right corner of the REDHAWK component. From the REDHAWK Explorer view, expand the Sandbox \u0026gt; Chalkboard and a \u0026lt;DEBUGGING\u0026gt; decorator is displayed to the right of the REDHAWK component.  The debugger can switch between Python, C++, and Java while debugging. The REDHAWK IDE can also launch other components in the Sandbox to interact with components in debug mode.\nNote that there are three separate debuggers for C++, Python, and Java. They all support the basic debugging capabilities such as setting breakpoints, stepping through executing code, and viewing variables. However, some debuggers have additional features that are not available to the others. For example, the Java debugger has the ability to hot swap code as it is executing.\nIf there are breakpoints set and triggered, a Confirm Perspective Switch dialog prompts the user to open the Debug perspective. Clicking Yes rearranges the workbench so it is geared towards debugging source code.\nThe Debug perspective displays these additional views:\n Debug view: The Debug view displays the stack frame for the suspended threads in debug mode. Each thread in the program appears as a node in the tree. It displays the process for each target that is running. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details. Variables view: The Variables view displays information about the variables associated with the stack frame selected in the Debug view. New values can be assigned to variables while stepping through the source code. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details. Breakpoints view: The Breakpoints view lists all the breakpoints currently set in the workspace. Double-click a breakpoint to display its location in the editor. Breakpoints can be enabled, disabled, deleted, created, grouped by working set, triggered by a user supplied hit count, triggered only in certain conditions, or triggered by exceptions. Refer to Help \u0026gt; Help Contents or the Eclipse documentation for more details.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/bulkio/examples/",
	"title": "Examples",
	"tags": [],
	"description": "",
	"content": " These two examples illustrate high-speed data exchange between two C++ components and basic data manipulation through the Sandbox.\nHigh-speed data In this example, two C++ components are created: a source and a sink. We will then deploy these components through the Sandbox and evaluate the statistics of the data transfer between them.\n Create a C++ component called source with a uses port called output of type dataShort. Add a simple property with ID xfer_length, type ulong, and default value of 100000. Generate the component code.\n Open the file source.h and add the following members to the source_i class:\nstd::vector\u0026lt;short\u0026gt; data; bulkio::OutShortStream stream; Open the file source.cpp and edit it in the following ways:\n In the source_i constructor:\ndata.resize(0); In serviceFunction() comment-out the LOG_DEBUG statement and add the following lines:\nif (data.size() != this-\u0026gt;xfer_length) { data.resize(xfer_length); } if (!stream) { stream = output-\u0026gt;createStream(\u0026#34;sample\u0026#34;); } BULKIO::PrecisionUTCTime tstamp = bulkio::time::utils::now(); stream.write(data,tstamp); return NORMAL;  Compile the component source and install it on Target SDR.\n Create a C++ component called sink with a provides port called input of type dataShort. Generate the component code.\n Open the file sink.cpp and edit it in the following ways:\n In serviceFunction(), comment-out the LOG_DEBUG statement\n Add the following lines:\nbulkio::InShortStream stream = input-\u0026gt;getCurrentStream(); if (!stream) { return NOOP; } bulkio::ShortDataBlock block = stream.read(); if (!block) { return NOOP; } return NORMAL;  Compile the component sink and install it on Target SDR.\n Start a Python session in a command line terminal and run the following commands:\nfrom ossie.utils import sb source = sb.launch(\u0026#34;source\u0026#34;) sink = sb.launch(\u0026#34;sink\u0026#34;) source.connect(sink) sb.start() print source._ports[0]._get_statistics()[0].statistics  The output of the print statement is an instance of the PortStatistics structure in Bulk Input/Output (BulkIO). This structure contains the statistics gathered from this connection. A measure of data rate is bits per second.\nTo display the number of Gigabits per second, run the following command:\nprint source._ports[0]._get_statistics()[0].statistics.bitsPerSecond/1e9 The resulting value is the measured data transfer rate between the two components. The current xfer_length property can be viewed by typing the following:\nsource.xfer_length The default value is 100000. Update the property to 200000 by running the following command:\nsource.xfer_length = 200000 Check the new data rate by repeating the call to _get_statistics(). The resulting data rate is now different.\nOctet Ports Octets are unsigned 8-bit units of data. In Java and C++, these map easily. However, that is not the case in Python, which treats a sequence of characters as a string. The following is an example of pushing Octet data out of a dataOctet port:\nimport numpy outputData = [1,2,3,4,5] outputDataAsString = numpy.array(outputData, numpy.uint8).tostring() self.port_output.pushPacket(outputDataAsString, T, EOS, streamID) Data manipulation In this example, a Python component is created that takes vectors of floats as inputs, multiplies the vector by some arbitrary number, and then outputs the resulting vector. This example demonstrates some basic data manipulation as well as the interaction between the Python environment and the running component.\n Create a Python component called mult with a provides port called input of type dataFloat and a uses port called output of type dataFloat. Add a simple property with ID factor, type float, and default value of 1. Generate the component code.\n Open the file mult.py and add the following lines:\ndata, T, EOS, streamID, sri, sriChanged, inputQueueFlushed = self.port_input.getPacket() if data == None: return NOOP outData = [] for value in data: outData.append(value*self.factor) if sriChanged: self.port_output.pushSRI(sri) self.port_output.pushPacket(outData, T, EOS, streamID) return NORMAL Save the project and drag the mult project to REDHAWK Explorer\u0026gt; Target SDR.\n Start a Python session in a command line terminal and run the following commands:\nfrom ossie.utils import sb mult = sb.launch(\u0026#34;mult\u0026#34;) source = sb.DataSource(dataFormat=\u0026#34;float\u0026#34;) sink = sb.DataSink() source.connect(mult) mult.connect(sink) sb.start() source.push([1,2,3,4,5]) sink.getData() Output:\n[1.0, 2.0, 3.0, 4.0, 5.0] The multiplication factor can be changed while the Sandbox is up.\nmult.factor = 2 source.push([1,2,3,4,5]) sink.getData() Output:\n[2.0, 4.0, 6.0, 8.0, 10.0]  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/getting-error-condition-details/",
	"title": "Getting Details About Error Conditions",
	"tags": [],
	"description": "",
	"content": "If an error condition occurs within the Domain Manager which prevents a component, device, Domain Manager, or Device Manager from running correctly, the object’s representation in the REDHAWK Explorer is marked with a decorator in the lower left corner. Mouse hovering over the item’s icon provides a short description of the issue; however, if more than one problem has occurred, the hover text reads “Multiple Problems exist with this item”.  Mouse Hovering Over Error Decorator   More detail about an error can be found within the Properties view of the item.\n To view the details about an error condition:\n With the item selected, select or open the Properties view.\n From the Properties view, select the Advanced tab\n Select the status row. This causes the Details button to appear.\n Click Details to bring up a detailed dialog of the current error conditions.  Error Event Details Dialog     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/python/misc/",
	"title": "Miscellaneous",
	"tags": [],
	"description": "",
	"content": " Saving and Loading Waveforms The components making up a waveform can be loaded into the workspace by passing the path and name of the waveform’s Software Assembly Descriptor (SAD) XML file to the loadSADFile() method. Note that usesdevice relationships are ignored when loading a SAD file onto the Sandbox.\n\u0026gt;\u0026gt;\u0026gt; sb.loadSADFile(\u0026#34;/path/to/sad/file/waveform.sad.xml\u0026#34;) The instantiated components and their associated connections can also be saved as a waveform. To perform this operation, pass the desired waveform name to the generateSADXML() method.\nThis method returns an XML string representing the contents of the SAD file; this string may then be written to a file:\n\u0026gt;\u0026gt;\u0026gt; sadString = sb.generateSADXML(\u0026#34;waveform_name\u0026#34;) \u0026gt;\u0026gt;\u0026gt; fp=open(\u0026#34;/path/to/sad/file/waveform_name.sad.xml\u0026#34;,\u0026#34;w\u0026#34;) \u0026gt;\u0026gt;\u0026gt; fp.write(sadString) \u0026gt;\u0026gt;\u0026gt; fp.close() Debug Statements and Standard Out Standard out and standard error can be redirected to a file:\n\u0026gt;\u0026gt;\u0026gt; sb.redirectSTDOUT(\u0026#34;/path/to/file/file.txt\u0026#34;) Debug statements can be set explicitly.\nTo set the debug output status, pass True or False to the setDEBUG() method:\n\u0026gt;\u0026gt;\u0026gt; sb.setDEBUG(True) To get the current state of the debug output, use the getDEBUG() method:\n\u0026gt;\u0026gt;\u0026gt; sb.getDEBUG() True Processing Components from the Command Line To process individual components from the command line, use the proc() function. The following command is an example of the proc() function call with sample arguments:\n\u0026gt;\u0026gt;\u0026gt;sb.proc(\u0026#34;my_component\u0026#34;,\u0026#34;input_file\u0026#34;,sink=\u0026#34;output_file\u0026#34;,sourceFmt=\u0026#34;16t\u0026#34;,sinkFmt=\u0026#34;8u\u0026#34;,sampleRate=10000,execparams={\u0026#34;execprop1\u0026#34;:5},configure={\u0026#34;prop2\u0026#34;:4},providesPortName=\u0026#34;input\u0026#34;,usesPortName=\u0026#34;output\u0026#34;,timeout=10) proc() Function Arguments    Name Description     \u0026lt;first argument\u0026gt; Specifies the name of the component to run (required).   \u0026lt;second argument\u0026gt; Specifies the name of the input file (required).   sink Specifies the name of the output file (optional). If this argument is omitted, exit the proc() function with Ctrl+C.   sourceFmt Specifies the format for the input file (optional).    - 8/16/32/64 bit resolution    - u/t: unsigned/signed    - c: complex (real if omitted)    - r: big endian (little endian if omitted)   sinkFmt Specifies the format for the output file (optional).   sampleRate Specifies the sampling rate for the input file (optional).   execparams Specifies the dictionary describing properties (of kind property with commandline set to true) to be passed as command-line arguments (optional).   configure Specifies the dictionary describing properties of kind property to be overridden (optional).   providesPortName Specifies the component input port name (optional).   usesPortName Specifies the component output port name (optional).   timeout Specifies how long the proc() function runs before exiting (optional).    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/plot-settings-dialog/",
	"title": "Plot Settings Dialog",
	"tags": [],
	"description": "",
	"content": " The Plot Settings dialog enables the user to adjust certain plot settings.  Plot Settings Dialog   Plot Selecting Plot in the left-hand navigation pane displays the Plot section. The Plot section enables you to change various settings on how the data is displayed within the plot.\n Mode: Select the Mode of the plot. Min: Set the minimum value for the plot. The default value is to automatically determine the minimum. Max: Set the maximum value for the plot. The default value is to automatically determine the maximum. Refresh Rate (fps): Set the desired refresh rate in frames per second (fps) to perform smart thinning of the data. Enter 0 to disable smart thinning. The default value is 30 fps. Enable plot configure menu using mouse: This checkbox enables the NeXtMidas plot configure menu using the mouse. Enable quick access control widgets: This checkbox enables the quick access control widgets to change plot settings from the view. When enabled, Plot Port FFT has a quick control widget for adjusting the Fast Fourier Transform (FFT) number of averages directly in the view.  Output Port Name Selecting the Output Port Name in the left-hand navigation pane displays the Output Port Settings dialog:  Output Port Settings Dialog   The Output Port Settings enable you to modify how the source is being displayed.\n The Show checkbox enables you to turn the plotting of individual data streams on and off. The Stream ID displays the Stream ID for each data stream in the plot. Clicking on Color brings up the Color Palette dialog, which enables you to select a color for the specified stream on the plot.  Color Palette Dialog    Framesize: Enables you to override the displayed default frame size. The IF and RF radio buttons enable you to toggle between Intermediate Frequency (IF) and RF values for the x-axis on FFT plots. Center Freq: Enables you to override the center frequency value for RF plots. This field is grayed out for IF plots.  Expanding the Output Port Name in the left-hand navigation pane makes the Bulk Input/Output (BulkIO) and FFT settings available.\nBulkIO Selecting BULKIO in the left-hand navigation pane displays the BULKIO Settings dialog:  BULKIO Settings Dialog   The BULKIO Settings dialog enables you to modify how the data is received via the CORBA Bulk Data.\n Connection ID: Displays the Connection ID of the current connection. Sample Rate: Enables you to set a custom sample rate to override the value in StreamSRI. Enter 0, or leave on AUTO, to use the value from StreamSRI. Remove on ‘End of Stream’: This checkbox enables you to select whether the stream is removed from the plot when an End of Stream (EOS) is received for the selected Stream ID. Blocking Option: This enables you to select a blocking option for pushPacket when the plot is not able to keep up with the data stream by selecting one of the radio buttons.  non-blocking - Do not block incoming data. blocking - Block incoming data. use SRI.blocking (default) - Set the blocking based on the StreamSRI.blocking field received from the pushSRI() call.   FFT Selecting FFT in the left-hand navigation pane displays the FFT Settings dialog:  FFT Settings Dialog   The FFT section enables you to change various settings on the FFT primitive.\n Num Averages: Enables you to change the number of averages in the FFT. Overlap: Enables you to change the overlap of the FFT. Sliding Num Averages: Enables you to change the sliding number averages of the FFT. Transform Size: Enables you to change the transform size of the FFT. For best results the entry should be a power of 2. Window Type: Enables you to change the window type of the FFT.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/persona-device-pattern/",
	"title": "REDHAWK Persona Device Pattern",
	"tags": [],
	"description": "",
	"content": " In REDHAWK, you can manage and maintain the lifecycle of programmable hardware, such as FPGAs, by implementing a specific design pattern: the Persona Pattern. This design pattern is rooted heavily in the concept of REDHAWK devices, proxies used to interface physical hardware with the REDHAWK Framework.\nTo accurately represent the dynamic nature of programmable hardware, two unique roles have been established: the programmable role and the persona role. These roles are represented in REDHAWK as two separate REDHAWK devices: Programmable Devices and Persona Devices.\nPotential Benefits Persona devices provide the following benefits:\n Enables the REDHAWK Framework to manage and maintain the lifecycle of programmable hardware. Ability to add/remove programmable hardware loads without the need to modify/rebuild source. Reduced development time and costs. Support for reuse and portability. Scalability across embedded, lightweight, and heavyweight architectures.  Theory of Operation This section describes the recommended methods to implement programmable and persona devices in REDHAWK.\nThe Programmable and Persona Roles The programmable role and the persona role attempt to model the polymorphic behavior of programmable hardware within the REDHAWK Framework. The programmable role can be thought of as a controller that may also provide generic functionality, whereas the persona role can be thought of as a standalone representation of a single hardware load. This delineation provides two distinct areas to accurately define functionality and assign responsibilities.\nThe Programmable Role The programmable role has a handful of responsibilities associated with it, but most important are its controller responsibilities. The programmable role has the ability to control which persona has permission to load the programmable hardware while also blocking subsequent personas from attempting to re-program loaded, running hardware. This simple controller role may also be extended to contain generic functionality that is common among all personas or that does not apply to the persona role.\nThe Persona Role The persona role is responsible for defining the hardware load and any interfaces pertaining to that specific load. This may include register definitions and/or data IO channels. The persona role supplies the bulk of the control over the programmable hardware, representing the state of the loaded programmable hardware.\nREDHAWK Devices The programmable and persona roles can be implemented via REDHAWK devices. Representing these roles as their own independent devices allows for more granular control and for a more precise representation of each role without needing to shoe-horn the two independent roles together into a single, complex entity.  Relationship between Programmable Devices and Persona Devices   REDHAWK Programmable Device The programmable role may be implemented in REDHAWK as a standard REDHAWK executable device. The Device Manager is responsible for launching this device, following the typical REDHAWK device lifecycle. What makes the programmable device unique is that it provides hooks for maintaining and managing the lifecycle of the persona devices registered to it.\nREDHAWK programmable devices also implement functionality to instantiate REDHAWK persona devices from shared libraries. This is achieved by using dlopen to load the shared library and dlsym to access/instantiate the device object contained within the shared library. This mechanism occurs when the following requirements are met:\n Programmable or persona devices are associated together using the compositepartofdevice tag in Device Configuration Descriptor (DCD) file. Aggregate (parent) device is an executable device. Composite (child) device is a shared library.  REDHAWK Persona Device A REDHAWK persona device is simply the XML representation of one specific behavior that may be assigned to a programmable device. This XML representation may include unique properties and/or ports that are only relevant to the persona. Each persona device is visible in the REDHAWK domain, which allows for run-time configuration of persona devices in a standardized way.\nREDHAWK persona devices may be built as shared objects rather than executables, therefore, allowing persona devices to exist within the same process space as a programmable device.  Dynamic Loading of Persona Devices onto a Programmable Device   Associating Programmable/Persona Devices Programmable devices and persona devices are linked together via the REDHAWK DCD files. Within these DCD files, the aggregate device relationship tag defines which persona devices should be associated to a programmable device. The advantage of describing this relationship within the DCD file comes with the added ability to dynamically add/remove/modify the possible personalities of programmable hardware without the need to rebuild source.\nAggregate Persona Device In the Software Communications Architecture (SCA) 2.2.2, aggregate devices are defined as devices that are loosely coupled together within a parent-child relationship. The extent of this relationship is left up to the developer and the persona pattern attempts to take full advantage of this loose coupling.\nBecause a single piece of programmable hardware can take on many personalities, the programmable device is said to have a one-to-many relationship with its loads. The DCD file, via the aggregate relationship tags, enables users to properly define this one-to-many relationship between a single programmable device and many available persona devices.\nDCD File Example In the following example DCD file, the compositepartofdevice tag is used to associate TestPersonaChild1 and TestPersonaChild2 to PersonaParent1.\n... \u0026lt;componentfiles\u0026gt; \u0026lt;componentfile id=\u0026#34;test_persona_parent\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/devices/programmable/programmable.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;componentfile id=\u0026#34;test_persona_child\u0026#34; type=\u0026#34;SPD\u0026#34;\u0026gt; \u0026lt;localfile name=\u0026#34;/devices/persona_device/persona_device.spd.xml\u0026#34;/\u0026gt; \u0026lt;/componentfile\u0026gt; \u0026lt;/componentfiles\u0026gt; \u0026lt;partitioning\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_parent\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_parent_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;persona_parent_1\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_child\u0026#34;/\u0026gt; \u0026lt;compositepartofdevice refid=\u0026#34;persona_node:persona_parent_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_child_1\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;test_persona_child_1\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;componentfileref refid=\u0026#34;test_persona_child\u0026#34;/\u0026gt; \u0026lt;compositepartofdevice refid=\u0026#34;persona_node:persona_parent_1\u0026#34;/\u0026gt; \u0026lt;componentinstantiation id=\u0026#34;persona_node:persona_child_2\u0026#34;\u0026gt; \u0026lt;usagename\u0026gt;test_persona_child_2\u0026lt;/usagename\u0026gt; \u0026lt;/componentinstantiation\u0026gt; \u0026lt;/componentplacement\u0026gt; \u0026lt;/partitioning\u0026gt; ... Hardware-Accelerated Components Hardware-accelerated components are REDHAWK components that are proxies into only a portion of hardware. An example for FPGAs is having multiple demodulator components within the fabric that all have their own register sets and data IO channels. Each individual register set and/or data IO channel may be represented within a single REDHAWK component that has a dependency on a specific behavior or persona.\nThe pattern used for hardware-accelerated components is very similar to the pattern used for persona devices. These components may be built as shared libraries and share state the same way programmable and persona devices share state.  Dynamic Loading of Hardware-Accelerated Components to a Persona Device   Code-Generation Support The persona code-generation support includes templates for both the persona device and the programmable device. These templates have been setup to allow for the easy redefinition of the entry-point method to share state from device-to-device as well as device-to-component. The code generation provides the following benefits:\n Provides C++ and Python templates for persona/programmable devices and hardware-accelerated components. Allows for custom definition of the entry-point method to pass state and/or other parameters from device-to-device as well as device-to-component. Generic shared library functionality tucked into base classes for ease of development. Manages and maintains generic functionality between device-to-device and device-to-component behavior.  Persona Pattern Development This section describes the recommended design patterns for developing programmable and persona devices.\nProgrammable Device Development Developing REDHAWK programmable devices is based heavily on interfacing with a manufacturer’s driver/API and/or custom drivers/APIs. If the driver/API is to be shared, the programmable device may be responsible for the initial construction/opening of the driver/API and the destruction/closing at the end of the lifecycle. The REDHAWK programmable device must also include properties that exist on that specific hardware (for example, temperatures) and any allocation properties that may exist (for example, tuner cards using FrontEnd Interfaces (FEI) 2.0). Any persona device that attempts to reserve the hardware may configure/allocate these properties to put the device into a known usable state for that persona.\nPersona Device Development Developing persona devices uses the code-generation support to abstract away the hooks and functionality used to associate persona devices with their parent programmable device.\nPersona devices, in theory, must contain any ports and/or properties that are strictly related to the hardware personality. These ports and properties must be unique to the load and must not overlap with the programmable device. The persona device may then choose to access the driver/API as needed for operations such as reading/writing registers.\nSystem Developers System developers may assign the programmable device behavior on the fly while also maintaining persona sets for a specific programmable device dynamically. The relationship between persona devices and programmable devices is defined at the node level within the DCD file. With programmable devices and persona devices defined, a system developer may chose to create/modify DCD files to dynamically add/remove/modify the personas that may be loaded onto the programmable hardware without the need to generate/build source.\nWhen to Use the Persona Pattern Persona devices are useful for programming hardware dynamically but may not be ideal for every programmable device situation. The following cases describe some common scenarios and explain why the persona pattern may or may not be practical for the scenarios.\n Case 1: You have a single FPGA that you want to always operate as X.\n Solution: Develop a single REDHAWK device without persona devices. In this scenario, a single device is adequate enough to represent both the hardware and the programmable behavior of the hardware. We are essentially treating the hardware and programmable behavior as a single unit because that behavior is static.  Case 2: You have a single FPGA that you want to operate like X, Y, and Z, where X, Y, and Z do not exhibit any of the same behavior.\n Solution: Develop a REDHAWK programmable device that interfaces with the hardware and develop X, Y, and Z REDHAWK persona devices that represent the unique behaviors. Using persona X, Y, and Z allows for all differences between X, Y, and Z to be represented properly while also allowing generic functionality to be retained within the programmable device.  Case 3: You have a single FPGA that you want to operate like X1, X2, and X3, where X1, X2, and X3 exhibit common behavior.\n Solution: There are multiple solutions and the best solution depends on the specific use-case and whether the behaviors are similar. Some possible solutions include:  Solution 1: Develop a REDHAWK programmable device that interfaces with the hardware and develop a REDHAWK persona device for each behavior. This requires the most amount of effort but will yield the most amount of flexibility if the behaviors wind up not being as similar as originally expected Solution 2: Develop a single REDHAWK device that interfaces with the hardware and maps the differences in X1, X2, and X3 behavior via the standard REDHAWK properties. This simplest solution can quickly yield \u0026ldquo;spaghetti\u0026rdquo; code if the house-keeping becomes more complex. Solution 3: Develop a REDHAWK programmable device that interfaces with the hardware and develop a dynamic REDHAWK persona device that can be configured to represent X1, X2, and/or X3. This approach allows the REDHAWK programmable device to maintain its appropriate role while offloading the housekeeping code to the dynamic REDHAWK persona device. This option also lends itself to adding additional REDHAWK persona devices further down the road to include a new behavior that was not originally intended.    Sharing Hardware Driver/API When using a single driver/API, it is possible to pass a single instance of the driver/API to each persona device and/or hardware-accelerated component. The programmable device is the layer closest to the physical hardware and is typically in charge of opening/instantiating the driver/API.\nThe REDHAWK Framework allows for SoftPkg dependencies, packages used to distribute shared libraries/headers amongst numerous resources. The persona pattern does not mandate the use of SoftPkg, but it may be beneficial to create a REDHAWK SoftPkg dependency for the driver/API libraries/headers instead of manually including/linking headers/libraries.\nOnce the headers and libraries are shared, it is possible to share a single instance of the library/API by using one of the following options.\nOption 1: Modifying the construct Method Because persona devices are shared objects, you can modify the entry-point method into those shared objects and append any additional arguments. The following procedure explains how to modify the construct method.\n For the programmable device, update any entry-point typedefs and pass in additional arguments to the entry-point method. For the persona devices, update the extern C construct method as follows:  extern \u0026#34;C\u0026#34; { Device_impl* construct(int argc, char* argv[], Device_impl* myParent, MyNewArg1Ptr* myNewArg1, MyNewArg2Ptr* myNewArg2){ . . // Standard construct logic  . . // Use myNewArg1 and myNewArg2 here  devicePtr-\u0026gt;setMyArg1(myNewArg1); devicePtr-\u0026gt;setMyArg2(myNewArg2); } } Option 2: Defining a Programmable Device Interface The following procedure explains how to define a programmable device interface.\n Create a programmable device interface that exposes desired state. Include the interface with the persona devices and cast the parent reference into the interface. Update the persona device entry-point construct method as follows:  extern \u0026#34;C\u0026#34; { Device_impl* construct(int argc, char* argv[], Device_impl* myParent) { . . // Standard construct logic  . . // Cast Programmable Device into interface  Interface myDevice = static_cast\u0026lt;Interface\u0026gt;(myParent); // Give Programmable Device interface to persona  devicePtr-\u0026gt;setMyDeviceInterface(myDevice); } }"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/allocation-manager/",
	"title": "The Allocation Manager",
	"tags": [],
	"description": "",
	"content": " The Allocation Manager provides a single point for creating, inspecting, and delegating allocations.\nUsing the Allocation Manager Performing an allocation is more than just allocating against a device; the allocation process involves searching for a device that will satisfy the allocation, making the allocation itself, and then storing the allocation such that it can be deallocated at some later arbitrary time. The Domain Manager uses the Allocation Manager to resolve allocations during application deployment. For example, if an application requires a specific resource, during deployment, the Allocation Manager searches the domain for resources that satisfy the requirement. Alternatively, the Allocation Manager can also be used programmatically through the Allocation Manager interface and the REDHAWK API.\nCreating Allocations The REDHAWK FrontEnd Interfaces (FEI) specification is a powerful tool that allows developers to generalize the selection of RF hardware for use by the system applications. Although it is possible to create any allocation, the set of allocations associated with FEI is the only standardized set of allocations in REDHAWK. While associating a specific FEI allocation with an application is useful, so is creating allocations to be used at a system level (beyond the scope of just one application).\nTo create a new FEI allocation, use the following Python code (assuming an FEI device is running, in this case, the FmRdsSimulator):\n\u0026gt;\u0026gt;\u0026gt; import frontend \u0026gt;\u0026gt;\u0026gt; from ossie.cf import CF \u0026gt;\u0026gt;\u0026gt; alloc = frontend.createTunerAllocation(center_frequency=100e6, bandwidth=0.0, sample_rate=0.0, returnDict=False) \u0026gt;\u0026gt;\u0026gt; requestId = \u0026#39;my_request\u0026#39; \u0026gt;\u0026gt;\u0026gt; pools = [] \u0026gt;\u0026gt;\u0026gt; devices = [] \u0026gt;\u0026gt;\u0026gt; sourceId = \u0026#39;my_script\u0026#39; \u0026gt;\u0026gt;\u0026gt; request = CF.AllocationManager.AllocationRequestType(requestId, [alloc], pools, devices, sourceId) The following table describes the parameters used in this Python code.\nParameters    Name Description     requestId Unique string the caller can use to identify the request.   alloc Parameterized request.   pools Currently unused parameter.   devices List of devices to search over (an empty list searches through all devices in the domain).   sourceId String that can be used to identify the application generating the request.    The Allocation Manager uses the parameters requestId and sourceId to help manage the allocations. For example, in complex systems with multiple subsystems, to manage all the allocation requests for a single application, requestId would be used. If an allocated device unexpectedly terminates, sourceId can be used to determine which allocations are no longer used by any subsystem and then the allocations can be deallocated. Because such management/cleanup is CONOP-specific, it is outside the scope of REDHAWK and must be implemented by system developers to suit their unique needs and environment.\nOnce the allocation is formulated, a list of requests can be submitted to the Allocation Manager using the allocate method. The allocate function returns a list of AllocationStatusType. This list contains one status for each successful allocation, along with the original allocation properties requested as well as the resulting Allocation ID. This AllocationProperties member can be useful when inspecting FEI allocations because it contains the values requested in the allocation. The response also contains the Allocation ID (generated by the Allocation Manager to guarantee uniqueness within the context of the Allocation Manager). This is required because requestIds can be duplicated. If the request is successful, it is added to the Allocation Manager’s allocations list.\nThe following Python code demonstrates a successful allocation using the allocation request in the previous code example. In this case, a response is returned; the response contains the submitted request ID. The allocation is then deallocated by using the deallocate function on the Allocation Manager; the only required argument is the Allocation ID because that Allocation ID is unique to the Allocation Manager.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; am = domain.getAllocationMgr() \u0026gt;\u0026gt;\u0026gt; responses = am.allocate([request]) \u0026gt;\u0026gt;\u0026gt; response = responses[0] \u0026gt;\u0026gt;\u0026gt; print response.requestID \u0026#39;my_request\u0026#39; \u0026gt;\u0026gt;\u0026gt; print response.allocationID \u0026#39;DCE:d46ce82b-31de-4010-95de-435aaa1f17c5\u0026#39; \u0026gt;\u0026gt;\u0026gt; am_allocs = am.allocations() \u0026gt;\u0026gt;\u0026gt; print len(am_allocs) 1 \u0026gt;\u0026gt;\u0026gt; print am_allocs[0].sourceID \u0026#39;my_script\u0026#39; \u0026gt;\u0026gt;\u0026gt; print am_allocs[0].allocationID \u0026#39;DCE:d46ce82b-31de-4010-95de-435aaa1f17c5\u0026#39; \u0026gt;\u0026gt;\u0026gt; am.deallocate([am_allocs[0].allocationID]) \u0026gt;\u0026gt;\u0026gt; print len(am.allocations()) 0 For allocations against an FEI device, the allocatedDevice member of the AllocationStatusType can be used to inspect the tuner status structure. The tuner status structure provides the actual values that were allocated, which may be different from what was originally requested.\nInspecting Allocations through the Python Sandbox To inspect the current allocations through the Python Sandbox:\nFirst, a reference to the running domain is needed. From the Domain Manager, the Allocation Manager can be retrieved:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk \u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() \u0026gt;\u0026gt;\u0026gt; am = domain.getAllocationMgr() If no applications are running, an application must be specified.\n\u0026gt;\u0026gt;\u0026gt; domain.createApplication(\u0026#39;/waveforms/rh/basic_components_demo/basic_components_demo.sad.xml\u0026#39;,\u0026#39;hello\u0026#39;) \u0026lt;ossie.utils.redhawk.core.App object at 0x33092d0\u0026gt; In this case, the default basic_components_demo application was selected. This application instance was given the name \u0026ldquo;hello\u0026rdquo; to simplify the subsequent output.\nThe Allocation Manager tracks which device has a component assigned to it, even if no explicit allocations against the device were made. In the case of basic_components_demo, there are a total of six components on the waveform. Viewing the current allocations on the Allocation Manager yields a list of six allocations:\n\u0026gt;\u0026gt;\u0026gt; allocs = am.allocations() \u0026gt;\u0026gt;\u0026gt; len(allocs) 6 Each allocation description returned is a CF.AllocationManager.AllocationStatusType instance, which contains the Allocation ID, requesting domain, any properties allocated, the device that satisfied the allocation, the Device Manager that hosts the device that satisfied the allocation, and the ID for the requester for the allocation.\n\u0026gt;\u0026gt;\u0026gt; allocs[0] CF.AllocationManager.AllocationStatusType(allocationID=\u0026#39;DCE:15c3ad3e-dbfa-48b6-b0d7-c12b450f9806\u0026#39;, requestingDomain=\u0026#39;REDHAWK_DEV\u0026#39;, allocationProperties=[], allocatedDevice=\u0026lt;ossie.cf.CF._objref_ExecutableDevice object at 0x28cc110\u0026gt;, allocationDeviceManager=\u0026lt;ossie.cf.CF._objref_DeviceManager object at 0x28cc250\u0026gt;, sourceID=\u0026#39;DCE:d4d99400-1a11-11e5-a6ce-3417ebc4aab5:hello_1\u0026#39;) \u0026gt;\u0026gt;\u0026gt; allocs[0].allocationProperties [] \u0026gt;\u0026gt;\u0026gt; allocs[0].sourceID \u0026#39;DCE:d4d99400-1a11-11e5-a6ce-3417ebc4aab5:hello_1\u0026#39; In this example, allocationProperties is an empty list because the deployment required the device to match an allocation requirement and no explicit capacity allocation was made. The source ID is a concatenation of the application’s sad.xml file softwareassembly id (the file’s globally unique identifier), a \u0026ldquo;:\u0026ldquo;, and the application name followed by an instance number.\nInspecting Allocations using the IDE To inspect the current allocations using the IDE:\n In the REDHAWK Explorer view, right-click a Domain Manager and select Allocation Manager.\nThe Allocation Manager view is displayed. The following figure displays the Allocation Manager view based on the results of following the instructions in Inspecting Allocations through the Python Sandbox\n Allocation Manager    To view the allocation properties associated with an allocation, select the allocation in the Allocation Manager view.\nThe Properties view displays the allocation properties.\nThe following figure displays the allocation properties from an FEI device allocation.\n Allocation Manager Properties    To view the device associated with an allocation, from the Allocation Manager view, right-click the allocation and select Find Device.\nThe device is highlighted in the REDHAWK Explorer view.\n To view the Device Manager associated with an allocation, from the Allocation Manager view, right-click the allocation and select Find Device Manager.\nThe Device Manager is highlighted in the REDHAWK Explorer view.\n  Delegating Allocations If an allocation resolution cannot be satisfied, the Allocation Manager delegates an available resource.\nA Domain Manager can register with other Domain Managers. If a Domain Manager is registered with another Domain Manager, then any usesdevice relationship allocation that cannot be satisfied by the Domain Manager is delegated to the remote Domain Managers. Through these registrations, it is possible for multiple Domains to share hardware resources. Sharing between Domains is limited to non-computing resources, like FEI devices. The AllocationStatusType instance returned by the allocate function on the Allocation Manager includes a requestingDomain member. The requestingDomain member shows the name of the Domain Manager that performed the allocation request that is currently satisfied by this Allocation Manager.\nTo perform multi- domain allocations, a Domain Manager first needs to be registered with a remote Domain Manager:\n\u0026gt;\u0026gt;\u0026gt; domain_1 = redhawk.attach(\u0026#39;First_Domain\u0026#39;, location=\u0026#39;\u0026lt;\u0026lt;some IP address\u0026gt;\u0026gt;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; domain_2 = redhawk.attach(\u0026#39;Second_Domain\u0026#39;, location=\u0026#39;\u0026lt;\u0026lt;some other IP address\u0026gt;\u0026gt;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; domain_1.registerRemoteDomainManager(domain_2.ref) In this example, once the Domain Manager is registered, any allocations made onto domain_1 that cannot be satisfied by domain_1, are then delegated to domain_2.\nThe allocate function on the Allocation Manager returns a list of all allocations. To simplify this list, the Allocation Manager also contains the localAllocations function, which returns a list of all allocations that were requested and satisfied by this local domain.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/component-structure/working-with-events/",
	"title": "Working with Events",
	"tags": [],
	"description": "",
	"content": " In addition to using message event properties and message ports, the REDHAWK library enables developers to interface with event channels to send and receive non-REDHAWK structured messages using the CORBA Any object. The library provides both Publisher and Subscriber interfaces for sending and receiving data. The libraries make use of existing marshaling and unmarshaling support for simple data types (i.e., int, float, string, etc.), REDHAWK Core Framework (CF) event messages, and defined structured messages used by your component. For custom structured data, it is the developer’s responsibility to implement the marshaling and unmarshaling methods into and out of a CORBA Any or serialize the data structure into string type that can be marshaled. This API is considered an advanced topic to support custom behavior using CORBA’s event channels.\nPublisher Support To publish data to an event channel, the Publisher role provides the following method:\n push - Accepts data to forward to an event channel. For C++, structured data types require the overload of \u0026ldquo;operator\u0026lt;\u0026lt;=\u0026ldquo;. For Python and Java, structured data should be marshaled into the CORBA Any object.  C++ Example of Publisher This section provides an example of a C++ Publisher.\nComponent.h struct MsgData { int id; std::string data; }; redhawk::events::ManagerPtr ecm; redhawk::events::PublisherPtr pub; Component.cpp Component::constructor { // get access to the [Event Channel](/manual/glossary/#event-channel) Manager  ecm = redhawk::events::GetManager( this ); // request a Publisher object for an event channel  if ( ecm ) { pub = ecm-\u0026gt;Publisher(\u0026#34;test1\u0026#34;); } } // required to marshall data into the CORBA::Any void operator\u0026lt;\u0026lt;=( CORBA::Any \u0026amp;any, const MsgData \u0026amp;msg ) { // marshall MsgData to Any }; Component::serviceFunction { // create a structured message  MsgData my_msg = generateMsg(); if ( pub ) { pub-\u0026gt;push( my_msg); } // or simple text based messages  if ( pub ) pub-\u0026gt;push( \u0026#34;simple message to send\u0026#34; ); } Python Example of Publisher This section provides an example of a Python Publisher.\nComponent.py from omniORB import CORBA, any from ossie.events import Manager class MsgData(object): def __init__(self): self.id = 0; self.data = \u0026#34;\u0026#34; # convert message to a dictionary def encode(self): return { \u0026#39;id\u0026#39;, : self.id, \u0026#39;data\u0026#39; : self.data } class Component: def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ); if self.ecm: # request a Publisher object for an event channel self.pub = self.ecm.Publisher(\u0026#34;test1\u0026#34;); def process(self): msgdata = self.generateMsgData() if self.pub: self.pub.push( msgdata.encode() ) // or simple text based messages if self.pub : self.pub.push( \u0026#34;simple text message\u0026#34;); Java Example of Publisher This section provides an example of a Java Publisher.\nComponent.java // add required imports import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Publisher; // add members to your component\u0026#39;s class private org.ossie.events.Manager ecm; private org.ossie.events.Publisher pub; public class MsgData { public int id; public String data; } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if (this.pub == null ) { this.pub = ecm.Publisher(\u0026#34;test1\u0026#34;); } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle registration error  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle registration error  } } catch( org.ossie.events.Manager.OperationFailed e) { logger.error( e.getMessage()); } } public void encodeMsg(Any a, MsgData msg) { // perform encoding of msg to CORBA any,  } protected int serviceFunction() { MsgData msg = generateMsg(); if ( this.pub != null ) { try { this.pub.push( encodeMsg( msg ) ); } catch( Exception ex ) { // handle exception  } } } Subscriber Support The Subscriber role provides two modes (polling vs callback), for receiving data from an event channel. Both methods require the developer to unmarshal data from a CORBA Any. For C++, structured data types require the overload of \u0026ldquo;operator\u0026gt;\u0026gt;=\u0026rdquo;. For Python and Java, structured data should be unmarshaled from the CORBA Any object.\n getData - (polling) Grab a message from the event channel. If no messages are available then return -1. For Python, a CORBA Any is returned or None for no messages available.\n callback - Provide a callback to the Subscriber object. As data arrives from the event channel, this callback is notified.\n  Example of C++ Subscriber Role Using getData Method The following is an example of a C++ Subscriber role using the getData method.\nComponent.h Polling Example redhawk::events::ManagerPtr ecm; redhawk::events::SubscriberPtr sub; struct MsgData { int id; std::string data; }; Component.cpp Polling Example // required to unmarshall data from the CORBA::Any bool operator\u0026gt;\u0026gt;=( const CORBA::Any \u0026amp;any, const MsgData *\u0026amp;msg ) { //unmarshall Any into MsgData }; Component::constructor { // get access to the Event Channel Manager  ecm = redhawk::events::GetManager( this ); // request a Subscriber object for an event channel  if ( ecm ) { sub = ecm-\u0026gt;Subscriber(\u0026#34;test1\u0026#34;); } } Component::serviceFunction { MsgData msgin; if ( sub \u0026amp;\u0026amp; sub-\u0026gt;getData( msgin ) == 0 ) { RH_NL_INFO(\u0026#34;mylogger\u0026#34;, \u0026#34;Received msg =\u0026#34; \u0026lt;\u0026lt; msgin.id); } } Example of C++ Subscriber Role Using callback Method The following is an example of a C++ Subscriber role using the callback method.\nComponent.h Callback Example redhawk::events::ManagerPtr ecm; redhawk::events::SubscriberPtr sub; struct MsgData { int id; std::string data; }; void my_msg_cb( const CORBA::Any \u0026amp;data ); Component.cpp Callback Example // required to unmarshall data from the CORBA::Any bool operator\u0026gt;\u0026gt;=( const CORBA::Any \u0026amp;any, const MsgData *\u0026amp;msg ) { //unmarshall Any into MsgData }; void Component::my_msg_cb( const CORBA::Any \u0026amp;data ) { // structure msg  MsgData msg; if ( data \u0026gt;\u0026gt;= msg ) { LOG_INFO( Component, \u0026#34;Received message \u0026#34; \u0026lt;\u0026lt; msg.id ); } } Component::constructor { // get access to the Event Channel Manager  ecm = redhawk::events::GetManager( this ); // request a Subscriber object for an event channel  if ( ecm ) { sub = ecm-\u0026gt;Subscriber(\u0026#34;test1\u0026#34;); sub-\u0026gt;setDataArrivedListener( this , \u0026amp;Component::my_msg_cb ); } } Example of Python Subscriber Role Using getData Method The following is an example of a Python Subscriber role using the getData method.\nComponent.py Polling Example from ossie.events import Manager from omniORB import CORBA, any class MsgData(object): def __init__(self): self.id = 0 self.data = \u0026#34;\u0026#34; def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ) if self.ecm: # request a Subscriber object for an event channel self.sub = self.ecm.Subscriber(\u0026#34;test1\u0026#34;) def decodeMsg(self, raw ): # unpack message back into mdict = any.from_any(raw) ret = MsgData() ret.id = mdict[\u0026#39;id\u0026#39;] ret.data = mdict[\u0026#39;data\u0026#39;] return ret def process(self): if self.sub: raw = self.sub.getData() if raw: msgin = self.decodeMsg(raw) self._log.info(\u0026#34;Received message = \u0026#34; +str(msgin.id)) Example of Python Subscriber Role Using callback Method The following is an example of a Python Subscriber role using the callback method.\nComponent.py Callback Example # Callback snippet example, define in Component.py from ossie.events import Manager from omniORB import CORBA, any class MsgData(object): def __init__(self): self.id = 0 self.data = \u0026#34;\u0026#34; def msg_cb(self, data): if data: # unpack message back into mdict = any.from_any(data) msg = MsgData() msg.id = mdict[\u0026#39;id\u0026#39;] msg.data = mdict[\u0026#39;data\u0026#39;] # do something with msg def constructor(self): # get access to the Event Channel Manager self.ecm = Manager.GetManager( self ); if self.ecm: # request a Subscriber object for an event channel self.sub = self.ecm.Subscriber(\u0026#34;test1\u0026#34;) self.sub.setDataArrivedCB( self.msg_cb ) Example of Java Subscriber Role Using getData Method The following is an example of a Java Subscriber role using the getData method.\nComponent.java Polling Example // add required imports  import org.omg.CORBA.Any; import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Subscriber; // add members to your component\u0026#39;s class  private org.ossie.events.Manager ecm; private org.ossie.events.Subscriber sub; public class MsgData { public int id; public String data; } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if ( this.sub == null ) { this.sub = ecm.Subscriber(\u0026#34;test1\u0026#34;); } } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle exceptions  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle exceptions  } } catch( org.ossie.events.Manager.OperationFailed e) { // handle exceptions  } } public void decodeMsg( org.omg.CORBA.Any any, MsgData msg ) { // decode message from CORBA.Any;  } protected int serviceFunction() { if ( this.sub != null ) { if ( this.sub.getData( any ) == 0 ) { MsgData msg = new MsgData(); decodeMsg( any, msg ); logger.info(\u0026#34;Received message = \u0026#34; + msg.id); } } } Example of Java Subscriber Role Using callback Method The following is an example of a Java Subscriber role using the callback method.\nComponent.java Callback Example // add required imports import org.omg.CORBA.Any; import org.omg.CORBA.ORB; import org.ossie.events.Manager; import org.ossie.events.Subscriber; import org.ossie.events.Subscriber.DataArrivedListener; // add members to your component\u0026#39;s class private org.ossie.events.Manager ecm; private org.ossie.events.Subscriber sub; public class MsgData { public int id; public String data; } public class MsgArrived implements DataArrivedListener { public [Component]() parent=null; public MsgArrived ( Component inParent ) { parent = inParent; } public void processData( final Any data ) { // decode message from CORBA.Any;  // do something with the message  } } public org.omg.CORBA.TypeCode getType () { return org.omg.CORBA.ORB.init().create_interface_tc(\u0026#34;IDL:MsgData/MsgData:1.0\u0026#34;, \u0026#34;MsgData\u0026#34;); } public void constructor() { try { this.ecm = Manager.GetManager( this ); try { if ( this.sub == null ) { this.sub = ecm.Subscriber(\u0026#34;test1\u0026#34;); this.my_ch = new MsgArrived(this); this.sub.setDataArrivedListener(this.my_cb ); } } catch( org.ossie.events.Manager.RegistrationFailed e) { // handle exceptions  } catch( org.ossie.events.Manager.RegistrationExists e) { // handle exceptions  } } catch( org.ossie.events.Manager.OperationFailed e) { // handle exceptions  } }"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/shared-memory/",
	"title": "Shared Memory Maintenance",
	"tags": [],
	"description": "",
	"content": " REDHAWK uses POSIX shared memory to provide optimized data transfer for Bulk Input/Output (BulkIO) connections between C++ components or devices on the same host. On Linux systems, POSIX shared memory is visible as a filesystem of type tmpfs mounted at /dev/shm. Files on this filesystem are backed by RAM and are not written to disk.\nThe shared memory used by REDHAWK is organized into heaps, one per process, that exist as files in /dev/shm. The heap is created on demand the first time the process attempts to allocate shared memory. In normal operation, the heap is removed by the process when it exits. Additionally, the REDHAWK GPP monitors its child processes and removes their heap files when the process crashes or is terminated abnormally. As such, heaps are typically only left behind when a component or device crashes in the Python Sandbox or the IDE Chalkboard. When this occurs, the heap is considered \u0026ldquo;orphaned.\u0026rdquo;\nIf shared memory is fully utilized, performance may be degraded because C++ components and devices will not be able to allocate additional shared memory for BulkIO data transfers. REDHAWK provides tools to help system maintainers view the state of their shared memory filesystem and remove unwanted files that are using shared memory.\nInspecting Shared Memory State The redhawk-shminfo program enables system maintainers to view the current state of their shared memory filesystem.\nBy default, it displays the total and current free shared memory amounts on the system, followed by a listing of REDHAWK heaps:\nredhawk-shminfo Example output:\n/dev/shm: size: 7.7G free: 7.6G (98.7%) heap-2286 type: REDHAWK heap file size: 60.1M heap size: 60.0M heap used: 32.0K (0.1%) creator: 2286 orphaned: false refcount: 2 user: redhawk group: redhawk mode: 640  Viewing REDHAWK heaps owned by other users may require superuser privileges.\n If a heap is listed as orphaned, the process that created it is no longer alive. Under normal circumstances, the heap is removed by the creating process or the REDHAWK GPP upon exit.\nWhen a shared memory file is removed, other processes that have mapped the memory can still access it, but no new processes may attach to it. The memory will not be returned to the free shared memory total until all attached processes have unmapped the memory or exited.\n Viewing All Shared Memory Files Other programs on the system may use shared memory as well. Although they are not listed when using redhawk-shminfo in its default mode, any memory that is in use by these files is counted against the free shared memory.\nTo view all shared memory files, use the --all or -a flag:\nredhawk-shminfo -a Example output:\n/dev/shm size: 7.7G free: 7.6G (98.4%) \u0026lt;...output elided...\u0026gt; pulse-shm-2249902370 type: other file size: 64.0M allocated: 4.0K user: gdm group: gdm mode: 400  REDHAWK heaps that cannot be read by the current user are displayed as files of type \u0026ldquo;other\u0026rdquo; when using --all.\nOnly the allocated size of files is counted against free memory. Shared memory files are sparse, meaning that no physical memory is dedicated until it is used. The total of all file sizes may therefore exceed the total shared memory on the system.\n Because the free shared memory takes into account files that were removed but are still mapped by active processes, it may be less than the total shared memory minus the sum of all REDHAWK heaps and other shared memory files. This memory will be reclaimed when the processes exit.\nCleaning Shared Memory With redhawk-shmclean The redhawk-shmclean tool can remove orphaned heaps and other shared memory files. With no arguments, it scans the entire shared memory filesystem and removes all orphaned heaps.\nredhawk-shmclean Example output:\nunlinking heap-2286  Removing REDHAWK heaps and shared memory files owned by other users may require superuser privileges.\n Removing Individual Heaps It is possible to remove one or more individual heaps by giving the heap names as arguments to redhawk-shmclean:\nredhawk-shmclean heap-2286 If the heap is not orphaned (that is, its creating process is still alive), redhawk-shmclean will refuse to remove it unless the --force or -f flag is given.\nRemoving Non-REDHAWK Files Because /dev/shm behaves like a regular UNIX filesystem, shared memory files can be removed with rm. It is also possible to remove these files with redhawk-shmclean using the --force or -f flag. Filenames must be relative to /dev/shm.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/deploying-projects/",
	"title": "Deploying Projects to the SDRROOT",
	"tags": [],
	"description": "",
	"content": "The following methods may be used to deploy a REDHAWK project into the target SDRROOT.\n Drag-and-drop from the Project Explorer:\n In the Project Explorer view, drag the top-level REDHAWK project onto the Target SDR in the REDHAWK Explorer view. In the REDHAWK Explorer view, expand Target SDR, then expand the appropriate sub-area: Components, Devices, Nodes, Services, or Waveforms, to display the deployed project.  From the Project menu:\n In the Project Explorer view, select the top-level REDHAWK project. From the Project menu, select Export to SDR.  From the Context menu:\n In the Project Explorer view, right-click the top-level REDHAWK project. Select Export to SDR.  From the Overview page of the Software Package Descriptor (SPD) Editor:\n Open the project’s spd.xml file. From the Overview tab of the SoftPkg Editor, in the Exporting section, click Export Wizard. In the Export Wizard, from the Available REDHAWK Projects section, check the desired projects to deploy. The Destination directory is prepopulated with the Target SDR. Click Finish to deploy selected projects into the Target SDR.  From the File menu:\n From the File menu, select Export. From the Export Wizard, expand REDHAWK Development and select Deployable REDHAWK Project. Click Next. From the Available REDHAWK Projects section, check the desired projects to deploy. The Destination directory is prepopulated with the Target SDR. Click Finish to deploy the selected projects into the Target SDR.   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/event-viewer-view/",
	"title": "Event Viewer View",
	"tags": [],
	"description": "",
	"content": "The Event Viewer view is used to listen to any event channel (for example, the default IDM_Channel or ODM_Channel for a domain) as well as message events emitted by MessageEvent ports. It also provides a means of filtering, sorting, and exporting the event traffic collected.\nThe following figure displays the Event Viewer view for the Outgoing Domain Management (ODM) channel.  Event Viewer View for ODM Channel   To listen to a channel from the REDHAWK Explorer view:\n Expand the domain.\n Expand the Event Channels folder.\n Right-click the desired channel, and select Listen to Event Channel.\nThe Event Viewer view for the selected channel is displayed and new events are added to the table.\n  To listen to a channel from the CORBA Name Browser view:\n Expand the Naming Service.\n Expand the domain.\n Right-click the desired channel, and select Listen to Event Channel.\nThe Event Viewer view for the selected channel is displayed, and new events are added to the table.\n  To listen to message events emitted by a uses (out) port from the Diagram tab:\n Right-click the port and select Listen to Message Events.\nThe Event Viewer view for the selected port is displayed and the message events are added to the table.\n  The controls in the upper right of the Event Viewer view provide the following functionality:\n To view details for events, click the See Details icon. The Properties tab is displayed with the all of the details for the selected event.  Properties tab with Event Details for the ODM Channel    To stop listening to a channel, click the Disconnect icon.\n To clear the logs, click the Clear icon.\n To ensure the view does not scroll automatically to the top as new events are received, click the Scroll Lock icon.\n  The controls at the bottom of the Event Viewer view enable the user to filter and search the event log.\nTo filter the event log:\n In the Filter field, enter the filter text for the event log. To remove the filter, click the Clear icon. To enable regular expressions in the Filter field, check the RE checkbox.  To search the event log:\n In the Search field, enter the text for which you want to search. To clear the search highlights from the event log, click the Clear icon. To enable regular expressions in the Search field, check the RE checkbox.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/messaging/",
	"title": "Messaging",
	"tags": [],
	"description": "",
	"content": "Messaging relies on CORBA’s event structure as a transport structure. In CORBA’s event API, messages are passed as an Any type using the function push().\nWhile CORBA manages marshaling and delivery of the data, it does not provide any mechanisms inherent to events to describe the contents of the Any type. REDHAWK decided to leverage an existing payload structure descriptor to describe the payload of messages, the properties Interface Description Language (IDL). The selection of this interface eliminates the need to create a new IDL describing messages. Furthermore, there is already an XML structure that is mapped to efficient binary data structures, allowing the use of XML to describe message contents while eliminating the need for introducing XML parsers in the message delivery mechanism.\nTo support this additional functionality, REDHAWK has expanded the properties descriptor to allow a property to have the kind message. The only property that can have a valid message kind is a structure.\n Message Producer   Message Consumer   Viewing Messages   Connecting Producers and Consumers   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/services/",
	"title": "Services",
	"tags": [],
	"description": "",
	"content": " In the context of REDHAWK, infrastructure software is managed by the Device Manager. Infrastructure software can take two forms: hardware management and system services. System services are the equivalent to Linux services like an HTTP server; the service does not directly control hardware but is some facility that becomes automatically available when the host is started.\nManagement A service is managed through the Device Manager. Nodes are described as a Device Manager instance and the set of devices and services associated with that Device Manager instance. When the Device Manager instance is created, it reads its configuration file (dcd.xml), which contains a list of all devices and services that the node contains. The devices and services are forked as individual processes and remain running until the Device Manager is shut down. Devices are bound to the Naming Service under the Device Manager’s context. Services, on the other hand, are bound to the domain’s naming context.\nService API REDHAWK does not include any standard service interfaces; the Software Communications Architecture (SCA) specification includes a logging service, but in REDHAWK, logging is performed through log4j/log4cxx.\nTo implement a service, it should use one of the standard REDHAWK interfaces, or a specialized interface to support some specific behavior. The specialized interface can be added using the SPD editor. The REDHAWK code generators provide the appropriate methods for the service’s selected interface. It is the developer’s task to implement the functionality of these methods. If the service is created with any of the following REDHAWK interfaces, LifeCycle: PropertySet, or PropertyEmitter, the same deployment behavior as used for a REDHAWK device is performed. That is, the Device Manager will try and call the service’s initializeProperties, initialize, and configure methods with the appropriate parameters.\nA service is created and torn-down by the Device Manager. Because there is no defined interface for the service, services do not support the LifeCycle interface, and more importantly, the releaseObject() method. Because there is no release method, the Device Manager issues operating-system level signals to terminate the Service. It is the developer’s task to perform whatever cleanup functionality is required in response to the receipt of a termination signal.\nFiles Defining a Service A service, much like a component or device, is a binary file and a set of XML descriptors, normally just the Software Package Descriptor (SPD) (describing the service’s software package) and Software Component Descriptor (SCD) (describing the service’s interfaces). The service file package resides in $SDRROOT/dev, usually in a services subdirectory or the devices subdirectory. More information can be found in the SPD editor section.\nFinding a Service Application descriptor files (sad.xml) are described in The Runtime Environment; these files describe a logical collection of components that are deployed to support some system-level application. In the application descriptor file, connections between deployed entities can be described in a variety of ways. These connection descriptions are how an application, or more specifically a component in an application, can interact with a service.\nThe Find By feature enables users to find services through either their (globally unique) name or by the interface that they support. Using a globally unique name as the search key allows a developer to specify an single instance of a service to connect to. On the other hand, by searching for a service through its supported interface, a developer can create a generalized search for a service that satisfies a particular need, irrespective of how it is associated with the Domain.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/connection-manager/",
	"title": "The Connection Manager",
	"tags": [],
	"description": "",
	"content": " The Connection Manager provides a single point for creation and inspection of connections between domain objects. Connections between domain objects can be defined on the Connection Manager irrespective of whether or not these objects are currently deployed. If one or more of the endpoints defined in a connection are not available, the connection is pending. Connections are resolved anytime domain objects enter or leave the domain.\nEndpoints can be applications, devices, services, event channels, or CORBA object references.\nInspecting Connections using the IDE To inspect the current connections using the IDE:\n In the REDHAWK Explorer view, right-click a Domain Manager and select Connection Manager.\nThe Connection Manager view is displayed. If a green check mark is displayed in the Connected column, this indicates that the connection has been made; otherwise, it is pending.  Connection Manager    To view the connection properties, select the connection in the Connection Manager view.\nThe Properties view displays the connection properties.  Connection Manager Properties    To view the source (provides/out port) of a connection, from the Connection Manager view, right-click the connection and select Find Source.\nThe source is highlighted in the REDHAWK Explorer view.\n To view the target (uses/in port) of a connection, from the Connection Manager view, right-click the connection and select Find Target.\nThe target is highlighted in the REDHAWK Explorer view.\n  Disconnecting Connections using the IDE To disconnect a current connection using the IDE:\n From the Connection Manager view, right-click the connection and select Disconnect.\nThe connection is disconnected.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/troubleshooting/",
	"title": "Troubleshooting",
	"tags": [],
	"description": "",
	"content": "For information on how to troubleshoot and resolve REDHAWK installation issues, omniNames and omniEvents failures, and connection issues, refer to the following:\n REDHAWK Installation Issues omniNames and omniEvents Issues Connection Issues  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/devices/",
	"title": "Working with Devices",
	"tags": [],
	"description": "",
	"content": "Devices in REDHAWK are generally used as proxies for hardware. As such, devices can be used to interact with the physical world, to run a component, or to interface with FPGAs.\n Using Devices to Interact with Hardware    Creating a FrontEnd Interfaces Device in the IDE     Interacting with an FEI Device with the Python Package     Using an FEI Device in the IDE      Associating a Waveform with an FEI Device     Using Devices to Run Components     Using Devices to Interface with FPGAs     Functions and Data Structures Provided by the FrontEnd Interfaces Library and Code Generators     Miscellaneous FrontEnd Tuner Library Implementation Details     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/connection-callbacks/",
	"title": "Connection Callbacks",
	"tags": [],
	"description": "",
	"content": " Within a component, many of the Uses port classes in REDHAWK support notification when a connection is made or broken. The supported port types and syntax vary by language.\nC++ In C++, the connection notification mechanism is standardized for Bulk Input/Output (BulkIO), Burst Input/Output (BurstIO), and Messaging Uses ports in C++. Connect and disconnect callbacks are registered with the port.\nThe following examples assume a C++ component with a BulkIO float output port, dataFloat_out; however, the syntax is the same for BurstIO and Message ports.\nIn the component header file, declare the callbacks as private member functions. Both connect and disconnect callbacks receive a single argument, the Connection ID (a std::string by reference):\nvoid dataFloatConnected(const std::string\u0026amp; connectionId); void dataFloatDisconnected(const std::string\u0026amp; connectionId); In the component source file, implement the callback functions:\nvoid MyComponent_i::dataFloatConnected(const std::string\u0026amp; connectionId) { LOG_INFO(MyComponent_i, \u0026#34;New connection \u0026#34; \u0026lt;\u0026lt; connectionId \u0026lt;\u0026lt; \u0026#34; on dataFloat_out\u0026#34;); } void MyComponent_i::dataFloatDisconnected(const std::string\u0026amp; connectionId) { LOG_INFO(MyComponent_i, \u0026#34;Disconnected \u0026#34; \u0026lt;\u0026lt; connectionId \u0026lt;\u0026lt; \u0026#34; on dataFloat_out\u0026#34;); } Then, in the component constructor(), register the callback functions:\ndataFloat_out-\u0026gt;addConnectListener(this, \u0026amp;MyComponent_i::dataFloatConnected); dataFloat_out-\u0026gt;addDisconnectListener(this, \u0026amp;MyComponent_i::dataFloatDisconnected); addConnectListener() and addDisconnectListener() take two arguments: the target object (typically this) and a pointer to a member function.\nIt is not necessary to register both a connect and disconnect callback.\n Java In Java, BulkIO and BurstIO Uses ports support connection notification using the listener pattern. The recommended style for Java connection notification is to define the callbacks as private methods on the component class, and use an anonymous subclass of the listener interface to dispatch the notifications to your callbacks.\nMessage ports do not support connection notification in Java.\nBulkIO BulkIO connection notification uses the bulkio.ConnectionEventListener interface, which has connect() and disconnect() methods that are called when the port makes or breaks a connection, respectively. Both methods receive a single argument, the Connection ID (a string).\nAdd to the list of imports:\nimport bulkio.ConnectionEventListener; Implement the callbacks as methods on the component class:\nprivate void dataFloatConnected(String connectionId) { this._logger.info(\u0026#34;New connection \u0026#34; + connectionId + \u0026#34; on dataFloat_out\u0026#34;); }private void dataFloatDisconnected(String connectionId) { this._logger.info(\u0026#34;Disconnected \u0026#34; + connectionId + \u0026#34; on dataFloat_out\u0026#34;); } In the constructor() method, register a ConnectionEventListener to dispatch connect and disconnect notifications to your callbacks:\nport_dataFloat_out.setConnectionEventListener(new ConnectionEventListener() { public void connect(String connectionId) { MyComponent.this.dataFloatConnected(connectionId); } public void disconnect(String connectionId) { MyComponent.this.dataFloatDisconnected(connectionId); } }); BurstIO BurstIO connection notification is similar to BulkIO but with a different listener interface, burstio.ConnectionListener. The connect and disconnect methods are named portConnected() and portDisconnected(), respectively.\nAdd to the list of imports:\nimport burstio.ConnectionListener; Implement the callbacks as methods on the component class:\nprivate void burstFloatConnected(String connectionId) { this._logger.info(\u0026#34;New connection \u0026#34; + connectionId + \u0026#34; on burstFloat_out\u0026#34;); }private void burstFloatDisconnected(String connectionId) { this._logger.info(\u0026#34;Disconnected \u0026#34; + connectionId + \u0026#34; on burstFloat_out\u0026#34;); } In the constructor() method, register a ConnectionListener to dispatch connect and disconnect notifications to your callbacks:\nport_burstFloat_out.addConnectionListener(new ConnectionListener() { public void portConnected(String connectionId) { MyComponent.this.burstFloatConnected(connectionId); } public void portDisconnected(String connectionId) { MyComponent.this.burstFloatDisconnected(connectionId); } }); Python In Python, only BurstIO Uses ports support connection notification.\nBurstIO Implement the callbacks as methods on the component class. Both methods receive a single argument, the Connection ID (a string):\ndef burstFloatConnected(self, connectionId): self._log.info(\u0026#39;New connection %son burstFloat_out\u0026#39;, connectionId) def burstFloatDisconnected(self, connectionId): self._log.info(\u0026#39;Disconnected %son burstFloat_out\u0026#39;, connectionId) In the constructor() method, register the callbacks:\nself.port_burstFloat_out.addConnectListener(self.burstFloatConnected) self.port_burstFloat_out.addDisconnectListener(self.burstFloatDisconnected) It is not necessary to register both a connect and disconnect listener.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/data-list-statistics-view/",
	"title": "Data List and Statistics Views",
	"tags": [],
	"description": "",
	"content": "The Data List and Statistics views are designed for simple runtime debugging of component ports.\n To open the Data List view, right-click a port of a started component.  Port Context Menu    From the context menu, select Data List.\nThe Data List view is opened:  Data List View    Select the preferred capture type:\n Number of Samples: Select a sample size Indefinitely: Collect until the user stops the process.  Select the Number of Dimensions of the sample data:\n Real Complex any positive integer number of dimensions  Click Start Acquire.\nAfter all desired samples have been acquired and displayed in the Data List table, two additional options are displayed:\n Save Chart  To open a wizard and write the data to a Midas BLUE file or a binary file, click Save.\n To open the Statistics view, which features a histogram and basic statistics of the sample data, click Chart:  Statistics View    There are two ways to change the dimensions displayed in the Statistics view:\n In the Data List view, click the column headers. In the Statistics view, from the View menu, select Settings. This opens the Chart Options dialog. In the Chart Options dialog, change the categories displayed in the chart:  Statistics View Chart Options Dialog   The chart and basic statistics refresh with each new collection of data in the Data List view.\n   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/events/",
	"title": "Events",
	"tags": [],
	"description": "",
	"content": " Events are heavily leveraged by REDHAWK to provide system awareness and exchange both synchronous and asynchronous data. This chapter describes the mechanics of creating and consuming events as well as standard event types defined in REDHAWK and how they are used. The methodology used to exchange synchronous and asynchronous data, although reliant on events as the communications mechanism, is discussed in Messaging.\nEvent Definition CORBA defines an interface for the transport of events as well as an interface for the creation of event channels that can support a publish/subscribe pattern; within REDHAWK, publishers are often described as producers, and subscribers are often described as consumers.\nIn REDHAWK, an event is defined as the payload sent on a single call to the push() function in the PushConsumer interface of the CosEventComm Interface Description Language (IDL) module.\nThe PushConsumer interface is as follows:\ninterface PushConsumer { void push (in any data) raises(Disconnected); void disconnect_push_consumer(); }; The description of the EventChannel interface and its use is complicated but luckily unnecessary for the use of events in REDHAWK. The main thing to be aware of regarding channels is that they provide a logical association between a plain text string (channel name) and an object that implements the interfaces necessary to interconnect producers and consumers, CosEventChannelAdmin::EventChannel. The EventChannel interface allows a producer or consumer to register itself with the event channel. This registration process gives the producer a reference to a virtual consumer where events can be pushed (recall that at the end of the day, CORBA is just an RPC mechanism). The registration process allows the consumer to give a reference to itself to a virtual producer, so that when an event becomes available, the correct function is invoked in the consumer. It is the job of the implementer of the EventChannel interface, also known as an Event Service, to maintain the registration interface as well as the different virtual producers and consumers necessary to re-direct all events to their appropriate destinations. The program omniEvents implements the EventChannel interface and enables the publish/subscribe pattern as described above; REDHAWK uses omniEvents as its Event Service.\nAn interesting aspect of the EventChannel interface is that there is no reason why that interface is implemented on a single central event broker. It is possible to create a consumer that implements both a consumer interface and the EventChannel interface. This allows that consumer to consume events either directly from a producer or indirectly through an Event Service. While a central event broker like omniEvents allows for the fluid addition of producers and consumers into the domain, the inherent latency to the distribution of the event can be significant (a single call for the publishing of the event, an intermediate process queuing that event, and then one or more pushes for the distribution of the event to one or more consumers). On the other hand, a point-to-point connection between a producer and a consumer removes the intermediary broker and enables low-latency messaging between components. In REDHAWK, low-latency point-to-point events are used only on messages, which are described in Messaging.\nStandard REDHAWK Events REDHAWK has defined several standard event types that can be used to monitor the overall state of a domain or individual components. The system management events are sent over the domain management channels. Individual component events are associated with property changes.\nREDHAWK defines an Outgoing Domain Management (ODM) channel as well as an Incoming Domain Management (IDM) channel. The ODM channel contains events that are generated by the Domain Manager which indicate the addition or removal of entities to and from the domain. The IDM channel contains events that are generated by devices which indicate changes in the state of a device.\nODM Channel The ODM channel contains event types used to describe the addition or removal of objects from the domain:\nstruct DomainManagementObjectAddedEventType { string producerId; string sourceId; string sourceName; StandardEvent::SourceCategoryType sourceCategory; Object sourceIOR; };struct DomainManagementObjectRemovedEventType { string producerId; string sourceId; string sourceName; StandardEvent::SourceCategoryType sourceCategory; }; Either event contains information as to who had something added/removed to/from it, the ID of the entity that was added/removed, the name of the entity that was added/removed, and the category of item that was added/removed. In the case of an added object, the Interoperable Object Reference (IOR) (stringified pointer to the object) is included in the event.\nThe category of item that was added or removed is of type SourceCategoryType, which is defined as:\nenum SourceCategoryType { DEVICE_MANAGER, DEVICE, APPLICATION_FACTORY, APPLICATION, [SERVICE]() }; The ODM channel can also contain an event type used to describe the state change of a resource, like an application:\nstruct ResourceStateChangeEventType { string sourceId; string sourceName; ExtendedEvent::ResourceStateChangeType stateChangeFrom; ExtendedEvent::ResourceStateChangeType stateChangeTo; } where ExtendedEvent::ResourceStateChangeType is defined as:\nenum ResourceStateChangeType { STOPPED, STARTED } IDM Channel The IDM channel can contain a StateChangeEventType event or a AbnormalComponentTerminationEventType event. The StateChangeEventType event is defined as:\nstruct StateChangeEventType { string producerId; string sourceId; StandardEvent::StateChangeCategoryType stateChangeCategory; StandardEvent::StateChangeType stateChangeFrom; StandardEvent::StateChangeType stateChangeTo; }; The producerId and sourceId of the event type are redundant; they are both the id of the device that is issuing the event.\nThe StateChangeCategoryType and StateChangeType are:\nenum StateChangeCategoryType { ADMINISTRATIVE_STATE_EVENT, OPERATIONAL_STATE_EVENT, USAGE_STATE_EVENT }; enum StateChangeType { LOCKED, UNLOCKED, SHUTTING_DOWN, ENABLED, DISABLED, IDLE, ACTIVE, BUSY }; The two enumerated types are closely linked; an ADMINISTRATIVE_STATE_EVENT can only contain states LOCKED, UNLOCKED, and SHUTTING_DOWN, while an OPERATIONAL_STATE_EVENT can only contain states ENABLED and DISABLED, and a USAGE_STATE_EVENT can only contain states IDLE, ACTIVE, or BUSY.\nThe AbnormalComponentTerminationEventType event is defined as:\nstruct AbnormalComponentTerminationEventType { string deviceId; string componentId; string applicationId; }; This event is triggered when a component abnormally terminates. The event contains the device ID that is producing the event, the component ID that terminated abnormally, and the application ID that hosts that component.\nProperty Change Events Whenever a property changes on a component or device, either through the internal update of the component property or through an external configuration update, an event can be triggered. Any consumer can be registered onto any component or device to listen to any arbitrary set of properties that the component or device may have.\nThe event type is PropertyChangeEvent, which is defined as:\nstruct PropertyChangeEvent { string evt_id; string reg_id; string resource_id; CF::Properties properties; }; Consuming Events Event consumption is meant as a system-level monitoring process. Therefore, REDHAWK does not include component ports that allow the consumption of these events. To monitor events over a given channel, a simple API is available. The Domain Manager contains the function registerWithEventChannel() to register a consumer to a given channel and unregisterFromEventChannel() to unregister a consumer from an event channel.\nA command-line tool is available that registers with event channels and displays the contents of the channel, eventviewer. The arguments to eventviewer are the name of the domain and the name of the channel.\nAn example of the use of eventviewer is described below:\n Start a Domain Manager:\nnodeBooter -D In a new terminal, attach the eventviewer to the domain’s ODM channel:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit In a new terminal, start a Device Manager:\nnodeBooter -d $SDRROOT/dev/nodes/DevMgr_localhost-localdomain/DeviceManager.dcd.xml On the Eventviewer terminal, the Device Manager and device registration are shown:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;,\u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_DeviceManager instance at 0x25160e0\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_AggregateExecutableDevice instance at 0x2d46638\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} Shutdown the Device Manager (Ctrl+C on the Device Manager terminal)\n On the Eventviewer terminal, the device and Device Manager unregistration is displayed:\neventviewer REDHAWK_DEV ODM_Channel Receiving events. Press \u0026#39;enter\u0026#39; key to exit {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_DeviceManager instance at 0x25160e0\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceIOR\u0026#39;: \u0026lt;ossie.cf.CF._objref_AggregateExecutableDevice instance at 0x2d46638\u0026gt;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:f5781785-9dd7-4873-8f30-99d7e2ca1a8f\u0026#39;, \u0026#39;sourceName\u0026#39;: \u0026#39;GPP_localhost_localdomain\u0026#39;, \u0026#39;sourceCategory\u0026#39;: DEVICE, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} {\u0026#39;sourceId\u0026#39;: \u0026#39;DCE:83f3c741-19bf-4794-877f-0322cd62290a\u0026#39;,\u0026#39;sourceName\u0026#39;: \u0026#39;DevMgr_localhost-localdomain\u0026#39;, \u0026#39;sourceCategory\u0026#39;: DEVICE_MANAGER, \u0026#39;producerId\u0026#39;: \u0026#39;DCE:516aa867-e262-4c70-8355-db415f4b0fc6\u0026#39;} Writing Your Own Event Consumer  In CORBA’s Event API, messages are passed as an CORBA::Any type, so when the event is consumed from an event channel, it arrives as a CORBA::Any type. The application eventviewer contains an example of how to create an event consumer.\nThe consumer object is an object that implements the PushConsumer interface.\nIn Python, the definition of such a class is:\nclass Consumer_i(CosEventComm__POA.PushConsumer): def __init__(self): pass def push(self, data): event = any.from_any(data) print event def disconnect_push_consumer (self): pass In the above example, the call to any.from_any converts from a CORBA::Any type to a Python dictionary.\nAn object of the class Consumer_i needs to be instantiated and given to the Domain Manager. In Python, the easiest way to access a running domain is to use the REDHAWK runtime package (a thorough description of the REDHAWK runtime package is available in Runtime Environment Inspection); in the case of a domain called REDHAWK_DEV, the process needed to associate this consumer with the event channel is:\nfrom ossie.utils import redhawk _consumer = Consumer_i() channel_name = \u0026#39;ODM_Channel\u0026#39; registration_id = \u0026#39;some random string\u0026#39; dom = redhawk.attach(\u0026#39;REDHAWK_DEV\u0026#39;) dom.registerWithEventChannel(_consumer._this(), registration_id, channel_name) In the example shown above, the consumer is attached to the ODM_Channel on the domain REDHAWK_DEV. The registration id is some string that can be used to uniquely identify this registration.\nUsing this id, to unregister the code the following method is invoked:\ndom.unregisterFromEventChannel(registration_id, channel_name) Cleaning up the Event Service Sometimes the system will fail in ways that the Event Service (omniEvents) will no longer be synchronized with the domain. When this happens, two utilities have been included with REDHAWK to help understand the state of the Event Service and clean it up if necessary.\nThe first tool is eventl, which lists all of the events that are currently being handled by the Event Service. The other tool is rmeventall, which cleans up all of the event channels that the Event Service is currently supporting.\nThe Event Channel Manager The Event Channel Manager provides a single point for creation and inspection of event channels on the domain. It also provides an interface for users to register publishers or subscribers to any of the available event channels.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/adminservice/support-files/",
	"title": "Linux Support Files",
	"tags": [],
	"description": "",
	"content": " In addition to running REDHAWK core services, the following support files are provided for REDHAWK logging properties, logging output files management, system limit definitions, and kernel setup.\nThe following table describes the support files.\nLinux Support File Descriptions    Support File Description     /etc/cron.d/redhawk Cron entry for root to run logrotate every 5 minutes with the configuration file /etc/redhawk/logging/logrotate.redhawk.   /etc/redhawk/logging/logrotate.redhawk logrotate configuration file to manage logfiles generated from REDHAWK services. Rotates all files in /var/log/redhawk/*.log when size exceeds 100 MB.   /etc/redhawk/logging/default.logging.properties Default logging configuration for a REDHAWK system. Defines all messages of INFO level or higher to append to the console, which is captured by the Domain Manager and Device Manager services.   /etc/redhawk/logging/example.logging.properties Logging configuration with example appenders that are supported by the REDHAWK logging subsystem.   /etc/redhawk/security/limits.d/99-redhawk-limits.conf Controls file and process limits associated with the redhawk group.   /etc/redhawk/sysctl.d/sysctl.conf Common kernel tuning parameters for network buffers and core file generation.    "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/logging-config-plugin/",
	"title": "Logging Configuration Plugin",
	"tags": [],
	"description": "",
	"content": " The Domain Manager may be extended to use a loadable library that can assist in the resolution of the LOGGING_CONFIG_URI parameter during application deployments. The following code and build files provide a template to build the loadable library: libossielogcfg.so.\nThe library should be installed in $OSSIEHOME/lib64 or $OSSIEHOME/lib depending on your hardware and operating system. If you choose to install the library in a different directory, you will need to add this path to LD_LIBRARY_PATH before starting the DomainManager. To enable this feature in the DomainManager, use the --useloglib option when launching the nodeBooter program.\nnodeBooter -D --useloglib LogConfigUriResolver Class and Example The LogConfigUriResolver class is the base class that your customized class will inherit. The class contains a single method get_uri, that will be used to resolve the logging configuration file location during deployment. The method accepts a single parameter path that describes the resource’s path in the Domain. The following list describes the different resource paths:\n Component\n syntax\nrsc:\u0026lt;DomainName\u0026gt;/\u0026lt;Application ID\u0026gt;/\u0026lt;Component's Naming Service Name\u0026gt;  example\nrsc:REDHAWK_DEV/TestWave_2/MyComp_4   Device\n syntax\ndev:\u0026lt;DomainName\u0026gt;/\u0026lt;Node ID\u0026gt;/\u0026lt;Device's Naming Service Name\u0026gt;  example\ndev:REDHAWK_DEV/Node_1/MyDevice_4   Service\n syntax\nsvc:\u0026lt;DomainName\u0026gt;/\u0026lt;Node ID\u0026gt;/\u0026lt;Service's Naming Service Name\u0026gt;  example\nsvc:REDHAWK_DEV/Node_1/MyRedis_3    Using this path, the customized code should return the location of a logging configuration file or an empty string (use current default resolution method). Logging configuration file locations should be formatted as follows:\n sca://path/to/config/file\nsca://logcfg/comp.log.cfg  file:///absolute/path/to/config/file\nfile:///var/redhawk/sdr/dom/logcfg/comp.log.cfg   The following example code creates a custom resolver class that provides logging configuration files from the local SDRROOT directory (file:///var/redhawk/sdr/dom/logcfg/device.log.cfg). The macro MAKE_FACTORY allows the class to be dynamically loaded by the Domain Manager.\n#include \u0026lt;ossie/logging/LogConfigUriResolver.h\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;sstream\u0026gt; class CustomLogConfigResolver : public ossie::logging::LogConfigUriResolver { public: CustomLogConfigResolver() {}; virtual ~CustomLogConfigResolver(){}; /** get_uri Return a string object that will be passed to a resource on the command line as LOGGING_CONFIG_URI parameter. An empty string will be ignored by the DomainManager. @param path Path of the resource in the domain. for components, rsc:\u0026lt;domain name\u0026gt;/\u0026lt;application name\u0026gt;/\u0026lt;component Naming Service name\u0026gt; e.g. rsc:REDHAWK_DEV/TestWave_2/MyComp_4 for devices, dev:\u0026lt;domain name\u0026gt;/\u0026lt;node name\u0026gt;/\u0026lt;device\u0026#39;s Naming Service name\u0026gt; e.g. dev:REDHAWK_DEV/Node_1/MyDevice_4 for service, svc:\u0026lt;domain name\u0026gt;/\u0026lt;node name\u0026gt;/\u0026lt;service\u0026#39;s Naming Service name\u0026gt; e.g. svc:REDHAWK_DEV/Node_1/MyRedis_1 */ std::string get_uri( const std::string \u0026amp;path ) { std::string sdrroot(\u0026#34;\u0026#34;); if ( ::getenv(\u0026#34;SDRROOT\u0026#34;)){ sdrroot = ::getenv(\u0026#34;SDRROOT\u0026#34;); } if ( path.find(\u0026#34;dev:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/device.log.cfg\u0026#34;; return std::string(os.str()); } if ( path.find(\u0026#34;svc:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/serviceq.log.cfg\u0026#34;; return std::string(os.str()); } if ( path.find(\u0026#34;rsc:\u0026#34;) != std::string::npos ) { std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;file://\u0026#34; \u0026lt;\u0026lt; sdrroot \u0026lt;\u0026lt; \u0026#34;/dom/logcfg/comp.log.cfg\u0026#34;; return std::string(os.str()); } // an empty string return value will be ignored by the DomainManager  return std::string(\u0026#34;\u0026#34;); }; }; MAKE_FACTORY(CustomLogConfigResolver); Build Files Use the following build files to compile and build the above example code in a file called ossielogcfg.cpp. The compiled code produces a library called libossielogcfg.so that is installed in $OSSIEHOME/lib or $OSSIEHOME/lib64. The build process follows the same paradigm as standard REDHAWK generated software: reconf; configure; make install.\nreconf Save the following code to a file called reconf, and make the file executable.\n#!/bin/sh  rm -f config.cache [ -d m4 ] || mkdir m4 autoreconf -i configure.ac Save the following code to a file called configure.ac.\nAC_INIT(ossielogcfg, 1.0.0) AM_INIT_AUTOMAKE([nostdinc foreign]) AC_CONFIG_MACRO_DIR([m4]) AC_PROG_CC AC_PROG_CXX AC_PROG_INSTALL AC_PROG_LIBTOOL AC_CORBA_ORB OSSIE_CHECK_OSSIE # TODO: Make this an installed macro OSSIE_SDRROOT_AS_PREFIX prefix=\u0026#34;${OSSIEHOME}\u0026#34; libdir=\u0026#34;${OSSIEHOME}/lib\u0026#34; AS_IF( [ test `uname -i` == \u0026#34;x86_64\u0026#34; ], [ libdir=\u0026#34;$prefix/lib64\u0026#34; ], [ libdir=\u0026#34;$prefix/lib\u0026#34; ] ) m4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])]) # Dependencies PKG_CHECK_MODULES([REDHAWK], [ossie \u0026gt;= 2.0]) OSSIE_ENABLE_LOG4CXX AX_BOOST_BASE([1.41]) AX_BOOST_SYSTEM AX_BOOST_THREAD AX_BOOST_REGEX AC_CONFIG_FILES([Makefile ]) AC_OUTPUT Makefile.am Save the following code to a file called Makefile.am.\nRemember to replace the spaces before rm -rf m4 with a tab to prevent the Makefile.am file from crashing.\n ACLOCAL_AMFLAGS = -I m4 -I${OSSIEHOME}/share/aclocal/ossie AUTOMAKE_OPTIONS = subdir-objects lib_LTLIBRARIES = libossielogcfg.la xmldir = $(prefix) dist_xml_DATA = distclean-local: rm -rf m4 libossielogcfg_la_SOURCES = ossielogcfg.cpp libossielogcfg_la_LIBADD = $(REDHAWK_LIBS) libossielogcfg_la_CPPFLAGS = -I . -I $(srcdir)/include $(REDHAWK_CFLAGS) $(BOOST_CPPFLAGS) libossielogcfg_la_CXXFLAGS = -Wall"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/nodes/",
	"title": "Nodes",
	"tags": [],
	"description": "",
	"content": "In The Runtime Environment, the Device Manager is introduced along with its primary role: to deploy and manage device proxies in whatever host the Device Manager has been launched. The term node is used to refer to the Device Manager and its associated devices and services.\nThe concept of a device and its relationship with the deployment of a set of components in an application is one of the more complicated concepts in REDHAWK. A device is a program that the Domain Manager interacts with to determine whether or not a component can run on the host where that device is located. If it is determined that the device can host that component, the device provides the Domain Manager with the API necessary to load the component binaries over the network and execute them. In short, the device provides the remote host discovery mechanism to the Domain Manager and the mechanism needed to load and execute whatever component files are needed to run the component on the device host.\nThis chapter provides a description of how to interact with devices and nodes using the REDHAWK IDE.\n Running a Node     Creating a New Node     Distributed Computing and RF Devices     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/snapshot-tool/",
	"title": "Snapshot Tool",
	"tags": [],
	"description": "",
	"content": "The Snapshot Tool enables users to save data from any Bulk Input/Output (BulkIO) port to a file. The following procedure explains how to use the Snapshot Tool.\n To open the Snapshot Wizard, right-click an output port in the Chalkboard or the REDHAWK Explorer and select Snapshot from the context menu:  Output Port Context Menu   The Snapshot Wizard is displayed:  Snapshot Wizard    To specify how much data is captured, select the capture mode from the first combo box. The following capture modes are supported:\n Number of Samples: Collects the number of samples specified by the text field to the right. Indefinitely: Collects samples until the user stops the snapshot or an End of Stream (EOS) occurs. Clock Time: Collects samples for a set period of time in real time set by the text field to the right (in seconds). Sample Time: Collects samples for a period of time as specified by the delta and number of samples (time = delta * number of samples), set in the text field to the right.  Optionally, enter a custom Connection ID in the Connection ID (Optional) field.\n To specify the file type to use when saving data, select a file type from the File Type combo box. The supported file types include:\n Binary files (.bin \u0026amp; .SRI): Saves data from the port to a .bin file and saves the metadata (Signal Related Information (SRI), start time, end time, data type, and number of samples) to an .SRI file. Binary files (.bin \u0026amp; .xml): Saves data from the port to a .bin file and saves the metadata (SRI, start time, end time, data type, and number of samples) to an .xml file. Midas BLUE File (.tmp): Saves output data and metadata to a BLUE .tmp file.  To specify where to save the file, you have two options.\n To save the file to a location other than the workspace, deselect the Save to Workspace checkbox, click Browse, navigate to the desired location, and click OK. To save the file in the workspace, select the Save to Workspace checkbox and select the file or directory in the displayed tree of workspace files and folders. Saving the file in the workspace automatically refreshes the project, and the files can be accessed in the IDE.  Snapshot Save to Workspace Navigation Tree   To add folders to the workspace, right-click the existing folder where the new folder is desired. A New Folder window is displayed. Enter the name of the folder and click Finish.  Snapshot New Folder Window   To delete files from the workspace, right-click the item you want to delete and select Delete. When prompted, verify the deletion request.\n  To be prompted before existing files are overwritten when the new snapshot is created, select the Confirm overwrite checkbox. If this option is not selected, any existing files are automatically overwritten when the new snapshot is created.\n Click Finish.\nThe Progress view is displayed. To stop a snapshot prematurely, click Cancel Operation (the red square icon) next to the job in the Progress view.  Snapshot - Progress View   When the snapshot completes, the completed job is shown in the Progress view:\n Snapshot - Completed Job    To view the results of the snapshot, click Finished. The following output message is displayed:  Snapshot - Results Dialog   If only a few files are written, then the output message lists all the files created by the snapshot. If a large number of files are written, the output message lists the base name of the files and the number of each type of file made.\n Click OK.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/connect-wizard/",
	"title": "Connect Wizard",
	"tags": [],
	"description": "",
	"content": "The Connect Wizard enables users to manually create a connection between two ports of compliant types and create a custom Connection ID. The following procedure explains how to use the Connect Wizard.\n To open the Connect Wizard, in the Chalkboard or the REDHAWK Explorer, right-click a port and select Connect from the context menu:  Port Context Menu in REDHAWK Explorer   The Connect Wizard is displayed:  Connect Wizard    Under Source, select a uses (output) port.\n Under Target, select a provides (input) port, or a resource such as a component or device.\n In the Connection ID text box, enter a Connection ID.\n Click Finish.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/connections/custom-idl-interfaces/",
	"title": "Custom IDL Interfaces",
	"tags": [],
	"description": "",
	"content": " REDHAWK provides Front End Interfaces (FEI) and standard Core Framework (CF) interfaces (like CF::Resource) to control entities and promote interoperability. There are some use cases where you may find the need to use custom Interface Description Language (IDL) to control entities. For these use cases, you can create custom IDL projects in the IDE.\nAdding ports from either the FEI interface or a custom IDL interface to a component or device allows that entity to control other entities through CORBA. Because of the generic nature of these ports, it is not possible to create a language mapping like BulkIO, so interaction is through the standard CORBA API, a full description of which is outside the scope of this manual. However, the REDHAWK code generators will generate ports that simplify the interaction with the port. The following sections explain uses (output) ports because they are the most likely to be generated, for example, to control FEI devices.\nConnectivity Feedback In all three supported languages, an FEI, standard CF, or custom IDL port will have all methods and attributes mapped to the port, and the port will then delegate the call to the remote connection. In REDHAWK, it is possible for a port to have no connections, one connection, or many connections. Each of these conditions can create issues for someone using a port for communications; for example, if a control request is sent out and there are no connections, then the user should be informed that the request did not go anywhere.\nAt the same time, not all methods are the same. Some methods push data in only one direction, some methods have a return value, and some methods have arguments that are pointers to be filled with information (out or inout arguments). When a port method is called and it is not possible for the port to make a call or for the call to be unambiguous (for example, if two connections exist and the function contains a return value), then a PortCallError is raised in the user code. The table below describes the method signature criteria met and its corresponding behavior.\nControl method and error conditions based on connectivity    method return value argument direction specified Connection ID no connection one connection many connections     void in only None ok ok ok   Non void in only None Error ok Error   All types in only valid ID Error ok ok   All types inout and/or out None Error ok Error   All types inout and/or out valid ID Error ok ok   All types any direction invalid ID Error Error Error    If a method has any kind of return value as part of its non-exception API (manifested as a non-void return value, or an out or inout argument), then an exception is raised if there is more than one connection out of the port. Furthermore, if a call is attempted with no connection in effect, an error is raised.\nConnection Selection While the generated port class triggers an error when the desired connection is ambiguous, it also contains an API to allow the developer to select which connection should be exercised. Each method has an optional argument, connection_id, that allows the caller to disambiguate which connection should be exercised. The default value behavior will use the last connection made. If the connection_id specified does not exist, a PortCallError will be raised.\nIn the following sections, the same pattern used to disambiguate the connections is provided in all three supported languages.\n The following code example uses the default behavior when calling the read method of the CF::File interface.\nCF::OctetSequence_var _data = new CF::OctetSequence(); CF::OctetSequence_out data(_data); this-\u0026gt;file_out-\u0026gt;read(data, 10); // read 10 characters from the last connection made to the port The following code example disambiguates the read call to a specific connection, connection1.\nCF::OctetSequence_var _data = new CF::OctetSequence(); CF::OctetSequence_out data(_data); this-\u0026gt;file_out-\u0026gt;read(data, 10, \u0026#34;connection1\u0026#34;); // read 10 characters from the connection called \u0026#34;connection1\u0026#34; To view the connections that are available, use the following code:\nstd::vector\u0026lt;std::string\u0026gt; _connection_ids = this-\u0026gt;file_out-\u0026gt;getConnectionIds(); Method Mapping Method name mapping follows the pattern described in Connection Selection; namely that methods have the same name as described in the IDL with an additional argument (to be optionally exercised) that can specify which connection should be used. Attributes are mapped as functions to the CORBA objects. REDHAWK provides additional APIs to disambiguate these calls for multiple connections.\nReading Attributes Reading attributes is performed by invoking the name of the attribute as a function. For example, if the port, my_port, contains the string attribute greeting, the value of greeting can be retrieved as follows:\nstd::string _greeting = this-\u0026gt;my_port-\u0026gt;greeting(); To retrieve the value from a specific connection, the _get_ prefix is needed:\nstd::string _greeting = this-\u0026gt;my_port-\u0026gt;_get_greeting(\u0026#34;some_connection_name\u0026#34;); Writing Attributes Writing attributes in C++ and Java involves invoking the function with the appropriate argument:\nthis-\u0026gt;my_port-\u0026gt;greeting(\u0026#34;hello\u0026#34;); // write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34;  this-\u0026gt;my_port-\u0026gt;greeting(\u0026#34;hello\u0026#34;, \u0026#34;some_connection_name\u0026#34;); // write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; over connection \u0026#34;some_connection_name\u0026#34; Python requires the prefix _set_ because it cannot be overloaded:\nself.my_port._set_greeting(\u0026#34;hello\u0026#34;) # write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; self.my_port._set_greeting(\u0026#34;hello\u0026#34;, \u0026#34;some_connection_name\u0026#34;) # write \u0026#34;hello\u0026#34; to the attribute \u0026#34;greeting\u0026#34; over connection \u0026#34;some_connection_name\u0026#34;"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/acronyms/",
	"title": "List of Acronyms",
	"tags": [],
	"description": "",
	"content": " AGC  Auto Gain Control  AJAX  Asynchronous JavaScript and XML  API  Application Programming Interface  AST  Abstract Syntax Tree  BulkIO  Bulk Input/Output  BurstIO  Burst Input/Output  CDT  C/C++ Development Tools  CentOS  Community Enterprise Operating System  CF  Core Framework  CORBA  Common Object Request Broker Architecture  CVS  Concurrent Versions System  DCD  Device Configuration Descriptor  DCE  Distributed Computing Environment  DDC  Digital Down Converter  DMD  Domain Manager Configuration Descriptor  DPD  Device Package Descriptor  DSP  Digital Signal Processing  DTD  Document Type Definition  EFS  Eclipse File System  EMF  Eclipse Modeling Framework  EOS  End of Stream  EPEL  Extra Packages for Enterprise Linux  FEI  FrontEnd Interfaces  FFT  Fast Fourier Transform  FPGA  Field-programmable gate array  FM  Frequency Modulation  GMF  Graphical Modeling Framework  GPP  General Purpose Processor  GUI  Graphical User Interface  HTTP  Hyper Text Transport Protocol  IDE  Integrated Development Environment  IDM  Incoming Domain Management  IF  Intermediate Frequency  IOR  Interoperable Object Reference  ID  Identifier  IDL  Interface Description Language  JAR  Java ARchive  JDT  Java Development Tools  JEE  Java Platform, Enterprise Edition  JTRS  Joint Tactical Radio System  MB  Megabyte  NOOP  No Operation  ODM  Outgoing Domain Management  OS  Operating System  OSGi  Open Services Gateway initiative  PDE  Plug-in Development Environment  PID  Process Identifier  POSIX  Portable Operating System Interface  PRF  Properties File  PSD  Power Spectral Density  PyDev  Python Development  RCP  Rich Client Platform  RF  Radio Frequency  RHEL  Red Hat Enterprise Linux  RPC  Remote Procedure Call  RPM  Red Hat Package Manager  SAD  Software Assembly Descriptor  SCA  Software Communications Architecture  SCD  Software Component Descriptor  SDR  Software-Defined Radio  SPD  Software Package Descriptor  SRI  Signal Related Information  SWT  Standard Widget Toolkit  UDP  User Datagram Protocol  UI  User Interface  URI  Uniform Resource Identifier  URL  Uniform Resource Locator  UUID  Universally Unique Identifier  VLAN  Virtual Local Area Network  VM  Virtual Machine  WAR  Web ARchive  XML  Extensible Markup Language  XSD  XML Schema Definition  UTC  Coordinated Universal Time  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/port-monitor-view/",
	"title": "Port Monitor View",
	"tags": [],
	"description": "",
	"content": " The Port Monitor view enables you to monitor the amount of data flowing out of or into a particular port. These statistics are helpful when debugging and can help identify which component is slowing down or dropping information during data processing.\nTo open the Port Monitor view, right-click the port of a started component and select Monitor Ports from the context menu:  Port Context Menu   The Port Monitor view is opened:  Port Monitor View   The view displays the following information:\n Name: The name of the port or port connection. Elements/sec: The rate of elements transferred in the pushPacket data call. Bytes/sec: Bytes transferred per second. Calls/sec: Number of push calls per second to the port. Stream ID(s): List of all active Stream IDs. Avg. Queue Depth: For components that queue data before processing/sending, the average queue depth measured as a percentage. If a port does not queue data, this value is set to zero. Time: The elapsed time, in seconds, since the last packet was transferred via a push packet call.  The following actions are available in the Port Monitor view.\n To Configure the Port Monitor view:\n From the View menu, select Configure.  The Port Monitor Configuration dialog box is displayed.  Port Monitor Configuration Dialog   The following options can be configured:\n Refresh Interval (sec): The time interval between fetching the port statistics. Column Configuration: Specifies which columns are visible.  To force a refresh of any connection or port:\n Right-click the item. Select Refresh.  To stop monitoring:\n Right-click the item. Select Stop Monitoring.   Port Monitoring in a Diagram If a diagram is open while monitoring ports, the diagram display changes the colors of connections and provides (in) ports to reflect the statistics. A green connection indicates that data is flowing. A yellow connection indicates it has been more than 1 second since data was pushed over the connection, which may indicate a data flow issue.\nFor provides (in) ports, a green port indicates the port\u0026rsquo;s queue has plenty of space left. After the queue depth reaches 60 percent, the port color changes to yellow, and the port color slowly changes to red as the queue depth approaches 100 percent. Additionally, if there is a queue flush, the port remains red for 30 seconds after that queue flush.\nTo configure the threshold values that trigger color changes for port statistics:\n Select Window \u0026gt; Preferences. Select the REDHAWK \u0026gt; Diagrams \u0026gt; Port Statistics page. Change the values. Click Apply and Close.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": "Components can run in either the sandbox or in a domain. The Sandbox is an environment to run components and devices without artifacts like a Domain Manager, Device Manager, Name Service, or event service.\nREDHAWK provides two sandboxes, a Python-based one or an IDE-based one. The Python-based sandbox can run from any Python session on any system with a REDHAWK install. The IDE-based sandbox can host an instance of a Python-based sandbox, with both interlinked, allowing artifacts from the Python environment to interact with those on the graphical UI.\n Python Sandbox    Working with Components, Devices, and Services     Helpers     Devices     Example Sandbox Interaction     Built-in Sources and Sinks     Working with SDDS Data     Plotting Data     Miscellaneous      IDE Sandbox     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/sri-view/",
	"title": "SRI View",
	"tags": [],
	"description": "",
	"content": "The Signal Related Information (SRI) view enables the user to view the SRI data from a particular port. The following procedure explains how to open the SRI view.\n To open the SRI view, right-click the port of a started component and select Display SRI from the context menu:  Port Context Menu with Display SRI Selected   The SRI view is opened:  SRI View    The following options are available in the SRI view.\n To clear the display of specific SRI data once an End of Stream (EOS) has been received, click Clear Selected SRI. To clear the display of all SRI data once the respective EOSs have been received, click Clear All SRIs. To pause the SRI data, click Pause Incoming SRI Data. To receive notification when new SRI data is displayed, click Notify on receiving new Push SRI. To change the active SRI data stream between different active components, click Change Active Stream. To generate both an .xml and a .SRI file for each stream being monitored, click Save SRI Data to file.   If a component is deleted from the Chalkboard, the SRI view closes automatically.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-environment/",
	"title": "The Runtime Environment",
	"tags": [],
	"description": "",
	"content": "The REDHAWK runtime environment provides a mechanism for managing the life cycle (creation/tear down/initialization) of components as well as the interconnection of deployed components.\nThe primary goal of the runtime environment is to support the necessary infrastructure to deploy and manage interconnected components as a running application.\nThe runtime environment is personified by two binaries, a Domain Manager program and a Device Manager program. The Domain Manager program hosts an instance of a DomainManager class as well as supporting objects (ApplicationFactory, Application, FileManager). The Device Manager program hosts an instance of a DeviceManager object and an instance of a File System. The only reason why the major classes making up these programs are imported is because their API is remotely available, so a user can arbitrarily interact with these objects. Irrespective of their API, these objects exclusively reside in either the Domain Manager or Device Manager programs.\nA single REDHAWK system instance has one Domain Manager and an arbitrary number of Device Managers. The Domain Manager’s role is as a central bookkeeper as well as a single point where applications can be deployed or torn down. A Device Manager is present in each host in the REDHAWK network area; in a purely processing context, there would be a single Device Manager in each computer that is intended to host running components. Each Device Manager has associated with it a set of devices that act as proxies for whatever hardware is running on the computer; in a purely processing context, there is a single device proxy describing the microprocessor for each hardware platform Device Manager.\nThe Domain Manager program:\n receives an XML file describing a waveform that is to be deployed. scans all running devices on all Device Managers for a suitable place to deploy the components making up the waveform. uses the File Manager / File System to copy whatever files are necessary to run the components to the target Device Managers. remotely invokes the component processes. interconnects components over the network. tears down applications appropriately.   Launching a Domain     Domain Manager     File System     Applications     The Application Factory     The Device Manager     The Allocation Manager     The Connection Manager     Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/octave-wizard/",
	"title": "Using the Octave Wizard",
	"tags": [],
	"description": "",
	"content": "The Octave Wizard enables users to import existing Octave M-files for easy conversion into REDHAWK C++ components. The user imports an existing M-file, as well as any required dependent M-files, and then maps the M-file’s inputs and outputs to REDHAWK ports and properties. The following procedure explains how to use the Octave Wizard.\n To open the Octave Wizard, select File \u0026gt; New \u0026gt; Other.\nThe Select a wizard page is displayed:  Select a Wizard Dialog    Select REDHAWK Octave Project and click Next.\nThe Create a REDHAWK Component Project page is displayed:  Create a REDHAWK Component Project Page    In the Project name field, enter a project name and click Next.\nThe New Implementation page is displayed:  New Implementation Page    Enter an ID and a description for this component implementation and click Next.\nThe New M-File page is displayed:  New M-File Page    In the Primary M-file field, enter the location of the Octave M-file you want to import or click Browse and navigate to the file. If the primary M-file depends on non-standard methods, select Primary M-file depends on non-standard M-files and select the dependent M-files. Click Next.\nThe Map M-file page is displayed:  Map M-file Page    The Map M-file page enables the user to map the Octave inputs and outputs to REDHAWK ports or properties. The Name/id field contains the names contained in the M-file. You have the following options for both Inputs and Outputs:\n In the Mapping field, select to map to either a Property (Simple), a Property (Sequence) or a port. In the Type field, select to map to either a String, a Double (Real) or Double (Complex) variable type.  Click Finish.\nThe Octave M-file based component is created.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/console-view/",
	"title": "Console View",
	"tags": [],
	"description": "",
	"content": "The Console view is a part of Eclipse and the basic use is well documented by the Eclipse documentation. The REDHAWK IDE uses multiple consoles for different purposes.\nThe primary consoles found in the REDHAWK IDE are:\n Domain \u0026amp; Device Manager: When a Domain or Device Manager is launched, a new Console view is created. These new consoles contain an instance of a running nodeBooter. By default, log messages, standard out, and standard error messages for components and devices are written to the Device Manager console. Domain Manager related messages, including waveform creation and resource allocation are written to the Domain Manager’s console.\n C++ builds: Compiling a C++ device or component creates a C-build console, which runs the component/device build script. While Eclipse does a relatively good job of parsing build output and providing in-context error indicators, it is sometimes helpful to view the output of the build from the console.\n Code Generators: When automatically generating code for a component or device, the appropriate code generator console is displayed and contains information pertaining to the code generation.\n Python Sandbox: The Python Sandbox is a powerful tool for testing and interacting with components and devices. A Python Sandbox may be created from within the IDE to aid in testing.\n Other Consoles: Additional consoles (not described in this section) are available, including PyDev Scripting, Java Stack Trace, etc. These are part of Eclipse or part of third party plug-ins such as PyDev.\n  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/plot-port-wizard/",
	"title": "Plot Port Wizard",
	"tags": [],
	"description": "",
	"content": "The Plot Port Wizard enables users to choose the settings for a plot before opening the Plot view. The following procedure explains how to use the Plot Port Wizard.\n In the REDHAWK Explorer or any running diagram (Chalkboard or Waveform running on a Domain), to open the Plot Port Wizard, select an output port, then right-click the selected port and select Plot Port \u0026hellip; from the context menu:  Port Context Menu   The Plot Port Wizard is displayed:  Plot Port Wizard    Select a Type. The following types are available:\n DOT LINE POINT RASTER  Select a Mode. The following modes are available:\n Auto Imaginary Magnitude Phase Real Real and Imaginary Real vs Imaginary 10 Log 20 Log  Select a Frame Size. This enables you to override the value in StreamSRI, which is the default. You may choose one of the existing values or enter a custom value, for example, 16000.\n Optionally, enter a value for Refresh Rate (fps):. This enables you to perform smart thinning of the line plot based on screen frames per second. To disable smart thinning, enter 0. The default value of 30 fps will be used if the field is left blank.\n Optionally, enter a value for Line Plot Frame Thinning. You may thin the line plot by displaying 1 out of every n frames. For no thinning, enter -1. The default value of 8 will be used if the field is left blank.\n Optionally, in the Connection ID field, enter a custom Connection ID.\n To override the value in StreamSRI (the default), in the Sample Rate field, enter a custom sample rate.\n To select a blocking option for pushPacket when the plot is not able to keep up with the data stream, select one of the radio buttons in Blocking option:\n non-blocking - Do not block incoming data. blocking - Block incoming data. use SRI.blocking (default) - Set the blocking based on the StreamSRI.blocking field received from the pushSRI() call.  To remove the stream when an End of Stream (EOS) is received, select the Remove Stream from Plot on End Of Stream checkbox.\n To plot a Fast Fourier Transform (FFT) of the signal, select the Take FFT checkbox. You have six options for the FFT:\n Select a Transform Size from the list or enter a custom value (Performance is best if the transform size is factorable by 2, 3, 4, and 5). Enter the Percent Overlap. Enter the Num Averages. Enter the Sliding Num Averages. Select the Output Type. The following types are available:\n Normal Magnitude Squared Power Spectral Density  Select a Window. The following windows are available:\n Bartlett Hanning Hamming Blackman-Harris Blackman   Click Finish.\n  The Plot view is displayed with the desired settings.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/editors-and-views/properties-view/",
	"title": "Properties View",
	"tags": [],
	"description": "",
	"content": "The Properties view provides the ability to view and edit properties of the current selection in the IDE. The view is context-specific, and will change based on the selection.  Properties View   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/runtime-inspection/",
	"title": "Runtime Environment Inspection",
	"tags": ["sandbox"],
	"description": "",
	"content": " During runtime, there are a large number of operations that are handled under the hood by the REDHAWK Core Framework (CF). At times though, it becomes necessary to take a closer look at these underlying parts to ensure that they are working properly or to inspect what kind of a state they are currently in. REDHAWK provides tools to help accomplish this task.\nREDHAWK Module A Python module called REDHAWK is provided with the capability to interact with running domains, devices, waveforms and components. This allows for individual control and assessment over all aspects of a runtime environment.\nIn order to use the REDHAWK utility module, begin a Python session from a terminal and enter the following command:\nfrom ossie.utils import redhawk The REDHAWK module is built on the same foundation as the Sandbox, and provides a compatible interface for domain objects. Sandbox objects, including plots, can be dynamically connected to devices, waveforms and components running in the domain.\nRefer to Working with Components, Devices, and Services for more information.\nAttach The module provides the ability to attach to a running domain.\nThis allows the user access to the underlying API of the Domain Manager in addition to other useful functionality: - createApplication() - install/create a particular waveform - removeApplication() - release a particular waveform\nTo attach to an existing domain, the name must be passed as an argument.\nAssuming the domain name is MY_DOMAIN, start a Python script and enter:\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach(\u0026#34;MY_DOMAIN\u0026#34;) Note that if there is only 1 Domain visible, no argument is needed for the attach call:\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.attach() Once attached to the running domain, waveforms that are installed in the $SDRROOT can easily be launched using the createApplication() function:\n\u0026gt;\u0026gt;\u0026gt; wave = domain.createApplication(\u0026#34;/waveforms/wave/wave.sad.xml\u0026#34;) Upon success, the above call returns an Application object which gives access to the external resource API. This allows for manual operation of the application. In addition, functions exist to allow the user to connect and disconnect ports. Finally, in order to inspect the current conditions of the waveform, an API function call is available. This shows any external ports, components that are in the application, and their properties.\n\u0026gt;\u0026gt;\u0026gt; wave \u0026lt;ossie.utils.redhawk.core.App object at 0x2bfb350\u0026gt; \u0026gt;\u0026gt;\u0026gt; wave.api() Waveform [wave_025_090314360_1] --------------------------------------------------- External Ports ============== Provides (Input) Ports ============== Port Name Port Interface --------- -------------- external_in IDL:BULKIO/dataChar Uses (Output) Ports ============== Port Name Port Interface --------- -------------- external_out IDL:BULKIO/UsesPortStatisticsProvider Components ============== 1. Sink 2. Source (Assembly Controller) Properties ============== Property Name (Data Type) [Default Value] Current Value ------------- ----------- --------------- ------------- sample_size (long/SL/32t) None None Once finished, the waveform needs to be removed from the domain by using the removeApplication() method:\n\u0026gt;\u0026gt;\u0026gt; domain.removeApplication(wave) Starting a Domain from within a Python session Normally, the REDHAWK Python package is used to either interact with a running domain, or to launch some Sandbox components. However, sometimes it may be required to launch a domain from a Python script.\nTo help in such a scenario, the REDHAWK Python package includes some helper functions. The kickDomain feature allows for an easy way to launch domain and Device Managers from within a Python script. With no arguments, the function launches and returns the Domain Manager that is installed in $SDRROOT. Additionally, all Device Managers in $SDRROOT/dev/nodes are started.\nOther arguments to the function exist to control different aspects to how the domain is started. A list of specific Device Managers to start can be passed if the user does not want to start all available. If the $SDRROOT that the user wishes to use is not in the standard location, a path can be supplied to direct the function to the desired place in the file system. Standard out and logging to a file can also be set.\n\u0026gt;\u0026gt;\u0026gt; domain = redhawk.kickDomain() INFO:DomainManager - Starting Domain Manager INFO:DeviceManager - Starting Device Manager with /nodes/DevMgr_localhost.localdomain/DeviceManager.dcd.xml INFO:DomainManager - Starting ORB! INFO:DeviceManager_impl - Connecting to Domain Manager MY_DOMAIN/MY_DOMAIN INFO:DeviceManager - Starting ORB! \u0026gt;\u0026gt;\u0026gt; INFO:DCE:9d9bcc38-d654-43b1-8b74-1dc024318b6f:Registering Device INFO:DeviceManager_impl - Registering device GPP_localhost_ localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Initializing device GPP_localhost_ localdomain on Device Manager DevMgr_localhost.localdomain INFO:DeviceManager_impl - Registering device GPP_localhost_ localdomain on Domain Manager \u0026gt;\u0026gt;\u0026gt; domain \u0026lt;ossie.utils.redhawk.core.Domain object at 0x2da6710\u0026gt; The ability to search for domains is also available through the scan function which searches the Naming Service.\n\u0026gt;\u0026gt;\u0026gt; redhawk.scan() [\u0026#39;MY_DOMAIN\u0026#39;] Domain State The domain proxy tracks the current state of the domain. For aspects of the domain state that may take a long time to process, scanning is deferred until the first access. If the Outgoing Domain Management (ODM) Channel is available, devices, Device Managers, and waveforms are tracked as they are added to and removed from the domain. Otherwise, the domain is re-scanned on access to ensure that the state is accurate.\nApplications The domain proxy provides a list of waveforms currently running via the apps attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.apps [\u0026lt;ossie.utils.redhawk.core.App object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The App class supports many of the Sandbox interfaces, such as properties, connect() and api().\nThe components within the waveform are available via the comps attribute:\n\u0026gt;\u0026gt;\u0026gt; app = domain.apps[0] \u0026gt;\u0026gt;\u0026gt; app.comps [\u0026lt;ossie.utils.redhawk.component.Component object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The REDHAWK module component class supports the same interfaces as sandbox components. Much like in the sandbox, ports, properties, and any other feature of a component is equally accessible from the Python environment, regardless of how the component was deployed.\nFor example, if one were to want to plot the output of a component running on the Domain:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import redhawk, sb \u0026gt;\u0026gt;\u0026gt; dom=redhawk.attach() \u0026gt;\u0026gt;\u0026gt; for app in dom.apps: ... if app.name == \u0026#34;my_app\u0026#34;: ... break \u0026gt;\u0026gt;\u0026gt; for comp in app.comps: ... if comp.name == \u0026#34;my_comp\u0026#34;: ... break \u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; plot.start() \u0026gt;\u0026gt;\u0026gt; comp.connect(plot) Device Managers The domain proxy provides a list of Device Managers registered with the domain via the devMgrs attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devMgrs [\u0026lt;ossie.utils.redhawk.core.DeviceManager object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] Each Device Manager maintains a list of its devices, accessible via the devs attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devMgrs[0].devs [\u0026lt;ossie.utils.redhawk.device.ExecutableDevice object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] Devices The domain proxy provides a list of all devices registered with the domain via the devices attribute:\n\u0026gt;\u0026gt;\u0026gt; domain.devices [\u0026lt;ossie.utils.redhawk.device.ExecutableDevice object at 0x\u0026lt;hex address\u0026gt;\u0026gt;, ...] The device list is the concatenation of the devices for all Device Managers.\nThe REDHAWK module device class supports the same interfaces as Sandbox devices.\nEvent Channels Event channels can be accessed through the eventChannels member of the domain object. Each of the returned objects contains the name of the channel and a reference to the channel object.\n\u0026gt;\u0026gt;\u0026gt; evt = dom.eventChannels \u0026gt;\u0026gt;\u0026gt; evt[0].name ODM_Channel \u0026gt;\u0026gt;\u0026gt; evt[0].ref \u0026lt;CosEventChannelAdmin._objref_EventChannel object at 0x1608550\u0026gt; Event channels can be created through the Event Channel Manager:\n\u0026gt;\u0026gt;\u0026gt; channel = dom.eventChannelMgr.create(\u0026#34;TestChan\u0026#34;) Subscribers and publishers to event channels can also be created in the Python Sandbox. They can be created as entities in the Python environment, with the constructor argument being the channel that they are to publish or subscribe to.\n\u0026gt;\u0026gt;\u0026gt; from ossie.events import Subscriber, Publisher \u0026gt;\u0026gt;\u0026gt; def my_callback(data): print data \u0026gt;\u0026gt;\u0026gt; sub=Subscriber(evt[0], dataArrivedCB=callback) \u0026gt;\u0026gt;\u0026gt; pub=Publisher(evt[0]) \u0026gt;\u0026gt;\u0026gt; pub.push(data) Managing Allocations The domain has an Allocation Manager that allows the developer to offload some of the bookkeeping tasks associated with capacity allocation. Interactions with the Allocation Manager are exercised through requests and responses. The Allocation Manager responds to requests by searching through all available devices to find Devices that can satisfy the request. An example of interactions with the Allocation Manager follows:\n\u0026gt;\u0026gt;\u0026gt; am = dom.allocationMgr \u0026gt;\u0026gt;\u0026gt; from ossie.utils import allocations \u0026gt;\u0026gt;\u0026gt; prop = allocations.createProps({\u0026#39;s_prop\u0026#39;:{\u0026#39;s_prop::a\u0026#39;:\u0026#39;hello\u0026#39;,\u0026#39;s_prop::b\u0026#39;:5}}) \u0026gt;\u0026gt;\u0026gt; request = am.createRequest(\u0026#39;request id\u0026#39;, prop) \u0026gt;\u0026gt;\u0026gt; response = am.allocate([request]) \u0026gt;\u0026gt;\u0026gt; am.listAllocations(CF.AllocationManager.LOCAL_ALLOCATIONS, 100) [...] \u0026gt;\u0026gt;\u0026gt; am.deallocate([response[0].allocationID]) Managing Connections While it is simple to establish point-to-point connections, sometimes it is desirable for a connection to be established as domain objects come and go. To manage these types of connections, the domain contains a Connection Manager. Helpers have been created to make it easy to create endpoints from Python objects connected to domain objects.\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import rhconnection \u0026gt;\u0026gt;\u0026gt; endpoint_1 = rhconnection.makeEndPoint(dom.apps[0], dom.apps[0].ports[0].name) \u0026gt;\u0026gt;\u0026gt; endpoint_2 = rhconnection.makeEndPoint(dom.apps[1], \u0026#39;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; cm = dom.connectionMgr \u0026gt;\u0026gt;\u0026gt; cm.connect(endpoint_1, endpoint_2) Using the Sandbox As shown briefly in section Applications, Sandbox and domain objects are inter-operable and can be connected together. This allows for inspection of different parts of the domain and more sophisticated testing of components.\nFor example, to use a Sandbox plot to view the data coming from a device, enter the following commands:\n\u0026gt;\u0026gt;\u0026gt; from ossie.utils import sb \u0026gt;\u0026gt;\u0026gt; plot = sb.LinePlot() \u0026gt;\u0026gt;\u0026gt; domain.devices[1].connect(plot) \u0026gt;\u0026gt;\u0026gt; plot.start() Use the following commands to capture an approximately one second cut from a waveform to a file:\n\u0026gt;\u0026gt;\u0026gt; import time \u0026gt;\u0026gt;\u0026gt; sink = sb.FileSink(\u0026#34;/data/tuner_out.dat\u0026#34;) \u0026gt;\u0026gt;\u0026gt; domain.apps[0].connect(sink, usesPortName=\u0026#34;tuner_out\u0026#34;) \u0026gt;\u0026gt;\u0026gt; sink.start() \u0026gt;\u0026gt;\u0026gt; time.sleep(1.0) \u0026gt;\u0026gt;\u0026gt; sink.stop() When the Sandbox exits, any connections made between Sandbox objects and domain objects are broken to limit interference with normal domain operation.\nFor more details on using the Sandbox, refer to Sandbox.\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/logging/",
	"title": "Logging",
	"tags": [],
	"description": "",
	"content": "REDHAWK provides a logging capability for use by all resources components, devices, and services. By default, the REDHAWK Framework and its support libraries have been developed to take advantage of the underlying language’s implementation: log4cxx, log4j, and log4py for C++, Java, and Python, respectively. All three libraries follow the basic premise of the log4j capabilities. A root logger definition is the parent of all loggers and configuration of the loggers is controlled through a Java style properties file. Each REDHAWK resource creates a named logger as a child of the root logger. (The name is based on the underlying resource’s name.) This chapter explains how to configure and use the logging capability. For a detailed description of log4j and its capabilities, refer to the log4j website (http://logging.apache.org/log4j/1.2/).\nAll REDHAWK-generated code for resources provides an instantiation of a logging object for use by the resource. For Java and Python implementations, the underlying logging implementation of the language is used. For C++, there is a set of macro definitions that enable a resource to use the underlying logging implementation associated with the REDHAWK Core Framework (CF) library.\n Logging Structure     Configuring Logger Settings     Adjusting Logging at Runtime     Logging Within A Resource     Viewing Logging Events     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/ide/",
	"title": "Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": "The REDHAWK IDE is a tool that enables developers to create, test, and deploy software for REDHAWK systems. This tool is built on Eclipse, which is a generic, extensible IDE that allows developers to add custom modules. The REDHAWK IDE, therefore, leverages all of the features available in a bare-bones Eclipse IDE while also providing customized features specific to REDHAWK development.\nThe following features are included in the REDHAWK IDE:\n Eclipse - http://eclipse.org/ Eclipse JDT - Java Development Tooling for Eclipse: http://www.eclipse.org/jdt/ Eclipse CDT - C++ Development Tooling for Eclipse. Includes tools for autoconf, rpm spec file editing, and many debugging tools: http://www.eclipse.org/cdt/ Eclipse CORBA - Interface Description Language (IDL) Editor for Eclipse: http://eclipsecorba.sourceforge.net/ PyDev - Python Development Tooling for Eclipse: http://pydev.org/ Eclipse Git - Git Tooling for Eclipse: https://www.eclipse.org/egit/  For signal processing developers, the REDHAWK IDE provides graphical interfaces for the auto-generation of component, device, and service code in C++, Python, and Java. Built on top of the Eclipse JDT, Eclipse PyDev, and Eclipse CDT, the IDE provides feature-rich editors for code written in any of the three languages. In addition, a drag-and-drop environment for testing these modules and constructing them into waveforms and nodes is available.\nFor system developers, the IDE provides an environment for deploying and maintaining applications onto fielded systems. Furthermore, the pluggable nature of Eclipse allows system developers to add customized system user-interface modules.\nThe REDHAWK Explorer is a lighter-weight application that includes a subset of the REDHAWK IDE’s functionality. The REDHAWK Explorer can be used to connect to a running REDHAWK domain, navigate the contents, launch and view waveforms, and so forth. It provides no development functionality, only runtime interaction with REDHAWK domains.\n  Launching the REDHAWK IDE for the First Time     PyDev Overview     The Workbench     Editors and Views    SoftPkg Editor     Waveform Editor     Node Editor     NeXtMidas Plot Editor     REDHAWK Explorer View     REDHAWK Plot View     Plot Settings Dialog     Event Viewer View     Data List and Statistics Views     Port Monitor View     SRI View     Console View     Properties View      Creating REDHAWK Projects     Adding/Changing/Removing REDHAWK Project Namespaces     Debugging REDHAWK Components and Devices with Eclipse     Deploying Projects to the SDRROOT     Snapshot Tool     Connect Wizard     Using the Octave Wizard     Plot Port Wizard     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-sdrroot/",
	"title": "Exploring SDRROOT Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a visualization of the file system contained within the SDRROOT in the REDHAWK Explorer view. The SDRROOT is referred to within the IDE as the Target SDR. The Target SDR location may be changed from within the IDE preferences page.\nTo change the Target SDR:\n Select Window \u0026gt; Preferences Select the REDHAWK \u0026gt; SDR preference page Change the Local SDR Location value Click OK  Browsing Installed SDR Objects From the REDHAWK Explorer view and the Target SDR, one can browse the installed components, devices, nodes, services and waveforms. Each of these REDHAWK Objects are placed in their own folder which may be expanded to show their content. Depending on the object type, different right-click operations and tree structure manipulation are permitted.\nComponents Mouse-hovering over a component within the REDHAWK Explorer view shows the full path to the Software Package Descriptor (SPD) file in the SDRROOT that defines it.\nFrom the REDHAWK Explorer view, you can perform the following actions on components:\n Local Component Launch: To launch an implementation of a component with default property values, right-click the component, select Launch in Sandbox, and select an implementation of the component to start within the Sandbox’s Chalkboard. Alternately, to launch an implementation of a component with customized property values, right-click the component, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Components in the IDE Sandbox.\n View within REDHAWK Editor: To open the component’s XML files in an editor, double-click the component. This opens the REDHAWK Component Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a component from the SDRROOT by right-clicking and selecting Delete. This removes all files pertaining to this component from the SDRROOT including the Software Package Descriptor (SPD), Properties File (PRF), Software Component Descriptor (SCD), and executable files. You can highlight multiple items and delete them at the same time. Deleting an item from the SDRROOT cannot be undone.\n   Devices Mouse-hovering over a device within the REDHAWK Explorer shows the full path to the SPD file in the SDRROOT that defines it.\nFrom the REDHAWK Explorer view, you can perform the following actions on device objects:\n Local Device Launch: Right-click the device, select Launch in Sandbox, and select an implementation of the device to start within the sandbox’s Device Manager. Expand Sandbox \u0026gt; Device Manager to view the running device. Alternately, to launch an implementation of a device with customized property values, right-click the device, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Devices in the IDE Sandbox.\n View within REDHAWK Editor: To open the device’s XML files in an editor, double-click the device. This opens the REDHAWK Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a device from the SDRROOT by right-clicking and selecting Delete. This removes all files pertaining to this device from the SDRROOT including the SPD, PRF, SCD, and executable files. You can highlight multiple items and delete them at the same time. Deleting an item from the SDRROOT cannot be undone.\n   Nodes Mouse-hovering over a node within the REDHAWK Explorer shows the full path to the Device Configuration Descriptor (DCD) file in the SDRROOT that defines it.\nFrom the REDHAWK Explorer view, you can perform the following actions on node objects:\n Launch Device Manager: You may launch a Device Manager onto a running domain for this node. Right-click the node and select Launch Device Manager to bring up a Launch Device Manager dialog. From this dialog, you may select from a list of running domains. Pressing OK in this dialog creates a new Console view and runs an instance of nodeBooter using this node’s DCD file.\n View within REDHAWK Editor: To open the node’s XML files in an editor, double-click the node. This opens the REDHAWK Node Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Expand node: Using the tree structure to expand the node, the IDE decomposes the sections of the DCD file into the referenced devices, Device Manager, Domain Manager, and partitioning sections. By selecting these objects with the Properties view open, all the information from the XML is displayed in tabular format.\n Delete: Delete a node from the SDRROOT by right-clicking and selecting Delete. This removes only the DCD file and the folder containing it from the Software-Defined Radio (SDR) and does not delete the referenced devices. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDRROOT cannot be undone.\n   Services Mouse-hovering over a service within the REDHAWK Explorer shows the full path to the SPD file in the SDRROOT that defines it.\nFrom the REDHAWK Explorer view, you can perform the following actions on service objects:\n Local service Launch: Right-click the service, select Launch in Sandbox, and select an implementation of the service to start within the sandbox’s chalkboard. Alternately, to launch an implementation of a service with customized property values, right-click the service, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Services in the IDE Sandbox.\n View within REDHAWK Editor: To open the SPD file within an editor, double-click the SPD file. This opens the REDHAWK Editor in read-only mode. You cannot edit the fields or perform any code generation from this version of the editor.\n Delete: Delete a service from the SDRROOT by right-clicking and selecting Delete. This removes all files pertaining to this service from the SDRROOT including any SPD, PRF, SCD, and executable files. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDRROOT cannot be undone.\n   Waveforms Mouse-hovering over a waveform within the REDHAWK Explorer shows the full path to the Software Assembly Descriptor (SAD) file in the SDRROOT that defines it.\nYou can perform the following actions from the REDHAWK Explorer view on waveform objects:\n Local waveform Launch: Right-click the waveform, select Launch in Sandbox, and select an implementation of the waveform to start within the sandbox’s chalkboard. Alternately, to launch an implementation of a waveform with customized property values, right-click the waveform, select Launch in Sandbox, and select Advanced. The Launch wizard is displayed. For more information, refer to Launching Waveforms in the IDE Sandbox.\n View within REDHAWK Editor: To open the SAD file within an editor, double-click the SAD file. This opens the Waveform Editor in read-only mode. You cannot edit the fields or add any additional components.\n Expand waveform: Using the tree structure to expand the waveform, the IDE decomposes the sections of the SAD file into the referenced assembly controller, component files, and partitioning sections. By selecting these objects with the Properties view open, all the information from the XML is displayed in a tabular format.\n Delete: Delete a waveform from the SDRROOT by right-clicking and selecting Delete. This removes only the SAD file and the folder containing it from the SDR and does not delete the referenced components. You can highlight multiple items and delete them at the same time.\nDeleting an item from the SDRROOT cannot be undone.\n   Browsing Installed Interface Description Language (IDL) Libraries Even though the IDL Repository is displayed within the Target SDR tree structure, the deployed IDLs and the core IDL library are not stored within the SDRROOT directory on the file system. All IDLs exist within the OSSIEHOME directory. However, the IDL repository is shown here so that one may browse the content and view the installed IDLs.\nExpanding the IDL Repository tree structure exposes the individual IDLs and a list of module folders which contain IDLs. To view the content of an IDL in a text editor, one may either double-click the IDL or right-click and select Text Editor or Open With… \u0026gt; Text Editor.\nOne may also expand an IDL. When an IDL is expanded, the IDE parses its content to decompose it into referenced methods and objects. By selecting these methods and objects with the Properties view open one can view all the information from the IDL in a tabular format.\nGetting Details About Error Conditions If an error condition occurs within the SDRROOT that the IDE can detect, it marks the object in error with a decorator in the lower left corner. Mouse hovering over the item’s icon provides a short description of the issue; however, if more than one problem has occurred the hover text reads “Multiple Problems exist with this item”.\nMore detail about an error can be found within the Properties view of the item. To view the details about an error condition:\n With the item selected, select or open the Properties view. From the Properties view, select the Advanced tab Select the status row. This causes the Details key to appear. Press the Details button to bring up a detailed dialog of the current error conditions  Error Event Details Dialog     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/sharing-projects/",
	"title": "Sharing REDHAWK Projects With Others",
	"tags": [],
	"description": "",
	"content": " The REDHAWK IDE provides a set of tools that allow for the collaborative development of REDHAWK capabilities. Projects can be exported or imported from the IDE or can be shared via a source code version-control system. The base REDHAWK IDE installation includes support for CVS, and Git and can easily be extended to include support for other systems, such as Mercurial.\nREDHAWK Project Metadata Files When sharing projects, it is important to include all of the source code, REDHAWK XML, and project metadata files. The project metadata files contain settings and preferences that allow the REDHAWK IDE to properly generate, build, and analyze the project.\nProject metadata files are typically hidden files (i.e., they start with a ’.’ ) and usually do not appear within the Project Explorer view. Furthermore, many project views also display or hide additional non-file content.\nTo view all of the files using the Navigator view:\n Select Window \u0026gt; Show View \u0026gt; Other….\nThe Show View dialog is displayed:  Show View Dialog    Expand General and select Navigator.\n Click OK.\nThe Navigator view is displayed:  Navigator View     The set of metadata files found in a project varies depending on the type of project. At a minimum, all projects contain a .project file.\nCommon metadata files are:\n .project file - Defines the basic Eclipse project settings .library file - Defines the Interface Description Language (IDL) search path for the project .PROJECTNAME.wavedev file - Defines REDHAWK specific settings for the project related to code generation. .cproject file - Defines settings related to the C/C++ Development Tools .pydevproject file - Defines settings related to the Python Development Tools .classpath file - Defines settings related to the Java Development Tools  When sharing projects, be sure to include all project metadata files. When in doubt, include all files found in the project.\nExporting Projects as Source Code Archives The quickest way to share projects is to export them as an archive file. A single archive may contain one or more projects of varying types. This allows easy distribution of an archive that includes all of the relevant components, libraries, and REDHAWK XML files that another developer would require.\nTo export a project as an archive:\n Select File \u0026gt; Export….\nThe Export Select dialog is displayed:  Export Select Dialog    Expand General and select Archive File\n Click Next.\nThe Export Archive file dialog is displayed:  Export Archive File Dialog    Select the projects or files to include in the archive.\nWhen selecting a project, all files within the project are included in the archive by default. To reduce the set of files being exported, click Filter Types… and select the desired file extensions to be included in the archive.\n  Specify the output file in To archive file.\n Click Finish.\nThe archive file is created.\n  Importing Existing Projects Existing projects can be imported into a REDHAWK IDE workspace.\nTo import existing projects:\n Select File \u0026gt; Import….\nThe Import Select dialog is displayed:  Import Select Dialog    Expand General and select Existing Projects into Workspace.\n Click Next.\nThe Import Projects dialog is displayed:  Import Projects Dialog    Select the location of the projects to import.\n If the existing projects are stored as a file system, select Select root directory, click Browse… and navigate to the directory containing the projects. If the existing projects are stored in an archive file, select Select archive file, click Browse… and navigate to the archive file containing the projects.  Select one or more projects to import.\n Click Finish.\nThe project is imported into the current workspace.\n  A common error is to attempt to import projects by choosing General \u0026gt; Archive File instead of General \u0026gt; Existing Projects into Workspace.\n When importing projects from a directory, you may choose to keep the project’s source code in its original location by deselecting Copy projects into workspace. (This may overwrite existing project files.) It is recommended to copy the project into the workspace whenever possible.\n Importing Incomplete Projects Users may forget to include the hidden files when exporting projects. As long as the Software Package Descriptor (SPD) file and code are included in the archive, the project can be imported into a REDHAWK IDE workspace using the Redhawk Import Wizard. This wizard makes a series of assumptions for the project folder layout and format based on the content of the SPD file and dynamically generates the missing project files.\nTo import incomplete projects:\n Select File \u0026gt; Import….\nThe Import Select dialog is displayed:  Import Select Dialog    Expand REDHAWK Development and select Redhawk Import Wizard.\n Click Next.\nThe Import Projects dialog is displayed:  Import Projects Dialog    Select the location of the projects to import.\n If the existing projects are stored as a file system, select Select root directory, click Browse… and navigate to the directory containing the projects. If the existing projects are stored in an archive file, select Select archive file, click Browse… and navigate to the archive file containing the projects.  Select one or more projects to import.\n Click Finish.\nThe project is imported into the current workspace.\n To create the missing metadata files, open the SPD file and click Generate All Implementations.\n  When importing projects from a directory, you may choose to keep the project’s source code in its original location by deselecting Copy projects into workspace. (This may overwrite existing project files.) It is recommended to copy the project into the workspace whenever possible.\n Collaborative REDHAWK Development Using a Version Control System REDHAWK projects can be shared by multiple developers by using a version-control system such as CVS or Git. When sharing projects via a version-control system, it is important to commit all of the project metadata files.\nAll version-control system integration within the Eclipse IDE is performed by the Team Capabilities. Because the REDHAWK IDE is built upon the Eclipse platform, one can easily install plug-ins that provide support for additional version-control systems. Details for installing these plug-ins can be found on the associated project web pages.\nThe details for sharing and importing projects differs for each type of version-control system. Documentation for most tools can be found on the Internet or through the built-in Eclipse help system.\nTo view full documentation:\n Select Help \u0026gt; Help Contents.\n Choose the appropriate topic:\n Workbench User Guide \u0026gt; Getting Started \u0026gt; Team CVS tutorial. Subversive User Guide. The appropriate topic for the specific tool being used.   To share a project:\n Right-click the project to share and select Team \u0026gt; Share Project….\nThe Share Project dialog is displayed:  Share Project Dialog    Choose the appropriate version-control system (e.g. CVS, Git, etc.)\n Follow the steps for sharing the project as described in the relevant documentation.\n  To import a project:\n Select File \u0026gt; Import. Expand the desired item (e.g. CVS, Git, etc.) and click Next. Follow the steps for importing the project as described in the relevant documentation.  Once a project is being tracked by the Eclipse team system, many additional capabilities are exposed. For example, files that have been modified are decorated to indicate their current status. This provides an “at-a-glance” view of which files need to be committed or reverted.\nOther useful features include:\n Quick review of outgoing changes using the Eclipse “diff” viewer. Commit changes from within the IDE. Update the projects with changes from the source repository. Review the logs and commit history for files in the project. Create and merge branches.  Managing Projects Outside of the Eclipse Workspace An alternate approach is to use the version-control system’s native tools and then import the project directories into the REDHAWK IDE. It is important to ensure that projects DO NOT select Copy projects into workspace when using the method.\nExporting Projects as a Deployable REDHAWK Project To install a REDHAWK project into the Target SDR or share a “ready to run” package, it is necessary to export the project as a Deployable REDHAWK project. Unlike a source code export, a deployable export only includes the REDHAWK XML files and the files identified in the SoftPkg implementation.\nIf the SoftPkg implementation references a directory, the export includes all files within the directory.\n To export a project as a deployable REDHAWK project:\n Select File \u0026gt; Export….\nThe Export Select dialog is displayed:  Export Select Dialog    Expand REDHAWK Development and select Deployable REDHAWK Project.\n Click Next.\nThe Deployable REDHAWK Project dialog is displayed:  Deployable REDHAWK Project Dialog    Select the projects to export.\n Select the export destination.\n To export to a directory, select Directory, click Browse… and navigate to the directory. To export to an archive file, select Archive file, click Browse… and navigate to the archive (zip) file.  Click Finish.\nThe project has been exported as a deployable REDHAWK project.\n  Deployable REDHAWK project archives are intended to provide a stop-gap capability to easily install a project into a REDHAWK Target SDR. In general, it is recommended to use the rpm format instead of a deployable REDHAWK project archive.\n "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/exploring-domain/",
	"title": "Exploring a Running Domain Using the REDHAWK IDE",
	"tags": [],
	"description": "",
	"content": "The Domain Manager contains knowledge of all existing CORBA-enabled objects installed or loaded onto the system. This includes references to all file systems (through the File Manager), Device Managers, and all applications (and their Resources). The Domain Manager is seen as the central bookkeeper. The REDHAWK IDE can be used to run or connect to a running domain, view the contents of a running domain, and launch and interact with applications within the domain.\n Connecting to a Domain     Viewing the Contents of the Domain in the REDHAWK Explorer View     Working with Waveforms on a Running Domain     Plotting BulkIO Ports     Increasing the Bandwidth of BulkIO Connections     Getting Details About Error Conditions     "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/appendices/",
	"title": "Appendices",
	"tags": [],
	"description": "",
	"content": "  REDHAWK Yum Repository and Packages   External Dependencies   Installing a Stand-alone IDE   Building and Installing REDHAWK from Source   Optimization   REDHAWK System Services   FrontEnd Interfaces   REDHAWK Persona Device Pattern   Shared Memory Maintenance   Troubleshooting   Logging Configuration Plugin   List of Acronyms   "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/manual/glossary/",
	"title": "Glossary",
	"tags": [],
	"description": "",
	"content": " Allocation Manager  An implementation of the AllocationManager interface, the Allocation Manager provides a central access point for all allocations performed in the domain.  Application  “Generically, an executable software program which may contain one or more modules. Within Software Communications Architecture (SCA), an application consists of one or more software modules which implement the base Application interfaces and which are identified within a Software Assembly Descriptor file. When loaded and executed, these modules create one or more components which comprise the application. ” Source: SCA v2.2.2.  Application Factory  “An instantiation of the ApplicationFactory interface is used to create an instance of an application. The Domain Manager creates an application factory for each Software Assembly Descriptor that is installed. ” Source: SCA v2.2.2.  Assembly Controller  “The assemblycontroller element of the Software Assembly Descriptor indicates the component that is the main resource controller for an application. ” Source: SCA v2.2.2.  Component  A processing module that implements the CF::Resource interface that is deployable by an Application Factory (refer to SCA v2.2.2 for a description of CF::Resource).  Connection Manager  An implementation of the ConnectionManager interface, the Connection Manager provides a central access point for connections between domain objects.  Console View  Displays a variety of console types depending on the type of development and the current set of user settings. The Console view is a part of Eclipse, and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org/. The REDHAWK IDE uses multiple Console views for different purposes. There are also third party plug-ins within REDHAWK that have their own Console views.  CORBA Name Browser  Maps names to specific CORBA Servants. The CORBA Name Browser can be used to examine the current contents of the Naming Service as well as perform basic manipulation of that context. The contents of the view displays all currently bound name contexts (folders) and objects.  Device  “The SCA defines a Device interface class. This interface is an abstraction of a hardware device that defines the capabilities, attributes, and interfaces for that device.” Source: SCA v2.2.2. In the context of REDHAWK, a device is is a software module that implements the Device interface class.  Device Manager  An implementation of the DeviceManager interface. The Device Manager is responsible for the creation of devices and services.  Domain  “A Domain defines a set of hardware devices and available applications under the control of a single Domain Manager.” Source: SCA v2.2.2.  Domain Manager  “An implementation of the DomainManager interface, a Domain Manager manages the complete set of available hardware devices and applications. It is responsible for the set-up and shut-down of applications and for allocating resources, devices, and non-CORBA components to hardware devices.” Source: SCA v2.2.2.  Error Log View  An Eclipse view that provides details of errors that have occurred with the running application.  Event Channel  A software object that mediates the transfer of CORBA events between producers and consumers.  Event Channel Manager  An implementation of the EventChannelManager interface, the Event Channel Manager provides a central access point for the management of event channels in the domain.  Event Service  Software that provides and manages event channels.  File Manager  An implementation of the FileManager interface, the File Manager provides a central access point for all of the file systems available in the domain.  GPP  General Purpose Processor Device that manages a computing node.  Hardware-Accelerated Component  A REDHAWK component that has the ability to access/maintain a designated portion of programmed hardware (for example, a single modem in a multi-modem load).  Message  Key/value pairs contained in a single instance of the CORBA::Any type and passed over the CORBA event API.  Naming Service  Software that provides a mapping between human-readable names of CORBA objects and the CORBA objects themselves.  NIC  The network interface card, usually interfacing with Ethernet.  Node  A single Device Manager, its associated devices, and its associated services.  Node Editor  The Node Editor is opened by double-clicking a Device Configuration Descriptor (DCD) file from the Project Explorer view. It presents all the content that can be found within the dcd.xml file in an editing environment designed for human use. The Node Editor contains an Overview, Devices, Diagram, and raw XML tab, which contains the DCD file content.  NUMA  Non-Uniform Memory Access.  Outline View  Displays an outline of a structured file that is currently open in the editor area. The Outline view is a part of Eclipse, and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org.  Persona  The load or programming files used to load functionality onto programmable hardware (for example, bit files).  Persona Device  A REDHAWK device that encapsulates a single load for specific programmable hardware and any corresponding ports/properties (defined in the REDHAWK XML descriptor files).  Perspective  Each workbench window contains one or more perspectives. A perspective defines the initial set and layout of views in the Workbench window. Within the window, each perspective shares the same set of editors. Each perspective provides a set of functionality aimed at accomplishing a specific type of task or works with specific types of resources. For example, the Java perspective combines views that you would commonly use while editing Java source files, while the Debug perspective contains the views that you would use while debugging Java programs. As you work in the workbench, you will probably switch perspectives frequently. Perspectives control what appears in certain menus and toolbars. They define visible action sets, which you can change to customize a perspective. You can save a perspective that you build in this manner, making your own custom perspective that you can open again later. Source: http://help.eclipse.org.  Port  A CORBA object that produces or consumes data and/or commands. A port is referred to as “uses” when it is a source/producer/output, and as a “provides” when it is a sink/consumer/input. A uses port implements the CF::Port interface (see SCA v2.2.2 for a description of CF::Port).  Problems View  As you work with resources in the workbench, various builders may automatically log problems, errors, or warnings in the Problems view. The Problems view is a part of Eclipse, and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org.  Programmable Device  A REDHAWK device that is the main proxy into physical hardware. It maintains which Persona (child) device should be loaded onto the hardware.  Programmable Hardware  Hardware that may be dynamically programmed to operate with specific functionality (such as FPGAs and some microprocessors).  Project Explorer View  Provides a hierarchical view of the resources in the workbench. The Project Explorer view is a part of Eclipse, and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org.  Properties View  Displays property names and basic properties of a selected resource. The Properties view is a part of Eclipse, and the basic use is well documented by the Eclipse documentation: http://help.eclipse.org.  Property  An SCA Property is a variable that contains a value of a specific type. Configuration Properties are parameters to the configure and query operations of the PropertySet interface. Allocation Properties define the capabilities required of a Device by a Resource.” Source: SCA v2.2.2.  PyDev  PyDev is a third-party plug-in for Eclipse. It is an IDE used for programming in Python supporting code refactoring, graphical debugging, code analysis and many other features.  REDHAWK Explorer  The REDHAWK Explorer, an application built on the REDHAWK Core Framework, is used to navigate the contents of a REDHAWK domain. It provides capabilities for viewing the contents of the domain, configuring domain resources, and launching domain waveforms.  REDHAWK Explorer View  Allows a user to navigate the contents of a REDHAWK domain. It provides capabilities for viewing the contents of the domain, configuring instantiated resources, and launching applications in a target Software-Defined Radio (SDR) environment. It also provides access to the Sandbox, which is an environment for running components and applications without a Domain Manager and Device Manager.  Sandbox  A Python environment that can be used to easily run and interact with components without creating a waveform or running a Domain Manager.  SCA Waveform  Deprecated. Refer to Waveform.  Service  Software made available by the Device Manager at the Device Manager startup.  SoftPkg Editor  The SoftPkg Editor is opened by double-clicking a Software Package Descriptor (SPD) file from the Project Explorer view. It presents all the content that can be found within the spd.xml file in an editing environment designed for human use. If the SPD file references a Properties File (PRF) or Software Component Descriptor (SCD) file, additional tabs are made available that represent these files in similar fashion.  Target SDR  The Target SDR refers to the REDHAWK resources that your workspace will be built and run against. It describes the platform for which you are developing. By default, it points to the file location specified by the environment variable SDRROOT.  usesdevice relationship  A logical association between a component and a specific device that provides some capacity to that component.  View  A view is a workbench part that can navigate a hierarchy of information or display properties for an object. Only one instance of any given view is open in a workbench page. When the user makes selections or other changes in a view, those changes are immediately reflected in the workbench. Views are often provided to support a corresponding editor. For example, an outline view shows a structured view of the information in an editor. A properties view shows the properties of an object that is currently being edited. Source: http://help.eclipse.org.  Waveform  A REDHAWK waveform is analogous to an SCA Waveform Application. A REDHAWK waveform is defined as a composition of components, their interconnections, and their configuration overrides. This composition is defined in a Software Assembly Descriptor file.  Waveform Editor  The Waveform Editor is opened by double-clicking a Software Assembly Descriptor (SAD) file from the Project Explorer view. It presents all the content that can be found within the sad.xml file in an editing environment designed for human use. The Waveform Editor contains an Overview, Diagram, and raw XML tab, which contains the SAD file content.  Workbench  The term workbench refers to the desktop development environment. The workbench aims to achieve seamless tool integration and controlled openness by providing a common paradigm for the creation, management, and navigation of workspace resources. Source: http://help.eclipse.org/.  Workspace  In Eclipse, a workspace is a logical collection of projects on which you are actively working. Source: http://help.eclipse.org.  "
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/_header/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "REDHAWK\n"
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/tags/sandbox/",
	"title": "Sandbox",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://redhawksdr.github.io/2.2.3/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]